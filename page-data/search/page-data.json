{"componentChunkName":"component---src-pages-search-tsx","path":"/search/","result":{"data":{"allMarkdownRemark":{"edges":[{"node":{"rawMarkdownBody":"\r\n불변 클래스란 간단히 말해 그 인스턴스의 내부 값을 수정할 수 없는 클래스다.  \r\n불변 인스턴스에 간직된 정보는 고정되어 객체가 파괴되는 순간까지 절대 달라지지 않는다.\r\n\r\n자바 플랫폼 라이브러리에도 다양한 불변 클래스가 있다.  \r\nString, 기본 타입의 박싱된 클래스들, BigInteger, BigDecimal이 여기 속한다.\r\n\r\n불변 클래스는 가변 클래스보다 설계하고 구현하고 사용하기 쉬우며, 오류가 생길 여지도 적고 훨씬 안전하다.  \r\n클래스를 불변으로 만들려면 다음 다섯 가지 규칙을 따르면 된다.\r\n\r\n- 객체의 상태를 변경하는 메서드(변경자)를 제공하지 않는다.\r\n- 클래스를 확장할 수 없도록 한다.\r\n- 모든 필드를 final로 선언한다.\r\n- 모든 필드는 private으로 선언한다.\r\n- 자신 외에는 내부의 가변 컴포넌트에 접근할 수 없도록 한다.\r\n\r\n```java\r\npublic final class Complex {\r\n    private final double re;\r\n    private final double im;\r\n\r\n    public static final Complex ZERO = new Complex(0, 0);\r\n    public static final Complex ONE  = new Complex(1, 0);\r\n    public static final Complex I    = new Complex(0, 1);\r\n\r\n    public Complex(double re, double im) {\r\n        this.re = re;\r\n        this.im = im;\r\n    }\r\n\r\n    public double realPart()      { return re; }\r\n    public double imaginaryPart() { return im; }\r\n\r\n    public Complex plus(Complex c) {\r\n        return new Complex(re + c.re, im + c.im);\r\n    }\r\n\r\n    public Complex minus(Complex c) {\r\n        return new Complex(re - c.re, im - c.im);\r\n    }\r\n\r\n    public Complex times(Complex c) {\r\n        return new Complex(re * c.re - im * c.im,\r\n                re * c.im + im * c.re);\r\n    }\r\n\r\n    public Complex dividedBy(Complex c) {\r\n        double tmp = c.re * c.re + c.im * c.im;\r\n        return new Complex((re * c.re + im * c.im) / tmp,\r\n                (im * c.re - re * c.im) / tmp);\r\n    }\r\n\r\n    @Override public boolean equals(Object o) {\r\n        if (o == this)\r\n            return true;\r\n        if (!(o instanceof Complex))\r\n            return false;\r\n        Complex c = (Complex) o;\r\n\r\n        // == 대신 compare를 사용하는 이유는 63쪽을 확인하라.\r\n        return Double.compare(c.re, re) == 0\r\n                && Double.compare(c.im, im) == 0;\r\n    }\r\n    @Override public int hashCode() {\r\n        return 31 * Double.hashCode(re) + Double.hashCode(im);\r\n    }\r\n\r\n    @Override public String toString() {\r\n        return \"(\" + re + \" + \" + im + \"i)\";\r\n    }\r\n}\r\n```\r\n이 사칙연산 메서드들이 인스턴스 자신은 수정하지 않고 새로운 Complex 인스턴스를 만들어 반환하는 모습에 주목하자.  \r\n이처럼 피연산자에 함수를 적용해 그 결과를 반환하지만, 피연산자 자체는 그대로인 프로그래밍 패턴을 함수형 프로그래밍이라 한다.\r\n\r\n이와 달리, 절차적 혹은 명령형 프로그래밍에서는 메서드에서 피연산자인 자신을 수정해 자신의 상태가 변하게 된다.\r\n\r\n함수형 프로그래밍에 익숙하지 않다면 조금 부자연스러워 보일 수도 있지만, 이 방식으로 프로그래밍하면 코드에서 불변이 되는 영역의 비율이 높아지는 장점을 누릴 수 있다.  \r\n불변 객체는 단순하다. 불변 객체는 생성된 시점의 상태를 파괴될 때까지 그대로 간직한다.\r\n\r\n모든 생성자가 클래스 불변식(class invariant)을 보장한다면 그 클래스를 사용하는 프로그래머가 다른 노력을 들이지 않더라도 영원히 불변으로 남는다.  \r\n반면 가변 객체는 임의의 복잡한 상태에 놓일 수 있다. 변경자 메서드가 일으키는 상태 전이를 정밀하게 문서로 남겨놓지 않은 가변 클래스는 믿고 사용하기 어려울 수도 있다.\r\n\r\n<br/>\r\n\r\n## 불변 객체 장점\r\n\r\n불변 객체는 근본적으로 스레드 안전하여 따로 동기화할 필요 없다.  \r\n불변 객체에 대해서는 그 어떤 스레드도 다른 스레드에 영향을 줄 수 없으니 불변 객체는 안심하고 공유할 수 있다.  \r\n따라서 불변 클래스라면 한번 만든 인스턴스를 최대한 재활용하기를 권한다.\r\n가장 쉬운 재활용 방법은 자주 쓰이는 값들을 상수(public static final)로 제공하는 것이다.\r\n\r\n불변 클래스는 자주 사용되는 인스턴스를 캐싱하여 같은 인스턴스를 중복 생성하지 않게 해주는 정적 팩터리를 제공할 수 있다. 박싱된 기본 타입 클래스 전부와 BigInteger가 여기 속한다.  \r\n이런 정적 팩터리를 사용하면 여러 클라이언트가 인스턴스를 공유하여 메모리 사용량과 가비지 컬렉션 비용이 줄어든다.  \r\n새로운 클래스를 설계할 때 public 생성자 대신 정적 팩터리르 만들어두면, 클라이언트를 수정하지 않고도 필요에 따라 캐시 기능을 덧붙일 수 있다.\r\n\r\n불변 객체를 자유롭게 공유할 수 있다는 점은 방어적 복사도 필요 없다는 결론으로 자연스럽게 이어진다.\r\n아무리 복사해봐야 원본과 똑같으니 복사 자체가 의미 없다. 그러니 불변 클래스는 clone 메서드나 복사 생성자를 제공하지 않는 게 좋다.\r\n\r\n불변 객체는 자유롭게 공유할 수 있음은 물론, 불변 객체끼리는 내부 데이터를 공유할 수 있다.  \r\nex) BigInteger 클래스 내부에는 부호인 int 변수, 크기인 int 배열이 있다. negate 메서드는 크기가 같고 부호만 반대인 새로운 BigInteger를 생성하는데, \r\n이때 배열은 비록 가변이지만 복사하지 않고 원본 인스턴스와 공유해도 된다. 그 결과 새로 만든 BigInteger 인스턴스도 원본 인스턴스가 가리키는 내부 배열을 그대로 가리킨다.\r\n\r\n객체를 만들 때 다른 불변 객체들을 구성요소로 사용하면 이점이 많다.\r\n값이 바꾸지 않는 구성요소들로 이뤄진 객체라면 그 구조가 아무리 복잡하더라도 불변식을 유지하기 훨씬 수월하기 때문이다.\r\n\r\n불변 객체는 그 자체로 실패 원자성을 제공한다.\r\n\r\n<br/>\r\n\r\n## 불변 객체 단점\r\n\r\n불변 클래스에도 단점은 있다. 값이 다르면 반드시 독립된 객체로 만들어야 한다는 것이다.  \r\n값의 가짓수가 많다면 이들을 모두 만드는 데 큰 비용을 처리해야 한다.  \r\n원하는 객체를 완성하기까지의 단계가 많고, 그 중간 단계에서 만들어진 객체들이 모두 버려진다면 성능 문제가 더 불거진다.  \r\n이 문제에 대처하는 방법은 두 가지다.\r\n\r\n흔히 쓰일 다단계 연산들을 예측하여 기본 기능으로 제공하는 방법.\r\n- 다단계 연산을 기본으로 제공한다면 더 이상 각 단계마다 객체를 생성하지 않아도 된다.  \r\n   - ex) BigInteger는 모듈러 지수 같은 다단계 연산 속도를 높여주는 가변 동반 클래스를 package-private으로 두고 있다.\r\n  \r\n클라이언트들이 원하는 복잡한 연산들을 정확히 예측할 수 있다면 package-private의 가변 동반 클래스만으로 충분하다. 그렇지 않다면 이 클래스를 public으로 제공하는게 최선이다.\r\n    ex) String 클래스. String의 가변 동반 클래스는 StringBuilder(와 StringBuffer)\r\n\r\n<br/>\r\n\r\n## 불변 클래스를 만드는 또 다른 설계 방법\r\n\r\n클래스가 불변임을 보장하려면 자신을 상속하지 못하게 해야 함.  \r\n자신을 상속하지 못하게 하는 가장 쉬운 방법은 final 클래스로 선언하는 것이지만, 더 유연한 방법이 있다.  \r\n모든 생성자를 private 혹은 package-private으로 만들고 public 정적 팩터리를 제공하는 방법이다.\r\n  \r\n```java\r\npublic class Complex {\r\n    private final double re;\r\n    private final double im;\r\n\r\n    private Complex(double re, double im) {\r\n        this.re = re;\r\n        this.im = im;\r\n    }\r\n\r\n    // 코드 17-2 정적 팩터리(private 생성자와 함께 사용해야 한다.) (110-111쪽)\r\n    public static Complex valueOf(double re, double im) {\r\n        return new Complex(re, im);\r\n    }\r\n}\r\n```\r\n외부에서 볼 수 없는 package-private 구현 클래스를 원하는 만큼 만들어 활용할 수 있으니 이 방식이 훨씬 유연하다.  \r\n패키지 바깥의 클라이언트에서 바라본 이 불변 객체는 사실상 final이다.  \r\npublic이나 protected 생성자가 없으니 다른 패키지에서는 이 클래스를 확장하는 게 불가능하기 때문이다.  \r\n정적 팩터리 방식은 다수의 구현 클래스를 활용한 유연성을 제공하고, 이에 더해 다음 릴리스에서 객체 캐싱 기능을 추가해 성능을 끌어올릴 수도 있다.\r\n\r\n불변 클래스의 규칙 목록에 따르면 모든 필드가 final이고 어떤 메서드도 그 객체를 수정할 수 없어야 한다.\r\n사실 이 규칙은 조금 과한 감이 있어서, 성능을 위해 다음처럼 살짝 완화할 수 있다.  \r\n\"어떤 메서드도 객체의 상태 중 외부에 비치는 값을 변경할 수 없다\"  \r\n어떤 불변 클래스는 계산 비용이 큰 값을 나중에 계산하여 final이 아닌 필드에 캐시해놓기도 한다.\r\n\r\n<br/>\r\n\r\n## 정리\r\n- getter가 있다고 해서 무조건 setter를 만들지는 말자.  \r\n    - 클래스는 꼭 필요한 경우가 아니라면 불변이어야 한다.  \r\n    - 불변 클래스는 장점이 많으며, 단점이라곤 특정 상황에서의 잠재적 성능 저하뿐이다.\r\n\r\n- PhoneNumber와 Complex 같은 단순한 값 객체는 항상 불변으로 만들자.  \r\n    - String과 BigInteger처럼 무거운 값 객체도 불변으로 만들 수 있는지 고심해야 한다.  \r\n    - 성능 때문에 어쩔 수 없다면 불변 클래스와 쌍을 이루는 가변 동반 클래스를 public 클래스로 제공하도록 하자.\r\n\r\n- 불변으로 만들 수 없는 클래스라도 변경할 수 있는 부분을 최소한으로 줄이자.  \r\n    - 다른 합당한 이유가 없다면 모든 필드는 private final이어야 한다.\r\n\r\n- 생성자는 불변식 설정이 모두 완료된, 초기화가 완벽히 끝난 상태의 객체를 생성해야 한다.  \r\n    - 이유가 없다면 생성자와 정적 팩터리 외에는 그 어떤 초기화 메서드도 public으로 제공해서는 안 된다.  \r\n    - 객체를 재활용할 목적으로 상태를 다시 초기화하는 메서드도 안 된다. 복잡성만 커지고 성능 이점은 거의 없다.","excerpt":"불변 클래스란 간단히 말해 그 인스턴스의 내부 값을 수정할 수 없는 클래스다. 불변 인스턴스에 간직된 정보는 고정되어 객체가 파괴되는 순간까지 절대 달라지지 않는다. 자바 플랫폼 라이브러리에도 다양한 불변 클래스가 있다. String, 기본 타입의 …","fields":{"slug":"/effective-java-item17/"},"frontmatter":{"date":"Dec 30, 2021","title":"[이펙티브 자바] 17. 변경 가능성을 최소화하라","tags":["java","book"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n이따금 인스턴스 필드들을 모아놓는 일 외에는 아무 목적도 없는 퇴보한 클래스를 작성하려 할 때가 있다.\r\n```java\r\nclsaa Point {\r\n    public double x;\r\n    public double y;\r\n}\r\n```\r\n이런 클래스는 데이터 필드에 접근할 수 있으니 캡슐화의 이점을 제공하지 못한다.  \r\nAPI를 수정하지 않고는 내부 표현을 바꿀 수 없고, 불변식을 보장할 수 없으며, 외부에서 필드에 접근할 때 부수 작업을 수행할 수도 없다.\r\n\r\n철저한 객체 지향 프로그래머는 이런 클래스를 상당히 싫어해서 필드들을 모두 private으로 바꾸고 public 접근자(getter)를 추가한다.\r\n\r\n```java\r\nclass Point {\r\n    private double x;\r\n    private double y;\r\n\r\n    public Point(double x, double y) {\r\n        this.x = x;\r\n        this.y = y;\r\n    }\r\n\r\n    public double getX() { return x; }\r\n    public double getY() { return y; }\r\n\r\n    public void setX(double x) { this.x = x; }\r\n    public void setY(double y) { this.y = y; }\r\n}\r\n```\r\n패키지 바깥에서 접근할 수 있는 클래스라면 접근자를 제공함으로써 클래스 내부 표현 방식을\r\n언제든 바꿀 수 있는 유연성을 얻을 수 있다.   \r\npublic 클래스가 필드를 공개하면 이를 사용하는 클라이언트가 생겨날 것이므로 내부 표현 방식을 마음대로 바꿀 수 없게 된다.\r\n\r\npackage-private 클래스 혹은 private 중첩 클래스라면 데이터 필드를 노출한다 해도 하등의 문제가 없다.  \r\n이 방식은 클래스 선언 면에서나 이를 사용하는 클라이언트 코드 면에서나 접근자 방식보다 훨씬 깔끔하다.  \r\n클라이언트 코드가 이 클래스 내부 표현에 묶이기는 하나, 클라이언트도 어차피 이 클래스를 포함하는 패키지 안에서만 동작하는 코드일 뿐이다.  \r\n따라서 패키지 바깥 코드는 전혀 손대지 않고도 데이터 표현 방식을 바꿀 수 있다. private 중첩 클래스의 경우라면 수정 범위가 더 좁아져서 이 클래스를 포함하는 외부 클래스까지로 제한된다.\r\n\r\n자바 플랫폼 라이브러리에도 public 클래스의 필드를 직접 노출하지 말라는 규칙을 어기는 사례가 종종 있다.  \r\n대표적인 예가 java.awt.package 패키지의 Point와 Dimension.\r\n![image](https://user-images.githubusercontent.com/62014888/147674418-ac0afcf9-d042-4619-ae3c-90d552f4b325.png)\r\n![image](https://user-images.githubusercontent.com/62014888/147674508-3f1377df-6032-4725-8ab6-f94fba67322c.png)\r\n- 내부를 노출한 Dimension 클래스의 심각한 성능 문제는 오늘날까지도 해결되지 못했다.\r\n\r\n```java\r\npublic final class Time {\r\n    private static final int HOURS_PER_DAY    = 24;\r\n    private static final int MINUTES_PER_HOUR = 60;\r\n\r\n    public final int hour;\r\n    public final int minute;\r\n\r\n    public Time(int hour, int minute) {\r\n        if (hour < 0 || hour >= HOURS_PER_DAY)\r\n            throw new IllegalArgumentException(\"Hour: \" + hour);\r\n        if (minute < 0 || minute >= MINUTES_PER_HOUR)\r\n            throw new IllegalArgumentException(\"Min: \" + minute);\r\n        this.hour = hour;\r\n        this.minute = minute;\r\n    }\r\n\r\n    // 나머지 코드 생략\r\n}\r\n```\r\npublic 클래스의 필드가 불변이라면 직접 노출할 때의 단점이 조금은 줄어들지만, 여전히 결코 좋은 생각이 아니다.  \r\nAPI를 변경하지 않고는 표현 방식을 바꿀 수 없고, 필드를 읽을 때 부수 작업을 수행할 수 없단느 단점은 여전하다.\r\n단, 불변식은 보장할 수 있게 된다.\r\n\r\n## 핵심 정리\r\n- public 클래스는 절대 가변 필드를 직접 노출해서는 안 된다.\r\n    - 불변 필드라면 노출해도 덜 위험하지만 완전히 안심할 수는 없다.\r\n    - 하지만 package-private 클래스나 private 중첩 클래스에서는 종종 (불변이든 가변이든) 필드를 노출하는 편이 나을 때도 있다.","excerpt":"이따금 인스턴스 필드들을 모아놓는 일 외에는 아무 목적도 없는 퇴보한 클래스를 작성하려 할 때가 있다. 이런 클래스는 데이터 필드에 접근할 수 있으니 캡슐화의 이점을 제공하지 못한다. API를 수정하지 않고는 내부 표현을 바꿀 수 없고, 불변식을 보…","fields":{"slug":"/effective-java-item16/"},"frontmatter":{"date":"Dec 28, 2021","title":"[이펙티브 자바] 16. public 클래스에서는 public 필드가 아닌 접근자 메서드를 사용하라","tags":["java","book"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"잘 설계된 컴포넌트는 모든 내부 구현을 완벽히 숨겨, 구현과 API를 깔끔히 분리한다.  \r\n오직 API를 통해서만 다른 컴포넌트와 소통하며 서로의 내부 동작 방식에는 전혀 개의치 않는다.\r\n- 정보 은닉, 혹은 캡슐화라고 하는 이 개념은 소프트웨어 설계의 근간이 되는 원리다.\r\n\r\n## 정보 은닉의 장점\r\n- 시스템 개발 속도를 높인다. 여러 컴포넌트를 병렬로 개발할 수 있기 때문이다.\r\n- 시스템 관리 비용을 낮춘다. 각 컴포넌트를 더 빨리 파악하여 디버깅할 수 있고, 다른 컴포넌트로 교체하는 부담도 적기 때문이다.\r\n- 정보 은닉 자체가 성능을 높여주지는 않지만, 성능 최적화에 도움을 준다. 완성된 시스템을 프로파일링해 최적화할 컴포넌트를 정한 다음\r\n다른 컴포넌트에 영향을 주지 않고 해당 컴포넌트만 최적화할 수 있기 때문.\r\n  \r\n- 소프트웨어 재사용성을 높인다. 외부에 거의 의존하지 않고 독자적으로 동작할 수 있는 컴포넌트라면\r\n그 컴포넌트와 함께 개발되지 않는 낯선 환경에서도 유용하게 쓰일 가능성이 크기 때문.\r\n  \r\n- 큰 시스템을 제작하는 난이도를 낮춰준다. 시스템 전체가 아직 완성되지 않은 상태에서도 개별 컴포넌트의 동작을 검증할 수 있기 때문.\r\n\r\n<br/>\r\n\r\n## 자바에서의 정보 은닉\r\n\r\n자바는 정보 은닉을 위한 다양한 장치를 제공하는데 그중 접근 제어 메커니즘은 클래스, 인터페이스, 멤버의 접근성(접근 허용 범위)을 명시한다.  \r\n각 요소의 접근성은 그 요소가 선언된 위치와 접근 제한자로 정해지는데 이를 제대로 활용하는 것이 정보 은닉의 핵심.\r\n\r\n기본 원칙은 모든 클래스와 멤버의 접근성을 가능한 한 좁혀야 한다.  \r\n즉, 소프트웨어가 올바로 동작하는 한 항상 가장 낮은 접근 수준을 부여해야 한다.\r\n\r\n톱레벨 클래스와 인터페이스 부여할 수 있는 접근 수준은 package-private(default)과 public 두 가지다.  \r\npublic으로 선언하면 공개 API가 되며, package-private으로 선언하면 해당 패키지 안에서만 이용할 수 있다.  \r\n패키지 외부에서 쓸 이유가 없다면 package-private으로 선언하자. 그러면 API가 아닌 내부 구현이 되어 언제든 수정할 수 있다.  \r\n즉, 클라이언트에 아무런 피해 없이 다음 릴리스에서 수정, 교체, 제거할 수 있다.  \r\n반면, public으로 선언한다면 API가 되므로 하위 호환을 위해 영원히 관리해줘야만 한다.\r\n\r\n한 클래스에서만 사용하는 package-private 톱레벨 클래스나 인터페이스는 이를 사용하는 클래스 안에 private static으로 중첩시켜보자.  \r\n톱레벨로 두면 같은 패키지의 모든 클래스가 접근할 수 있지만, private static으로 중첩시키면 바깥 클래스 하나에서만 접근할 수 있다.  \r\n물론 이보다 더 중요한 일은 public일 필요가 없는 클래스의 접근 수준을 package-private 톱레벨 클래스로 좁히는 일이다.\r\n\r\n<br/>\r\n\r\n## 접근 수준 네 가지\r\n\r\n멤버(필드, 메서드, 중첩 클래스, 중첩 인터페이스)에 부여할 수 있는 접근 수준은 네 가지다.\r\n- private: 멤버를 선언한 톱레벨 클래스에서만 접근할 수 있다.\r\n- package-private: 멤버가 소속된 패키지 안의 모든 클래스에서 접근할 수 있다. 접근 제한자를 명시하지 않았을 때 적용되는 패키지 접근 수준. (단, 인터페이스의 멤버는 기본적으로 public이 적용된다.)\r\n- protected: package-private의 접근 범위를 포함하며, 이 멤버를 선언한 클래스의 하위 클래스에서도 접근할 수 있다. (제약이 조금 따른다.)\r\n- public: 모든 곳에서 접근할 수 있다.\r\n\r\n클래스의 공개 API를 세심히 설계한 후, 그 외의 모든 멤버는 private으로 만들자.  \r\n그런 다음 오직 같은 패키지의 다른 클래스가 접근해야 하는 멤버에 한하여 (private 제한자를 제거해) package-private으로 풀어주자.  \r\n권한을 풀어주는 일을 자주 하게 된다면 여러분 시스템에서 컴포넌트를 더 분해해야 하는 것은 아닌지 다시 고민해보자.  \r\nprivate과 package-private 멤버는 모두 해당 클래스의 구현에 해당하므로 보통은 공개 API에 영향을 주지 않는다.\r\n단, Serializable을 구현한 클래스에서는 그 필드들도 의도치 않게 공개 API가 될 수도 있다.\r\n\r\npublic 클래스에서는 멤버의 접근 수준을 package-private에서 protected로 바꾸는 순간 그 멤버에 접근할 수 있는 대상 범위가 엄청나게 넓어진다.  \r\npublic 클래스의 protected 멤버는 공개 API이므로 영원히 지원돼야 한다. 또한 내부 동작 방식을 API 문서에 적어 사용자에게 공개해야 할 수도 있다.\r\n따라서 protected 멤버의 수는 적을수록 좋다.\r\n\r\n멤버 접근성을 좁히지 못하게 방해하는 제약이 하나 있다.\r\n- 상위 클래스의 메서드를 재정의할 때는 그 접근 수준을 상위 클래에서보다 좁게 설정할 수 없다는 것.\r\n\r\n이 제약은 상위 클래스의 인스턴스는 하위 클래스의 인스턴스로 대체해 사용할 수 있어야 한다는 규칙(리스코프 치환 원칙)을 지키기 위해 필요하다.\r\n이 규칙을 어기면 하위 클래스를 컴파일할 때 컴파일 오류가 난다.\r\n\r\n<br/>\r\n\r\n## 테스트에서 접근 범위\r\n\r\n테스트 목적으로 클래스, 인터페이스, 멤버의 접근 범위를 넓히려 할 때가 있다.\r\n적당한 수준까지도 넓혀도 괜찮다.  \r\n예를 들어, public 클래스의 private 멤버를 package-private까지 풀어주는 것은 허용할 수 있지만, 그 이상은 안 된다.\r\n\r\n즉, 테스트만을 위해 클래스, 인터페이스, 멤버를 공개 API로 만들어서는 안 된다.\r\n\r\n<br/>\r\n\r\n## public 클래스의 public 필드\r\n\r\npublic 클래스의 인스턴스 필드는 되도록 public이 아니어야 한다.  \r\n필드가 가변 객체를 참조하거나, final이 아닌 인스턴스 필드를 public으로 선언하면 그 필드에 담을 수 있는 값을 제한할 힘을 잃게 된다. \r\n그 필드와 관련된 모든 것은 불변식을 보장할 수 없게 된다는 뜻이다.  \r\n여기에 더해, 필드가 수정될 때 (락 획득 같은) 다른 작업을 할 수 없게 되므로 public 가변 필드를 갖는 클래스는 일반적으로 스레드 안전하지 않다.\r\n\r\n정적 필드에서도 마찬가지이나, 상수라면 public static final 필드로 공개해도 좋다.  \r\n관례상 이런 상수의 이름은 대문자 알파벳으로 쓰며, 각 단어 사이에 밑줄(_)을 넣는다.  \r\n이런 필드는 반드시 기본 타입 값이나 불변 객체를 잠조해야 한다. 가변 객체를 참조한다면 final이 아닌 필드에 적용되는 모든 불이익이 그대로 적용된다.\r\n\r\n길이가 0이 아닌 배열은 모두 변경 가능하니 주의하자.  \r\n따라서 클래스에서 public static final 배열 필드를 두거나 이 필드를 반환하는 접근자 메서드를 제공해서는 안 된다.\r\n```java\r\n// 보안 허점이 숨어 있다.\r\npublic static final Thing[] VALUES = {...};\r\n```\r\n이런 필드나 접근자를 제공한다면 클라이언트에서 그 배열의 내용을 수정할 수 있게 된다.\r\n\r\n해결책은 두 가지다.\r\n```java\r\nprivate static final Thing[] PRIVATE_VALUES = {...};\r\npublic static final List<Thing> VALUES = \r\n    Collections.unmodifiableList(Arrays.asList(PRIVATE_VALUES));\r\n```\r\n첫 번째 방법은 public 배열을 private으로 만들고 public 불변 리스트를 추가하는 것.\r\n\r\n```java\r\nprivate static final Thing[] PRIVATE_VALUES = {...};\r\npublic static final Thing[] values() {\r\n    return PRIVATE_VALUES.clone();\r\n}\r\n```\r\n두 번째는 배열을 private으로 만들고 그 복사본을 반환하는 public 메서드를 추가하는 방법(방어적 복사).\r\n\r\n<br/>\r\n\r\n## 모듈 시스템에서의 두 가지 암묵적 접근 수준\r\n\r\n자바 9에서는 모듈 시스템이라는 개념이 도입되면서 두 가지 암묵적 접근 수준이 추가되었다.\r\n\r\n패키지가 클래스들의 묶음이듯, 모듈은 패키지들의 묶음이다.  \r\n모듈은 자신에 속하는 패키지 중 공개(export)할 것들을 (관례상 module-info.java 파일에) 선언한다.  \r\nprotected 혹은 public 멤버라도 해당 패키지를 공개하지 않았다면 모듈 외부에서는 접근할 수 없다.\r\n\r\n모듈 시스템을 활용하면 클래스를 외부에 공개하지 않으면서도 같은 모듈을 이루는 패키지에서는 자유롭게 공유할 수 있다.\r\n\r\n두 가지 암묵적 접근 수준은 이 숨겨진 패키지 안에 있는 public 클래스의 public 혹은 protected 멤버와 관련이 있음.\r\n암묵적 접근 수준들은 각각 public 수준과 protected 수준과 같으나, 그 효과가 모듈 내부로 한정되는 변종인 것.\r\n\r\n모듈에 적용되는 새로운 두 접근 수준은 상당히 주의해서 사용해야 한다.  \r\n모듈의 JAR 파일을 자신의 모듈 경로가 아닌 애플리케이션의 클래스패스(classpath)에 두면 그 모듈 안의 모든 패키지는 마치 모듈이 없는 것처럼 행동한다.  \r\n즉, 모듈이 공개했는지 여부와 상관없이 public 클래스가 선언한 모든 public 혹은 protected 멤버를 모듈 밖에서도 접근할 수 있게 된다.\r\n\r\n새로 등장한 이 접근 수준을 적극 활용한 대표적인 예가 바로 JDK 자체다.  \r\n자바 라이브러리에서 공개하지 않은 패키지들은 해당 모듈 밖에서는 절대 접근할 수 없다.\r\n\r\n모듈은 여러 면에서 자바 프로그래밍에 영향을 준다.  \r\n모듈의 장점을 제대로 누리려면 해야 할 일이 많다.  \r\n먼저 패키지들을 모듈 단위로 묶고, 모듈 선언에 패키지들의 모든 의존성을 명시한다.\r\n그런 다음 소스 트리를 재배치하고, 모듈 안으로부터 (모듈 시스템을 적용하지 않는) 일반 패키지로의 모든 접근에 특별한 조치를 취해야 한다.  \r\nJDK 외에도 모듈 개념이 널리 받아들여질지 예측하기는 아직 이른 감이 있다.  \r\n꼭 필요한 경우가 아니라면 당분간은 사용하지 않는 게 좋을 것 같다.\r\n\r\n<br/>\r\n\r\n## 핵심 정리\r\n- 프로그램 요소의 접근성은 가능한 한 최소한으로 하라.\r\n- 꼭 필요한 것만 골라 최소한의 public API를 설계하자.\r\n    - 그 외에는 클래스, 인터페이스, 멤버가 의도치 않게 API로 공개되는 일이 없도록 해야 한다.\r\n- public 클래스는 상수용 public static final 필드 외에는 어떠한 public 필드도 가져서는 안 된다.\r\n    - public static final 필드가 참조하는 객체가 불변인지 확인하라.","excerpt":"잘 설계된 컴포넌트는 모든 내부 구현을 완벽히 숨겨, 구현과 API를 깔끔히 분리한다. 오직 API를 통해서만 다른 컴포넌트와 소통하며 서로의 내부 동작 방식에는 전혀 개의치 않는다. 정보 은닉, 혹은 캡슐화라고 하는 이 개념은 소프트웨어 설계의 근…","fields":{"slug":"/effective-java-item15/"},"frontmatter":{"date":"Dec 28, 2021","title":"[이펙티브 자바] 15. 클래스와 멤버의 접근 권한을 최소화하라","tags":["java","book"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n현재 깃헙 블로그 템플릿으로 [Borderless](https://github.com/junhobaik/junhobaik.github.io) 를 사용하고 있다.  \r\n인텔리제이로 마크다운을 작성하고 있는데 이때 매번 특정 형식에 맞게 마크다운을 작성해야 했다.\r\n```markdown\r\n---\r\ntitle:  \r\ndate:   \r\ntags:\r\n---\r\n```\r\n그러다보니 글을 작성하기 위해 마크다운 파일을 만들때 항상 파일 이름은 index로 설정하고 위 항목들도 다 작성해줘야 했는데\r\n한 두번은 괜찮은데 이걸 계속한다고 생각하니 너무 귀찮아질거 같았다.\r\n\r\n인텔리제이에 메서드 템플릿 만드는게 있는데 파일 템플릿 만드는거도 있지 않을까? 싶었는데 진짜 있었다.  \r\n그래서 방법을 공유하려고 한다.\r\n\r\n<br/>\r\n\r\n1. File -> Settings -> File and Code Templates 로 이동한다.\r\n\r\n<p align=\"center\"><img width=\"80%\" src=\"https://user-images.githubusercontent.com/62014888/147543151-1022d658-e5b4-4bc3-9277-ed4905f92e8d.jpg\"></p>\r\n\r\n<br/>\r\n\r\n2. Markdown 파일 템플릿을 설정하므로 Markdown을 새롭게 추가하고 원하는 형식을 작성한다.  \r\n    Name은 Markdown, Extension은 md로 설정한다.  \r\n   ${}는 새롭게 마크다운을 작성할 때 받는 파라미터가 들어가게 된다.\r\n   \r\n<p align=\"center\"><img width=\"80%\" src=\"https://user-images.githubusercontent.com/62014888/147543297-66d01480-b62f-499f-8faf-2702456ff016.png\"></p>\r\n\r\n<br/>\r\n\r\n3. 새롭게 마크다운을 작성할 때 그림과 같이 설정한 값을 입력할 수 있게 된다.\r\n<p align=\"center\"><img width=\"80%\" src=\"https://user-images.githubusercontent.com/62014888/147543840-87a07484-16a1-4e2a-a713-8854c5193261.png\"></p>\r\n\r\n<br/>\r\n\r\n4. 입력 값과 함께 설정한 템플릿에 맞게 글이 작성된 것을 볼 수 있다. \r\n<p align=\"center\"><img width=\"80%\" src=\"https://user-images.githubusercontent.com/62014888/147543911-d75a295c-9fe3-438f-aa90-eca3b64a42c4.png\"></p>\r\n\r\n<br/>\r\n\r\n## 참고\r\n- https://jojoldu.tistory.com/128","excerpt":"현재 깃헙 블로그 템플릿으로 Borderless 를 사용하고 있다. 인텔리제이로 마크다운을 작성하고 있는데 이때 매번 특정 형식에 맞게 마크다운을 작성해야 했다. 그러다보니 글을 작성하기 위해 마크다운 파일을 만들때 항상 파일 이름은 index로 설…","fields":{"slug":"/file-template-tip/"},"frontmatter":{"date":"Dec 28, 2021","title":"IntelliJ Custom File Template 만들기","tags":["intellij"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"트랜잭션은 작업의 완전성을 보장해주는 것이다.\r\n\r\n즉, 논리적인 작업 셋을 모두 완벽하게 처리하거나, 처리하지 못할 경우에는 원 상태로 복구해서 작업의 일부만 적용되는 현상(Partial update)이 발생하지 않게 만들어주는 기능이다.\r\n\r\n잠금은 동시성을 제어하기 위한 기능이고 트랜잭션은 데이터의 정합성을 보장하기 위한 기능이다.\r\n\r\n- 잠금 - 여러 커넥션에서 동시에 동일한 자원(레코드 or 테이블)을 요청할 경우 순서대로 한 시점에는 하나의 커넥션만 변경할 수 있게 해주는 역할을 함.\r\n- 격리 수준 - 하나의 트랜잭션 내에서 또는 여러 트랜잭션 간의 작업 내용을 어떻게 공유하고 차단할 것인지를 결정하는 레벨을 의미.\r\n\r\n## 5.1 트랜잭션\r\n\r\n트랜잭션을 지원하지 않는 MyISAM과 트랜잭션을 지원하는 InnoDB의 처리 방식 차이를 살펴보자.\r\n\r\n### 5.1.1 MySQL에서의 트랜잭션\r\n\r\n트랜잭션은 꼭 여러 개의 변경 작업을 수행하는 쿼리가 조합됐을 때만 의미 있는 개념은 아니다.\r\n\r\n- 트랜잭션 - 하나의 논리적인 작업 셋에 하나의 쿼리가 있든 두 개 이상의 쿼리가 있든 관계없이 논리적인 작업 셋 자체가 100% 적용되거나(COMMIT을 실행했을 때) 아무것도 적용되지 않아야(ROLLBACK 또는 트랜잭션을 ROLLBACK 시키는 오류가 발생했을 때) 함을 보장해 주는 것.\r\n\r\n```sql\r\nCREATE TABLE tab_myisam (fpdk INT NOT NULL, PRIMARY KEY (fpdk)) ENGINE=MyISAM;\r\nINSERT INTO tab_myisam (fdpk) VALUES (3);\r\n\r\nCREATE TABLE tab_innodb (fpdk INT NOT NULL, PRIMARY KEY (fpdk)) ENGINE=INNODB;\r\nINSERT INTO tab_innodb (fdpk) VALUES (3);\r\n```\r\n\r\n```sql\r\nSET autocommit=ON;\r\n\r\nINSERT INTO tab_myisam (fpdk) VALUES (1),(2),(3);\r\nINSERT INTO tab_innodb (fpdk) VALUES (1),(2),(3);\r\n```\r\n\r\n위 두 개의 스토리지 엔진에서 결과가 어떻게 다를까?\r\n\r\n두 INSERT 문장 모두 프라이머리 키 중복 오류로 쿼리가 실패한다. 그런데 두 테이블의 레코드를 조회해보면 MyISAM 테이블에는 오류가 발생했음에도 ‘1’과 ‘2’는 INSERT된 상태로 남아 있는 것을 확인할 수 있다.\r\n\r\n즉, MyISAM 테이블에 INSERT 문장이 실행되면서 차례대로 ‘1’, ‘2’를 저장하고, 그다음 ‘3’을 저장하려고 하는 순간 중복키 오류가 발생한 것이다.\r\n\r\n하지만 MyISAM 테이블에서 실행되는 쿼리는 이미 INSERT된 ‘1’,’2’를 그대로 두고 쿼리 실행을 종료해 버린다.\r\n\r\nInnoDB는 쿼리 중 일부라도 오류가 발생하면 전체를 원 상태로 만든다는 트랜잭션의 원칙대로 INSERT 문장을 실행하기 전 상태로 그대로 복구한다.\r\n\r\nMyISAM 테이블에서 발생하는 이상 현상을 부분 업데이트(Partial Update)라고 표현하며, 부분 업데이트 현상은 테이블 데이터의 정합성을 맞추는데 상당히 어려운 문제를 만든다.\r\n\r\n- 트랜잭션이란 애플리케이션 개발에서 고민해야 할 문제를 줄여주는 아주 필수적인 DBMS의 기능이라는 점을 기억하자!\r\n- 부분 업데이트 현상이 발생하면 남은 레코드를 다시 삭제하는 재처리 작업이 필요할 수 있는데 InnoDB를 사용하면 IF ... ELSE ... 로 가득한 코드를 깔끔하게 처리할 수 있다.\r\n\r\n### 5.1.2 주의사항\r\n\r\n트랜잭션 또한 DBMS의 커넥션과 동일하게 꼭 필요한 최소의 코드에만 적용하는 것이 좋다.\r\n\r\n- 이는 프로그램 코드에서 트랜잭션의 범위를 최소화하라는 의미!\r\n\r\n```\r\n1) 처리 시작\r\n=> 데이터베이스 커넥션 생성\r\n=> 트랜잭션 시작\r\n2) 사용자의 로그인 여부 확인\r\n3) 사용자의 글쓰기 내용의 오류 여부 확인\r\n4) 첨부로 업로드된 파일 확인 및 저장\r\n5) 사용자의 입력 내용을 DBMS에 저장\r\n6) 첨부 파일 정보를 DBMS에 저장\r\n7) 저장된 내용 또는 기타 정보를 DBMS에서 조회\r\n8) 게시물 등록에 대한 알림 메일 발송\r\n9) 알림 메일 발송 이력을 DBMS에 저장\r\n<= 트랜잭션 종료(COMMIT)\r\n<= 데이터베이스 커넥션 반납\r\n10) 처리 완료\r\n```\r\n\r\n위 처리 절차 중에서 DBMS의 트랜잭션 처리에 좋지 않은 영향을 미치는 부분을 나눠서 살펴보자.","excerpt":"트랜잭션은 작업의 완전성을 보장해주는 것이다. 즉, 논리적인 작업 셋을 모두 완벽하게 처리하거나, 처리하지 못할 경우에는 원 상태로 복구해서 작업의 일부만 적용되는 현상(Partial update)이 발생하지 않게 만들어주는 기능이다. 잠금은 동시성…","fields":{"slug":"/real-mysql-ch5/"},"frontmatter":{"date":"Dec 24, 2021","title":"[Real MySQL] 5. 트랜잭션과 잠금","tags":["database","book"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n## compareTo, Comparable?\r\n\r\n- compareTo는 단순 동치성 비교에 더해 순서까지 비교할 수 있으며, 제네릭하다.\r\n- Comparable을 구현했다는 것은 그 클래스의 인스턴스들에는 자연적인 순서(natural order)가 있음을 뜻한다.\r\n```java\r\nArrays.sort(a);\r\n```\r\n- Comparable을 구현한 객체들의 배열은 위처럼 손쉽게 정렬할 수 있다.\r\n- 검색, 극단값 계산, 자동 정렬되는 컬렉션 관리도 역시 쉽게 할 수 있다.\r\n\r\n```java\r\npublic class WordList {\r\n    public static void main(String[] args) {\r\n        Set<String> s = new TreeSet<>();\r\n        Collections.addAll(s, args);\r\n        System.out.println(s);\r\n    }\r\n}\r\n```\r\n- 위 프로그램은 명령줄 인수들을 (중복을 제거하고) 알파벳순으로 출력한다.\r\n    - String이 Comparable을 구현한 덕분임.\r\n    \r\n- 사실상 자바 플랫폼 라이브러리의 모든 값 클래스와 열거 타입이 Comparable을 구현했다.\r\n- 알파벳, 숫자, 연대 같이 순서가 명확한 값 클래스를 작성한다면 반드시 Comparable 인터페이스를 구현하자.\r\n\r\n<br/>\r\n\r\n## compareTo 메서드의 일반 규약\r\n\r\n> 이 객체와 주어진 객체의 순서를 비교한다. 이 객체가 주어진 객체보다 작으면 음의 정수를, 같으면 0을, 크면 양의 정수를 반환한다.\r\n> 이 객체와 비교할 수 없는 타입의 객체가 주어지면 ClassCastException을 던진다.\r\n> - Comparable을 구현한 클래스는 모든 x,y에 대해 sgn(x.compareTo(y)) == -sgn(y.compareTo(x))여야 한다 (따라서 x.compareTo(y)는 y.compareTo(x)가 예외를 던질 때에 한해 예외를 던져야 한다)\r\n> - Comparable을 구현한 클래스는 추이성을 보장해야 한다. 즉, (x.compareTo(y) > 0 && y.compareTo(z) > 0)이면 x.compareTo(z) > 0이다.\r\n> - Comparable을 구현한 클래스는 모든 z에 대해 x.compareTo(y) == 0이면 sgn(x.compareTo(z)) == sgn(y.compareTo(z))다.\r\n> - 이번 권고가 필수는 아니지만 꼭 지키는게 좋다. (x.compareTo(y) == 0) == (x.equals(y))여야 한다. Comparable을 구현하고 이 권고를 지키지 않는 모든 클래스는 그 사실을 명시해야 한다.  \r\n> \"주의: 이 클래스의 순서는 equals 메서드와 일관되지 않다.\"\r\n\r\n- 첫 번째 규약은 두 객체 참조의 순서를 바꿔 비교해도 예상한 결과가 나와야 한다는 얘기.\r\n  - 첫 번째 객체가 두 번째 객체보다 작으면, 두 번째가 첫 번째보다 커야 한다.\r\n  - 첫 번째가 두 번째와 크기가 같다면, 두 번째는 첫 번째와 같아야 한다.\r\n  - 첫 번째가 두 번째보다 크면, 두 번째는 첫 번째보다 작아야 한다.\r\n- 두 번째 규약은 첫 번째가 두 번째보다 크고 두 번째가 세 번째보다 크면, 첫 번째는 세 번째보다 커야 한다는 뜻.\r\n- 세 번째 규약은 크기가 같은 객체들끼리는 어떤 객체와 비교하더라도 항상 같아야 한다는 뜻.\r\n- 마지막 규약은 필수는 아니지만 꼭 지키길 권한다.\r\n  - compareTo 메서드로 수행한 동치성 테스트의 결과가 equals와 같아야 한다는 것.\r\n  - compareTo의 순서와 equals의 결과가 일관되지 않은 클래스도 여전히 동작은 하지만 이 클래스의 객체를 정렬된 컬렉션애 넣으면 해당 컬렉션이 구현한 인터페이스에 정의된 동작과 엇박자를 낼 것.\r\n  - 이 인터페이스들은 equals 메서드의 규약을 따른다고 되어 있지만, 동치성을 비교할 때 equals 대신 compareTo를 사용하기 때문.\r\n  \r\n<br/>\r\n\r\n- 모든 객체에 대해 전역 동치관계를 부여하는 equals 메서드와 달리, compareTo는 타입이 다른 객체를 신경 쓰지 않아도 된다.\r\n  - 타입이 다른 객체가 주어지면 간단히 ClassCastException을 던져도 된다.\r\n- hashCode 규약을 지키지 못하면 해시를 사용하는 클래스와 어울리지 못하듯, compareTo 규약을 지키지 못하면 비교를 활용하는 클래스와 어울리지 못함.\r\n  - 대표적인 예로 정렬된 컬렉션인 TreeSet, TreeMap, 검색과 정렬 알고리즘을 활용하는 유틸리티 클래스인 Collections, Arrays\r\n\r\n\r\n<br/>\r\n\r\n## 객체 참조 필드가 하나뿐인 비교자\r\n\r\n- Comparable은 타입을 인수로 받는 제네릭 인터페이스이므로 compareTo 메서드의 인수 타입은 컴파일타임에 정해진다.\r\n  - 입력 인수의 타입을 확인하거나 형변환할 필요가 없다는 뜻.\r\n- null을 인수로 넣어 호출하면 NullPointerException을 던져야 함.\r\n\r\n- compareTo 메서드는 각 필드가 동치인지를 비교하는 게 아니라 그 순서를 비교함.\r\n- 객체 참조 필드를 비교하려면 compareTo 메서드를 재귀적으로 호출함.\r\n- Comparable을 구현하지 않은 필드나 표준이 아닌 순서로 비교해야 한다면 비교자(Comparator)를 대신 사용함.\r\n  - 비교자는 직접 만들거나 자바가 제공하는 것 중에 골라 쓰면 됨.\r\n    ```java\r\n    // 코드 14-1 객체 참조 필드가 하나뿐인 비교자 (90쪽)\r\n    public final class CaseInsensitiveString\r\n    implements Comparable<CaseInsensitiveString> {\r\n    \r\n        // 자바가 제공하는 비교자를 사용해 클래스를 비교한다.\r\n        public int compareTo(CaseInsensitiveString cis) {\r\n            return String.CASE_INSENSITIVE_ORDER.compare(s, cis.s);\r\n        }\r\n    }\r\n    ```\r\n    - CaseInsensitiveString의 참조는 CaseInsensitiveString 참조와만 비교할 수 있음.\r\n\r\n- 정수 기본 타입 필드를 비교할 때도 박싱된 기본 타입 클래스의 정적 메서드인 compare를 이용하자.\r\n  - compareTo 메서드에서 관계 연산자 <,>를 사용하는 이전 방식은 거추장스럽고 오류를 유발하니, 추천하지 않음.\r\n\r\n<br/>\r\n\r\n## 기본 타입 필드가 여럿일 때의 비교자\r\n\r\n```java\r\n// 코드 14-2 기본 타입 필드가 여럿일 때의 비교자 (91쪽)\r\npublic int compareTo(PhoneNumber pn) {\r\n    int result = Short.compare(areaCode, pn.areaCode);\r\n    if (result == 0)  {\r\n        result = Short.compare(prefix, pn.prefix);\r\n        if (result == 0)\r\n            result = Short.compare(lineNum, pn.lineNum);\r\n    }\r\n    return result;\r\n}\r\n```\r\n- 클래스에 핵심 필드가 여러 개라면 어느 것을 먼저 비교하느냐가 중요해진다.\r\n- 가장 핵심적인 필드부터 비교해나가자.\r\n  - 비교 결과가 0이 아니라면, 즉 순서가 결정되면 거기서 끝임.\r\n  - 가장 핵심이 되는 필드가 똑같다면, 똑같지 않은 필드를 찾을 때까지 그 다음으로 중요한 필드를 비교해나감.\r\n\r\n<br/>\r\n\r\n## 비교자 생성 메서드를 활용한 비교자\r\n\r\n```java\r\n // 코드 14-3 비교자 생성 메서드를 활용한 비교자 (92쪽)\r\nprivate static final Comparator<PhoneNumber> COMPARATOR =\r\n        comparingInt((PhoneNumber pn) -> pn.areaCode)\r\n                .thenComparingInt(pn -> pn.prefix)\r\n                .thenComparingInt(pn -> pn.lineNum);\r\n\r\npublic int compareTo(PhoneNumber pn) {\r\n    return COMPARATOR.compare(this, pn);\r\n}\r\n```\r\n\r\n- 자바 8에서는 Comparator 인터페이스가 일련의 비교자 생성 메서드와 팀을 꾸려 메서드 연쇄 방식으로 비교자를 생성할 수 있게 되었다.\r\n  - 이 비교자들을 Comparable 인터페이스가 원하는 compareTo 메서드를 구현하는 데 멋지게 활용할 수 있다.\r\n  - 이 방식은 간결하지만 약간의 성능 저하가 뒤따름.\r\n- Comparator는 수많은 보조 생성 메서드들로 중무장하고 있음.\r\n  - long과 double용으로는 comparingInt와 thenComparingInt의 변형 메서드도 준비되어 있음.\r\n  - short처럼 더 작은 정수 타입에는 int용 버전을 사용하면 됨.\r\n  - 이런 식으로 자바의 숫자용 기본 타입을 모두 커버함.\r\n  \r\n- 객체 참조용 비교자 생성 메서드도 준비되어 있음.\r\n- comparing이라는 정적 메서드 2개가 다중정의되어 있음.\r\n  - 첫 번째는 키 추출자를 받아서 그 키의 자연적 순서를 사용함.\r\n  - 두 번째는 키 추출자 하나와 추출된 키를 비교할 비교자까지 총 2개의 인수를 받음.\r\n- thenComparing이란 인스턴스 메서드 3개가 다중정의되어 있음.\r\n  - 첫 번째는 비교자 하나만 인수로 받아 그 비교자로 부차 순서를 정함.\r\n  - 두 번째는 키 추출자를 인수로 받아 그 키의 자연적 순서로 보조 순서를 정함.\r\n  - 마지막 세 번째는 키 추출자 하나와 추출된 키를 비교할 비교자까지 총 2개의 인수를 받음.\r\n\r\n<br/>\r\n\r\n## 주의사항\r\n\r\n- 이따금 '값의 차'를 기준으로 첫 번째 값이 두 번째 값보다 작으면 음수를, 두 값이 같으면 0을, 첫 번째 값이 크면 양수를 반환하는 compareTo나 compare 메서드와 마주할 것.\r\n```java\r\nstatic Comparator<Object> hashCodeOrder = new Comparator<>() {\r\n    public int compare(Object o1, Object o2) {\r\n        return o1.hashCode() - o2.hashCode();\r\n    }\r\n};\r\n```\r\n- 이 방식은 사용하면 안 됨.\r\n  - 정수 오버플로를 일으키거나 IEEE 754 부동소수점 계산 방식에 따른 오류를 낼 수 있음.\r\n- 대신 다음의 두 방식 중 하나를 사용하자\r\n```java\r\nstatic Comparator<Object> hashCodeOrder = new Comparator<>() {\r\n    public int compare(Object o1, Object o2) {\r\n        return Integer.compare(o1.hashCode(), o2.hashCode());\r\n    }\r\n};\r\n```\r\n```java\r\nstatic Comparator<Object> hashCodeOrder = \r\n        Comparator.comparingInt(o -> o.hashCode());\r\n};\r\n```\r\n\r\n<br/>\r\n\r\n## 핵심 정리\r\n\r\n- 순서를 고려해야 하는 값 클래스를 작성한다면 꼭 Comparable 인터페이스를 구현하여, 그 인스턴스들을 쉽게 정렬하고, 검색하고, 비교 기능을 제공하는 컬렉션과 어우러지도록 해야 함.\r\n- compareTo 메서드에서 필드의 값을 비교할 때 <,> 연산자는 쓰지 말자.\r\n  - 대신 박싱된 기본 타입 클래스가 제공하는 정적 compare 메서드나 Comparator 인터페이스가 제공하는 비교자 생성 메서드를 사용하자.","excerpt":"compareTo, Comparable? compareTo는 단순 동치성 비교에 더해 순서까지 비교할 수 있으며, 제네릭하다. Comparable을 구현했다는 것은 그 클래스의 인스턴스들에는 자연적인 순서(natural order)가 있음을 뜻한다.…","fields":{"slug":"/effective-java-item14/"},"frontmatter":{"date":"Dec 21, 2021","title":"[이펙티브 자바] 14. Comparable을 구현할지 고려하라","tags":["java","book"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n- Cloneable은 복제해도 되는 클래스임을 명시하는 용도의 믹스인 인터페이스지만, 아쉽게도 의도한 목적을 제대로 이루지 못했음.\r\n    - 가장 큰 문제는 clone 메서드가 선언된 곳이 Cloneable이 아닌 Object이고, 그마저도 protected라는 데 있음.\r\n    - Cloneable을 구현하는 것만으로는 외부 객체에서 clone 메서드를 호출할 수 없음.\r\n\r\n- Cloneable 인터페이스는 Object의 protected 메서드인 clone의 동작 방식을 결정함.\r\n- Cloneable을 구현한 클래스의 인스턴스에서 clone을 호출하면 그 객체의 필드들을 하나하나 복사한 객체를 반환함.\r\n    - 그렇지 않은 클래스가 호출하면 CloneNotSupportedException을 던짐.\r\n- 인터페이스를 구현한다는 것은 일반적으로 해당 클래스가 그 인터페이스에서 정의한 기능을 제공한다고 선언하는 행위.\r\n    - Cloneable의 경우는 상위 클래스에 정의된 protected 메서드의 동작 방식을 변경한 것.\r\n- 실무에서는 Cloneable을 구현한 클래스는 clone 메서드를 pulbic으로 제공하며, 사용자는 당연히 복제가 제대로 이뤄지리라 기대함.\r\n\r\n<br/>\r\n\r\n## clone 메서드의 일반 규약\r\n\r\n> 이 객체의 복사본을 생성해 반환한다. '복사'의 정확한 뜻은 그 객체를 구현한 클래스에 따라 다를 수 있음.\r\n> 어떤 객체 x에 대해 다음 식은 참이다.\r\n> x.clone() != x\r\n> 다음 식도 참이다.\r\n> x.clone().getClass() == x.getClass()\r\n> 하지만 이상의 요구를 반드시 만족해야 하는 것은 아니다.\r\n> 다음 식도 참이지만, 역시 필수는 아니다.\r\n> x.clone().equals(x)\r\n> 관례상, 이 메서드가 반환하는 객체는 super.clone()을 호출해 얻어야 한다.\r\n> 관례를 따른다면 다음 식은 참이다.\r\n> x.clone().getClass() == x.getClass()\r\n> 관례상, 반환된 객체와 원본 객체는 독립적이어야 한다. 이를 만족하려면 super.clone으로 얻은 객체의 필드 중 하나 이상을 반환 전에 수정해야 할 수도 있다.\r\n\r\n- 강제성이 없다는 점만 빼면 생성자 연쇄와 비슷한 메커니즘.\r\n- clone 메서드가 super.clone이 아닌 생성자를 호출해 얻은 인스턴스를 반환해도 컴파일러는 불평하지 않을 것.\r\n    - 하지만 이 클래스의 하위 클래스에서 super.clone을 호출한다면 잘못된 클래스의 객체가 만들어져, 결국 하위 클래스의 clone 메서드가 제대로 동작하지 않게 됨.\r\n\r\n<br/>\r\n\r\n## 가변 상태를 참조하지 않는 클래스용 clone 메서드\r\n  \r\n```java\r\n // 코드 13-1 가변 상태를 참조하지 않는 클래스용 clone 메서드 (79쪽)\r\n@Override public PhoneNumber clone() {\r\n    try {\r\n        return (PhoneNumber) super.clone();\r\n    } catch (CloneNotSupportedException e) {\r\n        throw new AssertionError();  // 일어날 수 없는 일이다.\r\n    }\r\n}\r\n```\r\n- 모든 필드가 기본 타입이거나 불변 객체를 참조한다면 이 객체는 완벽히 우리가 원하는 상태라 더 손볼 것이 없음.\r\n  - 단, 쓸데없는 복사를 지양한다는 관점에서 보면 불변 클래스는 굳이 clone 메서드를 제공하지 않는 게 좋음.\r\n- 위와 같이 자바는 공변 반환 타이핑을 지원해 PhoneNumber의 clone 메서드는 PhoneNumber를 반환하게 했음.\r\n  - 즉, 재정의한 메서드의 반환 타입은 상위 클래스의 메서드가 반환하는 타입의 하위 타입일 수 있음.\r\n  - 이 방식으로 클라이언트가 형변환하지 않아도 되게끔 해주자.\r\n- try-catch 블록으로 감싼 이유는 Object의 clone 메서드가 checked exception인 CloneNotSupportedException을 던지도록 선언되었기 때문.\r\n  - 사실 CloneNotSupportedException은 unchecked exception이었어야 했다..\r\n\r\n<br/>\r\n\r\n## 가변 객체를 참조하는 클래스의 clone 메서드\r\n\r\n```java\r\npublic class Stack implements Cloneable {\r\n  private Object[] elements;\r\n  private int size = 0;\r\n  private static final int DEFAULT_INITIAL_CAPACITY = 16;\r\n\r\n  public Stack() {\r\n    this.elements = new Object[DEFAULT_INITIAL_CAPACITY];\r\n  }\r\n\r\n  public void push(Object e) {\r\n    ensureCapacity();\r\n    elements[size++] = e;\r\n  }\r\n\r\n  public Object pop() {\r\n    if (size == 0)\r\n      throw new EmptyStackException();\r\n    Object result = elements[--size];\r\n    elements[size] = null; // 다 쓴 참조 해제\r\n    return result;\r\n  }\r\n\r\n  // 원소를 위한 공간을 적어도 하나 이상 확보한다.\r\n  private void ensureCapacity() {\r\n    if (elements.length == size)\r\n      elements = Arrays.copyOf(elements, 2 * size + 1);\r\n  }\r\n}\r\n```\r\n- 앞서 했던 구현이 클래스가 가변 객체를 참조하는 순간 재앙으로 변함.\r\n- clone 메서드가 단순히 super.clone의 결과를 반환한다면?\r\n  - size 필드는 올바른 값을 갖겠지만, elements 필드는 원본 Stack 인스턴스와 똑같은 배열을 참고할 것.\r\n  - 둘 중 하나를 수정하면 다른 하나도 수정되어 불변식을 해침.\r\n  - 따라서 프로그램이 이상하게 동작하거나 NullPointerException을 던질 것.\r\n- clone 메서드는 사실상 생성자와 같은 효과를 낸다. 즉, clone은 원본 객체에 아무런 해를 끼치지 않는 동시에 복제된 객체의 불변식을 보장해야 함.\r\n\r\n```java\r\n// 코드 13-2 가변 상태를 참조하는 클래스용 clone 메서드\r\n@Override public Stack clone() {\r\n    try {\r\n        Stack result = (Stack) super.clone();\r\n        result.elements = elements.clone();\r\n        return result;\r\n    } catch (CloneNotSupportedException e) {\r\n        throw new AssertionError();\r\n    }\r\n}\r\n```\r\n- elements 배열의 clone을 재귀적으로 호출해 해결 가능.\r\n- 배열의 clone은 런타임 타입과 컴파일타임 타입 모두 원본 배열과 똑같은 배열을 반환하므로 Object[]으로 형변환할 필요는 없음.\r\n- elements 필드가 final이었다면 위 방식은 작동하지 않음.\r\n  - final 필드는 새로운 값을 할당할 수 없기 때문.\r\n  - Cloneable 아키텍처는 '가변 객체를 참조하는 필드는 final로 선언하라'는 일반 용법과 충돌함. (원본과 가변 객체를 공유해도 안전하다면 괜찮음)\r\n  - 복제할 클래스를 만들기 위해 일부 필드에서 final을 제거해야 할 수도 있음.\r\n\r\n<br/>\r\n\r\n## 해시테이블용 clone 메서드\r\n\r\n- clone을 재귀적으로 호출하는 것만으로는 충분하지 않을 때도 있음.\r\n```java\r\npublic class HashTable implements Cloneable {\r\n    public Entry[] buckets = ...;\r\n    \r\n    private static class Entry {\r\n        final Object key;\r\n        Object value;\r\n        Entry next;\r\n        \r\n        Entry(Object key, Object value, Entry next) {\r\n            this.key = key;\r\n            this.value = value;\r\n            this.next = next;\r\n        }\r\n    }\r\n}\r\n```\r\n- 해시테이블 내부는 버킷들의 배열이고 각 버킷은 키-값 쌍을 담는 연결 리스트의 첫 번째 엔트리를 참조함.\r\n\r\n```java\r\n@Override public HashTable clone() {\r\n    try {\r\n        HashTable result = (HashTable) super.clone();\r\n        result.buckets = buckets.clone();\r\n        return result;\r\n    } catch (CloneNotSupportedException e) {\r\n      throw new AssertionError();\r\n    }\r\n}\r\n```\r\n- 복제본은 자신만의 버킷 배열을 갖지만, 이 배열은 원본과 같은 연결 리스트를 참조하여 원본과 복제본 모두 예기치 않게 동작할 가능성이 생김.\r\n  - 해결하려면 각 버킷을 구성하는 연결 리스트를 복사해야 함.\r\n  \r\n```java\r\npublic class HashTable implements Cloneable {\r\n    public Entry[] buckets = ...;\r\n    \r\n    private static class Entry {\r\n        final Object key;\r\n        Object value;\r\n        Entry next;\r\n        \r\n        Entry(Object key, Object value, Entry next) {\r\n            this.key = key;\r\n            this.value = value;\r\n            this.next = next;\r\n        }\r\n        \r\n        // 이 엔트리가 가리키는 연결 리스트를 재귀적으로 복사\r\n        Entry deepCopy() {\r\n            return new Entry(key, value,\r\n                    next == null ? null : next.deepCopy());\r\n        }\r\n    }\r\n\r\n    @Override public HashTable clone() {\r\n        try {\r\n          HashTable result = (HashTable) super.clone();\r\n          result.buckets = new Entry[buckets.length];\r\n          for (int i = 0; i < buckets.length; i++) {\r\n              if (buckets[i] != null) {\r\n                  result.buckets[i] = buckets[i].deepCopy();\r\n              }\r\n          }\r\n          return result;\r\n        } catch (CloneNotSupportedException e) {\r\n          throw new AssertionError();\r\n        }\r\n    }\r\n}\r\n```\r\n- private 클래스인 HashTable.Entry는 깊은복사(deep copy)를 지원하도록 보강되었음.\r\n- clone 메서드는 적절한 크기의 새로운 버킷 배열을 할당한 다음 순회하며 깊은복사를 수행함.\r\n  - 이때 deepCopy 메서드는 연결 리스트 전체를 복사하기 위해 재귀적으로 호출함.\r\n- 이 방법은 리스트가 길다면 스택 오버플로를 일으킬 위험이 있어 좋지 않음.\r\n  - 재귀 호출 대신 반복자를 써서 순회하는 방향으로 수정해야 함.\r\n  ```java\r\n  Entry deepCopy() {\r\n      Entry result = new Entry(key, value, next);\r\n      for (Entry p = result; p.next != null; p = p.next)\r\n          p.next = new Entry(p.key, p.value, p.next);\r\n      }\r\n      return result;\r\n  }\r\n  ```\r\n\r\n<br/>\r\n\r\n## 복잡한 가변 객체를 복제하는 마지막 방법\r\n\r\n- super.clone을 호출하여 얻은 객체의 모든 필드를 초기 상태로 설정한 다음, 원본 객체의 상태를 다시 생성하는 고수준 메서드들을 호출함.\r\n- 고수준 API를 활용해 복제하면 보통은 간단하고 제법 우아한 코드를 얻게 되지만, 아무래도 저수준에서 바로 처리할 때보다는 느리다.\r\n- Cloneable 아키텍처의 기초가 되는 필드 단위 객체 복사를 우회하기 때문에 전체 Cloneable 아키텍처와는 어울리지 않는 방식이기도 함.\r\n- clone이 하위 클래스에서 재정의한 메서드를 호출하면, 하위 클래스는 복제 과정에서 자신의 상태를 교정할 기회를 잃게 되어 원본과 복제본의 상태가 달라질 가능성이 큼.\r\n  - clone에서 사용되는 메서드는 final이거나 private이어야 함.\r\n\r\n<br/>\r\n\r\n## 주의사항\r\n\r\n- Object의 clone 메서드는 CloneNotSupportedException을 던진다고 선언했지만 재정의한 메서드는 그렇지 않음.\r\n  - public인 clone 메서드에서는 throws 절을 없애야 함.\r\n- 상속용 클래스는 Cloneable을 구현해서는 안 된다.\r\n- Object의 방식을 모방해서 사용할 수도 있음.\r\n  - 제대로 작동하는 clone 메서드를 구현해 protected로 두고 ClassNotSupportedException도 던질 수 있다고 선언하는 것.\r\n    - Cloneable 구현 여부를 하위 클래스에서 선택하도록 해줌.\r\n  - clone을 동작하지 않게 구현해놓고 하위 클래스에서 재정의하지 못하게 할 수도 있음.\r\n  \r\n- Cloneable을 구현한 스레드 안전 클래스를 작성할 때는 clone 메서드 역시 적절히 동기화해줘야 함.\r\n  - Object의 clone 메서드는 동기화를 신경 쓰지 않았음.\r\n- Cloneable을 구현하는 모든 클래스는 clone을 재정의해야 함.\r\n  - 접근 제한자는 public, 반환 타입은 클래스 자신으로 변경.\r\n  - super.clone을 호출한 후 필요한 필드를 전부 적절히 수정함.\r\n    - 깊은 구조에 숨어 있는 모든 가변 객체를 복사하고, 복사본이 가진 객체 참조 모두가 복사된 객체들을 가리키게 함.\r\n    - 기본 타입, 불변 객체 참조만 갖는 클래스는 아무 필드도 수정할 필요 없음.\r\n    - 일련번호, 고유 ID는 비록 기본 타입이나 불변일지라도 수정해줘야 함.\r\n\r\n<br/>\r\n\r\n## 복사 생성자, 복사 팩터리\r\n\r\n- 그런데 이 모든 작업이 꼭 필요한 걸까?\r\n- 복사 생성자와 복사 팩터리라는 더 나은 객체 복사 방식을 제공할 수 있음.\r\n\r\n<br/>\r\n\r\n### 복사 생성자\r\n- 복사 생성자란 단순히 자신과 같은 클래스의 인스턴스를 인수로 받는 생성자를 말함.\r\n```java\r\npublic Yum(Yum yum) {...};\r\n```\r\n\r\n<br/>\r\n\r\n### 복사 팩터리\r\n- 복사 생성자를 모방한 정적 팩터리\r\n\r\n```java\r\npublic statci Yum newInstance(Yum yum) {...};\r\n```\r\n\r\n<br/>\r\n\r\n- 복사 생성자와 복사 팩터리는 Cloneable/clone 방식보다 나은 면이 많음.\r\n  1. 언어 모순적이고 위험천만한 객체 생성 메커니즘(생성자를 쓰지 않는 방식)을 사용하지 않음 \r\n  2. 엉성하게 문서화된 규약에 기대지 않음\r\n  3. 정상적인 final 필드 용법과도 충돌하지 않음\r\n  4. 불필요한 검사 예외를 던지지 않음\r\n  5. 형변환도 필요치 않음\r\n\r\n- 복사 생성자와 복사 팩터리는 해당 클래스가 구현한 인터페이스 타입의 인스턴스를 인수로 받을 수 있음.\r\n  - 예컨대 관례상 모든 범용 컬렉션 구현체는 Collection이나 Map 타입을 받는 생성자를 제공함.\r\n  - 인터페이스 기반 복사 생성자와 복사 팩터리의 더 정확한 이름은 '변환 생성자'와 '변환 팩터리'다.\r\n  - 클라이언트의 원본 구현 타입에 얽매이지 않고 복제본의 타입을 직접 선택할 수 있음.\r\n  - ex) HashSet 객체 s를 TreeSet 타입으로 복제 -> new TreeSet<>(s);\r\n\r\n<br/>\r\n\r\n## 핵심 정리\r\n- 새로운 인터페이스를 만들 때, 새로운 클래스를 만들 때 Cloneable을 확장하지도 구현하지도 말자.\r\n- final 클래스라면 위험이 크지 않지만, 성능 최적화 관점에서 검토한 후 별다른 문제가 없을 때만 드물게 허용해야 한다.\r\n- 기본 원칙은 '복제 기능은 생성자와 팩터리를 이용하는 게 최고'라는 것.\r\n- 단, 배열만은 clone 메서드 방식이 가장 깔끔한, 이 규칙의 합당한 예외라 할 수 있음.","excerpt":"Cloneable은 복제해도 되는 클래스임을 명시하는 용도의 믹스인 인터페이스지만, 아쉽게도 의도한 목적을 제대로 이루지 못했음. 가장 큰 문제는 clone 메서드가 선언된 곳이 Cloneable이 아닌 Object이고, 그마저도 protected라…","fields":{"slug":"/effective-java-item13/"},"frontmatter":{"date":"Dec 20, 2021","title":"[이펙티브 자바] 13. clone 재정의는 주의해서 진행하라","tags":["java","book"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n## toString을 재정의하자.\r\n\r\n- Object의 기본 toString 메서드는 PhoneNumber@abddb처럼 단순히 **클래스\\_이름@16진수로\\_표시한\\_해시코드**를 반환할 뿐임.\r\n- toString의 일반 규약에 따르면 '간결하면서 사람이 읽기 쉬운 형태의 유익한 정보'를 반환해야 함.\r\n    - 규약은 \"모든 하위 클래스에서 이 메서드를 재정의하라\"고 함.\r\n- toString을 잘 구현한 클래스는 사용하기에 훨씬 즐겁고, 그 클래스를 사용한 시스템은 디버깅이 쉬움.\r\n    - toString을 제대로 재정의하지 않는다면 쓸모없는 메시지만 로그에 남을 것.\r\n- 좋은 toString은 (특히 컬렉션처럼) 이 인스턴스를 포함하는 객체에서 유용하게 쓰인다.\r\n- 실전에서 toString은 그 객체가 가진 주요 정보 모두를 반환하는게 좋음.\r\n    - 단, 객체가 거대하거나 객체의 상태가 문자열로 표현하기에 적합하지 않다면 무리가 있음.\r\n        - 이럴 땐 요약 정보를 담자.\r\n\r\n<br/>\r\n\r\n## toString 포맷 문서화\r\n\r\n- toString을 구현할 때면 반환값의 포맷을 문서화할지 정해야 함.\r\n    - 전화번호나 행렬 같은 값 클래스라면 문서화하기를 권함.\r\n    \r\n### 장점\r\n\r\n- 포맷을 명시하면 그 객체는 표준적이고, 명확하고, 사람이 읽을 수 있게 됨.\r\n    - 따라서 그 값 그대로 입출력에 사용하거나 CSV 파일처럼 사람이 읽을 수 있는 데이터 객체로 저장할 수도 있음.\r\n- 포맷을 명시하기로 했다면, 명시한 포맷에 맞는 문자열과 객체를 상호 전환할 수 있는 정적 팩터리나 생성자를 함께 제공하는 것이 좋다.\r\n    - BigInteger, BigDecimal 등이 예\r\n    \r\n### 단점\r\n\r\n- 포맷을 한번 명시하면 평생 그 포맷에 얽매이게 됨.\r\n- 포맷을 바꾼다면 이를 사용하던 코드들과 데이터들은 엉망이 될 것.\r\n- 포맷을 명시하지 않는다면 향후 릴리스에서 정보를 더 넣거나 포맷을 개선할 수 있는 유연성을 얻게 됨.\r\n\r\n<br/>\r\n\r\n- 포맷을 명시하든 아니든 의도는 명확히 밝혀야 함.\r\n- 포맷 명시 여부와 상관없이 toString이 반환하는 값에 포함된 정보를 얻어올 수 있는 API를 제공하자.\r\n  - 그렇지 않으면 이 정보가 필요한 프로그래머는 toString의 반환값을 파싱할 수 밖에 없음.\r\n  - 성능이 나빠지고 필요하지도 않은 작업.\r\n  \r\n<br/>\r\n\r\n## 자동 생성 toString\r\n\r\n- AutoValue 프레임워크, IDE는 toString을 생성해줌.\r\n- 자동 생성된 toString은 필드의 내용은 나타내어 주지만 클래스의 '의미'까지 파악하지는 못함.\r\n  - 비록 자동 생성에 적합하지는 않더라도 객체의 값에 관해 아무것도 알려주지 않는 Object의 toString보다는 자동 생성된 toString이 훨씬 유용함.\r\n\r\n<br/>\r\n\r\n## 핵심 정리\r\n\r\n- 모든 구체 클래스에서 Object의 toString을 재정의하자.\r\n  - 상위 클래스에서 이미 알맞게 재정의한 경우는 예외.\r\n- toString을 재정의한 클래스는 사용하기도 즐겁고 그 클래스를 사용한 시스템을 디버깅하기 쉽게 해준다.\r\n- toString은 해당 객체에 관한 명확하고 유용한 정보를 읽기 좋은 형태로 반환해야 한다.","excerpt":"toString을 재정의하자. Object의 기본 toString 메서드는 PhoneNumber@abddb처럼 단순히 클래스_이름@16진수로_표시한_해시코드를 반환할 뿐임. toString의 일반 규약에 따르면 '간결하면서 사람이 읽기 쉬운 형태의 …","fields":{"slug":"/effective-java-item12/"},"frontmatter":{"date":"Dec 19, 2021","title":"[이펙티브 자바] 12. toString을 항상 재정의하라","tags":["java","book"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n## hashCode 재정의\r\n\r\n- equals를 재정의한 클래스 모두에서 hashCode도 재정의해야 한다.\r\n    - 그렇지 않으면 hashCode 일반 규약을 어기게 되어 해당 클래스의 인스턴스를 HashMap이나 HashSet 같은 컬렉션의 원소로 사용할 때 문제를 일으킬 것.\r\n- Object 명세에서 발췌한 규약이다.\r\n  > - equals 비교에 사용되는 정보가 변경되지 않았다면, 애플리케이션이 실행되는 동안 그 객체의 hashCode 메서드는 몇 번을 호출해도 일관되게 항상 같은 값을 반환해야 한다. 단, 애플리케이션을 다시 실행한다면 이 값이 달라져도 상관없다.\r\n  > - equals(Object)가 두 객체를 같다고 판단했다면, 두 객체의 hashCode는 똑같은 값을 반환해야 한다.\r\n  > - equals(Object)가 두 객체를 다르다고 판단했더라도, 두 객체의 hashCode가 서로 다른 값을 반환할 필요는 없다. 단, 다른 객체에 대해서는 다른 값을 반환해야 해시테이블의 성능이 좋아진다.\r\n  \r\n- hashCode 재정의를 잘못했을 때 크게 문제가 되는 조항은 두 번째.\r\n  - 논리적으로 같은 객체는 같은 해시코드를 반환해야 한다.\r\n\r\n<br/>\r\n\r\n## 예시\r\n```java\r\npublic final class PhoneNumber {\r\n    private final short areaCode, prefix, lineNum;\r\n\r\n    public PhoneNumber(int areaCode, int prefix, int lineNum) {\r\n        this.areaCode = rangeCheck(areaCode, 999, \"지역코드\");\r\n        this.prefix   = rangeCheck(prefix,   999, \"프리픽스\");\r\n        this.lineNum  = rangeCheck(lineNum, 9999, \"가입자 번호\");\r\n    }\r\n\r\n    private static short rangeCheck(int val, int max, String arg) {\r\n        if (val < 0 || val > max)\r\n            throw new IllegalArgumentException(arg + \": \" + val);\r\n        return (short) val;\r\n    }\r\n\r\n    @Override public boolean equals(Object o) {\r\n        if (o == this)\r\n            return true;\r\n        if (!(o instanceof PhoneNumber))\r\n            return false;\r\n        PhoneNumber pn = (PhoneNumber)o;\r\n        return pn.lineNum == lineNum && pn.prefix == prefix\r\n                && pn.areaCode == areaCode;\r\n    }\r\n}\r\n```\r\n```java\r\nMap<PhoneNumber, String> m = new HashMap<>();\r\nm.put(new PhoneNumber(707, 867, 5309), \"제니\");\r\n```\r\n\r\n- m.get(new PhoneNumber(707, 867, 5309))를 실행하면 \"제니\"가 나와야 할 것 같지만, 실제로는 null을 반환함.\r\n- PhoneNumber 클래스는 hashCode를 재정의하지 않았기 때문에 논리적 동치인 두 객체가 서로 다른 해시코드를 반환하여 두 번째 규약을 지키지 못함.\r\n  - HashMap은 해시코드가 다른 엔트리끼리는 동치성 비교를 시도조차 하지 않도록 최적화되어 있음\r\n  \r\n- 좋은 해시 함수라면 서로 다른 인스턴스에 다른 해시코드를 반환한다.\r\n  - hashCode의 세 번째 규약이 요구하는 속성.\r\n- 이상적인 해시 함수는 주어진 (서로 다른) 인스턴스들을 32비트 정수 범위에 균일하게 분배해야 함.  \r\n\r\n<br/>\r\n\r\n### 좋은 hashCode를 작성하는 요령\r\n\r\n1. int 변수 result를 선언한 후 값 c로 초기화한다. 이때 c는 해당 객체의 첫 번째 핵심 필드를 단계 2.a 방식으로 계산한 해시코드다\r\n\r\n2. 해당 객체의 나머지 핵심 필드 f 각각에 대해 다음 작업을 수행한다.\r\n    1. 해당 필드의 해시코드 c를 계산한다.\r\n        1. 기본 타입 필드라면, Type.hashCode(f)를 수행한다. Type은 박싱 클래스.\r\n        2. 참조 타입 필드면서 이 클래스의 equals 메서드가 이 필드의 equals를 재귀적으로 호출해 비교한다면, 이 필드의 hashCode를 재귀적으로 호출한다. 계산이 복잡해질 것 같으면 표준형을 만들어 그 표준형의 hashCode를 호출한다. 필드의 값이 null이면 0을 사용.\r\n        3. 필드가 배열이라면, 핵심 원소 각각을 별도 필드처럼 다룬다. 이상의 규칙을 재귀적으로 적용해 각 핵심 원소의 해시코드를 계산한 다음, 단계 2.b 방식으로 갱신한다. 배열에 핵심 원소가 하나도 없다면 단순히 상수(0을 추천)를 사용한다. 모든 원소가 핵심 원소라면 Arrays.hashCode를 사용.\r\n    2. 단계 2.a에서 계산한 해시코드 c로 result를 갱신함.  \r\n    result = 31 * result + c;\r\n3. result를 반환한다.\r\n\r\n<br/>\r\n\r\n- 파생 필드는 해시코드 계산에서 제외해도 됨.\r\n- equals 비교에 사용되지 않은 필드는 '반드시' 제외해야 함.\r\n    - hashCode 두 번째 규약을 어기게 될 위험이 있음.\r\n- 2.b의 곱셈 31 * result는 필드를 곱하는 순서에 따라 result 값이 달라지게 함.\r\n    - 클래스에 비슷한 필드가 여러 개일 때 해시 효과를 크게 높여줌.\r\n    - 31로 정한 이유는 홀수이면서 소수이기 때문.\r\n        - 짝수이고 오버플로가 발생한다면 정보를 잃게 됨.\r\n        - 2를 곱하는 것은 시프트 연산과 같은 결과.\r\n    \r\n<br/>\r\n\r\n### 예시에 요령 적용해보기\r\n\r\n```java\r\n 코드 11-2 전형적인 hashCode 메서드 (70쪽)\r\n@Override public int hashCode() {\r\n    int result = Short.hashCode(areaCode);\r\n    result = 31 * result + Short.hashCode(prefix);\r\n    result = 31 * result + Short.hashCode(lineNum);\r\n    return result;\r\n}\r\n```\r\n- 핵심 필드 3개만을 사용해 간단한 계산만 수행함.\r\n- 비결정적 요소는 전혀 없으므로 동치인 PhoneNumber 인스턴스들은 같은 해시코드를 가질 것.\r\n- 단순하고, 충분히 빠르고, 서로 다른 전화번호들은 다른 해시 버킷들로 제법 훌륭히 분배해줌.\r\n    - 단, 해시 충돌이 더욱 적은 방법을 꼭 써야 한다면 구아바의 com.google.common.hash.Hashing을 참고.\r\n\r\n```java\r\n 코드 11-3 한 줄짜리 hashCode 메서드 - 성능이 살짝 아쉽다. (71쪽)\r\n@Override public int hashCode() {\r\n    return Objects.hash(lineNum, prefix, areaCode);\r\n}\r\n```\r\n- Objects 클래스는 임의의 개수만큼 객체를 받아 해시코드를 계산해주는 정적 메서드인 hash를 제공함.\r\n- 단 한줄로 작성할 수 있으나 아쉽게도 속도는 더 느림.\r\n    - 입력 인수를 담기 위한 배열이 만들어지고, 입력 중 기본 타입이 있다면 박싱, 언박싱도 거쳐야 하기 때문.\r\n- hash 메서드는 성능에 민감하지 않은 상황에서만 사용하자.\r\n\r\n```java\r\n 해시코드를 지연 초기화하는 hashCode 메서드 - 스레드 안정성까지 고려해야 한다. (71쪽)\r\nprivate int hashCode; // 자동으로 0으로 초기화된다.\r\n\r\n@Override public int hashCode() {\r\n    int result = hashCode;\r\n    if (result == 0) {\r\n        result = Short.hashCode(areaCode);\r\n        result = 31 * result + Short.hashCode(prefix);\r\n        result = 31 * result + Short.hashCode(lineNum);\r\n        hashCode = result;\r\n    }\r\n    return result;\r\n}\r\n```\r\n- 클래스가 불변이고 해시코드를 계산하는 비용이 크다면, 매번 새로 계산하기 보다는 캐싱하는 방식을 고려해야 함.\r\n- 이 타입의 객체가 주로 해시의 키로 사용될 것 같다면 인스턴스가 만들어질 때 해시코드를 계산해둬야 하지만 그렇지 않은 경우는 hashCode가 처음 불릴 때 계산하는 지연 초기화 전략을 사용할 수 있음.\r\n    - 필드를 지연 초기화하려면 그 클래스를 스레드 안전하게 만들도록 신경 써야 함.\r\n    \r\n<br/>\r\n\r\n## 주의 사항\r\n\r\n- 성능을 높인답시고 해시코드를 계산할 때 핵심 필드를 생략해서는 안 됨.\r\n    - 속도야 빨라지겠지만, 해시 품질이 나빠져 해시테이블의 성능을 심각하게 떨어뜨릴 수 있음.\r\n    - 어떤 필드는 특정 영역에 몰린 인스턴스들의 해시코드를 넓은 범위로 고르게 퍼트려주는 효과가 있을지도 모르는데 이를 생략한다면 해시테이블의 속도가 선형으로 느려질 것임.\r\n    - 실제 자바 2 전의 String은 최대 16개의 문자만으로 해시코드를 계산했음.\r\n- hashCode가 반환하는 값의 생성 규칙을 API 사용자에게 자세히 공표하지 말자.\r\n    - 그래야 클라이언트가 이 값에 의지하지 않게 되고, 추후에 계산 방식을 바꿀 수 있음.\r\n    \r\n<br/>\r\n\r\n## 핵심 정리\r\n\r\n- equals를 재정의할 때는 hashCode도 반드시 재정의해야 함.\r\n- 재정의한 hashCode는 Object의 API 문서에 기술된 일반 규약을 따라야 하며, 서로 다른 인스턴스라면 되도록 해시코드도 서로 다르게 구현해야 함.\r\n- 이는 조금 따분한 일이지만 AutoValue 프레임워크나 IDE의 힘을 빌리면 된다.","excerpt":"hashCode 재정의 equals를 재정의한 클래스 모두에서 hashCode도 재정의해야 한다. 그렇지 않으면 hashCode 일반 규약을 어기게 되어 해당 클래스의 인스턴스를 HashMap이나 HashSet 같은 컬렉션의 원소로 사용할 때 문제를…","fields":{"slug":"/effective-java-item11/"},"frontmatter":{"date":"Dec 19, 2021","title":"[이펙티브 자바] 11. equals를 재정의하려거든 hashCode도 재정의하라","tags":["java","book"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n## equals를 재정의하지 않는 상황\r\n\r\n1. 각 인스턴스가 본질적으로 고유하다.\r\n    - 값을 표현하는 게 아니라 동작하는 개체를 표현하는 클래스.\r\n    - Thread가 좋은 예.\r\n2. 인스턴스의 '논리적 동치성(logical equality)'을 검사할 일이 없다.\r\n3. 상위 클래스에서 재정의한 equals가 하위 클래스에도 딱 들어맞는다.\r\n    - Set 구현체는 AbstractSet이 구현한 equals를 상속받아 씀.\r\n    - List 구현체들은 AbstractList, Map 구현체들은 AbstractMap.\r\n4. 클래스가 private이거나 package-private이고 equals 메서드를 호출할 일이 없다.\r\n\r\n<br/>\r\n\r\n## 그렇다면 equals를 재정의해야 할 때는 언제일까?\r\n\r\n- 객체 식별성(object identity; 두 객체가 물리적으로 같은가)이 아니라 논리적 동치성을 확인해야 하는데, 상위 클래스의 equals가 논리적 동치성을 비교하도록 재정의되지 않았을 때.\r\n    - 주로 값 클래스들이 여기 해당함.\r\n- 값 클래스란 Integer, String처럼 값을 표현하는 클래스를 뜻함.\r\n    - 객체가 같은지가 아니라 값이 같은지를 확인\r\n    - 재정의해두면, 인스턴스는 값을 비교하길 원하는 프로그래머의 기대에 부응함은 물론 Map의 키와 Set의 원소로 사용할 수 있게 된다.\r\n- 값 클래스라 해도, 값이 같은 인스턴스가 둘 이상 만들어지지 않음을 보장하는 인스턴스 통제 클래스라면 equals를 재정의하지 않아도 됨.\r\n    Enum도 마찬가지.\r\n\r\n<br/>\r\n\r\n## equals 메서드 재정의 시 따라야 하는 규약\r\n\r\n- equals 메서드는 동치관계(equivalence relation)를 구현하며, 다음을 만족한다.  \r\n    - 동치관계란 집합을 서로 같은 원소들로 이뤄진 부분집합으로 나누는 연산.  \r\n    - 부분집합을 동치류(equivalence class; 동치 클래스)라 함.\r\n    - equals 메서드가 쓸모 있으려면 모든 원소가 같은 동치류에 속한 어떤 원소와도 서로 교환할 수 있어야 함.\r\n    \r\n### 규약 다섯 가지\r\n\r\n- 반사성(reflexivity): null이 아닌 모든 참조 값 x에 대해, x.equals(x)는 true다.\r\n- 대칭성(symmetry): null이 아닌 모든 참조 값 x,y에 대해, x.equals(y)가 true면 y.equals(x)도 true다.\r\n- 추이성(transitivity): null이 아닌 모든 참조 값 x,y,z에 대해, x.equals(y)가 true이고, y.equals(z)도 true면 x.equals(z)도 true다.\r\n- 일관성(consistency): null이 아닌 모든 참조 값 x,y에 대해, x.equals(y)를 반복해서 호출하면 항상 true를 반환하거나 항상 false를 반환한다.\r\n- null 아님: null이 아닌 모든 참조 값 x에 대해, x.equals(null)은 false다.\r\n\r\n### 반사성\r\n\r\n- 객체는 자기 자신과 같아야 한다는 뜻.\r\n- 이 요건을 어긴 클래스의 인스턴스를 컬렉션에 넣은 다음 contains 메서드를 호출하면 넣은 인스턴스가 없다고 답할 것.\r\n\r\n### 대칭성\r\n\r\n- 두 객체는 서로에 대한 동치 여부에 똑같이 답해야 한다는 뜻.\r\n\r\n```java\r\npublic final class CaseInsensitiveString {\r\n    private final String s;\r\n\r\n    public CaseInsensitiveString(String s) {\r\n        this.s = Objects.requireNonNull(s);\r\n    }\r\n\r\n    // 대칭성 위배!\r\n    @Override\r\n    public boolean equals(Object o) {\r\n        if (o instanceof CaseInsensitiveString)\r\n            return s.equalsIgnoreCase(\r\n                    ((CaseInsensitiveString) o).s);\r\n        if (o instanceof String)  // 한 방향으로만 작동한다!\r\n            return s.equalsIgnoreCase((String) o);\r\n        return false;\r\n    }\r\n}\r\n```\r\n```java\r\nCaseInsensitiveString cis = new CaseInsensitiveString(\"Polish\");\r\nString s = \"polish\";\r\n```\r\n- cis.equals(s)는 true를 반환.  \r\ns.equals(cis)는 false를 반환.\r\n    - 대칭성 위반!\r\n```java\r\nList<CaseInsensitiveString> list = new ArrayList<>();\r\nlist.add(cis);\r\n```\r\n- list.contains(s)를 호출하면 현재의 OpenJDK에서는 false를 반환.\r\n    - OpenJDK 버전이 바뀌거나 다른 JDK에서는 true를 반환하거나 런타임 예외를 던질 수도 있음.\r\n- equals 규약을 어기면 그 객체를 사용하는 다른 객체들이 어떻게 반응할지 알 수 없다.\r\n```java\r\n@Override public boolean equals(Object o) {\r\n    return o instanceof CaseInsensitiveString &&\r\n            ((CaseInsensitiveString) o).s.equalsIgnoreCase(s);\r\n}\r\n```\r\n- 수정된 equals의 모습. CaseInsensitiveString과만 연동하자.\r\n\r\n### 추이성\r\n\r\n- 첫 번째 객체와 두 번째 객체가 같고, 두 번째 객체와 세 번째 객체가 같다면, 첫 번째 객체와 세 번째 객체도 같아야 한다는 뜻.\r\n- 상위 클래스에는 없는 새로운 필드를 하위 클래스에 추가하는 상황을 생각해보자.\r\n```java\r\npublic class Point {\r\n    private final int x;\r\n    private final int y;\r\n\r\n    public Point(int x, int y) {\r\n        this.x = x;\r\n        this.y = y;\r\n    }\r\n\r\n    @Override\r\n    public boolean equals(Object o) {\r\n        if (!(o instanceof Point))\r\n            return false;\r\n        Point p = (Point) o;\r\n        return p.x == x && p.y == y;\r\n    }\r\n}\r\n```\r\n```java\r\npublic class ColorPoint extends Point {\r\n    private final Color color;\r\n\r\n    public ColorPoint(int x, int y, Color color) {\r\n        super(x, y);\r\n        this.color = color;\r\n    }\r\n\r\n    // 코드 10-2 잘못된 코드 - 대칭성 위배! (57쪽)\r\n    @Override\r\n    public boolean equals(Object o) {\r\n        if (!(o instanceof ColorPoint))\r\n            return false;\r\n        return super.equals(o) && ((ColorPoint) o).color == color;\r\n    }\r\n}\r\n```\r\n- 일반 Point를 ColorPoint에 비교한 결과와 그 둘을 바꿔 비교한 결과가 다를 수 있음.\r\n    - Point의 equals는 색상을 무시하고, ColorPoint의 equals는 입력 매개변수의 클래스 종류가 다르다며 매번 false만 반환할 것.\r\n    - 즉, 대칭성을 위배함.\r\n- ColorPoint.equals가 Point와 비교할 때는 색상을 무시하도록 변경하면?\r\n```java\r\n @Override public boolean equals(Object o) {\r\n    if (!(o instanceof Point))\r\n        return false;\r\n\r\n    // o가 일반 Point면 색상을 무시하고 비교한다.\r\n    if (!(o instanceof ColorPoint))\r\n        return o.equals(this);\r\n\r\n    // o가 ColorPoint면 색상까지 비교한다.\r\n    return super.equals(o) && ((ColorPoint) o).color == color;\r\n}\r\n```\r\n- 대칭성을 지켜주지만, 추이성을 위배함.\r\n```java\r\nColorPoint p1 = new ColorPoint(1, 2, Color.RED);\r\nPoint p2 = new Point(1, 2);\r\nColorPoint p3 = new ColorPoint(1, 2, Color.BLUE);\r\n```\r\n- p1.equals(p2), p2.equals(p3)는 true를 반환하지만 p1.equals(p3)는 false를 반환함.\r\n    - p1과 p2, p2와 p3 비교는 색상을 무시했지만, p1과 p3 비교에서는 색상까지 고려했기 때문.\r\n- 또한 이 방식은 무한 재귀에 빠질 위험도 있음.\r\n- 이 현상은 모든 객체 지향 언어의 동치관계에서 나타나는 근본적인 문제.\r\n    - 구체 클래스를 확장해 새로운 값을 추가하면서 equals 규약을 만족시킬 방법은 존재하지 않음.\r\n```java\r\n@Override public boolean equals(Object o) {\r\n    if (o == null || o.getClass() != getClass())\r\n        return false;\r\n    Point p = (Point) o;\r\n    return p.x == x && p.y == y;\r\n}\r\n```\r\n- instanceof 검사를 getClass 검사로 바꾸게 되면?\r\n    - 리스코프 치환 원칙에 위배된다.\r\n        - 리스코프 치환 원칙에 따르면, 어떤 타입에 있어 중요한 속성이라면 그 하위 타입에서도 마찬가지로 중요하다. 따라서 그 타입의 모든 메서드가 하위 타입에서도 똑같이 잘 작동되어야 한다.\r\n        - 즉, Point의 하위 클래스는 정의상 여전히 Point이므로 어디서든 Point로써 활용될 수 있어야 한다.\r\n```java\r\n// 단위 원 안의 모든 점을 포함하도록 unitCircle을 초기화한다. (58쪽)\r\nprivate static final Set<Point> unitCircle = Set.of(\r\n        new Point( 1,  0), new Point( 0,  1),\r\n        new Point(-1,  0), new Point( 0, -1));  \r\npublic static boolean onUnitCircle(Point p) {\r\n    return unitCircle.contains(p);\r\n}\r\n```\r\n\r\n```java\r\npublic class CounterPoint extends Point {\r\n    private static final AtomicInteger counter =\r\n            new AtomicInteger();\r\n\r\n    public CounterPoint(int x, int y) {\r\n        super(x, y);\r\n        counter.incrementAndGet();\r\n    }\r\n    public static int numberCreated() { return counter.get(); }\r\n}\r\n```\r\n- 위와 같은 예시에서 CounterPoint의 인스턴스를 onUnitCircle 메서드에 넘기면 false를 반환할 것.\r\n- Set을 포함하여 대부분의 컬렉션은 주어진 원소를 담고 있는지를 확인하는 작업에 eqauls를 이용함.\r\n    - CounterPoint의 인스턴스는 어떤 Point와도 같을 수 없음.\r\n    - instanceof 기반으로 올바로 구현했다면 CounterPoint 인스턴스를 건네줘도 onUnitCircle 메서드가 제대로 동작할 것.\r\n    \r\n```java\r\npublic class ColorPoint {\r\n    private final Point point;\r\n    private final Color color;\r\n\r\n    public ColorPoint(int x, int y, Color color) {\r\n        point = new Point(x, y);\r\n        this.color = Objects.requireNonNull(color);\r\n    }\r\n\r\n    /**\r\n     * 이 ColorPoint의 Point 뷰를 반환한다.\r\n     */\r\n    public Point asPoint() {\r\n        return point;\r\n    }\r\n\r\n    @Override\r\n    public boolean equals(Object o) {\r\n        if (!(o instanceof ColorPoint))\r\n            return false;\r\n        ColorPoint cp = (ColorPoint) o;\r\n        return cp.point.equals(point) && cp.color.equals(color);\r\n    }\r\n}\r\n```\r\n- 괜찮은 우회 방법으로 컴포지션을 사용하면 됨.\r\n- 자바 라이브러리에도 구체 클래스를 확장해 값을 추가한 클래스가 종종 있음\r\n    - 대표적인 예로 java.sql.Timestamp.\r\n    - java.sql.Timestamp는 java.util.Date를 확장해서 사용.\r\n    - 따라서 섞어 사용하면 엉뚱하게 동작할 수 있으니 주의하자.\r\n- 참고로 추상 클래스의 하위 클래스라면 equals 규약을 지키면서도 값을 추가할 수 있음.\r\n\r\n### 일관성\r\n\r\n- 두 객체가 같다면 (어느 하나 혹은 두 객체 모두가 수정되지 않는 한) 앞으로도 영원히 같아야 한다는 뜻.\r\n- 클래스가 불변이든 가변이든 equals의 판단에 신뢰할 수 없는 자원이 끼어들게 해서는 안 됨.\r\n    - 대표적인 예로 java.net.URL의 equals는 주어진 URL과 매핑된 호스트의 IP 주소를 이용해 비교함.\r\n    - 호스트 이름을 IP 주소로 바꾸려면 네트워크를 통해야 하는데, 그 결과가 항상 같다고 보장할 수 없음.\r\n    - 이렇게 구현한 것은 커다란 실수였으니 절대 따라 해서는 안 된다.\r\n    - equals는 항시 메모리에 존재하는 객체만을 사용한 결정적 계산만 수행하자.\r\n\r\n### null-아님\r\n\r\n- 모든 객체가 null과 같지 않아야 한다는 뜻.\r\n- 입력이 null인지를 확인해 자신을 보호해야 함.\r\n```java\r\n// 명시적 null 검사 - 필요 없다!\r\n@Override\r\npublic boolean equals(Object o) {\r\n    if (o == null) {\r\n        return false;\r\n    }\r\n}\r\n```\r\n- 이런 검사는 필요치 않다.\r\n```java\r\n// 묵시적 null 검사 - 이쪽이 낫다!\r\n@Override\r\npublic boolean equals(Object o) {\r\n    if (!(o instanceof MyType)) {\r\n        return false;\r\n    }\r\n    MyType mt = (MyType) o;\r\n}\r\n```\r\n- equals는 건네받은 객체를 적절히 형변환한 후 필수 필드들의 값을 알아내야 하므로 형변환에 앞서 instanceof 연산자로 입력 매개변수가 올바른 타입인지 검사해야 한다.\r\n\r\n<br/>\r\n\r\n## equals 메서드 구현 방법 단계별 정리\r\n\r\n1. == 연산자를 사용해 입력이 자기 자신의 참조인지 확인한다.\r\n    - 자기 자신이면 true를 반환\r\n2. instanceof 연산자로 입력이 올바른 타입인지 확인한다.\r\n    - 올바른 타입은 equals가 정의된 클래스인 것이 보통이지만, 가끔은 그 클래스가 구현한 특정 인터페이스가 될 수도 있다.\r\n3. 입력을 올바른 타입으로 형변환한다.\r\n4. 입력 객체와 자기 자신의 대응되는 '핵심' 필드들이 모두 일치하는지 하나씩 검사한다.\r\n    - float, double을 제외한 기본 타입 필드는 == 연산자로 비교하고, 참조 타입 필드는 각각의 eqauls 메서드로, float과 double은 Float.compare(float, float), Double.compare(double, double)로 비교한다.\r\n        - Float.NAN, -0.0f, 특수한 부동소수 값을 다뤄야 하기 때문.\r\n        - Float.equals와 Double.equals는 오토박싱을 수반할 수 있어 성능상 좋지 않다.\r\n    - 배열 필드는 원소 각각을 비교하고 배열의 모든 원소가 핵심 필드라면 Arrays.equals 메서드들 중 하나를 사용하자.\r\n    - null도 정상 값으로 취급하는 참조 타입 필드라면 Objects.equals(Object, Object)로 비교해 NullPointerException 발생을 예방하자.\r\n    - 복잡한 필드를 가진 클래스는 필드의 표준형을 저장해두고 표준형끼리 비교하면 훨씬 경제적이다.\r\n    - 어떤 필드를 먼저 비교하느냐가 equals의 성능을 좌우하기도 하므로 최상의 성능을 바란다면 다를 가능성이 더 크거나 비교하는 비용이 싼 필드를 먼저 비교하자.\r\n    - 동기화용 lock 필드 같이 객체의 논리적 상태와 관련 없는 필드는 비교하면 안 된다.\r\n    - 파생 필드는 굳이 비교할 필요는 없지만 비교하는 쪽이 더 빠를 때도 있다.\r\n        - 파생 필드가 객체 전체의 상태를 대표하는 상황 (자신의 영역을 캐시해두는 클래스)\r\n    \r\n- equals를 다 구현했다면 세 가지만 자문해보자. 대칭적인가? 추이성이 있는가? 일관적인가?\r\n    - 자문에서 끝내지 말고 단위 테스트를 작성해 돌려보자.\r\n    - 나머지 요건도 만족해야 하지만, 이 둘이 문제되는 경우는 별로 없다.\r\n    \r\n```java\r\n// 전형적인 equals 메서드의 예\r\npublic final class PhoneNumber {\r\n    private final short areaCode, prefix, lineNum;\r\n\r\n    public PhoneNumber(int areaCode, int prefix, int lineNum) {\r\n        this.areaCode = rangeCheck(areaCode, 999, \"지역코드\");\r\n        this.prefix   = rangeCheck(prefix,   999, \"프리픽스\");\r\n        this.lineNum  = rangeCheck(lineNum, 9999, \"가입자 번호\");\r\n    }\r\n\r\n    private static short rangeCheck(int val, int max, String arg) {\r\n        if (val < 0 || val > max)\r\n            throw new IllegalArgumentException(arg + \": \" + val);\r\n        return (short) val;\r\n    }\r\n\r\n    @Override public boolean equals(Object o) {\r\n        if (o == this)\r\n            return true;\r\n        if (!(o instanceof PhoneNumber))\r\n            return false;\r\n        PhoneNumber pn = (PhoneNumber)o;\r\n        return pn.lineNum == lineNum && pn.prefix == prefix\r\n                && pn.areaCode == areaCode;\r\n    }\r\n\r\n    // 나머지 코드는 생략 - hashCode 메서드는 꼭 필요하다(아이템 11)!\r\n}\r\n```\r\n\r\n<br/>\r\n\r\n## 주의사항\r\n- equals를 재정의할 땐 hashcode도 반드시 재정의하자.\r\n- 너무 복잡하게 해결하려 들지 말자.\r\n    - 필드들의 동치성만 검사해도 equals 규약을 어렵지 않게 지킬 수 있음.\r\n    - 일반적으로 별칭은 비교하지 않는게 좋다.\r\n- Object 외의 타입을 매개변수로 받는 equals 메서드는 선언하지 말자.\r\n    ```java\r\n    // 잘못된 예 - 입력 타입은 반드시 Object여야 한다!\r\n    public boolean equals(MyClass o) {\r\n    }\r\n    ```\r\n    - 재정의가 아니라 다중정의한 것.\r\n    - 기본 equals를 그대로 둔 채로 추가한 것일지라도, 타입을 구체적으로 명시한 equals는 오히려 해가 됨.\r\n    - @Override 애너테이션을 일관되게 사용하면 이러한 실수를 예방할 수 있다.\r\n    \r\n<br/>\r\n\r\n## 매번 직접 equals를 작성해야할까?\r\n\r\n- equals(hashCode도 마찬가지)를 작성하고 테스트하는 일은 지루하고 이를 테스트하는 코드도 항상 뻔함.\r\n- 이 작업을 대신해줄 구글이 만든 AutoValue라는 프레임워크가 있음.\r\n- 또한 대다수의 IDE도 같은 기능을 제공하므로 직접 작성하는 것보다는 IDE에 맡기자. (특별한 경우를 제외하고)\r\n\r\n<br/>\r\n\r\n## 핵심 정리\r\n\r\n- 꼭 필요한 경우가 아니면 equals를 재정의하지 말자.\r\n- 많은 경우에 Object의 equals가 원하는 비교를 정확히 수행해준다.\r\n- 재정의해야 할 때는 그 클래스의 핵심 필드 모두를 빠짐없이, 다섯 가지 규약을 지켜가며 비교해야 한다.","excerpt":"equals를 재정의하지 않는 상황 각 인스턴스가 본질적으로 고유하다. 값을 표현하는 게 아니라 동작하는 개체를 표현하는 클래스. Thread가 좋은 예. 인스턴스의 '논리적 동치성(logical equality)'을 검사할 일이 없다. 상위 클래스…","fields":{"slug":"/effective-java-item10/"},"frontmatter":{"date":"Dec 18, 2021","title":"[이펙티브 자바] 10. equals는 일반 규약을 지켜 재정의하라","tags":["java","book"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n### Cache 구조\r\n\r\n### #1 - Look aside Cache\r\n\r\n### #2 - Write Back\r\n\r\nRedis는 Collection을 제공\r\n\r\n## 왜 Collection이 중요한가?\r\n\r\n### 개발의 편의성\r\n\r\n랭킹 서버를 직접 구현한다면?\r\n\r\n- 가장 간단한 방법\r\n    - DB에 유저의 Score를 저장 order by로 정렬 후 읽어오기\r\n    - 개수가 많아지면 속도에 문제가 발생\r\n        - 디스크를 사용하므로\r\n    - Redis의 Sorted Set을 이용하면, 랭킹을 구현할 수 있음\r\n        - replication도 가능\r\n        - 단, 종속적\r\n\r\n### 개발의 난이도\r\n\r\n- 친구 리스트를 key value 형태로 저장해야 한다면?\r\n- 어떤 문제가 발생할 수 있을까?\r\n    - Race Condition\r\n    - Redis의 경우는 자료구조가 Atomic하기 때문에, 해당 Race Condition을 피할 수 있다.\r\n- 외부의 Collection을 잘 이용하는 것으로, 여러가지 개발 시간을 단축시키고, 문제를 줄여줄 수 있다.\r\n\r\n## Redis 사용 처\r\n\r\n- Remote Data Store\r\n    - A,B,C 서버에서 데이터를 공유하고 싶을 때\r\n- 한대에서만 필요하다면, 전역 변수를 쓰면 되지 않을까?\r\n    - Redis 자체가 Atomic을 보장해준다. (싱글 스레드라)\r\n- 주로 많이 쓰는 곳들\r\n    - 인증 토큰 등을 저장(Strings 또는 hash)\r\n    - Ranking 보드로 사용(Sorted Set)\r\n    - 유저 API Limit\r\n    - 잡 큐(list)\r\n\r\n\r\n## Redis Collections\r\n\r\n- Strings\r\n    - 단일 Key\r\n    - 간단한 sql을 대체한다면?\r\n- List\r\n    - insert\r\n        - LPUSH, RPUSH\r\n    - pop\r\n        - LPOP, RPOP\r\n    - lpop, blpop, rpop, brpop\r\n- Set\r\n    - 데이터가 있는지 없는지만 체크하는 용도\r\n        - 특정 유저를 follow하는 목록\r\n- Sorted Sets\r\n    - 랭킹에 따라서 순서가 바뀌길 바란다면\r\n        - Sorted Sets의 score는 double 타입이기 때문에, 값이 정확하지 않을 수 있다\r\n    - 정렬이 필요한 값이 필요하다면?\r\n    - Score 기준으로 뽑고 싶다면?\r\n- Hash\r\n    - key 밑에 sub key가 존재\r\n    - 간단한 sql을 대체한다면?\r\n\r\n\r\n## Collection 주의 사항\r\n\r\n- 하나의 컬렉션에 너무 많은 아이템을 담으면 좋지 않음\r\n    - 10000개 이하 몇천개 수준으로 유지하는게 좋음\r\n- Expire는 Collection의 item 개별로 걸리지 않고 전체 Collection에 대해서만 걸림\r\n    - 즉 해당 10000개 아이템 가진 Collection에 expire가 걸려있다면 그 시간 후에 10000개의 아이템 모두 삭제\r\n\r\n\r\n## Redis 운영\r\n\r\n- 메모리 관리를 잘하자\r\n- O(N) 관련 명령어는 주의하자.\r\n- Replication\r\n\r\n## 메모리 관리\r\n\r\n- Redis는 In-Memory Data Store\r\n- Physical Memory 이상을 사용하면 문제가 발생\r\n    - swap이 있다면 swap 사용으로 해당 메모리 page 접근시마다 늦어짐\r\n    - swap이 없다면?\r\n- Maxmemory를 설정하더라도 이보다 더 사용할 가능성이 큼.\r\n    - redis는 자신이 사용하는 메모리를 정확하게 알 수가 없다\r\n- RSS 값을 모니터링 해야함\r\n- 많은 업체가 현재 메모리를 사용해서 swap을 쓰고 있다는 것을 모를 때가 많음.\r\n- 큰 메모리를 사용하는 instance 하나보다는 적은 메모리를 사용하는 instance 여러 개가 안전함\r\n    - 관리하기 귀찮지만 운영의 안전성이 높아짐\r\n- Redis는 메모리 파편화가 발생할 수 있음. 4.x대부터 메모리 파편화를 줄이도록 jemalloc에 힌트를 주는 기능이 들어갔으나, jemalloc 버전에 따라서 다르게 동작할 수 있음.\r\n- 3.x대 버전의 경우\r\n    - 실제 used memory는 2gb로 보고되지만 11gm의 rss를 사용하는 경우가 자주 발생\r\n- 다양한 사이즈를 가지는 데이터보다는 유사한 크기의 데이터를 가지는 경우가 유리\r\n\r\n## 메모리가 부족할 때는?\r\n\r\n- Cache is Cash\r\n    - 좀 더 메모리 많은 장비로 마이그레이션\r\n    - 메모리 빡빡하면 마이그레이션 중에 문제가 발생할 수도\r\n- 있는 데이터 줄이기\r\n\r\n## 메모리를 줄이기 위한 설정\r\n\r\n- 기본적으로 Collection들은 다음과 같은 자료구조를 사용\r\n    - Hash → HashTable을 하나 더 사용\r\n    - Sorted Set → Skiplist와 HashTable을 이용\r\n    - Set → HashTable 사용\r\n    - 해당 자료구조들은 메모리를 많이 사용함\r\n- Ziplist를 이용하자\r\n\r\n## Ziplist 구조\r\n\r\n- In-Memory 특성 상, 적은 개수라면 선형 탐색을 하더라도 빠르다.\r\n- List, hash, sorted set 등을 ziplist로 대체해서 처리를 하는 설정이 존재\r\n\r\n## O(N) 관련 명령어는 주의하자\r\n\r\n- Redis는 Single Threaded\r\n    - Redis가 동시에 여러 개의 명령을 처리할 수 있을까?\r\n    - 참고로 단순한 get/set의 경우 초당 10만 TPS 이상 가능(CPU 속도에 영향을 받는다)\r\n    - Packet으로 하나의 Command가 완성되면 processCommand에서 실제로 실행됨\r\n\r\n\r\n## Single Threaded의 의미\r\n\r\n- 한번에 하나의 명령만 수행 가능\r\n    - 그럼 긴 시간이 필요한 명령을 수행하면?\r\n    - 망합니다\r\n\r\n\r\n## 대표적인 O(N) 명령들\r\n\r\n- KEYS\r\n- FLUSHALL, FLUSHDB\r\n- Delete Collections\r\n- Get All Collections\r\n\r\n## 대표적인 실수 사례\r\n\r\n- Key가 백만개 이상인데 확인을 위해 KEYS 명령을 사용하는 경우\r\n    - 모니터링 스크립트가 1초에 한번씩 KEYS를 호출하는 경우도..\r\n- 아이템이 몇만개든 hash, sorted set, set에서 모든 데이터를 가져오는 경우\r\n- 예전에 Spring security oauth RedisTokenStore\r\n\r\n## KEYS는 어떻게 대체할 것인가?\r\n\r\n- scan 명령을 사용하는 것으로 하나의 긴 명령을 짧은 여러번의 명령으로 바꿀 수 있다\r\n\r\n## Collection의 모든 item을 가져와야 할 때?\r\n\r\n- Collection의 일부만 가져오거나..\r\n    - Sorted Set\r\n- 큰 Collection을 작은 여러개의 Collection으로 나눠서 저장\r\n    - Userranks → Userrank1, 2, 3\r\n    - 하나당 몇너개 안쪽으로 저장하는게 좋음\r\n\r\n\r\n## Spring security oauth RedisTokenStore 이슈\r\n\r\n- Access Token의 저장을 List(O(N)) 자료구조를 통해서 이루어짐\r\n    - 검색, 삭제시에 모든 item을 매번 찾아봐야 함\r\n        - 100만개 쯤 되면 전체 성능에 영향을 줌\r\n    - 현재는 Set(O(1))을 이용해서 검색, 삭제를 하도록 수정되어 있음\r\n\r\n\r\n## Redis Replication\r\n\r\n- Async Replication\r\n    - Replication Lag 발생할 수 있다\r\n        - 틈 사이에 데이터가 다를 수 있다\r\n- Replicaof (≥5.0.0) or slaveof 명령으로 설정 가능\r\n    - Replicaof hostname port\r\n- DBMS로 보면 statement replication가 유사\r\n- Replication 설정 과정\r\n    - Secondary에 replicaof or slaveof 명령을 전달\r\n    - Secondary는 Primary에 sync 명령 전달\r\n    - Primary는 현재 메모리 상태를 저장하기 위해\r\n        - Fork\r\n    - Fork한 프로세서는 현재 메모리 정보를 disk에 dump\r\n    - 해당 정보를 secondary에 전달\r\n    - Fork 이후의 데이터를 secondary에 계속 전달\r\n\r\n\r\n## Redis Replication 시 주의할 점\r\n\r\n- Replication 과정에서 fork가 발생하므로 메모리 부족이 발생할 수 있음\r\n- Redis-cli —rdb 명령은 현재 상태의 메모리 스냅샷을 가져오므로 같은 문제를 발생시킴\r\n- AWS나 클라우드의 Redis는 좀 다르게 구현되어서 좀 더 해당 부분이 안정적\r\n- 많은 대수의 Redis 서버가 Replica를 두고 있다면\r\n    - 네트웍 이슈나, 사람의 작업으로 동시에 replication이 재시도 되도록 하면 문제가 발생할 수 있음\r\n    - ex) 같은 네트웍 안에서 30GB를 쓰면 Redis Master 100대 정도가 리플리케이션을 동시에 재시작하면 어떤 일이 벌어질 수 있을까?\r\n\r\n\r\n## redis.conf 권장 설정 Tip\r\n\r\n- Maxclient 설정 50000\r\n- RDB/AOF 설정 off\r\n- 특정 commands disable\r\n    - Keys\r\n    - AWS의 ElasticCache는 이미 하고 있음\r\n- 전체 장애의 90% 이상이 KEYS와 SAVE 설정을 사용해서 발생\r\n- 적절한 ziplist 설정\r\n\r\n## Redis 데이터 분산\r\n\r\n- 데이터의 특성에 따라서 선택할 수 있는 방법이 달라진다\r\n    - Cache 일때는 우아한 Reids\r\n    - Persistent 해야하면 안 우아한 Reids\r\n        - Open the hellgate\r\n\r\n\r\n## 데이터 분산 방법\r\n\r\n- Application\r\n    - Consistent Hashing\r\n        - twemproxy를 사용하는 방법으로 쉽게 사용 가능\r\n    - Sharding\r\n- Redis Cluster\r\n\r\n## Sharding\r\n\r\n- 데이터를 어떻게 나눌것인가?\r\n- 데이터를 어떻게 찾을것인가?\r\n- 하나의 데이터를 모든 서버에서 찾아야 하면?\r\n- 상황마다 샤딩 전략이 달라짐\r\n\r\n## Range\r\n\r\n- 그냥 특정 Range를 정의하고 해당 Range에 속하면 거기에 저장\r\n\r\n## Indexed\r\n\r\n- 해당 Key가 어디에 저장되어야 할 관리 서버가 따로 존재\r\n\r\n## Monitoring Factor\r\n\r\n- Reids Info를 통한 정보\r\n    - RSS\r\n    - Used Memory\r\n    - Connection 수\r\n    - 초당 처리 요청 수\r\n- System\r\n    - CPU\r\n    - Disk\r\n    - Network rx/tx\r\n\r\n\r\n## CPU가 100%를 칠 경우\r\n\r\n- 처리량이 매우 많다면?\r\n    - 좀 더 CPU 성능이 좋은 서버로 이전\r\n    - 실제 CPU 성능에 영향을 받음\r\n        - 그러나 단순 get/set은 초당 10만 이상 처리가능\r\n- O(N) 계열의 특정 명령이 많은 경우\r\n    - Monitor 명령을 통해 특정 패턴을 파악하는 것이 필요\r\n    - Monitor 잘못쓰면 부하로 해당 서버에 더 큰 문제를 일으킬 수도 있음(짧게 쓰는게 좋음)\r\n\r\n\r\n## 결론\r\n\r\n- 기본적으로 Redis는 매우 좋은 툴\r\n- 그러나 메모리를 빡빡하게 쓸 경우, 관리하기가 어려움\r\n    - 32기가 장비라면 24기가 이상 사용하면 장비 증설을 고려하는 것이 좋음\r\n    - write가 heavy할 때는 migration도 매우 주의해야함\r\n- Client-output-buffer-limit 설정이 필요\r\n\r\n## Redis as Cache\r\n\r\n- Cahce일 경우는 문제가 적게 발생\r\n    - Redis가 문제가 있을 때 DB등의 부하가 어느정도 증가하는 지 확인 필요\r\n    - Consistent Hashing도 실제 부하를 아주 균등하게 나누지는 않음. Adaptive Consistent Hashing을 이용해 볼 수도 있음.\r\n\r\n## Redis as Persistent Store\r\n\r\n- Persistent Store의 경우\r\n    - 무조건 Primary/Secondary 구조로 구성이 필요함\r\n    - 메모리를 절대로 빡빡하게 사용하면 안됨.\r\n        - 정기적인 migration이 필요\r\n        - 가능하면 자동화 툴을 만들어서 이용\r\n    - RDB/AOF가 필요하다면 Secondary에서만 구동\r\n- 답이 별로 없다.\r\n    - 최대한 돈을 많이 투자.\r\n    - 메모리 덜 쓰고\r\n    - 자주 체크해주고","excerpt":"Cache 구조 #1 - Look aside Cache #2 - Write Back Redis는 Collection을 제공 왜 Collection이 중요한가? 개발의 편의성 랭킹 서버를 직접 구현한다면? 가장 간단한 방법 DB에 유저의 Score를 …","fields":{"slug":"/woowa-redis/"},"frontmatter":{"date":"Dec 18, 2021","title":"우아한레디스를 보고 정리","tags":["redis"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"- 자바 라이브러리에는 close 메서드를 호출해 직접 닫아줘야 하는 자원이 많다.\r\n    - InputStream, OutputStream, java.sql.Connection 등이 좋은 예.\r\n    - 자원 닫기는 클라이언트가 놓치기 쉬워서 예측할 수 없는 성능 문제로 이어지기도 함.\r\n    - finalizer를 안전망으로 활용해도 믿을만하지 못함.\r\n\r\n<br/>\r\n\r\n## try-finally\r\n\r\n- 전통적으로 닫힘을 보장하는 수단으로 try-finally가 쓰였다.\r\n\r\n    ```java\r\n    static String firstLineOfFile(String path) throws IOException {\r\n        BufferedReader br = new BufferedReader(new FileReader(path));\r\n        try {\r\n            return br.readLine();\r\n        } finally {\r\n            br.close();\r\n        }\r\n    }\r\n    ```\r\n\r\n- 자원을 하나 더 사용하면 이러하다.\r\n\r\n    ```java\r\n    static void copy(String src, String dst) throws IOException {\r\n        InputStream in = new FileInputStream(src);\r\n        try {\r\n            OutputStream out = new FileOutputStream(dst);\r\n            try {\r\n                byte[] buf = new byte[BUFFER_SIZE];\r\n                int n;\r\n                while ((n = in.read(buf)) >= 0)\r\n                    out.write(buf, 0, n);\r\n            } finally {\r\n                out.close();\r\n            }\r\n        } finally {\r\n            in.close();\r\n        }\r\n    }\r\n    ```\r\n\r\n- try-finally 문은 미묘한 결점이 있다.\r\n    - 기기에 물리적인 문제가 생긴다면 firstLineOfFile 메서드 안의 readLine 메서드가 예외를 던지고, 같은 이유로 close 메서드도 실패할 것임.\r\n    - 이 상황이라면 두 번째 예외가 첫 번째 예외를 완전히 집어삼켜 버린다.\r\n        - 스택 추적 내역에 첫 번째 예외에 관한 정보는 남지 않게 되어, 실제 시스템에서의 디버깅을 몹시 어렵게 함.\r\n\r\n<br/>\r\n\r\n## try-with-resources\r\n\r\n- 위 문제들은 try-with-resources 덕에 모두 해결되었음.\r\n- 이 구조를 사용하려면 해당 자원이 AutoCloseable 인터페이스를 구현해야 함.\r\n\r\n    ```java\r\n    static String firstLineOfFile(String path) throws IOException {\r\n        try (BufferedReader br = new BufferedReader(\r\n                new FileReader(path))) {\r\n            return br.readLine();\r\n        }\r\n    }\r\n    ```\r\n\r\n    ```java\r\n    static void copy(String src, String dst) throws IOException {\r\n        try (InputStream   in = new FileInputStream(src);\r\n             OutputStream out = new FileOutputStream(dst)) {\r\n            byte[] buf = new byte[BUFFER_SIZE];\r\n            int n;\r\n            while ((n = in.read(buf)) >= 0)\r\n                out.write(buf, 0, n);\r\n        }\r\n    }\r\n    ```\r\n\r\n- try-with-resources 버전이 짧고 읽기 수월할 뿐 아니라 문제를 진단하기도 훨씬 좋음.\r\n    - firstLineOfFile 메서드를 보면 readLine과 close 호출 양쪽에서 예외가 발생하면, close에서 발생한 예외는 숨겨지고 readLine에서 발생한 예외가 기록됨.\r\n    - 프로그래머에게 보여줄 예외 하나만 보존되고 여러 개의 다른 예외가 숨겨질 수도 있음.\r\n    - 숨겨진 예외들은 그냥 버려지지 않고, 스택 추적 내역에 ‘숨겨졌다(suppressed)’는 꼬리표를 달고 출력됨.\r\n- try-finally 처럼 catch 절을 쓸 수 있음.\r\n    - catch 덕분에 try 문을 더 중첩하지 않고도 다수의 예외를 처리할 수 있음\r\n\r\n        ```java\r\n        static String firstLineOfFile(String path, String defaultVal) {\r\n            try (BufferedReader br = new BufferedReader(\r\n                    new FileReader(path))) {\r\n                return br.readLine();\r\n            } catch (IOException e) {\r\n                return defaultVal;\r\n            }\r\n        }\r\n        ```\r\n\r\n<br/>\r\n\r\n## 핵심 정리\r\n\r\n- 꼭 회수해야 하는 자원을 다룰 때는 try-finally 말고, try-with-resources를 사용하자.\r\n- 코드는 더 짧고 분명해지고, 만들어지는 예외 정보도 훨씬 유용하다.\r\n- try-finally로 작성하면 실용적이지 못할 만큼 코드가 지저분해지는 경우라도, try-with-resources로는 정확하고 쉽게 자원을 회수할 수 있다.","excerpt":"자바 라이브러리에는 close 메서드를 호출해 직접 닫아줘야 하는 자원이 많다. InputStream, OutputStream, java.sql.Connection 등이 좋은 예. 자원 닫기는 클라이언트가 놓치기 쉬워서 예측할 수 없는 성능 문제로 …","fields":{"slug":"/effective-java-item9/"},"frontmatter":{"date":"Dec 17, 2021","title":"[이펙티브 자바] 9. try-finally보다는 try-with-resources를 사용하라","tags":["java","book"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n- 자바는 두 가지 객체 소멸자를 제공함.\r\n- finalizer는 예측할 수 없고, 상황에 따라 위험할 수 있어 일반적으로 불필요하다.\r\n    - 오동작, 낮은 성능, 이식성 문제의 원인이 되기도 함.\r\n    - 자바 9에서는 deprecated API로 지정하고 cleaner를 대안으로 소개함.\r\n- cleaner는 finalizer보다는 덜 위험하지만, 여전히 예측할 수 없고, 느리고, 일반적으로 불필요하다.\r\n- finalizer와 cleaner는 즉시 수행된다는 보장이 없음.\r\n    - 객체에 접근할 수 없게 된 후 finalizer나 cleaner가 실행되기까지 얼마나 걸릴지 알 수 없음.\r\n    - 즉, finalizer와 cleaner로는 제때 실행되어야 하는 작업은 절대 할 수 없음.\r\n        - 예를 들어 시스템이 동시에 열 수 있는 파일 개수에 한계가 있기에 파일 닫기 작업을 맡기면 중대한 오류를 일으킬 수 있음.\r\n    - 얼마나 신속히 수행할지는 전적으로 가비지 컬렉터 알고리즘에 달렸음.\r\n- 클래스에 finalizer를 달아두면 그 인스턴스의 자원 회수가 제멋대로 지연될 수 있음\r\n    - cleaner는 자신을 수행할 스레드를 제어할 수 있다는 면에서 조금 낫다.\r\n    - 하지만 여전히 백그라운드에서 수행되며 gc의 통제하에 있으니 즉각 수행되리라는 보장이 없음.\r\n- finalizer나 cleaner의 수행 여부조차 보장하지 않음.\r\n    - 상태를 영구적으로 수정하는 작업에서는 절대 finalizer나 cleaner에 의존해서는 안 됨.\r\n    - 예를 들어 DB와 같은 공유 자원의 영구 lock 해제를 finalizer나 cleaner에 맡겨 놓으면 분산 시스템 전체가 서서히 멈출 것이다.\r\n    - System.gc나 System.runFinalization 메서드도 실행될 가능성을 높여줄 수 있으나, 보장해주진 않음.\r\n- finalizer 동작 중 발생한 예외는 무시되며 처리할 작업이 남았더라도 그 순간 종료됨.\r\n    - 경고조차 출력하지 않음.\r\n    - cleaner를 사용하는 라이브러리는 자신의 스레드를 통제하기 때문에 이러한 문제가 발생하지는 않음.\r\n- finalizer와 cleaner는 심각한 성능 문제도 동반함.\r\n    - 객체를 생성하고 가비지 컬렉터가 수거하기까지 걸린 시간\r\n    - AutoCloseable - 12ns\r\n    - finalizer - 550ns, cleaner - 500ns\r\n- finalizer 사용한 클래스는 finalizer 공격에 노출되어 심각한 보안 문제를 일으킬 수도 있음.\r\n    - 생성자나 직렬화 과정에서 예외가 발생하면, 생성되다 만 객체에서 악의적인 하위 클래스의 finalizer가 수행될 수 있게 됨.\r\n    - 이 finalizer는 정적 필드에 자신의 참조를 할당하여 gc가 수집하지 못하게 막을 수 있음.\r\n    - 일그러진 객체가 만들어지고 나면, 이 객체의 메서드를 호출해 애초에는 허용되지 않았을 작업을 수행하는 건 일도 아님.\r\n    - 위 예시가 있는 [블로그](https://yangbongsoo.tistory.com/8?category=919799) 를 참고하자.\r\n    - 객체 생성을 막으려면 생성자에서 예외를 던지는 것만으로 충분하지만, finalizer가 있다면 그렇지도 않음.\r\n    - final 클래스들은 하위 클래스를 만들 수 없으니 이 공격에서 안전하다.\r\n    - final이 아닌 클래스를 finalizer 공격으로부터 방어하려면 아무 일도 하지 않는 finalize 메서드를 만들고 final을 선언하자.\r\n\r\n- 그렇다면 파일이나 스레드 등 종료해야 할 자원을 담고 있는 객체의 클래스에서 finalizer나 cleaner를 대신해줄 묘안은 무엇인가?\r\n    - AutoCloseable을 구현해주고, 클라이언트에서 인스턴스를 다 쓰고 나면 close 메서드를 호출하면 된다. (일반적으로 try-with-resourses를 사용)\r\n\r\n- finalizer와 cleaner의 적절한 쓰임새가 두 가지 정도 있다.\r\n    1. 자원의 소유자가 close 메서드를 호출하지 않는 것에 대비한 안전망 역할.\r\n        - 늦게라도 해주는 것이 아예 안 하는 것보다는 나으니 작성한다.\r\n        - FileInputStream, FileOutputStream, ThreadPoolExecutor가 대표적\r\n    2. 네이티브 피어(native peer)와 연결된 객체\r\n        - 네이티브 피어란 일반 자바 객체가 네이티브 메서드를 통해 기능을 위임한 네이티브 객체를 말함.\r\n        - gc가 네이티브 객체까지 회수하지 못하니 cleaner나 finalizer를 사용하기 적당한 작업임.\r\n        - 단, 성능 저하를 감당할 수 있고 네이티브 피어가 심각한 자원을 가지고 있지 않을 때에만 해당됨.\r\n\r\n- cleaner를 안전망으로 사용하기 조금 까다롭다.\r\n\r\n    ```java\r\n    public class Room implements AutoCloseable {\r\n        private static final Cleaner cleaner = Cleaner.create();\r\n    \r\n        // 청소가 필요한 자원. 절대 Room을 참조해서는 안 된다!\r\n        private static class State implements Runnable {\r\n            int numJunkPiles; // Number of junk piles in this room\r\n    \r\n            State(int numJunkPiles) {\r\n                this.numJunkPiles = numJunkPiles;\r\n            }\r\n    \r\n            // close 메서드나 cleaner가 호출한다.\r\n            @Override public void run() {\r\n                System.out.println(\"Cleaning room\");\r\n                numJunkPiles = 0;\r\n            }\r\n        }\r\n    \r\n        // 방의 상태. cleanable과 공유한다.\r\n        private final State state;\r\n    \r\n        // cleanable 객체. 수거 대상이 되면 방을 청소한다.\r\n        private final Cleaner.Cleanable cleanable;\r\n    \r\n        public Room(int numJunkPiles) {\r\n            state = new State(numJunkPiles);\r\n            cleanable = cleaner.register(this, state);\r\n        }\r\n    \r\n        @Override public void close() {\r\n            cleanable.clean();\r\n        }\r\n    }\r\n    ```\r\n\r\n    - State의 run 메서드는 cleanable에 의해 딱 한 번만 호출될 것임.\r\n    - run 메서드가 호출되는 상황은 둘 중 하나.\r\n        - 보통은 Room의 close 메서드를 호출할 때.\r\n            - close 메서드에서 Cleanable의 clean을 호출하면 이 메서드 안에서 run을 호출한다.\r\n        - gc가 Room을 회수할 때까지 클라이언트가 close를 호출하지 않는다면, cleaner가 State의 run 메서드를 호출해줄 것.\r\n    - State 인스턴스는 '절대로' Room 인스턴스를 참조해서는 안 된다.\r\n        - 참조하면 순환참조가 생겨 gc가 Room 인스턴스를 회수해갈 기회가 오지 않음.\r\n        - 정적 중첩 클래스로 구성한 이유도 여기에 있음.\r\n        - 정적이 아닌 중첩 클래스는 자동으로 바깥 객체의 참조를 갖게 됨.\r\n            - 람다 역시 바깥 객체의 참조를 갖기 쉬우니 사용하지 말자.\r\n\r\n- Room 생성을 try-with-resources 블록으로 감쌌다면 자동 청소는 전혀 필요하지 않음.\r\n\r\n    ```java\r\n    public class Adult {\r\n        public static void main(String[] args) {\r\n            try (Room myRoom = new Room(7)) {\r\n                System.out.println(\"안녕~\");\r\n            }\r\n        }\r\n    }\r\n    ```\r\n\r\n    - \"안녕~\"을 출력한 후, 이어서 \"방 청소\"를 출력한다.\r\n\r\n- 아래의 경우는 \"방 청소\"가 출력되는 것을 예측할 수 없음.\r\n\r\n    ```java\r\n    public class Teenager {\r\n        public static void main(String[] args) {\r\n            new Room(99);\r\n            System.out.println(\"Peace out\");\r\n    \r\n            // 다음 줄의 주석을 해제한 후 동작을 다시 확인해보자.\r\n            // 단, 가비지 컬렉러를 강제로 호출하는 이런 방식에 의존해서는 절대 안 된다!\r\n    //      System.gc();\r\n        }\r\n    }\r\n    ```\r\n\r\n    - cleaner 명세는 이렇게 적혀 있음.\r\n\r\n      > System.exit을 호출할 때의 cleaner 동작은 구현하기 나름이다. 청소가 이뤄질지는 보장하지 않는다.\r\n    >\r\n    - System.gc()를 추가하는 것으로 종료 전에 \"방 청소\"를 출력할 수 있었지만, 보장할 수 없다.\r\n\r\n\r\n## 핵심 정리\r\n\r\n- cleaner(자바 8까지는 finalizer)는 안전망 역할이나 중요하지 않은 네이티브 자원 회수용으로만 사용하자.\r\n- 이런 경우라도 불확실성과 성능 저하에 주의해야 한다.","excerpt":"자바는 두 가지 객체 소멸자를 제공함. finalizer는 예측할 수 없고, 상황에 따라 위험할 수 있어 일반적으로 불필요하다. 오동작, 낮은 성능, 이식성 문제의 원인이 되기도 함. 자바 9에서는 deprecated API로 지정하고 cleaner…","fields":{"slug":"/effective-java-item8/"},"frontmatter":{"date":"Dec 16, 2021","title":"[이펙티브 자바] 8. finalizer와 cleaner 사용을 피하라","tags":["java","book"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n- 자바와 같이 가비지 컬렉터를 갖춘 언어를 사용하기에 자칫 메모리 관리에 더 이상 신경 쓰지 않아도 된다고 오해할 수 있는데, 절대 사실이 아니다.\r\n\r\n```java\r\npublic class Stack {\r\n    private Object[] elements;\r\n    private int size = 0;\r\n    private static final int DEFAULT_INITIAL_CAPACITY = 16;\r\n\r\n    public Stack() {\r\n        elements = new Object[DEFAULT_INITIAL_CAPACITY];\r\n    }\r\n\r\n    public void push(Object e) {\r\n        ensureCapacity();\r\n        elements[size++] = e;\r\n    }\r\n\r\n    public Object pop() {\r\n        if (size == 0)\r\n            throw new EmptyStackException();\r\n        return elements[--size];\r\n    }\r\n\r\n    /**\r\n     * 원소를 위한 공간을 적어도 하나 이상 확보한다.\r\n     * 배열 크기를 늘려야 할 때마다 대략 두 배씩 늘린다.\r\n     */\r\n    private void ensureCapacity() {\r\n        if (elements.length == size)\r\n            elements = Arrays.copyOf(elements, 2 * size + 1);\r\n    }\r\n}\r\n```\r\n\r\n- 이 스택을 사용하는 프로그램을 오래 실행하다 보면 '메모리 누수'로 점차 가비지 컬렉션 활동과 메모리 사용량이 늘어나 결국 성능이 저하될 것이다.\r\n- 상대적으로 드문 경우긴 하지만 심할 때는 디스크 페이징이나 OutOfMemoryError를 일으켜 프로그램이 예기치 않게 종료되기도 한다.\r\n- 그렇다면 어디서 메모리 누수가 일어날까?\r\n    - 이 코드에서는 스택이 커졌다가 줄어들었을 때 스택에서 꺼내진 객체들을 가비지 컬렉터로 회수하지 않는다. (프로그램에서 그 객체들을 더 이상 사용하지 않더라도)\r\n    - 다 쓴 참조(obsolete reference)를 여전히 가지고 있기 때문이다.\r\n        - 다 쓴 참조란 문자 그대로 앞으로 다시 쓰지 않을 참조를 뜻한다.\r\n        - elements 배열의 '활성 영역' 밖의 참조들이 모두 여기에 해당됨.\r\n        - 활성 영역은 인덱스가 size보다 작은 원소들로 구성.\r\n- 객체 참조 하나를 살려두면 가비지 컬렉터는 그 객체뿐 아니라 그 객체가 참조하는 모든 객체를 회수해가지 못함.\r\n    - 단 몇 개의 객체가 매우 많은 객체를 회수되지 못하게 할 수 있고 잠재적으로 성능에 악영향을 줄 수 있음.\r\n- 해당 참조를 다 썼을 때 null 처리(참조 해제)하면 해결될 수 있다.\r\n\r\n    ```java\r\n    public Object pop() {\r\n          if (size == 0)\r\n              throw new EmptyStackException();\r\n          Object result = elements[--size];\r\n          elements[size] = null; // 다 쓴 참조 해제\r\n          return result;\r\n    }\r\n    ```\r\n\r\n    - null 처리를 통해 실수로 사용할 때 NullPointerException을 던지며 종료되는 이점을 가질 수 있음.\r\n    - 단, 객체 참조를 null 처리하는 일은 예외적인 경우여야 함.\r\n        - 다 쓴 참조를 해제하는 가장 좋은 방법은 그 참조를 담은 변수를 유효 범위(scope) 밖으로 밀어내는 것임.\r\n            - 메서드, for문에서만 사용하는 지역변수 등 변수의 범위를 최소가 되게 정의하면 됨.\r\n        - 참고로 ArrayList의 remove도 null 처리를 해준다.\r\n\r\n            ![Untitled (91)](https://user-images.githubusercontent.com/62014888/146503206-2dabd7a6-4e1e-41a5-9e95-639de4dbd096.png)\r\n\r\n- 그렇다면 null 처리는 언제?\r\n    - 자기 메모리를 직접 관리할 때!\r\n    - 이 스택의 경우 객체 참조를 담는 elements 배열로 저장소 풀을 만들어 원소들을 관리함.\r\n    - 가비지 컬렉터가 보기에는 비활성 영역에서 참조하는 객체도 똑같이 유효한 객체이므로 프로그래머는 비활성 영역이 되는 순간 null 처리해서 해당 객체를 더는 쓰지 않을 것임을 가비지 컬렉터에 알려야 함.\r\n    - 자기 메모리를 직접 관리하는 클래스라면 프로그래머는 항시 메모리 누수에 주의해야 함.\r\n\r\n- 캐시 역시 메모리 누수를 일으키는 주범임.\r\n    - 캐시 외부에서 key를 참조하는 동안만 엔트리가 살아 있는 캐시가 필요한 상황이라면 WeakHashMap을 사용해 캐시를 만들자.\r\n    - 다 쓴 엔트리는 그 즉시 자동으로 제거될 것임.\r\n    - 단, WeakHashMap은 이러한 상황에서만 유용하다는 사실을 기억하자.\r\n    - WeakHashMap의 간단한 캐시 예시는 [블로그](http://blog.breakingthat.com/2018/08/26/java-collection-map-weakhashmap/) 참고.\r\n    - 캐시 엔트리의 유효 기간을 정확히 정의하기 어려울 때는 쓰지 않는 엔트리를 이따금 청소해줘야 함.\r\n        - (ScheduledThreadPoolExecutor 같은) 백그라운드 스레드를 활용\r\n        - 캐시에 새 엔트리를 추가할 때 부수 작업으로 수행하는 방법이 있음.\r\n            - LinkedHashMap은 removeEldestEntry 메서드를 써서 후자의 방식으로 처리\r\n            - 간단하게 얘기하면 removeEldestEntry를 오버라이딩하고 직접 구현하여 엔트리 개수에 따라 추가할 때 오래된 엔트리를 삭제하는 방식으로 만들 수도 있다. 예시는 [블로그](https://javafactory.tistory.com/735) 참고\r\n        - 더 복잡한 캐시를 만들고 싶다면 java.lang.ref 패키지를 직접 활용해야 할 것이다.\r\n            - Reference 클래스 관련 내용으로 필요한 경우 더 공부해야 할 듯하다.\r\n            - [GC, Reference 클래스 관련된 글](https://d2.naver.com/helloworld/329631) 참고\r\n\r\n- 메모리 누수의 세 번째 주범은 바로 리스너(listener) 혹은 콜백(callback)이라 부르는 것이다.\r\n    - 클라이언트가 콜백을 등록만 하고 명확히 해지하지 않는다면, 뭔가 조치해주지 않는 한 콜백은 계속 쌓여갈 것.\r\n    - 콜백을 약한 참조(weak reference)로 저장하면 가비지 컬렉터가 즉시 수거해간다.\r\n        - 예를 들어 WeakHahMap에 키로 저장.\r\n\r\n\r\n## 핵심 정리\r\n\r\n- 메모리 누수는 겉으로 잘 드러나지 않아 시스템에 수년간 잠복하는 사례도 있다.\r\n- 이런 누수는 철저한 코드 리뷰나 힙 프로파일러 같은 디버깅 도구를 동원해야만 발견되기도 한다.\r\n- 그래서 이런 종류의 문제는 예방법을 익혀두는 것이 중요하다!","excerpt":"자바와 같이 가비지 컬렉터를 갖춘 언어를 사용하기에 자칫 메모리 관리에 더 이상 신경 쓰지 않아도 된다고 오해할 수 있는데, 절대 사실이 아니다. 이 스택을 사용하는 프로그램을 오래 실행하다 보면 '메모리 누수'로 점차 가비지 컬렉션 활동과 메모리 …","fields":{"slug":"/effective-java-item7/"},"frontmatter":{"date":"Dec 16, 2021","title":"[이펙티브 자바] 7. 다 쓴 객체 참조를 해제하라","tags":["java","book"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n- 똑같은 기능의 객체를 매번 생성하기보다는 객체 하나를 재사용하는 편이 나을 때가 많다.\r\n    - 재사용은 빠르고 세련됨.\r\n    - 특히 불변 객체는 언제든 재사용할 수 있다.\r\n\r\n```java\r\nString s = new String(\"bikini\"); // 따라 하지 말 것\r\nString s = \"bikini\";\r\n```\r\n\r\n- 첫번째 코드는 String 인스턴스를 새로 만들게 되어 생성자에 넘겨진 \"bikini\" 자체가 이 생성자로 만들어내려는 String과 기능적으로 완전히 똑같다.\r\n    - 반복문이나 빈번히 호출되는 메서드 안에 있다면 쓸데없는 String 인스턴스가 수백만 개 만들어질 수도 있다.\r\n- 두번째 코드는 새로운 인스턴스를 매번 만드는 대신 하나의 String 인스턴스를 사용한다.\r\n    - 같은 가상 머신 안에서 이와 똑같은 문자열 리터럴을 사용하는 모든 코드가 같은 객체를 재사용함이 보장됨. (상수 풀 사용)\r\n\r\n- 생성자 대신 정적 팩터리 메서드를 제공하는 불변 클래스에서는 정적 팩터리 메서드를 사용해 불필요한 객체 생성을 피할 수 있다.\r\n    - Boolean(String) 생성자 대신 Boolean.valueOf(String) 팩터리 메서드를 사용하는 것이 좋다. (그래서 이 생성자는 자바 9에서 deprecated 되었다)\r\n- 생성 비용이 아주 비싼 객체도 있다.\r\n    - 이런 객체는 반복해서 필요하다면 캐싱하여 재사용하길 권함.\r\n    - 대표적인 예로 String의 matches 메서드가 있다.\r\n\r\n        ```java\r\n        static boolean isRomanNumeralSlow(String s) {\r\n              return s.matches(\"^(?=.)M*(C[MD]|D?C{0,3})\"\r\n                      + \"(X[CL]|L?X{0,3})(I[XV]|V?I{0,3})$\");\r\n        }\r\n        ```\r\n\r\n        - String.matches는 정규표현식으로 문자열 형태를 확인하는 가장 쉬운 방법이지만, 성능이 중요한 상황에서 반복해 사용하기엔 적합하지 않음.\r\n        - 메서드 내부에서 정규표현식용 Pattern 인스턴스를 만드는데 Patten은 입력받은 정규표현식에 해당하는 유한 상태 머신(finite state machine)을 만들기 때문에 인스턴스 생성 비용이 높음.\r\n            - 유한 상태 머신이란 한번에 하나의 상태를 가지며 특정 이벤트에 의해 한 상태에서 다른 상태로 전이할 수 있는 기계라고 하는데 정규표현식은 이러한 유한 상태 머신을 이용해서 구현된다고 한다.\r\n            - 모든 상태와 전이를 찾아놓고 매칭을 하기에 생성 비용이 높다고 한다.\r\n        - 성능 개선을 위해 정규표현식을 표현하는 (불변인) Pattern 인스턴스를 클래스 초기화(정적 초기화) 과정에서 직접 생성해 캐싱해두고, 나중에 isRomanNumeral 메서드가 호출될 때마다 이 인스턴스를 재사용함.\r\n\r\n        ```java\r\n        public class RomanNumerals {\r\n            private static final Pattern ROMAN = Pattern.compile(\r\n                    \"^(?=.)M*(C[MD]|D?C{0,3})\"\r\n                            + \"(X[CL]|L?X{0,3})(I[XV]|V?I{0,3})$\");\r\n        \r\n            static boolean isRomanNumeralFast(String s) {\r\n                return ROMAN.matcher(s).matches();\r\n            }\r\n        }\r\n        ```\r\n\r\n        - ROMAN 필드를 메서드가 처음 호출될 때 필드를 초기화할 수 있게 지연 초기화를 사용할 순 있지만 권하지는 않는다.\r\n            - 코드가 복잡해지고 성능은 크게 개선되지 않을 때가 많기 때문.\r\n\r\n- 객체가 불변이라면 재사용해도 안전함이 명백하다.\r\n    - 하지만 훨씬 덜 명확하거나, 심지어 직관에 반대되는 상황도 있음.\r\n    - 대표적인 예로 어댑터 패턴(Adapter Pattern)이 있음.\r\n        - 어댑터는 실제 작업은 뒷단 객체에 위임하고, 자신은 제2의 인터페이스 역할을 해주는 객체.\r\n        - 어댑터는 뒷단 객체만 관리하면 됨.\r\n        - 즉, 뒷단 객체 외에는 관리할 상태가 없으므로 뒷단 객체 하나당 어댑터 하나씩만 만들어지면 충분함.\r\n    - 예컨대 Map 인터페이스의 keySet 메서드는 Map 객체 안의 키 전부를 담은 Set 뷰를 반환함.\r\n        - keySet을 호출할 때마다 새로운 Set 인스턴스가 만들어지는게 아닌 매번 같은 Set 인스턴스를 반환함.\r\n        - 반환한 객체 중 하나를 수정하면 다른 모든 객체가 따라서 바뀜.\r\n\r\n        ![Untitled (90)](https://user-images.githubusercontent.com/62014888/146502948-b51323f6-a365-4c64-8685-92313f51c1e5.png)\r\n\r\n        - keySet이 뷰 객체를 여러 개 만들어도 상관없지만, 그럴 필요도 없고 이득도 없음.\r\n\r\n- 불필요한 객체를 만들어내는 또 다른 예로 오토박싱(auto boxing)을 들 수 있음.\r\n    - 오토박싱은 프로그래머가 기본 타입과 박싱된 기본 타입을 섞어 쓸 때 자동으로 상호 변환해주는 기술.\r\n    - 오토박싱은 기본 타입과 그에 대응하는 박싱된 기본 타입의 구분을 흐려주지만, 완전히 없애주는 것은 아님.\r\n    - 의미상으로는 별다를 것 없지만 성능에는 그렇지 않음.\r\n\r\n    ```java\r\n    private static long sum() {\r\n        Long sum = 0L;\r\n        for (long i = 0; i <= Integer.MAX_VALUE; i++)\r\n            sum += i;\r\n        return sum;\r\n    }\r\n    ```\r\n\r\n    - sum 변수를 Long으로 선언해서 불필요한 Long 인스턴스가 약 2의 31승개나 만들어진 것.\r\n    - 이 경우에 박싱된 기본 타입보다는 기본 타입을 사용하고, 의도치 않은 오토박싱이 숨어들지 않도록 주의하자.\r\n\r\n\r\n## 정리\r\n\r\n- \"객체 생성은 비싸니 피해야 한다\"로 오해하면 안 됨.\r\n    - 요즘 JVM은 작은 객체 생성하고 회수하는 일이 크게 부담되지 않음.\r\n    - 프로그램의 명확성, 간결성, 기능을 위해서 객체를 추가로 생성하는 것이라면 일반적으로 좋은 일.\r\n- 아주 무거운 객체가 아닌 이상 단순히 객체 생성을 피하고자 객체 풀(pool)을 만들지는 말자.\r\n    - DB Connection과 같이 생성 비용이 비싼 경우가 아니고서야 자체 객체 풀은 코드를 헷갈리게 만들고 메모리 사용량을 늘리고 성능을 떨어뜨림.\r\n    - 요즘 JVM GC는 상당히 잘 최적화되어서 가벼운 객체용을 다룰 때는 직접 만든 객체 풀보다 훨씬 빠르다.\r\n- 방어적 복사가 필요한 상황에서 객체를 재사용했을 때의 피해가 필요 없는 객체를 반복 생성했을 때의 피해보다 훨씬 크다는 사실을 기억하자.\r\n    - 방어적 복사에 실패하면 버그와 보안 구멍으로 이어지지만, 불필요한 객체 생성은 그저 코드 형태와 성능에만 영향을 줌.","excerpt":"똑같은 기능의 객체를 매번 생성하기보다는 객체 하나를 재사용하는 편이 나을 때가 많다. 재사용은 빠르고 세련됨. 특히 불변 객체는 언제든 재사용할 수 있다. 첫번째 코드는 String 인스턴스를 새로 만들게 되어 생성자에 넘겨진 \"bikini\" 자체…","fields":{"slug":"/effective-java-item6/"},"frontmatter":{"date":"Dec 15, 2021","title":"[이펙티브 자바] 6. 불필요한 객체 생성을 피하라","tags":["java","book"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"- 사용하는 자원에 따라 동작이 달라지는 클래스에는 정적 유틸리티 클래스나 싱글턴 방식이 적합하지 않다.\r\n- 대신 클래스가 여러 자원 인스턴스를 지원해야 하며, 클라이언트가 원하는 자원을 사용해야 한다.\r\n    - 이 조건을 만족하는 간단한 패턴이 있으니, 바로 인스턴스를 생성할 때 생성자에 필요한 자원을 넘겨주는 방식이다.\r\n    - 의존 객체 주입의 한 형태로, 맞춤법 검사기를 생성할 때 의존 객체인 사전을 주입해주면 된다.\r\n\r\n    ```java\r\n    public class SpellChecker {\r\n    \tprivate final Lexicon dictionary;\r\n    \r\n    \tpublic SpellChecker(Lexicon dictionary) {\r\n    \t\tthis.dictionary = Objects.requireNonNull(dictionary);\r\n    \t}\r\n    \r\n    \tpublic boolean isValid(String word) {}\r\n    \tpublic List<String> suggestions(String typo) {}\r\n    }\r\n    ```\r\n\r\n    - 불변을 보장하여 여러 클라이언트가 의존 객체들을 안심하고 공유할 수 있다.\r\n    - 의존 객체 주입은 생성자, 정적 팩터리, 빌더 모두에 똑같이 응용할 수 있다.\r\n- 이러한 패턴의 쓸만한 변형으로, 생성자에 자원 팩터리를 넘겨주는 방식이 있다.\r\n    - 팩터리란 호출할 때마다 특정 타입의 인스턴스를 반복해서 만들어주는 객체를 말한다. 즉, 팩터리 메서드 패턴을 구현한 것이다.\r\n    - 자바 8에서 소개한 Supplier<T> 인터페이스가 팩터리를 표현한 완벽한 예.\r\n        - 클라이언트는 자신이 명시한 타입의 하위 타입이라면 무엇이든 생성할 수 있는 팩터리를 넘길 수 있음.\r\n\r\n        ```java\r\n        Mosaic create(Supplier<? extends Tile> tileFactory) {...}\r\n        ```\r\n\r\n        - 클라이언트가 제공한 팩터리가 생성한 Tile들로 구성된 Mosaic을 만드는 메서드\r\n- 의존 객체 주입이 유연성과 테스트 용이성을 개선해주긴 하지만, 의존성이 수 천개나 되는 큰 프로젝트에서는 코드를 어지럽게 만들기도 한다.\r\n    - Dagger, Guice, Spring 같은 의존 객체 주입 프레임워크를 사용하면 이런 어질러짐을 해소할 수 있다.\r\n    - 이들 프레임워크는 의존 객체를 직접 주입하도록 설계된 API를 알맞게 응용해 사용하고 있음.\r\n\r\n## 핵심 정리\r\n\r\n- 클래스가 내부적으로 하나 이상의 자원에 의존하고, 그 자원이 클래스 동작에 영향을 준다면 싱글턴과 정적 유틸리티 클래스는 사용하지 않는 것이 좋다.\r\n- 이 자원들을 클래스가 직접 만들게 해서도 안된다. 대신 필요한 자원을 (혹은 그 자원을 만들어주는 팩터리를) 생성자에 (혹은 정적 팩터리나 빌더에) 넘겨주자.\r\n- 의존 객체 주입이라 하는 이 기법은 클래스의 유연성, 재사용성, 테스트 용이성을 기막히게 개선해준다.","excerpt":"사용하는 자원에 따라 동작이 달라지는 클래스에는 정적 유틸리티 클래스나 싱글턴 방식이 적합하지 않다. 대신 클래스가 여러 자원 인스턴스를 지원해야 하며, 클라이언트가 원하는 자원을 사용해야 한다. 이 조건을 만족하는 간단한 패턴이 있으니, 바로 인스…","fields":{"slug":"/effective-java-item5/"},"frontmatter":{"date":"Dec 15, 2021","title":"[이펙티브 자바] 5. 자원을 직접 명시하지 말고 의존 객체 주입을 사용하라","tags":["java","book"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n- 정적 메서드와 정적 필드만을 담은 클래스를 만들고 싶을 때가 있을 것.\r\n    - 객체 지향적으로 사고하지 않는 이들이 종종 남용하는 방식이기에 그리 곱게 보이지는 않지만, 분명 나름의 쓰임새가 있음.\r\n    - 그렇다면 정적 메서드와 정적 필드를 사용하는 것이 왜 객체 지향적이 아닐까?\r\n        - [https://jgrammer.tistory.com/entry/이펙티브자바-인스턴스화를-막으려거든-private-생성자를-사용해라-java-static-개념](https://jgrammer.tistory.com/entry/%EC%9D%B4%ED%8E%99%ED%8B%B0%EB%B8%8C%EC%9E%90%EB%B0%94-%EC%9D%B8%EC%8A%A4%ED%84%B4%EC%8A%A4%ED%99%94%EB%A5%BC-%EB%A7%89%EC%9C%BC%EB%A0%A4%EA%B1%B0%EB%93%A0-private-%EC%83%9D%EC%84%B1%EC%9E%90%EB%A5%BC-%EC%82%AC%EC%9A%A9%ED%95%B4%EB%9D%BC-java-static-%EA%B0%9C%EB%85%90)\r\n        - 위 블로그 글에 적혀있는 것처럼 정적 필드와 정적 메서드를 사용하면 다형성과 거리가 멀어진다.\r\n        - 객체 지향의 여러 특징 중에 다형성이 있는데 이 다형성을 해치기 때문에 객체 지향적이 아니라고 하는 것 같다.\r\n- 하지만 그럼에도 불구하고 정적 필드와 정적 메서드는 나름의 쓰임새가 있다.\r\n    - 예를 들어 java.lang.Math나 java.util.Arrays 처럼 기본 타입 값이나 배열 관련 메서드들을 모아놓을 수 있다.\r\n    - java.util.Collections처럼 특정 인터페이스를 구현하는 객체를 생성해주는 정적 메서드(혹은 팩터리)를 모아놓을 수도 있음. (자바 8부터는 이런 메서드를 인터페이스에 넣을 수 있다.)\r\n    - final 클래스와 관련한 메서드들을 모아놓을 수도 있음.\r\n        - final 클래스를 상속해서 하위 클래스에서 메서드를 넣는 건 불가능하기 때문이다.\r\n- 정적 멤버만 담은 유틸리티 클래스는 인스턴스로 만들어 쓰려고 설계한게 아니다.\r\n    - 하지만 생성자를 명시하지 않으면 컴파일러가 자동으로 기본 생성자를 만들어 준다.\r\n    - 즉, 매개변수를 받지 않는 public 생성자가 만들어지며, 사용자는 이 생성자가 자동 생성된 것인지 구분할 수 없음.\r\n- **단순하게 추상 클래스로 만드는 것으로는 인스턴스화를 막을 수 없음.**\r\n    - 하위 클래스를 만들어 인스턴스화하면 그만이다.\r\n    - 사용자는 상속해서 쓰라는 뜻으로 오해할 수 있으니 더 큰 문제이다.\r\n- 이를 해결하기 위해 private 생성자를 추가하여 클래스의 인스턴스화를 막을 수 있음.\r\n\r\n    ![Untitled (66)](https://user-images.githubusercontent.com/62014888/146129252-81aa01e2-50a4-42e0-a16e-dcd32b4efc16.png)\r\n\r\n    - 필요에 따라 생성자 코드 내부에 throw new AssertionError()와 같이 예외를 추가할 수 있음.\r\n    - 다만, 이 코드는 직관적이지 않으니 적절한 주석을 달아주는 것을 추천\r\n    - 이 방식은 상속이 불가능하게 하는 효과도 있음!\r\n    \r\n\r\n## 느낀 점\r\n\r\n- 유틸리티 클래스를 만들때 private 생성자를 명시한다는 것 잊지말자","excerpt":"정적 메서드와 정적 필드만을 담은 클래스를 만들고 싶을 때가 있을 것. 객체 지향적으로 사고하지 않는 이들이 종종 남용하는 방식이기에 그리 곱게 보이지는 않지만, 분명 나름의 쓰임새가 있음. 그렇다면 정적 메서드와 정적 필드를 사용하는 것이 왜 객체…","fields":{"slug":"/effective-java-item4/"},"frontmatter":{"date":"Dec 14, 2021","title":"[이펙티브 자바] 4. 인스턴스화를 막으려거든 private 생성자를 사용하라","tags":["java","book"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n- 싱글턴이란 인스턴스를 오직 하나만 생성할 수 있는 클래스를 말한다.\r\n    - 전형적인 예 - 함수와 같은 무상태 객체나 설계상 유일하게 하는 시스템 컴포넌트\r\n- 클래스를 싱글턴으로 만들면 이를 사용하는 클라이언트를 테스트하기가 어려워질 수 있다.\r\n    - 인터페이스를 구현해서 만든 싱글턴이 아니라면 싱글턴 인스턴스를 mocking으로 대체할 수 없기 때문!\r\n- 싱글턴을 만드는 방식은 보통 둘 중 하나.\r\n    - 두 방식 모두 생성자는 private으로 감춰두고, 유일한 인스턴스에 접근할 수 있는 수단으로 public static 멤버를 하나 마련해 둠.\r\n    1. public static 멤버가 final 필드인 방식\r\n\r\n        ```java\r\n        public class Elvis {\r\n            public static final Elvis INSTANCE = new Elvis();\r\n        \r\n            private Elvis() { }\r\n        \r\n            public void leaveTheBuilding() {\r\n            }\r\n        }\r\n        ```\r\n\r\n        - private 생성자는 Elvis.INSTANCE를 초기화할 때 딱 한 번만 호출됨.\r\n        - 단, 리플렉션 API의 AccessibleObject.setAccessible을 사용하면 private 생성자를 호출할 수 있음.\r\n            - 이를 방어하려면 두 번째 객체가 생성되려 할 때 생성자에서 예외를 던지게 하면 됨.\r\n        - 장점\r\n            - 해당 클래스가 싱글턴임이 API에 명백히 드러남.\r\n            - 간결함.\r\n\r\n    2. 정적 팩터리 메서드를 public static 멤버로 제공\r\n\r\n        ```java\r\n        public class Elvis {\r\n            private static final Elvis INSTANCE = new Elvis();\r\n            private Elvis() { }\r\n            public static Elvis getInstance() { return INSTANCE; }\r\n        \r\n            public void leaveTheBuilding() {\r\n            }\r\n        }\r\n        ```\r\n\r\n        - Elvis.getInstance는 항상 같은 객체의 참조를 반환. (리플렉션을 통한 예외는 똑같이 적용됨)\r\n        - 장점\r\n            - (마음이 바뀌면) API를 바꾸지 않고도 싱글턴이 아니게 변경할 수 있음.\r\n            - 원한다면 정적 팩터리를 제너릭 싱글턴 팩터리로 만들 수 있음.\r\n            - 정적 팩터리의 메서드 참조를 공급자(supplier)로 사용할 수 있음.\r\n\r\n    - 둘 중 하나의 방식으로 만든 싱글턴 클래스를 직렬화하려면 단순히 Serializable을 구현한다고 선언하는 것만으로는 부족하다.\r\n        - 모든 인스턴스 필드를 일시적(transient)이라고 선언하고 readResolve 메서드를 제공해야 함.\r\n\r\n            ```java\r\n            // 싱글턴임을 보장해주는 readResolve 메서드\r\n            private Obejct readResolve() {\r\n            \t// '진짜' Elvis를 반환하고, 가짜 Elvis는 가비지 컬렉터에 맡긴다.\r\n            \treturn INSTANCE;\r\n            }\r\n            ```\r\n\r\n            - 이렇게 하지 않으면 직렬화된 인스턴스를 역직렬화할 때마다 새로운 인스턴스가 만들어짐.\r\n\r\n    3. 원소가 하나인 열거 타입을 선언하는 것.\r\n\r\n        ```java\r\n        public enum Elvis {\r\n            INSTANCE;\r\n        \r\n            public void leaveTheBuilding() {\r\n            }\r\n        }\r\n        ```\r\n\r\n        - public 필드 방식과 비슷하지만, 더 간결하고, 추가 노력 없이 직렬화할 수 있고, 심지어 아주 복잡한 직렬화 상황이나 리플렉션 공격에서도 제2의 인스턴스가 생기는 일을 완벽히 막아준다.\r\n        - 대부분 상황에서는 원소가 하나뿐인 열거 타입이 싱글턴을 만드는 가장 좋은 방법임.\r\n            - 단, 만들려는 싱글턴이 Enum 외의 클래스를 상속해야 한다면 이 방법은 사용할 수 없다. (열거 타입이 다른 인터페이스를 구현하도록 선언할 수는 있음)\r\n    \r\n\r\n## 느낀 점\r\n\r\n- 싱글턴으로 클래스를 만들면 직렬화하고 역직렬화할때마다 새로운 인스턴스가 만들어지는 줄은 몰랐는데 흥미로웠다. 제네릭 싱글턴 팩터리나 supplier에 대한 내용 때문에 빨리 뒷부분 아이템을 읽고 싶어졌다.","excerpt":"싱글턴이란 인스턴스를 오직 하나만 생성할 수 있는 클래스를 말한다. 전형적인 예 - 함수와 같은 무상태 객체나 설계상 유일하게 하는 시스템 컴포넌트 클래스를 싱글턴으로 만들면 이를 사용하는 클라이언트를 테스트하기가 어려워질 수 있다. 인터페이스를 구…","fields":{"slug":"/effective-java-item3/"},"frontmatter":{"date":"Dec 14, 2021","title":"[이펙티브 자바] 3. private 생성자나 열거 타입으로 싱글턴임을 보증하라","tags":["java","book"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n- 정적 팩터리와 생성자에는 똑같은 제약이 있다.\r\n    - 선택적 매개변수가 많을때 적절히 대응하기 어렵다는 점!\r\n- 필드에 변수가 많이 있을 때 이런 클래스용 생성자 혹은 정적 팩터리는 어떤 모습일까?\r\n- 3가지 방법을 사용한 모습이 있겠다.\r\n\r\n1. 점층적 생성자 패턴(telescoping constructor pattern)\r\n    - 필수 매개변수 하나만 받는 생성자, 필수 매개변수와 선택 매개변수 1개를 받는 생성자, 2개까지 받는 생성자 .... 이런 식으로 선택 매개변수를 전부 다 받는 생성자까지 늘려가는 방식이다.\r\n\r\n    ```java\r\n    public class NutritionFacts {\r\n        private final int servingSize;  // (mL, 1회 제공량)     필수\r\n        private final int servings;     // (회, 총 n회 제공량)  필수\r\n        private final int calories;     // (1회 제공량당)       선택\r\n        private final int fat;          // (g/1회 제공량)       선택\r\n        private final int sodium;       // (mg/1회 제공량)      선택\r\n        private final int carbohydrate; // (g/1회 제공량)       선택\r\n    \r\n        public NutritionFacts(int servingSize, int servings) {\r\n            this(servingSize, servings, 0);\r\n        }\r\n    \r\n        public NutritionFacts(int servingSize, int servings,\r\n                              int calories) {\r\n            this(servingSize, servings, calories, 0);\r\n        }\r\n    \r\n        public NutritionFacts(int servingSize, int servings,\r\n                              int calories, int fat) {\r\n            this(servingSize, servings, calories, fat, 0);\r\n        }\r\n    \r\n        public NutritionFacts(int servingSize, int servings,\r\n                              int calories, int fat, int sodium) {\r\n            this(servingSize, servings, calories, fat, sodium, 0);\r\n        }\r\n        public NutritionFacts(int servingSize, int servings,\r\n                              int calories, int fat, int sodium, int carbohydrate) {\r\n            this.servingSize  = servingSize;\r\n            this.servings     = servings;\r\n            this.calories     = calories;\r\n            this.fat          = fat;\r\n            this.sodium       = sodium;\r\n            this.carbohydrate = carbohydrate;\r\n        }\r\n    }\r\n    ```\r\n\r\n    - 매개변수가 많아지면 클라이언트 코드를 작성하거나 읽기 어렵다는 단점이 있다.\r\n\r\n1. 자바빈즈 패턴(JavaBeans pattern)\r\n    - JavaBeans란 데이터를 표현하기 위한 Java 클래스를 만들 때의 규약으로 아래의 규약을 지킨 Java 클래스를 JavaBeans라고 부른다.\r\n        - 모든 클래스의 프로퍼티는 private이며 getter, setter 메서드로 제어한다.\r\n        - 인자가 없는 public 생성자가 있어야 한다.\r\n        - Serializable 인터페이스를 구현해야 한다.\r\n    - 즉, 매개변수가 없는 생성자로 객체를 만든 후, 세터(setter) 메서드들을 호출해 원하는 매개변수의 값을 설정하는 방식이다.\r\n    - 점층적 생성자 패턴에 비해 코드가 길어지긴 했지만, 인스턴스를 만들기 쉽고 그 결과 더 읽기 쉬운 코드가 되었다.\r\n\r\n    ```java\r\n    public class NutritionFacts {\r\n        // 매개변수들은 (기본값이 있다면) 기본값으로 초기화된다.\r\n        private int servingSize  = -1; // 필수; 기본값 없음\r\n        private int servings     = -1; // 필수; 기본값 없음\r\n        private int calories     = 0;\r\n        private int fat          = 0;\r\n        private int sodium       = 0;\r\n        private int carbohydrate = 0;\r\n    \r\n        public NutritionFacts() { }\r\n        // Setters\r\n        public void setServingSize(int val)  { servingSize = val; }\r\n        public void setServings(int val)     { servings = val; }\r\n        public void setCalories(int val)     { calories = val; }\r\n        public void setFat(int val)          { fat = val; }\r\n        public void setSodium(int val)       { sodium = val; }\r\n        public void setCarbohydrate(int val) { carbohydrate = val; }\r\n    \r\n        public static void main(String[] args) {\r\n            NutritionFacts cocaCola = new NutritionFacts();\r\n            cocaCola.setServingSize(240);\r\n            cocaCola.setServings(8);\r\n            cocaCola.setCalories(100);\r\n            cocaCola.setSodium(35);\r\n            cocaCola.setCarbohydrate(27);\r\n        }\r\n    }\r\n    ```\r\n\r\n    - 하지만 심각한 단점이 있다.\r\n      자바빈즈 패턴에서는 객체 하나를 만들려면 메서드를 여러 개 호출해야 하고, 객체가 완전히 생성되기 전까지 일관성(consistency)이 무너진 상태에 놓이게 된다.\r\n      따라서 클래스를 불변으로 만들수 없으며 스레드 안전성을 얻으려면 프로그래머가 추가 작업을 해줘야만 한다.\r\n\r\n1. 빌더 패턴(Builder pattern)\r\n    - 점층적 생성자 패턴의 안전성과 자바빈드 패턴의 가독성을 겸비했다.\r\n    - 클라이언트는 필요한 객체를 직접 만드는 대신, 필수 매개변수만으로 생성자(혹은 정적 팩터리)를 호출해 빌더 객체를 얻는다.\r\n      그런 다음 빌더 객체가 제공하는 일종의 세터 메서드들로 원하는 선택 매개변수들을 설정한다.\r\n      마지막으로 매개변수가 없는 build 메서드를 호출해 드디어 우리에게 필요한 (보통은 불변인) 객체를 얻는다.\r\n\r\n    ```java\r\n    public class NutritionFacts {\r\n        private final int servingSize;\r\n        private final int servings;\r\n        private final int calories;\r\n        private final int fat;\r\n        private final int sodium;\r\n        private final int carbohydrate;\r\n    \r\n        public static class Builder {\r\n            // 필수 매개변수\r\n            private final int servingSize;\r\n            private final int servings;\r\n    \r\n            // 선택 매개변수 - 기본값으로 초기화한다.\r\n            private int calories      = 0;\r\n            private int fat           = 0;\r\n            private int sodium        = 0;\r\n            private int carbohydrate  = 0;\r\n    \r\n            public Builder(int servingSize, int servings) {\r\n                this.servingSize = servingSize;\r\n                this.servings    = servings;\r\n            }\r\n    \r\n            public Builder calories(int val)\r\n            { calories = val;      return this; }\r\n            public Builder fat(int val)\r\n            { fat = val;           return this; }\r\n            public Builder sodium(int val)\r\n            { sodium = val;        return this; }\r\n            public Builder carbohydrate(int val)\r\n            { carbohydrate = val;  return this; }\r\n    \r\n            public NutritionFacts build() {\r\n                return new NutritionFacts(this);\r\n            }\r\n        }\r\n    \r\n        private NutritionFacts(Builder builder) {\r\n            servingSize  = builder.servingSize;\r\n            servings     = builder.servings;\r\n            calories     = builder.calories;\r\n            fat          = builder.fat;\r\n            sodium       = builder.sodium;\r\n            carbohydrate = builder.carbohydrate;\r\n        }\r\n    \r\n        public static void main(String[] args) {\r\n            NutritionFacts cocaCola = new NutritionFacts.Builder(240, 8)\r\n                    .calories(100).sodium(35).carbohydrate(27).build();\r\n        }\r\n    }\r\n    ```\r\n\r\n\r\n- 빌더 패턴은 (파이썬과 스칼라에 있는) 명명된 선택적 매개변수를 흉내 낸 것이다.\r\n- 잘못된 매개변수를 일찍 발견하려면 빌더의 생성자와 메서드에서 입력 매개변수를 검사하고, build 메서드가 호출하는 생성자에서 여러 매개변수에 걸친 불변식을 검사하자.\r\n    - 불변(immutable 혹은 immutability) - 어떠한 변경도 허용하지 않는다는 뜻. 주로 변경을 허용하는 가변 객체와 구분하는 용도로 쓰임.\r\n    - 불변식(invariant) - 프로그램이 실행되는 동안, 혹은 정해진 기간 동안 반드시 만족해야 하는 조건을 말함. 즉, 변경을 허용할 수 있으나 주어진 조건 내에서만 허용한다는 뜻.\r\n    - 가변 객체에도 불변식은 존재할 수 있으며, 넓게 보면 불변은 불변식의 극단적인 예라 할 수 있음.\r\n- 그리고 빌더 패턴은 계층적으로 설계된 클래스와 함께 쓰기 좋다.\r\n\r\n    ```java\r\n    // 참고: 여기서 사용한 '시뮬레이트한 셀프 타입(simulated self-type)' 관용구는\r\n    // 빌더뿐 아니라 임의의 유동적인 계층구조를 허용한다.\r\n    \r\n    public abstract class Pizza {\r\n        public enum Topping { HAM, MUSHROOM, ONION, PEPPER, SAUSAGE }\r\n        final Set<Topping> toppings;\r\n    \r\n        abstract static class Builder<T extends Builder<T>> {\r\n            EnumSet<Topping> toppings = EnumSet.noneOf(Topping.class);\r\n            public T addTopping(Topping topping) {\r\n                toppings.add(Objects.requireNonNull(topping));\r\n                return self();\r\n            }\r\n    \r\n            abstract Pizza build();\r\n    \r\n            // 하위 클래스는 이 메서드를 재정의(overriding)하여\r\n            // \"this\"를 반환하도록 해야 한다.\r\n    \t\t\t\t// 하위 클래스에서는 형변환하지 않고도 메서드 연쇄를 지원할 수 있음.\r\n            protected abstract T self();\r\n        }\r\n        \r\n        Pizza(Builder<?> builder) {\r\n            toppings = builder.toppings.clone(); // 아이템 50 참조\r\n        }\r\n    }\r\n    \r\n    public class NyPizza extends Pizza {\r\n        public enum Size { SMALL, MEDIUM, LARGE }\r\n        private final Size size;\r\n    \r\n        public static class Builder extends Pizza.Builder<Builder> {\r\n            private final Size size;\r\n    \r\n            public Builder(Size size) {\r\n                this.size = Objects.requireNonNull(size);\r\n            }\r\n    \r\n            @Override public NyPizza build() {\r\n                return new NyPizza(this);\r\n            }\r\n    \r\n            @Override protected Builder self() { return this; }\r\n        }\r\n    \r\n        private NyPizza(Builder builder) {\r\n            super(builder);\r\n            size = builder.size;\r\n        }\r\n    }\r\n    \r\n    public class Calzone extends Pizza {\r\n        private final boolean sauceInside;\r\n    \r\n        public static class Builder extends Pizza.Builder<Builder> {\r\n            private boolean sauceInside = false; // 기본값\r\n    \r\n            public Builder sauceInside() {\r\n                sauceInside = true;\r\n                return this;\r\n            }\r\n    \r\n            @Override public Calzone build() {\r\n                return new Calzone(this);\r\n            }\r\n    \r\n            @Override protected Builder self() { return this; }\r\n        }\r\n    \r\n        private Calzone(Builder builder) {\r\n            super(builder);\r\n            sauceInside = builder.sauceInside;\r\n        }\r\n    }\r\n    ```\r\n\r\n\r\n- 빌더 패턴은 상당히 유연하다.\r\n    - 빌더 하나로 여러 객체를 순회하면서 만들 수 있고, 빌더에 넘기는 매개변수에 따라 다른 객체를 만들 수도 있다.\r\n    - 객체에게 부여되는 일련번호와 같은 특정 필드는 빌더가 알아서 채우도록 할 수도 있다.\r\n- 단, 장점만 있는 것은 아니다.\r\n    - 객체를 만들려면, 그에 앞서 빌더부터 만들어야한다.\r\n    - 빌더 생성 비용이 크지는 않지만 성능에 민감한 상황에서는 문제가 될 수 있다.\r\n    - 매개변수가 4개 이상은 되어야 값어치를 한다.\r\n    - 하지만 api는 시간이 지날수록 매개변수가 많아지는 경향이 있음을 명시하자!\r\n\r\n## 핵심정리\r\n\r\n- 생성자나 정적 팩터리가 처리해야 할 매개변수가 많다면 빌더 패턴을 선택하는게 더 낫다!\r\n\r\n## 느낀 점\r\n\r\n- 짱 긴 생성자나 setter 범벅인 코드에 비해서 빌더는 깔끔하고 편하다.\r\n  특히 롬복을 더한다면..ㅋㅋ;;\r\n  그렇다면 무조건적인 빌더 사용이 좋을까? 책에서는 매개변수가 많아지는 경향이 있기에\r\n  애초에 빌더 사용하는 거도 좋은 방법이라곤 하지만 직접 빌더를 만들어서 사용하려면\r\n  그거도 비용이기 때문에 고민해봐야 할 것 같다.","excerpt":"정적 팩터리와 생성자에는 똑같은 제약이 있다. 선택적 매개변수가 많을때 적절히 대응하기 어렵다는 점! 필드에 변수가 많이 있을 때 이런 클래스용 생성자 혹은 정적 팩터리는 어떤 모습일까? 3가지 방법을 사용한 모습이 있겠다. 점층적 생성자 패턴(te…","fields":{"slug":"/effective-java-item2/"},"frontmatter":{"date":"Dec 13, 2021","title":"[이펙티브 자바] 2. 생성자에 매개변수가 많다면 빌더를 고려하라","tags":["java","book"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n- 클라이언트가 클래스의 인스턴스를 얻는 전통적인 수단은 public 생성자다.\r\n- 클래스는 생성자와 별도로 정적 팩터리 메서드를 제공할 수 있다.\r\n    - 정적 팩터리 메서드는 클래스의 인스턴스를 반환하는 단순한 정적 메서드를 뜻한다.\r\n    - 정적 팩터리 메서드는 디자인 패턴에서의 팩터리 메서드와 다르다.\r\n\r\n## 정적 메서드의 장점 5가지\r\n\r\n1. 이름을 가질 수 있다.\r\n    - 생성자에 넘기는 매개변수, 생성자 자체 만으로는 반환될 객체의 특성을 제대로 설명하지 못한다.\r\n      반면, 정적 팩터리는 이름만 잘 지으면 반환될 객체의 특성을 쉽게 묘사할 수 있다.\r\n        - BigInteger(int, int ,Random)과 BigInteger.probablaPrime 중 어느 쪽이\r\n          '값이 소수인 BigInteger를 반환한다'는 의미를 더 잘 설명할 것 같은지 생각해보라.\r\n    - 한 클래스에 시그니처가 같은 생성자가 여러 개 필요할 것 같으면, 생성자를 정적 팩터리 메서드로 바꾸고 각각의 차이를 잘 드러내는 이름을 지어주자.\r\n2. 호출될 때마다 인스턴스를 새로 생성하지는 않아도 된다.\r\n    - 불변 클래스는 인스턴스를 미리 만들어 놓거나 새로 생성한 인스턴스를 캐싱하여 재활용하는 식으로 불필요한 객체 생성을 피할 수 있다.\r\n        - 대표적인 예로 Boolean.valueOf(boolean), 플라이웨이트 패턴\r\n        - 플라이웨이트 패턴은 동일하거나 유사한 객체들 사이에 가능한 많은 데이터를 공유하여 메모리 사용을 최소화하는 디자인 패턴\r\n\r\n            ![Untitled (64)](https://user-images.githubusercontent.com/62014888/146127817-4b75b2b3-9e47-4a6f-87ee-38629537abd7.png)\r\n    \r\n    - 정적 팩터리 방식의 클래스는 언제 어느 인스턴스를 살아 있게 할지를 철저히 통제할 수 있다.\r\n        - 클래스를 통제하는 이유는?\r\n          클래스를 싱글턴으로 만들 수도, 인스턴스화 불가로 만들 수도 있음.\r\n          불변 값 클래스에서 동치인 인스턴스가 단 하나뿐임을 보장할 수 있음.\r\n3. 반환 타입의 하위 타입 객체를 반환할 수 있는 능력이 있다.\r\n    - 반환할 객체의 클래스를 자유롭게 선택할 수 있게 하는 '엄청난 유연성'을 선물한다!\r\n    - 자바 8 전에는 인터페이스 정적 메서드를 선언할 수 없었다.\r\n        - 그래서 자바 컬렉션 프레임워크는 Collections라는 인스턴스화 불가 클래스에서 정적 팩터리 메서드를 통해 구현체를 얻도록 했음.\r\n    - 자바 8 후에는 인터페이스가 정적 메서드를 가질 수 있어졌기에 인스턴스화 불가 동반 클래스를 둘 이유가 별로 없어짐.\r\n        - 그래서 이러한 List 인터페이스에 List.of()와 같은 정적 팩터리 메서드가 생김.\r\n\r\n        ![Untitled (65)](https://user-images.githubusercontent.com/62014888/146127819-698c8dac-3c7a-4ea7-9fab-126a262cf05a.png)\r\n\r\n\r\n1. 입력 매개변수에 따라 매번 다른 클래스의 객체를 반환할 수 있다.\r\n    - EnumSet 클래스는 원소가 64개 이하면 RegularEnumSet 인스턴스를, 65개 이상이면 JumboEnumSet 인스턴스를 반환한다.\r\n        - 클라이언트는 이 두 클래스의 존재를 모른다. 더 나아가 알 필요도 없다. EnumSet의 하위 클래스이기만 하면 되는 것이다.\r\n\r\n2. 정적 팩터리 메서드를 작성하는 시점에는 반환할 객체의 클래스가 존재하지 않아도 된다.\r\n    - 나중에 만들 클래스가 기존의 인터페이스나 클래스를 상속 받는 상황이라면 언제든지 의존성 주입 받아서 사용이 가능하다.\r\n      반환값이 인터페이스여도 되며, 정적 팩터리 메서드의 변경 없이 구현체를 바꿔 끼울 수 있다.\r\n    - 이러한 유연함은 서비스 제공자 프레임워크를 만드는 근간이 된다.\r\n        - 서비스 제공자 프레임워크에서의 제공자는 서비스의 구현체로 3개의 핵심 컴포넌트로 이뤄짐.\r\n            - 구현체의 동작을 정의하는 서비스 인터페이스\r\n            - 제공자가 구현체를 등록할 때 사용하는 제공자 등록 API\r\n            - 클라이언트가 서비스의 인스턴스를 얻을 때 사용하는 서비스 접근 API\r\n        - 대표적인 예로 JDBC가 있다.\r\n            - Connection이 서비스 인터페이스 역할\r\n            - DriverManager.registerDriver가 제공자 등록 API 역할\r\n            - DriverManager.getConnection이 서비스 접근 API 역할\r\n            - Driver가 서비스 제공자 인터페이스 역할\r\n        - 자바 6부터는 ServiceLoader라는 범용 서비스 제공자 프레임워크가 제공됨.\r\n\r\n## 정적 메서드의 단점 2가지\r\n\r\n1. 상속을 하려면 public이나 protected 생성자가 필요하니 정적 팩터리 메서드만 제공하면 하위 클래스를 만들 수 없다.\r\n    - 우테코 레벨 1 로또 미션에서 사용했던 코드를 예로 들 수 있다.\r\n\r\n        ```java\r\n        public class LottoTicket {\r\n            private static final int VALID_LOTTO_NUMBER_COUNTS = 6;\r\n            private static final String INVALID_LOTTO_NUMBER_COUNTS = \"로또 티켓은 중복되지 않은 6자리의 숫자로 구성되어야 합니다.\";\r\n            \r\n            private final Set<LottoNumber> lottoNumbers;\r\n        \r\n            private LottoTicket(Set<LottoNumber> lottoNumbers) {\r\n                validateNumberCounts(lottoNumbers.size());\r\n                this.lottoNumbers = lottoNumbers;\r\n            }\r\n        \r\n            public static LottoTicket generateTicket(List<LottoNumber> numbers) {\r\n                return numbers.stream()\r\n                        .collect(Collectors.collectingAndThen(Collectors.toSet(), LottoTicket::new));\r\n            }\r\n        }\r\n        \r\n        public class WinningLottoTicket {\r\n            private static final String DUPLICATION_NUMBER = \"보너스 볼 번호는 당첨 번호와 중복될 수 없습니다.\";\r\n        \r\n            private final LottoTicket lottoTicket;\r\n            private final LottoNumber bonusBallNumber;\r\n        \r\n            private WinningLottoTicket(LottoTicket lottoTicket, LottoNumber bonusBallNumber) {\r\n                validateDuplicateNumbers(lottoTicket, bonusBallNumber);\r\n                this.lottoTicket = lottoTicket;\r\n                this.bonusBallNumber = bonusBallNumber;\r\n            }\r\n        }\r\n        ```\r\n\r\n        - LottoTicket 클래스 내부에는 private 생성자와 LottoTicket 클래스를 반환하는 정적 팩터리 메서드가 있었다.\r\n        - WinningLottoTicket 이라는 클래스를 만들기 위해 LottoTicket 클래스를 상속받았는데 그러다보니 상위 클래스의 생성자를 public이나 protected로 바꾸지 않는 이상 상속받을 수가 없었다.\r\n        - 그래서 상속보다는 컴포지션(조합)을 사용하라는 조언을 통해 문제를 해결했다.\r\n        - 이는 어떻게 보면 상속보다는 컴포지션을 사용하도록 유도하고 불변 타입으로 만들려면 이 제약을 지켜야 한다는 점에서 오히려 장점으로 받아들일 수도 있다!\r\n2. 정적 팩터리 메서드는 프로그래머가 찾기 어렵다.\r\n    - 생성자처럼 API 설명에 명확히 드러나지 않으니 사용자는 정적 팩터리 메서드 방식 클래스를 인스턴스화할 방법을 알아내야 한다.\r\n      이러한 어려움을 해결하기 위해 API 문서를 잘 써놓고 메서드 이름도 널리 알려진 규약을 따라 짓는 식으로 문제를 완화해줘야 한다.\r\n    - 흔히 사용하는 정적 팩터리 메서드 명명 방식들\r\n        - from: 매개변수를 하나 받아서 해당 타입의 인스턴스를 반환하는 형변환 메서드\r\n        - of: 여러 매개변수를 받아 적합한 타입의 인스턴스를 반환하는 집계 메서드\r\n        - valueOf: from과 of의 더 자세한 버전\r\n        - instance or getInstance: (매개변수를 받는다면) 매개변수로 명시한 인스턴스를 반환하지만, 같은인스턴스임을 보장하지는 않는다.\r\n        - create or newInstance: instance 혹은 getInstance와 같지만, 매번 새로운 인스턴스를 생성해 반환함을 보장한다.\r\n        - getType: getInstance와 같으나, 생성할 클래스가 아닌 다른 클래스에 팩터리 메서드를 정의할 때 쓴다. \"Type\"은 팩터리 메서드가 반환할 객체의 타입이다.\r\n        - newType: newInstance와 같으나, 생성할 클래스가 아닌 다른 클래스에 팩터리 메서드를 정의할 때 쓴다. \"Type\"은 팩터리 메서드가 반환할 객체의 타입이다.\r\n        - type: getType과 newType의 간결한 버전\r\n\r\n## 핵심정리\r\n\r\n- 정적 팩터리 메서드와 public 생성자는 각자의 쓰임새가 있으니 상대적인 장단점을 이해하고 사용하는 것이 좋다.\r\n  그렇다 하더라도 정적 팩터리를 사용하는 게 유리한 경우가 더 많으므로 무작정 public 생성자를 제공하던 습관이 있으면 고치자!\r\n  \r\n\r\n## 느낀 점\r\n\r\n- Collections가 인터페이스에 정적 메서드를 선언하지 못해서 만든 클래스고\r\n  List.of()와 같은 메서드가 선언할 수 있게 되어서 생긴 메서드라니 흥미로웠다.\r\n  그리고 솔직히 흔히 사용되는 명명 방식의 기준은 잘 모르겠다.. 중요한건 그것보다\r\n  정적 팩터리 메서드를 사용할 때 메서드 명에 대한 팀 컨벤션을 만들어 혼용해서 쓰지 않도록 하는 것이 좋을 것 같다.","excerpt":"클라이언트가 클래스의 인스턴스를 얻는 전통적인 수단은 public 생성자다. 클래스는 생성자와 별도로 정적 팩터리 메서드를 제공할 수 있다. 정적 팩터리 메서드는 클래스의 인스턴스를 반환하는 단순한 정적 메서드를 뜻한다. 정적 팩터리 메서드는 디자인…","fields":{"slug":"/effective-java-item1/"},"frontmatter":{"date":"Dec 13, 2021","title":"[이펙티브 자바] 1. 생성자 대신 정적 팩터리 메서드를 고려하라","tags":["java","book"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\nSpring Framework는 자바 기반의 엔터프라이즈 애플리케이션을 위해서 여러가지 기능을 제공한다. 그 중 웹 애플리케이션 구현을 위한 모듈로 Spring Web MVC가 제공되는데 클라이언트가 요청을 하고 Spring Web MVC에 의해 응답을 반환하기 까지 어떠한 흐름으로 진행되는지 구조를 파악해보도록 하자.\r\n\r\n기본적으로 DispatcherServlet에 대한 설명은 생략하고 @Controller, @RestController 애노테이션에 따라 흐름이 진행되는 순서를 설명할 것이니 DistpatcherServlet에 대해 알아보려면 이 [포스트](https://www.notion.so/Servlet-Dispatcher-Servlet-2f0ad465b2484bd0ae5f55b83b1a2e65) 를 참고하자.\r\n\r\n<br/>\r\n\r\n## @Controller\r\n\r\n![Untitled (13)](https://user-images.githubusercontent.com/62014888/145709182-5d95c1d7-83bf-419f-ba77-d7f6d13db00b.png)\r\n\r\n- 조금 많이 간략화했지만 @Controller 애노테이션을 사용하면서 @RequestMapping을 사용한다면 이런 흐름으로 진행된다.\r\n- HandlerMapping의 경우 기본적으로 5개 정도 있는데 @RequestMapping을 사용할 경우 RequestMappingHandlerMapping을 사용해서 handler를 가져온다.\r\n\r\n  ![Untitled (14)](https://user-images.githubusercontent.com/62014888/145709191-9ecac958-3f71-4387-9849-7d602efb8386.png)\r\n  \r\n    - 보는바와 같이 Spring에서 기본적으로 List에 5개의 HandlerMapping을 우선순위에 따라 저장시켜두는데 RequestMappingHandlerMapping이 우선순위가 제일 높은 것을 볼 수 있다.\r\n    - Handler를 가져오면서 Interceptor가 설정되어 있으면 해당하는 url일 경우 Interceptor를 타게 된다.\r\n- HandlerReturnValueHandlerComposite에서 selectHandler 메소드를 통해 적절한  HandlerMethodReturnValueHandler를 반환해주게 된다.\r\n  만약 Controller에 해당하는 메소드가 ModelAndView를 반환해주게 된다면 ModelAndViewReturnValueHandler를 String이라면 ViewNameMethodReturnValueHandler를 반환해주게 된다.\r\n\r\n  ![Untitled (15)](https://user-images.githubusercontent.com/62014888/145709203-91a724e8-e95d-4bc1-a1d6-c1c238839ded.png)\r\n\r\n    - supportsReturnType이라는 메소드를 사용해 HandlerMethodReturnValueHandler에게 적절한 리턴 타입인지를 물어보게 되는 것이다.\r\n    - ViewNameMethodReturnValueHandler일 경우 View Name을 저장해 DispathcerServlet의 render 메소드에서 ViewResolver를 통해 View 객체로 resolve 시켜준다.\r\n\r\n<br/>\r\n\r\n## @RestController\r\n\r\n![Untitled (16)](https://user-images.githubusercontent.com/62014888/145709213-61394e37-af89-4d24-993c-6d5966d56523.png)\r\n\r\n- @RestController도 마찬가지로 같은 흐름으로 진행되나 Return Value를 처리해주는 HandlerMethodReturnValueHandler가 다르다.\r\n- @RestController를 열어보면 @ResponseBody가 포함되어 있는데 이 애노테이션에 의해 RequestResponseBodyMethodProcessor가 선택된다.\r\n\r\n  ![Untitled (17)](https://user-images.githubusercontent.com/62014888/145709220-8bfb6125-3838-43a1-96e6-fe635e07ca7c.png)\r\n\r\n\r\n- RequestResponseBodyMethodProcessor 내부에는 메시지 컨버터를 가지고 있는데 MappingJackson2HttpMessageConverter에 의해 Json으로 변환하여 클라이언트에게 반환하게 된다.\r\n- 코드를 보다보면 HandlerAdapter의 handle 메소드는 ModelAndView를 반환해주게 되던데 RequestResponseBodyMethodProcessor의 경우 메시지 컨버터를 사용하며 ModelAndViewContatiner의 requestHandled 필드를 true로 바꿔주고 이 필드가 true일 경우 ModelAndView를 null로 리턴하게 된다.\r\n  DispatcherServlet에서는 ModelAndView가 null일 경우 이미 렌더링 되어있다고 판단하고 넘어가게 된다.\r\n\r\n![Untitled (18)](https://user-images.githubusercontent.com/62014888/145709229-8d7c6353-5731-43a0-b39d-57e8d7cce50c.png)\r\n\r\n<br/>\r\n\r\n## 마무리\r\n\r\n- 예전에도 DispatcherServlet을 파보았지만 이번에 @Controller와 @RestController 애노테이션에 따라 어떻게 진행되는지 조금 더 깊게 파보았다.\r\n- 한번 더 Spring을 정리하게 되는 계기가 되었다.\r\n- 더 자세히 공부하실 분은 Spring 코드를 직접 열어보면서 공부하는 걸 추천드린다.\r\n\r\n<br/>\r\n\r\n## 참고\r\n\r\n- [https://yoon0120.tistory.com/60](https://yoon0120.tistory.com/60)","excerpt":"Spring Framework는 자바 기반의 엔터프라이즈 애플리케이션을 위해서 여러가지 기능을 제공한다. 그 중 웹 애플리케이션 구현을 위한 모듈로 Spring Web MVC가 제공되는데 클라이언트가 요청을 하고 Spring Web MVC에 의해 응…","fields":{"slug":"/spring-mvc/"},"frontmatter":{"date":"Dec 07, 2021","title":"Spring MVC 구조 파악하기","tags":["spring","mvc"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n## 무엇을 캐싱했을까?\r\n\r\n[보고 또 보고](https://github.com/woowacourse-teams/2021-botobo) 에서는 문제집 검색 기능을 제공한다.  \r\n검색 기능이 고도화되면서 키워드로 검색된 문제집 결과에 유저, 태그로 필터해주는 기능도 추가되었다.  \r\n이렇게만 들었을 때는 '검색된 문제집들의 유저와 태그 리스트가 있을테니 이를 사용하면 되겠다!' 싶겠지만 그렇게 간단하지만은 않았다.  \r\n그 이유는 페이징 처리때문이었다.\r\n\r\n문제집 검색은 문제집 이름 중 키워드가 포함되어 있는 문제집 20개씩 페이징 처리를 해서 보여준다.  \r\n하지만 필터를 위해서 필요한 태그와 유저 리스트는 키워드에 해당하는 문제집 전체의 태그와 유저 리스트였다.  \r\n즉, 필요한 유저와 태그 리스트는 페이징 처리로 인해 매번 데이터를 추가해야 하는 것이 아닌 고정되어 있어야 했다.\r\n\r\n<p align=\"center\"><img width=\"70%\" src=\"https://user-images.githubusercontent.com/62014888/147463724-b5480561-9108-426f-bc80-59f6ae9d9226.jpg\"></p>\r\n\r\n\r\n그렇게 하기 위해서 결국 우리가 생각했던 방식은 새롭게 유저 및 태그 리스트를 불러오는 api를 만들고 이를 이용하는 것이었다.  \r\n마음에 들지 않았지만 현재 상황에서는 이 방법이 최선이라고 생각했고 결과적으로 해당 기능은 무사히 구현하게 되었다.\r\n\r\n**하지만** 문제는 매번 검색을 할 때마다 키워드에 해당하는 문제집 리스트만 I/O 작업을 통해 DB에서 들고 오는 것이 아니라 유저와 태그 리스트도 DB에서 들고와야 했다.  \r\n즉, 문제집 조회 기능을 위해서 매번 유저, 태그 리스트 조회를 위해 쿼리가 추가적으로 나가야 했다.\r\n\r\n- 문제집 조회 쿼리\r\n\r\n<p align=\"center\"><img width=\"70%\" src=\"https://user-images.githubusercontent.com/62014888/147400960-8d939d92-0746-4a92-a7e1-315ba53d4788.png\"></p>\r\n\r\n\r\n- 태그 조회 쿼리\r\n\r\n<p align=\"center\"><img width=\"70%\" src=\"https://user-images.githubusercontent.com/62014888/147873743-57198f9f-1664-474c-8127-4393b49759e0.png\"></p>\r\n\r\n\r\n\r\n\r\n\r\n동일한 키워드를 계속해서 검색할 때마다 유저, 태그 리스트를 조회하는 쿼리가 나가는 것은 매번 I/O 작업을 하는 것이라 속도가 느리고 성능상 좋지 않을 것이라고 판단했고 이를 위해 캐싱을 적용해야겠다고 생각하게 되었다.  \r\n그리고 때마침 인기 검색어와 인기 문제집을 위해서 Redis를 사용하고 있었고 `WAS별로 캐시 공유` 및 `TTL 설정`을 위해 저장소로 Redis를 사용하기로 했다!\r\n\r\n- 그렇다면 Memcached는?\r\n  - 캐싱을 위한 저장소로 Memcached도 있는 것으로 알고 있다.\r\n  - 두 개 다 메모리에 데이터를 저장하여 캐싱 기능으로 사용하기 좋고 편리하다고 할 수 있지만 팀에서 이미 '인기 검색어'와 '인기 문제집' 기능을 위해 Redis를 사용하고 있었다\r\n  - 특히, 인기 검색어는 sorted set이라는 자료구조를 활용하여 랭킹 처리를 하고 있었기에 Redis 사용이 확실했다.\r\n  - 정리하자면 Redis에서 제공해주는 다양한 자료구조, 기존에 사용하던 Redis를 그대로 사용함으로써 관리 포인트를 줄이기 위해 Redis를 사용했다고 볼 수 있다. (물론 문서가 다양하다는 장점도 있다ㅎㅎ)\r\n\r\n<br/>\r\n\r\n## 왜 캐싱을 하면 빠를까?\r\n\r\n왜 캐싱을 하면 빠를까?  \r\n조금 더 구체적으로 말하면 '왜 In-Memory가 Disk I/O보다 빠를까?'라고 말할 수 있다.\r\n\r\n<p align=\"center\"><img width=\"70%\" src=\"https://user-images.githubusercontent.com/62014888/147469334-aa69b436-263c-43c9-a3ef-8f71facdf8c6.png\"></p>\r\n\r\n메모리 계층 구조를 보게 되면 위에서 아래로 갈수록 CPU 접근 속도가 느려진다.  \r\nCPU는 레지스터, 캐시, 메인 메모리는 직접적인 접근이 가능하나 하드 디스크의 경우 직접 접근할 방법이 없다.  \r\n그래서 하드 디스크의 데이터를 메모리로 이동시키고, 메모리에서 접근해야 한다.\r\n\r\n그러다보니 당연히 메인 메모리에 데이터를 저장하는 In-Memory DB가 하드 디스크에 저장하는 Disk-Based DB보다 빠른 것이다.\r\n\r\n<br/>\r\n\r\n## 캐싱 전략 및 적용해보기\r\n\r\n캐싱 전략으로 두 가지 정도 짚고 넘어볼 수 있다.\r\n\r\n### 1) Look Aside (= Lazy Loading)\r\n이름 그대로 캐시를 옆에 두고 필요할 때만 데이터를 캐시에 로드하는 캐싱 전략이다. 캐시는 데이터베이스와 애플리케이션 사이에 위치하여 단순 key-value 형태를 저장한다.\r\n애플리케이션에서 데이터를 가져올 때 Redis에 항상 먼저 요청하고, 데이터가 캐시에 있을 때에는 Redis에서 데이터를 반환한다.\r\n만약 데이터가 캐시에 없을 경우 데이터베이스에 데이터를 요청하고, 애플리케이션은 이 데이터를 다시 Redis에 저장한다.\r\n\r\n- 장점\r\n    - 실제로 사용되는 데이터만 캐시할 수 있다.\r\n    - Redis의 장애가 애플리케이션에 치명적인 영향을 주지 않는다.\r\n- 단점\r\n    - 캐시에 없는 데이터를 조회할 때는 캐시에서 데이터에 대한 초기 요청, 데이터베이스 쿼리, 캐시에 데이터 쓰기와 같은 과정이 발생해 오랜 시간이 걸릴 수 있다.\r\n    - 캐시가 최신 데이터를 가지고 있다는 것을 보장하지 못한다. 데이터베이스에서 데이터가 변경될 때 캐시에 대한 업데이트가 없기 때문에 발생한다.\r\n        - Write Through 전략을 택하거나 TTL(Time To Live) 설정을 통해 해결할 수 있다.\r\n    \r\n<br/>\r\n\r\n### 2) Write Through\r\n데이터베이스에 데이터를 작성할 때마다 캐시에 데이터를 추가하거나 업데이트한다.\r\n\r\n- 장점\r\n    - 캐시의 데이터는 항상 최신 상태로 유지할 수 있다.\r\n- 단점\r\n    - 데이터 입력시 두번의 과정을 거쳐야 하기 때문에 지연 시간이 증가한다.\r\n    - 사용되지 않을 수도 있는 데이터도 일단 캐시에 저장하기 때문에 리소스 낭비가 발생한다.\r\n        - TTL 설정으로 해결할 수 있다.\r\n\r\n<br/>\r\n\r\n### 보또보에서는?\r\n\r\n캐싱에 사용되는 key는 검색 키워드고 value는 태그 리스트였다.  \r\n당시에는 이정도까지 전략에 대해 깊은 고민을 하지 않았다. (용어도 잘 몰랐다)  \r\n그렇기에 검색할 때 캐시 데이터가 존재하면 그 데이터를 반환하고 아니면 새로 DB에서 조회하고 캐싱하면 되겠다 싶어서 Look Aside 전략을 택했다.  \r\n최신 데이터가 아닌 점은 해당 데이터가 짧은 시간동안 정합성이 어긋나도 사용자 입장에서 서비스를 이용하는데 크게 영향을 끼칠 데이터가 아니므로 괜찮다고 생각했기에 TTL 설정을 통해 해결하고자 했다.\r\n\r\nTTL의 경우 현재 10분으로 설정되어 있지만... 아무리 캐싱으로 성능을 높이고 태그라는 데이터가 미치는 영향이 엄청 크지 않다고 해도 10분간 데이터 정합성이 어긋나는건 조금 아닌거 같다는 생각이 든다.  \r\n추후에 변경을 해야겠다.\r\n\r\n<br/>\r\n\r\n### 적용 코드\r\n\r\n본 코드는 프로젝트에서 사용한 코드 일부를 가져온 것이다.  \r\n필자가 구현한 부분은 Redis를 사용한 캐싱이었으므로 코드 또한 캐싱 관련 설정 및 구현 코드다.  \r\n이외에도 RedisTemplate, StringRedisTemplate 등을 사용하여 다른 팀원들이 구현한 리프레시 토큰을 저장한다던가 랭킹 기능 부분도 존재하지만 그 부분은 추후에 다뤄보겠다. \r\n\r\n```groovy\r\ndependencies {\r\n    // Redis\r\n    implementation 'org.springframework.boot:spring-boot-starter-data-redis'\r\n    implementation 'org.springframework.boot:spring-boot-starter-cache'\r\n\r\n}\r\n```\r\nCache를 사용하고 저장소로 Redis를 사용하기 위해 위와 같은 의존성을 추가했다.\r\n\r\n<br/>\r\n\r\n```yaml\r\nspring:\r\n  redis:\r\n    host: redis 서버 ip 주소\r\n    port: 6379 # redis 기본포트는 6379다\r\n```\r\n```java\r\n@Configuration\r\npublic class RedisConfig {\r\n\r\n    private final RedisProperties redisProperties;\r\n\r\n    public RedisConfig(RedisProperties redisProperties) {\r\n        this.redisProperties = redisProperties;\r\n    }\r\n\r\n    // 1\r\n    @Bean\r\n    public RedisConnectionFactory redisConnectionFactory() {\r\n        RedisStandaloneConfiguration redisStandaloneConfiguration = new RedisStandaloneConfiguration();\r\n        redisStandaloneConfiguration.setHostName(redisProperties.getHost());\r\n        redisStandaloneConfiguration.setPort(redisProperties.getPort());\r\n        return new LettuceConnectionFactory(redisStandaloneConfiguration);\r\n    }\r\n}\r\n```\r\n\r\nRedis 설정 클래스와 Cache 설정 클래스를 따로 나누었다.  \r\n1. yml에 설정한 Redis 정보를 이용해 RedisConnectionFactory 인터페이스 구현체를 만들어서 반환한다.  \r\n   RedisConnectionFactory는 Redis에 접근을 도와주는 인터페이스로 구체적으로 Redis 연결에 사용되는 RedisConnection을 생성한다.  \r\n   이때 구현체인 Client로 Java는 크게 Jedis, Lettuce 크게 2가지를 지원해준다.  \r\n   2개 중에 Lettuce를 택하게 되었는데 그 이유는  \r\n   Lettuce는 Netty 기반 Reids Client로 비동기 방식으로 요청을 처리해주므로 성능이 좋고 무엇보다 Spring-data-redis에서 제공해주는 기본 Client이므로 따로 의존성을 추가할 필요가 없기 때문에 간편하게 사용할 수 있기 때문이다.  \r\n   성능과 관련한 글은 [이동욱님의 글](https://jojoldu.tistory.com/418) 을 참고하길 바란다.\r\n\r\n<br/>\r\n\r\n```java\r\n// 1\r\n@Configuration\r\n@EnableCaching\r\n// 2\r\npublic class CacheConfig extends CachingConfigurerSupport {\r\n\r\n    private final RedisConnectionFactory redisConnectionFactory;\r\n\r\n    public CacheConfig(RedisConnectionFactory redisConnectionFactory) {\r\n        this.redisConnectionFactory = redisConnectionFactory;\r\n    }\r\n\r\n    // 3\r\n    @Bean\r\n    @Override\r\n    public CacheManager cacheManager() {\r\n        return RedisCacheManager.RedisCacheManagerBuilder.fromConnectionFactory(redisConnectionFactory)\r\n                .cacheDefaults(defaultConfiguration())\r\n                .withInitialCacheConfigurations(cacheConfigurations())\r\n                .build();\r\n    }\r\n\r\n    // 4\r\n    private Map<String, RedisCacheConfiguration> cacheConfigurations() {\r\n        return Map.of(\r\n                \"filterTags\", durationConfiguration()\r\n        );\r\n    }\r\n\r\n    // 5\r\n    private RedisCacheConfiguration defaultConfiguration() {\r\n        return RedisCacheConfiguration.defaultCacheConfig()\r\n                .entryTtl(Duration.ofDays(7))\r\n                .disableCachingNullValues()\r\n                .serializeValuesWith(\r\n                        RedisSerializationContext.SerializationPair.fromSerializer(\r\n                                new GenericJackson2JsonRedisSerializer()\r\n                        )\r\n                );\r\n    }\r\n\r\n    // 6\r\n    private RedisCacheConfiguration durationConfiguration() {\r\n        return RedisCacheConfiguration.defaultCacheConfig()\r\n                .entryTtl(Duration.ofMinutes(10));\r\n    }\r\n}\r\n\r\n```\r\n캐싱 설정 관련 클래스다.  \r\n\r\n1. @EnableCaching은 내부적으로 Spring AOP를 이용하여 애노테이션 기반 캐싱 설정을 사용하게 해준다.\r\n2. 현재 코드에는 없지만 프로젝트에서 CacheManager를 2개를 빈으로 등록해두고 사용한다.  \r\n    RedisCacheManager와 ConcurrentMapCacheManager인데 이러한 Multiple CacheManager 사용을 위해서는 @Primary를 사용해 우선적으로 등록을 시켜줄 CacheManager를 정해주거나\r\n   CacheConfigurerSupport를 상속하여 구현하면 된다.\r\n3. 빈으로 등록된 RedisConnectionFactory를 사용하는 RedisCacheManager를 만드는데 이때 cacheDefaults와 withInitialCacheConfigurations를 설정했다.  \r\n    기본적으로 withInitialCacheConfigurations에서 관리되는 cacheName 인지 먼저 보고 없으면 cacheDefaults를 사용한다고 한다.  \r\n   참고로 현재 cacheDefaults에 설정된 RedisCacheConfiguration은 리프레시 토큰 관련 설정이다.\r\n4. cacheName 별로 RedisCacheConfiguration을 가지고 있는 Map을 반환한다. 코드에는 filterTags 밖에 없지만 실제로는 다른 설정도 등록되어 있다.\r\n5. 리프레시 토큰 관련 설정으로 TTL은 7일 직렬화 옵션으로 GenericJackson2JsonRedisSerializer를 사용했다.\r\n6. 태그 캐시 설정으로 TTL을 10분으로 설정했다.\r\n\r\n<br/>\r\n\r\n```java\r\n@Service\r\n@Transactional(readOnly = true)\r\npublic class TagService {\r\n\r\n    private final TagRepository tagRepository;\r\n    private final TagSearchRepository tagSearchRepository;\r\n\r\n    public TagService(TagRepository tagRepository, TagSearchRepository tagSearchRepository) {\r\n        this.tagRepository = tagRepository;\r\n        this.tagSearchRepository = tagSearchRepository;\r\n    }\r\n    \r\n    @Cacheable(value = \"filterTags\", key = \"#filterCriteria.workbook\")\r\n    public List<TagResponse> findAllTagsByWorkbookName(FilterCriteria filterCriteria) {\r\n        String keyword = filterCriteria.getWorkbook();\r\n        if (filterCriteria.isEmpty()) {\r\n            return TagResponse.listOf(Tags.empty());\r\n        }\r\n\r\n        List<Tag> findTags = tagSearchRepository.findAllByContainsWorkbookName(keyword);\r\n        return TagResponse.listOf(Tags.of(findTags));\r\n    }\r\n}\r\n```\r\n마지막으로 TagService에서 캐시 애노테이션을 사용한 코드다.\r\n\r\n저장하는 key는 검색 키워드, value는 TagResponse List로 설정하였다.  \r\n먼저 Redis에 key가 존재하는지 확인하고 존재하면 바로 해당 value를 이용해 응답을 보내주고\r\n존재하지 않으면 DB에 요청을 해서 태그 리스트를 조회하고 TagResponse로 변환한 뒤 응답을 보내주었다.\r\n\r\n<br/>\r\n\r\n## 성능 측정\r\n\r\n성능 테스트를 위해 테스트 서버를 구축하고 데이터베이스에 문제집 100만, 태그 만 개 정도를 넣어두고 테스트를 진행해봤다.  \r\n하지만, 아쉽게도 쿼리가 문제가 있었는지 데이터가 많을 때는 테스트를 하기 힘들 정도로 조회 속도가 느렸다.\r\n\r\n추후에 쿼리 튜닝을 해야겠다는 생각을 하고 일단 개발 서버에 존재하던 데이터로만 테스트를 진행했다.  \r\n테스트 도구로 k6를 사용했고 VUSER는 100으로 설정했다.  \r\n100으로 설정한 이유는 1명당 1일 평균 요청 수를 피크시간 대에 60~70이라고 잡고 태그 조회 api의 요청 수는 1이고 지연시간이 0.5라고 가정했을 때  \r\n(60\\*1.5)/1 = 90이고 (70\\*1.5)/1 = 105 니까 어림잡아 100으로 설정하게 되었다.\r\n\r\n- 캐싱 전\r\n<p align=\"center\"><img width=\"80%\" src=\"https://user-images.githubusercontent.com/62014888/147479729-bde97d19-eb7d-4423-a3da-e137176756f2.png\"></p>\r\n\r\n- 캐싱 후\r\n<p align=\"center\"><img width=\"80%\" src=\"https://user-images.githubusercontent.com/62014888/147479767-bd8086cb-c1b7-46e0-a081-ad7261b31507.png\"></p>\r\n\r\n측정 결과 요청 응답 시간이 평균 2.72sec에서 587ms로 줄어든 것을 볼 수 있었다.\r\n\r\n\r\n<br/>\r\n\r\n## 아쉬운 점\r\n\r\n1. 성능테스트를 조금 더 깊게 해볼껄 이라는 아쉬움이 들었다.  \r\n   앞서 말했듯 대량의 데이터를 이용해 측정을 하지 못했고 단순하게 k6만 돌려놓기만 하고 해당 서버에서 vmstat을 사용해 시스템 모니터링을 하지 못했다.  \r\n   k6 설정도 조금 아쉬웠다. 테스트 시간을 더 길게 잡고 해봤어야 했는데..\r\n\r\n<br/>\r\n\r\n2. 다른 크루에게 '왜 검색 결과에 해당하는 문제집 리스트를 캐싱하지 않았어?' 라는 질문을 들었던 적이 있었다.  \r\n   당시에는 문제집 결과를 캐싱할 생각을 못했다.  \r\n   아마 api가 여러번 나가게 된다는 것에 초점을 뒀고 문제집은 페이징 처리가 되어있다보니 힘들다고 예상해서 제외를 했던 것 같다.  \r\n   하지만 지금 생각해보니 페이징 처리가 되어있다고 해도 캐싱은 충분히 해줄 수 있을 것 같았다.  \r\n   그렇다면 데이터 정합성과 관련해서 캐싱 전략을 세우고 적절한 트레이드 오프를 찾는다면 문제집 결과를 캐싱하는 것이 성능을 더 향상시킬 수 있지 않을까? 라는 생각이 든다.\r\n\r\n<br/>\r\n\r\n3. 면접에서 받았던 질문으로 '키워드에 해당하는 문제집이 추가가 되었을 때 태그 리스트도 변경이 될 수 있는데 이 부분은 어떻게 생각하냐?' 가 있는데  \r\n   당시에 'TTL을 1분(인줄 알았는데 10분이었다)으로 설정했고 해당 데이터가 짧은 시간동안 정합성이 어긋나도 사용자 입장에서 서비스를 이용하는데 크게 영향을 끼칠 데이터가 아니므로 괜찮다고 생각한다. 그리고 키워드에 해당하는 문제집이 추가되었을 때 저장되어있던 캐시를 비워주는 방법도 생각하고 있다. 어쩌고 저쩌고~'  \r\n   이런 느낌으로 대답을 했었는데 돌아온 질문이 '어떻게 문제집을 추가할 때 키워드와 관련된 캐시를 삭제할 수 있냐?' 였고 그럼 캐시 전부를 비우는 방법도 있겠는데 그 부분은 조금 더 생각해봐야겠다고 답변했던 경험이 있다.  \r\n   끝나고 나서도 지금까지 드는 고민은 어떻게 할 수 있을까? 였다.  \r\n   결국 트레이드 오프라고 생각하고 받아들여야 하는건가 아님 전략을 바꿔 문제를 해결해야 하는건가 계속 고민 중이다.\r\n\r\n<br/>\r\n\r\n## 마무리\r\n\r\n- 캐싱과 Redis에 대해 공부하게 된 좋은 시간이었다.\r\n- 과연 현재 캐싱한 데이터가 정말로 캐싱하기 적합한 데이터였을까? 하고 생각하면 자신있게 대답은 하기 힘들 것 같다.\r\n하지만 당시에는 이 방법이 최선이었다고 생각한다..ㅎㅎ\r\n- 항상 캐싱을 할땐 데이터 정합성을 생각하며 팀 차원에서 적절한 전략을 세우도록 하자.\r\n\r\n<br/>\r\n\r\n## 참고\r\n\r\n- https://meetup.toast.com/posts/225\r\n- https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/Strategies.html\r\n- https://ko.wikipedia.org/wiki/메모리_계층_구조\r\n- https://www.baeldung.com/spring-multiple-cache-managers\r\n- https://velog.io/@bonjugi/RedisCacheManager-TTL-Serializer-%EB%A5%BC-%EC%BA%90%EC%8B%9C%EC%9D%B4%EB%A6%84%EB%B3%84%EB%A1%9C-%EB%8B%A4%EB%A5%B4%EA%B2%8C-%EC%84%A4%EC%A0%95%ED%95%98%EA%B8%B0\r\n- https://jojoldu.tistory.com/418\r\n- https://github.com/binghe819/TIL/blob/master/Spring/Redis/spring%EC%9C%BC%EB%A1%9C%20redis%EB%A5%BC%20%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0%20%EC%A0%84%EC%97%90%20%EB%B3%B4%EB%A9%B4%20%EC%A2%8B%EC%9D%80%20%ED%81%B0%20%EA%B7%B8%EB%A6%BC/spring%EC%9C%BC%EB%A1%9C%20redis%EB%A5%BC%20%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0%20%EC%A0%84%EC%97%90%20%EB%B3%B4%EB%A9%B4%20%EC%A2%8B%EC%9D%80%20%ED%81%B0%20%EA%B7%B8%EB%A6%BC.md","excerpt":"무엇을 캐싱했을까? 보고 또 보고 에서는 문제집 검색 기능을 제공한다. 검색 기능이 고도화되면서 키워드로 검색된 문제집 결과에 유저, 태그로 필터해주는 기능도 추가되었다. 이렇게만 들었을 때는 '검색된 문제집들의 유저와 태그 리스트가 있을테니 이를 …","fields":{"slug":"/redis-cache/"},"frontmatter":{"date":"Dec 04, 2021","title":"프로젝트에서 캐싱을 통해 성능 개선하기","tags":["redis","cache"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n캐싱이라는 용어는 프로그래밍에서 자주 등장하게 된다.\r\n캐싱이란 '성능 향상을 위해 사용이 많은 데이터를 별도 공간에 일시적으로 저장하여 필요할 때마다 데이터를 가져오는 기술'이다.\r\n메모리, 네트워크 등 다양한 곳에서 사용하게 되는데 Spring에서도 편리하게 캐싱을 사용하기 위해 캐싱 추상화 형식으로 제공해준다.\r\n공식 문서를 바탕으로 간단하게 이를 알아보도록 하자.\r\n\r\n---\r\n\r\n## Spring Cache?\r\n\r\nSpring Framework는 버전 3.1 부터 기존 Spring 애플리케이션에 투명하게 캐싱을 추가하는 지원을 제공한다. Spring에서 제공하는 트랜잭션 지원과 유사하게 캐싱 추상화를 통해 코드에 미치는 영향을 최소화하면서 다양한 캐싱 솔루션을 일관되게 사용할 수 있다.\r\n\r\n간단하게 이야기하자면 Java 메소드에 애노테이션과 같은 추상화된 캐싱을 적용하여 캐시에서 사용 가능한 정보를 기반으로 실행 횟수를 줄이는 것이다. 즉, 해당 메소드가 호출될 때 주어진 인자에 대해 메소드가 이미 실행되었는지 여부를 확인하고 실행되었다면 실제 메소드를 실행할 필요 없이 캐시된 결과가 반환된다.\r\n\r\n이를 통해 값비싼 메소드(CPU or I/O 바인딩 여부)를 주어진 매개변수 집합에 대해 한 번만 실행할 수 있으며 실제로 메소드를 다시 실행할 필요 없이 결과를 재사용할 수 있다.\r\n\r\n캐시 추상화를 사용하려면 개발자는 두 가지 측면을 처리해야 한다.\r\n\r\n- caching declaration(캐싱 선언) - 캐싱해야 하는 메소드와 해당 정책 식별\r\n- cache configuration(캐시 구성) - 데이터가 저장되고 읽히는 백업 캐시\r\n\r\nSpring Framework의 다른 서비스와 마찬가지로 캐싱 서비스는 추상화(캐시 구현이 아님)이며 캐시 데이터를 저장하기 위해 실제 저장소를 사용해야 한다. 기본적으로 Spring에서는 EhCache, Caffeine, Redis 등 여러 캐시들을 지원해주며 애플리케이션에 저장하는 ConcurrentMap 또한 저장소로 사용할 수 있다.\r\n\r\n<br/>\r\n\r\n## Configuration\r\n\r\nSpring Boot, Gradle을사용하고 있다면 간단하게 아래 dependencies를 추가하여 사용 가능하다.\r\n\r\n```groovy\r\ndependencies {\r\n    implementation 'org.springframework.boot:spring-boot-starter-cache'\r\n}\r\n```\r\n\r\n```java\r\n@EnableCaching\r\n@Configuration\r\npublic class CacheConfig {\r\n\r\n    @Bean\r\n    public CacheManager cacheManager() {\r\n        return new ConcurrentMapCacheManager(\"workbooks\");\r\n    }\r\n\r\n}\r\n```\r\n\r\n- Spring에서는 설정과 상관없이 동일한 코드로 캐시에 접근하기 위해서 CacheManager를 제공헤준다.\r\n- 예시를 위해 ConcurrentMap을 사용했는데 상황에 따라 무엇을 사용할지 결정될 것 같다.\r\n    - ConcurrerntMap의 경우 TTL을 설정할 수 없고 애플리케이션 내에서 사용되는 캐시이기에 WAS가 늘어나면 WAS 별로 따로 관리를 해줘야한다.\r\n        - TTL을 설정할 수 없기에 Scheduling 등을 이용해 삭제해줘야 한다.\r\n    - 외부에 같은 캐시 저장소를 사용하려면 Redis나 Memcached를 사용하는게 좋다.\r\n- @EnableCaching은 내부적으로 Spring AOP를 이용하여 애노테이션 기반 캐싱 설정을 사용하게 해준다.\r\n    - 원래는 proxyTargetClass가 false인 경우 JDK Dynamic Proxy 사용, true인 경우 CGLIB Proxy를 사용하나 Spring Boot가 버전이 업데이트 되면서 CGLIB 사용을 강제했기 때문에 현재 2.5.1 기준 false 여도 CGLIB를 사용한다.\r\n\r\n<br/>\r\n\r\n## @Cacheable\r\n\r\n@Cacheable은 캐싱할 수 있는 메소드를 지정하는데 사용한다.\r\n\r\n```java\r\n\r\n@Cacheable(cacheNames = \"workbooks\", key = \"#keyword\")\r\npublic Workbook findWorkbookByKeyword(String keyword) {\r\n    return workbookRepository.findByName(keyword);\r\n}\r\n```\r\n\r\n```java\r\n\r\n@Test\r\nvoid findWorkbookByKeyword() {\r\n    // given\r\n    String keyword = \"java\";\r\n    given(workbookRepository.findByName(anyString()))\r\n            .willReturn(new Workbook());\r\n\r\n    // when\r\n    workbookService.findWorkbookByKeyword(keyword);\r\n    workbookService.findWorkbookByKeyword(keyword);\r\n    workbookService.findWorkbookByKeyword(keyword);\r\n\r\n    // then\r\n    then(workbookRepository)\r\n            .should(times(1))\r\n            .findByName(anyString());\r\n}\r\n```\r\n\r\n- cacheNames는 설정에서 ConcurrentMapCacheManager의 저장소 명과 일치한 값이 들어가며 value도 같은 역할을 한다. (일치하지 않으면 캐싱이 안됨)\r\n- key의 경우 캐시 데이터가 들어있는 key (여기서는 ConcurrentMap의 key) 이며 해당 key의 value가 존재하면 findWorkbookByKeyword 메소드가 수행되지 않고, 존재하지 않으면 수행된다.\r\n    - key는 SpEL (Spring Expression Language) 문법을 사용할 수 있는데 위와 같이 파라미터로 넘어온 값을 지정할 수 있고 파라미터가 객체일 경우 객체의 멤버 변수에도 접근할 수 있다.\r\n    - SpEL에 대한 자세한 사항은 [공식 문서](https://docs.spring.io/spring-framework/docs/3.2.x/spring-framework-reference/html/cache.html) 를 참고하자.\r\n\r\n    ```java\r\n    @Cacheable(cacheNames = \"workbooks\", key = \"#workbook.name\")\r\n    public Workbook findWorkbookByKeyword(Workbook workbook) {\r\n        return workbookRepository.findByName(workbook.getName());\r\n    }\r\n    ```\r\n\r\n    ```java\r\n    @Test\r\n    void findWorkbookByKeyword() {\r\n        // given\r\n        Cache cache = Objects.requireNonNull(concurrentMapCacheManager.getCache(\"workbooks\"));\r\n        Workbook workbook = new Workbook(\"java\");\r\n        given(workbookRepository.findByName(anyString()))\r\n                .willReturn(workbook);\r\n    \r\n        // when\r\n        workbookService.findWorkbookByKeyword(workbook);\r\n    \r\n        // then\r\n        assertThat(cache.get(workbook.getName())).isNotNull();\r\n    }\r\n    ```\r\n\r\n\r\n- condition 속성을 이용하면 조건도 부여할 수 있다.\r\n\r\n    ```java\r\n    @Cacheable(cacheNames = \"workbooks\", key = \"#workbook.name\", condition = \"#workbook.name.length() > 4\")\r\n    public Workbook findWorkbookByKeyword(Workbook workbook) {\r\n        return workbookRepository.findByName(workbook.getName());\r\n    }\r\n    ```\r\n\r\n    ```java\r\n    @Test\r\n    void findWorkbookByKeywordWhenConditionExists() {\r\n        // given\r\n        Workbook workbook = new Workbook(\"java\");\r\n        given(workbookRepository.findByName(anyString()))\r\n                .willReturn(workbook);\r\n    \r\n        // when\r\n        workbookService.findWorkbookByKeyword(workbook);\r\n        workbookService.findWorkbookByKeyword(workbook);\r\n        workbookService.findWorkbookByKeyword(workbook);\r\n    \r\n        // then\r\n        then(workbookRepository)\r\n                .should(times(3))\r\n                .findByName(anyString());\r\n    }\r\n    ```\r\n\r\n    - workbook의 name length가 4보다 큰 경우에 캐싱하도록 조건을 부여했기에 캐싱이 되지 않은 모습을 볼 수 있다.\r\n\r\n- 특정 로직에 의해 key를 만들고자 하는 경우 KeyGenerator 인터페이스를 별도로 구현하여 Custom KeyGenerator를 만들어 사용할 수 있다고 한다.\r\n    - default는 SimpleKeyGeneretor를 사용한다고 하며 파라미터를 보고 key를 생성해주게 된다.\r\n\r\n        ![Untitled (11)](https://user-images.githubusercontent.com/62014888/145708088-61abe80d-72c8-4dda-b679-053c455ada65.png)\r\n\r\n    - 파라미터가 없는 경우는 빈 값,\r\n      1개일 경우 해당 파라미터,\r\n      여러 개일 경우 모든 파라미터의 해시에서 계산된 키를 반환한다.\r\n    - 만약 key를 따로 지정하지 않는다면 side effect가 생길 수 있으니 지정해주는 것이 좋다.\r\n\r\n- cacheManager가 여러 개라면 cacheManager 속성을 사용해 원하는 cacheManager 설정도 가능하다.\r\n\r\n<br/>\r\n\r\n## @CachePut\r\n\r\n@CachePut은 메소드 실행에 영향을 주지 않고 캐시를 갱신해야 할 경우 사용한다. 즉, 메소드를 항상 실행하고 그 결과를 캐시에 보관한다.\r\n\r\n```java\r\n@CachePut(cacheNames = \"workbooks\", key = \"#workbook.name\")\r\npublic Workbook findWorkbookByKeyword(Workbook workbook) {\r\n    return workbookRepository.findByName(workbook.getName());\r\n}\r\n```\r\n\r\n```java\r\n@Test\r\nvoid findWorkbookByKeywordWhenCachePut() {\r\n\t  // given\r\n\t  Workbook workbook = new Workbook(\"java\");\r\n\t  given(workbookRepository.findByName(anyString()))\r\n\t          .willReturn(workbook);\r\n\t\r\n\t  // when\r\n\t  workbookService.findWorkbookByKeyword(workbook);\r\n\t  workbookService.findWorkbookByKeyword(workbook);\r\n\t  workbookService.findWorkbookByKeyword(workbook);\r\n\t\r\n\t  // then\r\n\t  then(workbookRepository)\r\n\t          .should(times(3))\r\n\t          .findByName(anyString());\r\n}\r\n```\r\n\r\n- Spring에서는 같은 메소드에 @CachePut과 @Cacheable을 사용하는 것을 권장하지 않는다. @Cacheable은 캐시를 사용해서 메소드를 건너뛰려하고 @CachePut은 메소드 실행을 강제하기 때문에 의도치 않은 동작이 발생할 수 있기 때문이다.\r\n\r\n    ![Untitled (12)](https://user-images.githubusercontent.com/62014888/145708123-70dd5b48-4324-4088-894d-8b70c3e3c841.png)\r\n\r\n\r\n<br/>\r\n\r\n## @CacheEvict\r\n\r\n@CacheEvict는 저장된 캐시를 제거할 때 사용한다. 메소드 실행 시,  해당 캐시를 삭제한다.\r\n\r\n```java\r\n@CacheEvict(cacheNames = \"workbooks\", key = \"#keyword\")\r\npublic void removeWorkbookCache(String keyword) {\r\n    // ...\r\n}\r\n```\r\n\r\n```java\r\n@Test\r\nvoid removeWorkbookCacheByKeyword() {\r\n    // given\r\n    String keyword = \"java\";\r\n    String anotherKeyword = \"spring\";\r\n    Cache cache = Objects.requireNonNull(concurrentMapCacheManager.getCache(\"workbooks\"));\r\n    given(workbookRepository.findByName(anyString()))\r\n            .willReturn(new Workbook());\r\n\r\n    // when\r\n    workbookService.findWorkbookByKeyword(keyword);\r\n    workbookService.findWorkbookByKeyword(anotherKeyword);\r\n    workbookService.removeWorkbookCache(keyword);\r\n\r\n    // then\r\n    assertThat(cache.get(keyword)).isNull();\r\n    assertThat(cache.get(anotherKeyword)).isNotNull();\r\n}\r\n```\r\n\r\n- allEntries 속성을 true로 설정하여 하나의 캐시가 아닌 전체 캐시를 제거할 수 있다. default가 false다.\r\n\r\n    ```java\r\n    @CacheEvict(cacheNames = \"workbooks\", allEntries = true)\r\n    public void removeWorkbookCache() {\r\n        // ...\r\n    }\r\n    ```\r\n\r\n    ```java\r\n    @Test\r\n    void removeWorkbookAllCacheByKeyword() {\r\n        // given\r\n        String keyword = \"java\";\r\n        String anotherKeyword = \"spring\";\r\n        Cache cache = Objects.requireNonNull(concurrentMapCacheManager.getCache(\"workbooks\"));\r\n        given(workbookRepository.findByName(anyString()))\r\n                .willReturn(new Workbook());\r\n    \r\n        // when\r\n        workbookService.findWorkbookByKeyword(keyword);\r\n        workbookService.findWorkbookByKeyword(anotherKeyword);\r\n        workbookService.removeWorkbookCache();\r\n    \r\n        // then\r\n        assertThat(cache.get(keyword)).isNull();\r\n        assertThat(cache.get(anotherKeyword)).isNull();\r\n    }\r\n    ```\r\n\r\n\r\n- beforeInvocation 속성을 이용해 true면 메소드 실행 이전에 캐시를 삭제하고, false면 메소드 실행 이후 삭제를 할 수 있다. default가 false다.\r\n- 위 예제처럼 void 메소드와 함께 사용할 수 있다. 메소드가 트리거로 동작하므로 반환값은 무시한다.\r\n\r\n<br/>\r\n\r\n## @Caching\r\n\r\n@Caching은 @CacheEvict나 @CachePut을 여러 개 지정해야 하는 경우에 사용한다.\r\n\r\n- 예를 들어 조건이나 키 표현식이 캐시에 따라 다른 경우다.\r\n- 여러가지의 key에 대한 캐시를 중첩적으로 삭제해야할 때 사용할 수 있다.\r\n\r\n```java\r\n@Caching(evict = {@CacheEvict(value = \"workbooks\", key = \"#keyword\"), @CacheEvict(\"tags\")})\r\npublic void removeWorkbookCache(String keyword) {\r\n    // ...\r\n}\r\n```\r\n\r\n- @Cacheable, @CachePut, @CacheEvict를 같은 메소드에 다수 사용할 수 있다.\r\n\r\n<br/>\r\n\r\n## @CacheConfig\r\n\r\n@CacheConfig는 클래스 단위로 캐시 설정을 동일하게 하는데 사용한다.\r\n\r\n- CacheManager가 여러 개인 경우 사용할 수 있다.\r\n- 프로젝트를 진행하면서 Redis용 CacheManager와 ConcurrentMapCacheManager를 같이 사용했는데 이때 ConcurrentMapCacheManager를 사용하는 클래스에서 다음과 같이 @CacheConfig를 사용할 수 있다.\r\n\r\n    ```java\r\n    @Slf4j\r\n    @Service\r\n    @CacheConfig(cacheManager = \"concurrentMapCacheManager\")\r\n    public class SearchRankService {\r\n    \r\n        private static final String SEARCH_RANKS_CACHE_VALUE = \"SearchRanks\";\r\n        private static final int SEARCH_RANK_COUNT = 3;\r\n    \r\n        private final SearchRankRepository searchRankRepository;\r\n        private final SearchScoreRepository searchScoreRepository;\r\n    \r\n        public SearchRankService(SearchRankRepository searchRankRepository, SearchScoreRepository searchScoreRepository) {\r\n            this.searchRankRepository = searchRankRepository;\r\n            this.searchScoreRepository = searchScoreRepository;\r\n        }\r\n    \r\n        @Cacheable(value = SEARCH_RANKS_CACHE_VALUE, key = \"'SearchRanksKey'\")\r\n        public List<SearchRankResponse> bringSearchRanks() {\r\n            List<SearchRank> searchRanks = findSearchRanks();\r\n            return SearchRankResponse.listOf(searchRanks);\r\n        }\r\n    \r\n        @CacheEvict(value = SEARCH_RANKS_CACHE_VALUE, key = \"'SearchRanksKey'\")\r\n        public void removeSearchRanksCache() {\r\n            log.info(\"cleared cache for search rankings request\");\r\n        }\r\n    \t\r\n    \t\t// ...\r\n    }\r\n    ```\r\n\r\n<br/>\r\n\r\n## 마무리\r\n\r\n- Spring Cache에 대해 대략적으로 알아보았다. Spring에서 제공하는 이러한 추상화 기술(PSA)을 통해 트랜잭션을 사용하는 것과 마찬가지로 간단하게 캐싱을 적용할 수가 있었다.\r\n- 위에서 설명한 것보다 더 많은 애노테이션 속성이 존재하기 때문에 필요한 경우 공식 문서를 참고하는 것이 좋을 듯 하다.\r\n- 프로젝트에서 사용한 캐싱 전략 및 설정, 코드에 대한 설명은 다음 포스트에 적도록 하겠다.\r\n\r\n<br/>\r\n\r\n## 참고\r\n\r\n- [https://docs.spring.io/spring-framework/docs/4.3.x/spring-framework-reference/html/cache.html](https://docs.spring.io/spring-framework/docs/4.3.x/spring-framework-reference/html/cache.html)\r\n- [https://12bme.tistory.com/550](https://12bme.tistory.com/550)\r\n- [https://sunghs.tistory.com/132](https://sunghs.tistory.com/132)\r\n- [https://jaehun2841.github.io/2018/11/07/2018-10-03-spring-ehcache/#spring-cache-annotation](https://jaehun2841.github.io/2018/11/07/2018-10-03-spring-ehcache/#spring-cache-annotation)","excerpt":"캐싱이라는 용어는 프로그래밍에서 자주 등장하게 된다.\n캐싱이란 '성능 향상을 위해 사용이 많은 데이터를 별도 공간에 일시적으로 저장하여 필요할 때마다 데이터를 가져오는 기술'이다.\n메모리, 네트워크 등 다양한 곳에서 사용하게 되는데 Spring에서도…","fields":{"slug":"/spring-cache/"},"frontmatter":{"date":"Dec 04, 2021","title":"Spring Cache 살펴보기","tags":["spring","cache"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n보통 로깅을 위해서 System.out.println() 보다는 logback 이나 log4j 같은 로깅 프레임워크를 사용하는 것이 좋다고 한다.\r\n\r\n로깅 프레임워크를 사용하면 로깅 레벨을 설정할 수 있다는 점이 좋다고는 알고 있지만 성능상으로도 더 좋다고 하는데 그게 진짜일까?\r\n\r\n둘 다 입출력을 위해 i/o 작업이 발생하는데 왜 System.out.println()이 성능상 떨어진다고 할까? 한번 알아보도록 하자.\r\n\r\n---\r\n\r\n## System.out.println()\r\n\r\n- System.out.println 은 정확히 코드를 열어보게 되면\r\n  System이라는 final 클래스에 있는 out이라는 변수명을 가진 PrintStream 객체의 println 이라는 메소드를 뜻한다.\r\n\r\n- println이라는 메소드는 오버로딩이 많이 되어있는 메소드인데 보는바와 같이 동기화를 위해 synchronized 키워드를 많이 사용을 하고 라인 단위로 flush를 한다.\r\n\r\n![Untitled (25)](https://user-images.githubusercontent.com/62014888/145754156-4426b0ec-dbb9-4acf-a5f5-8d28afa567ef.png)\r\n\r\n![Untitled (26)](https://user-images.githubusercontent.com/62014888/145754160-44600f2a-2b96-4a21-ada3-90c3fa2843c6.png)\r\n\r\n- 이는 곧 동기화를 위해 오버헤드가 많이 발생한다는 뜻이다.\r\n  즉 작업이 순차적으로 진행되어야 하기에 콘솔에 출력을 완료할 때까지 다음 작업은 block된 상태로 대기하고 있어야한다.\r\n\r\n<br/>\r\n\r\n## Logger\r\n\r\n- logger로 사용되는 다양한 로깅 프레임워크가 존재한다. 기본적으로 SLF4J라는 다양한 로깅 프레임워크들에 대한 공용 인터페이스(Facade)가 존재하고 이들의 구현체인 log4j, logback, log4j2 등의 로깅 프레임워크가 존재한다.\r\n- 예시로 들 것은 logback이며 logger를 사용하여 콘솔에 로그를 출력하기로 했다.\r\n- logback에서는 콘솔에 출력하기 위해 ConsoleAppender를 사용하게 되는데 해당 클래스의 모습이다.\r\n\r\n![Untitled (27)](https://user-images.githubusercontent.com/62014888/145754208-5d07a394-f1a4-4aa7-bea1-7dc71fd8aa14.png)\r\n\r\n- 근데 뭔가 이상하지 않은가? 해당 클래스의 주석에도 그렇고 공식 문서에도 그렇고 콘솔에 출력하기 위해 기본적으로 System.out을 사용한다고 적혀있다.\r\n\r\n![Untitled (28)](https://user-images.githubusercontent.com/62014888/145754215-83bd9002-a633-4b34-bab1-0ccffccb7f1e.png)\r\n\r\n- 실제로 ConsoleTarget이라는 enum도 살펴보면 System.out.write를 사용하는 모습을 볼 수 있다.\r\n- 이걸 보고 \"System.out.println()을 사용하는 것은 logger를 사용해 로깅하는 것에 비해 성능상 좋지 않아!\" 라고 무조건적으로 생각하는 것은 조금 잘못되었다라는 것을 알게 되었다.\r\n- 결국은 둘 다 System.out을 사용하여 i/o 작업이 발생하는 것이며 println의 경우 synchronized 키워드가 더 붙여져 있는 것일뿐 성능상으로 크게 차이가 없다고 추측이 된다.\r\n- 실제로 for문으로 출력 테스트를 해보았을 때 logger를 사용한 출력 시간이 더 오래걸렸다.\r\n- 그렇다면 왜 성능에 관해서 이야기가 나오는 걸까?\r\n    - 결론적으로 비동기 로깅을 사용하면 성능이 향상된다.\r\n    - 특히 파일로 로그를 남길 때 비동기 로깅을 적용시킬 수가 있는데 적용하게 되면 로그 발생과 로그 쓰기를 분리시키기에 로깅 메소드를 호출하는 시점에 i/o 작업이 바로 수행되지 않아 성능이 향상된다.\r\n- Baeldung 블로그나 스택오버플로우를 검색해봐도 System.out.println() vs logger에서 성능 이야기는 전혀 나오지 않았다. 나오더라도 비동기와 같이 나오는 경우만 볼 수 있었다.\r\n\r\n<br/>\r\n\r\n\r\n## 그렇다면 언제 무엇을 쓸까?\r\n\r\n- 당연히 프로젝트를 진행하는 상황이라면 디버깅을 위해서 또는 로그를 남기기 위해서 logger를 사용해야한다.\r\n- System.out.println()은 사용하긴 편하나 콘솔에만 출력이 가능하고 날짜, 시간을 출력하지 않아 기록을 위한 로그용으로 불편하다.\r\n  또한 출력되는 메시지를 제어할 수 없다.\r\n- logger는 로깅 레벨을 설정하여 필요한 로그만 출력할 수 있다.\r\n  또한 로그 내역을 별도의 파일에 저장할 수 있다. 파일로 저장할 경우 프레임워크에 의해 파일 유지 기간, 용량 등도 설정이 가능하여 자동화된 관리가 가능하다.\r\n  원하는 패턴으로 출력이 되도록 설정할 수도 있다.\r\n- System.out.println()을 사용하여 디버깅하는 습관을 들이게 되면 프로젝트를 진행하다 깜빡하고 코드를 삭제하지 못한 채로 운영 서버 코드로 반영되는 경우도 있고하니 logger를 사용하여 디버깅하는 습관을 들이도록 하자!\r\n\r\n<br/>\r\n\r\n\r\n## 참고\r\n\r\n- [https://lob-dev.tistory.com/entry/Logging-slf4j-Logback-Framework](https://lob-dev.tistory.com/entry/Logging-slf4j-Logback-Framework)\r\n- [https://ckddn9496.tistory.com/81?category=428336](https://ckddn9496.tistory.com/81?category=428336)\r\n- [https://stackoverflow.com/questions/31869391/what-is-the-difference-between-java-logger-and-system-out-println](https://stackoverflow.com/questions/31869391/what-is-the-difference-between-java-logger-and-system-out-println)\r\n- [https://www.baeldung.com/java-system-out-println-vs-loggers](https://www.baeldung.com/java-system-out-println-vs-loggers)\r\n- [https://xlffm3.github.io/spring & spring boot/async-logger-performance/](https://xlffm3.github.io/spring%20&%20spring%20boot/async-logger-performance/)","excerpt":"보통 로깅을 위해서 System.out.println() 보다는 logback 이나 log4j 같은 로깅 프레임워크를 사용하는 것이 좋다고 한다. 로깅 프레임워크를 사용하면 로깅 레벨을 설정할 수 있다는 점이 좋다고는 알고 있지만 성능상으로도 더 좋…","fields":{"slug":"/sout-vs-logger/"},"frontmatter":{"date":"Dec 01, 2021","title":"System.out.println() vs Logger","tags":["java","logger"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n## 혼잡 제어(Congestion Control)\r\n\r\n- 혼잡 상황이 발생하면 네트워크 자원이 낭비되므로 혼잡 상황을 최소화 하기 위한 기법\r\n    - 데이터의 양이 라우터가 처리할 수 있는 양을 초과하면 초과된 데이터는 라우터가 처리하지 못한다.\r\n      송신측에서 라우터가 처리하지 못한 데이터를 손실 데이터로 간주하고 계속 재전송하게 되므로 네트워크는 더욱 더 혼잡하게 된다.\r\n- 흐름 제어\r\n    - 송신측과 수신측의 데이터 처리 속도 차이를 해결하기 위한 기법\r\n    - 송신측의 데이터 전송량 제어\r\n- 혼잡 제어\r\n    - 송신측의 데이터 전달과 네트워크 상의 데이터 처리 속도 차이를 해결하기 위한 기법\r\n    - 송신측의 데이터 전송 속도 제어\r\n\r\n<br/>\r\n\r\n## 혼잡 제어 방법\r\n\r\n![Untitled - 2021-12-18T133859 551](https://user-images.githubusercontent.com/62014888/146629187-ddf0d5ae-c589-469a-99ca-f9a688282738.png)\r\n\r\n### AIMD (Additive Increase / Multiplicative Decrease)\r\n\r\n- 합 증가 / 곱 감소 방식.\r\n- 처음에 패킷을 하나씩 보내고 문제없이 도착하면 윈도우의 크기(단위 시간 내에 보내는 패킷의 수)를 1씩 증가시켜가며 전송한다.\r\n- 만약 전송에 실패하면 윈도우 크기를 반으로 줄임.\r\n- 공평한 방식으로, 여러 호스트가 한 네트워크를 공유하고 있으면 나중에 집입하는 쪽이 처음에는 불리하지만, 시간이 흐르면 평형 상태로 수렴한다.\r\n- 윈도우 크기를 너무 조금씩 늘리기 때문에 모든 대역을 활용하여 제대로 된 속도로 통신하기까지 시간이 오래 걸린다.\r\n\r\n### Slow Start\r\n\r\n- 윈도우의 크기를 1, 2, 4, 8... 과 같이 2배씩 증가시킨다.\r\n- 혼잡이 감지되면 윈도우의 크기를 1로 줄여버림.\r\n- 시간이 지날수록 AIMD보다 빠르게 윈도우 크기를 증가시킨다.\r\n- 처음에는 네트워크 수용량을 예상할 수 있는 정보가 없지만, 한번 혼잡 현상이 발생하고 나면 네트워크 수용량을 어느 정도 예상할 수 있다.\r\n- 그러므로 혼잡 현상이 발생하였던 윈도우 크기의 절반까지는 이전처럼 지수 함수 꼴로 증가시키고 이후부터는 1씩 증가시킨다.\r\n    - 이를 임계점(sshthresh, Slow Start Threshold)이라고 함. 이 임계점은 윈도우 사이즈가 기하급수적으로 증가하는 것을 방지하기 위해 설정하는 것으로 임계점부터 윈도우 크기는 1씩 증가한다.\r\n\r\n### Fast Retransmit(빠른 재전송)\r\n\r\n![Untitled - 2021-12-18T133902 669](https://user-images.githubusercontent.com/62014888/146629188-08a5576b-b2f8-4a27-a8bc-37d048e52ab9.png)\r\n\r\n- Fast Restransmit은 TCP 혼잡 제어에 추가된 정책.\r\n- 먼저 도착해야 할 패킷이 도착하지 않고 다음 패킷이 도착한 경우에도 ACK 패킷을 보냄.\r\n- 순서대로 잘 도착한 마지막 패킷의 다음 순번을 ACK 패킷에 실어보내게 되므로 송신측에서는 순번이 중복된 것을 알게 됨.\r\n- 이것을 감지하여 중복된 순번의 패킷을 3개 받으면 타임아웃 전에 문제가 되는 순번의 패킷을 즉시 재전송해줌.\r\n- 이런 현상이 일어나면 혼잡 현상이 발생한 것이므로 윈도우 크기를 줄임.\r\n\r\n### Fast Recovery (빠른 회복)\r\n\r\n- 혼잡 상태가 되면 윈도우 크기를 1로 줄이지 않고 반으로 줄인 후 선형 증가\r\n- 혼잡 상태를 한 번 겪고 나서부터는 AIMD 방식으로 동작.\r\n\r\n<br/>\r\n\r\n## 혼잡 제어 정책\r\n\r\nTCP는 혼잡 제어를 위하여 다양한 기법을 혼합하여 사용하고 있으며 가장 오래되고 기본이 되는 2가지 방식이 있음.\r\n\r\n### TCP Tahoe\r\n\r\n![Untitled - 2021-12-18T133906 384](https://user-images.githubusercontent.com/62014888/146629189-4cbf9558-8a18-4155-a804-8c28ad72e937.png)\r\n\r\n- 처음에는 Slow Start 방식으로 사용하다가 임계점에 도달하면 AIMD 방식 사용\r\n- 그러다 3 ACK 순번 중복 (중간 패킷 유실) 이나 타임아웃이 발생하면 혼잡이라고 판단하여 임계점은 혼잡 발생한 윈도우 크기 절반으로, 윈도우 크기는 1로 줄임.\r\n- 혼잡 이후 Slow Start 구간에서 윈도우 크기를 키울 때 너무 오래걸림.\r\n\r\n### TCP Reno\r\n- Tahoe와 마찬가지로 Slow Start로 시작해서 임계점 이후에는 AIMD 방식으로 변경\r\n- 단, 3 ACK 중복과 타임아웃을 구분함.\r\n- 3 ACK 중복이 발생하면 Fast Recovery 방식을 사용\r\n    - 윈도우 크기를 1로 줄이는 것이 아니라 반으로 줄인 후 윈도우 크기를 선형적으로 증가시킴\r\n    - 임계점은 줄어든 윈도우 값으로 설정\r\n- 타임아웃이 발생하면 Tahoe와 마찬가지로 윈도우 1로 줄이고 Slow Start 진행\r\n    - 임계점은 반으로 줄인다.","excerpt":"혼잡 제어(Congestion Control) 혼잡 상황이 발생하면 네트워크 자원이 낭비되므로 혼잡 상황을 최소화 하기 위한 기법 데이터의 양이 라우터가 처리할 수 있는 양을 초과하면 초과된 데이터는 라우터가 처리하지 못한다.\n송신측에서 라우터가 처…","fields":{"slug":"/congestion-control/"},"frontmatter":{"date":"Oct 23, 2021","title":"혼잡 제어(Congestion Control)란?","tags":["network"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n## 1. 교착상태 특징\r\n\r\n- 멀티 프로그래밍 환경에서는 여러 프로세스들이 한정된 자원을 사용하기 위해 경쟁하고 있으며, 한 프로세스가 자원을 요청했을 때 해당 자원이 사용 불가능한 상태라면 교착상태(Deadlock)가 발생하게 된다.\r\n  즉, 요청한 자원을 다른 프로세스가 점유하고 있고, 점유하고 있는 프로세스도 다른 자원에 대해 대기 상태에 있기 때문에 두 프로세스가 대기 상태에서 벗어날 수 없는 상황을 교착상태라고 한다.\r\n\r\n![Untitled (95)](https://user-images.githubusercontent.com/62014888/146518312-d72c8294-b6eb-4d37-8714-e99488ca800c.png)\r\n\r\n### 교착상태 발생 조건\r\n\r\n- 교착상태는 다음과 같은 네 가지 조건을 모두 성립해야 발생한다.\r\n  (하나라도 성립하지 않으면 교착상태 문제 해결 가능)\r\n1. 상호 배제(Mutual Exclusion)\r\n    - 한 번에 프로세스 하나만 해당 자원을 사용할 수 있다. 사용 중인 자원을 다른 프로세스가 사용하려면 요청한 자원이 해제될 때까지 기다려야 한다.\r\n2. 점유 대기(Hold-and-wait)\r\n    - 자원을 최소한 하나 보유하고, 다른 프로세스에 할당된 자원을 점유하기 위해 대기하는 프로세스가 존재해야 한다.\r\n3. 비선점(No preemption)\r\n    - 이미 할당된 자원을 강제로 빼앗을 수 없다.\r\n4. 순환 대기(Circular wait)\r\n    - 대기 프로세스의 집합이 순환 형태로 자원을 대기하고 있어야 한다.\r\n\r\n\r\n### 자원 할당 그래프\r\n\r\n![Untitled (96)](https://user-images.githubusercontent.com/62014888/146518397-28c949b5-7080-43af-9357-3440ab419c44.png)\r\n\r\n- Vertex\r\n    - 동그라미로 그려진 P1, P2, P3는 프로세스를 의미함.\r\n    - 사각형으로 그려진 R1, R2, R3, R4는 자원을 의미함.\r\n    - 각 사각형 안의 점들은 할당 가능한 자원 개수를 의미함.\r\n- Edge\r\n    - 자원 → 프로세스 (이 프로세스가 해당 자원에게 할당되었다.)\r\n    - 프로세스 → 자원 (프로세스가 자원을 요청하고 있으며 아직  획득하진 못하였다)\r\n\r\n- 그래프에서 사이클이 없으면 교착상태가 아니다.\r\n- 그래프에서 사이클이 있으면\r\n    - 자원당 개수가 하나라면 교착상태\r\n    - 자원당 개수가 여러 개라면 교착상태 가능성이 있음\r\n\r\n- 사이클이 있고 교착상태인 경우\r\n\r\n    ![Untitled (97)](https://user-images.githubusercontent.com/62014888/146518402-4a2d487d-9f10-4db3-a93b-e94073c40d83.png)\r\n\r\n- 사이클이 있지만 교착상태가 아닌 경우\r\n\r\n    ![Untitled (98)](https://user-images.githubusercontent.com/62014888/146518405-a64eed6a-a336-476b-81aa-fb22ab1d6b2c.png)\r\n\r\n<br/>\r\n\r\n## 2. 교착상태 처리 방법\r\n\r\n### 교착상태 예방\r\n\r\n- 교착상태 예방은 교착상태가 되지 않도록 교착상태 발생 조건 네 가지 중 하나라도 발생하지 않게 방지하는 방법이다.\r\n1. 상호 배제(Mutual Exclusion) 조건 방지\r\n    1. 상호 배제가 일어나는 경우는 공유가 불가능한 자원에 의해서임.\r\n    2. 여러 프로세스가 자원에 대한 동시 접근을 보장받으면 상호 배제가 깨어지게 되어 교착상태를 예방할 수 있음.\r\n    3. 어떤 자원들은 근본적으로 공유가 불가능하기 때문에 교착상태를 예방하기 어렵다고 할 수 있음.\r\n2. 점유 대기(Hold-and-wait) 조건 방지\r\n    1. 점유 대기 조건을 부정하기 위해서는 프로세스가 작업을 수행하기 전에 필요한 자원들을 모두 요청하고 획득해야함.\r\n    2. 프로세스 하나를 실행하는데 필요한 모든 자원을 먼저 다 할당하고 끝나면 다른 프로세스에 자원을 할당하는 것.\r\n    3. 프로세스가 자원을 전혀 갖고 있지 않을 때만 자원 요청을 허용해주는 방법도 있다.\r\n    4. 자원의 이용률이 낮아지고 기아 상태가 발생할 수 있다.\r\n3. 비선점(No preemption) 조건 방지\r\n    1. 모든 자원에 대한 선점을 허용한다.\r\n    2. 프로세스가 할당받을 수 없는 자원을 요청하는 경우, 기존에 가지고 있던 자원을 모두 반납하고 새 자원과 이전 자원을 얻기 위해 대기하도록 한다.\r\n4. 순환 대기(Circular wait) 조건 방지\r\n    1. 자원에 고유한 번호를 할당하고 번호 순서대로 자원을 요구하도록 한다.\r\n\r\n\r\n### 교착상태 회피\r\n\r\n- 교착상태 회피는 자원이 어떻게 요청될지에 대한 정보를 미리 파악하고 회피 알고리즘을 통해 교착상태가 일어나지 않도록 자원을 할당하는 방식.\r\n    - 조건을 차단하는 것이 아니라, 정보를 미리 파악하고 일어나지 않는 방향으로 자원을 할당하는 것.\r\n- 프로세스 수, 자원 종류 수가 고정되어 있어야 하고 프로세스가 요구하는 자원 및 최대 자원의 수를 알아야 하며 반드시 자원을 사용 후 반납해야 한다는 가정들이 필요하기 때문에 현실성이 부족함.\r\n- 자원 요청이 있을 때마다 교착상태 회피 알고리즘을 사용한다는 것은 상당한 오버헤드임.\r\n\r\n1. 안정 상태(Safe State)\r\n\r\n    ![Untitled (99)](https://user-images.githubusercontent.com/62014888/146518410-e6a24d09-bae2-4c5d-a429-96cb9054517a.png)\r\n    \r\n    1. 안정 순서(Safe Sequence)를 찾을 수 있는 경우.\r\n        - 안정 순서란 프로세스들이 요청한 모든 자원들을 교착상태 발생 없이 할당할 수 있는 순서를 의미함.\r\n    2. 즉 프로세스가 순서만 잘 조정해주면 교착상태가 일어나지 않는 상태를 의미함.\r\n    3. 불안정 상태(Unsafe State)\r\n        - 안정 순서를 찾을 수 없는 경우이며 불안정 상태라고 무조건 교착 상태가 발생하는 것은 아니다.\r\n\r\n        ![Untitled (100)](https://user-images.githubusercontent.com/62014888/146518416-238d2d2c-a380-4cc5-aa95-e624250f5191.png)\r\n    \r\n        - 할당 가능한 자원 수가 12개일 때 안정 순서는 P0 → P1 → P2 → P1 → P2 → P0가 된다.\r\n\r\n        ![Untitled - 2021-12-17T180447 364](https://user-images.githubusercontent.com/62014888/146518422-902435e2-12c1-4a53-b133-c592d1fb3591.png)\r\n    \r\n        - P1이 작업을 끝마친 후 4개의 자원을 P0, P2 어느쪽으로도 할당하든 작업을 마칠 수 없다.\r\n        - 어느 한 쪽이 자원을 선점하지 않는 한 무한히 대기하게 되므로 교착상태가 발생하게 된다.\r\n        - 즉, 처음 세 개의 프로세스에게 5, 2, 3개의 자원을 할당하는 순간 불안정 상태가 됨.\r\n\r\n2. 자원 할당 그래프 알고리즘(Resource-Allocation Graph Algorithm)\r\n\r\n    ![Untitled - 2021-12-17T180517 190](https://user-images.githubusercontent.com/62014888/146518475-e2474de6-ffaf-4e7a-85c6-fbdf04860910.png)\r\n\r\n    ![Untitled - 2021-12-17T180519 016](https://user-images.githubusercontent.com/62014888/146518486-4359524f-d294-4098-84e0-4eeccae31d2a.png)\r\n\r\n    1. 자원이 하나일 때 사용하는 방법으로 자원 할당 그래프를 이용해 교착상태를 회피하는 것.\r\n    2. 자원 할당 그래프에 예약 간선(claim edge)를 추가한다.\r\n        - 예약 간선이란 향후 요청할 수 있는 자원을 가리키는 점선으로 표시된 간선을 뜻함.\r\n    3. 프로세스 시작 전에 모든 예약 간선들을 자원 할당 그래프에 표시한다.\r\n    4. 예약 간선으로 설정한 자원에 대해서만 요청할 수 있고 사이클이 형성되지 않을 때만 자원을 할당 받는다.\r\n    5. 사이클 생성 여부를 조사할 때 O(n^2) 시간이 걸린다.\r\n\r\n3. 은행원 알고리즘(Banker's Algorithm)\r\n    1. 자원이 여러 개일 때 은행원 알고리즘으로 교착상태를 회피할 수 있음.\r\n    2. 프로세스 시작 시 자신이 필요한 각 자원의 최대(Max) 개수를 미리 선언한다.\r\n    3. 각 프로세스에서 자원 요청이 있을 때 요청을 승인하면 시스템이 안정 상태로 유지되는 경우에만 자원을 할당함.\r\n    4. 불안정 상태가 예상되면 다른 프로세스가 끝날 때까지 대기를 한다.\r\n\r\n<br/>\r\n\r\n## 3. 교착상태 탐지 & 회복\r\n\r\n- 교착상태 예방이나 회피 알고리즘을 사용하지 않는 시스템, 교착상태가 발생할 수 있는 환경이라면 두 알고리즘을 지원해야 한다.\r\n    - 교착상태가 발생했는지 결정하기 위해 시스템 상태를 검사하는 알고리즘\r\n    - 교착상태로부터 회복하는 알고리즘\r\n- 탐지와 회복 알고리즘 방법은 필요한 정보를 유지하고 탐지 알고리즘을 실행시키기 위한 실행 시간, 비용, 교착상태로부터 회복할 때 내재하는 가능한 손실을 포함하는 오버헤드가 필요함.\r\n\r\n### 교착상태 탐지\r\n\r\n- 자원이 하나일 때는 자원 할당 그래프를 변형하여 대기 그래프를 그린다.\r\n    - 대기 그래프에서 사이클을 감지하면, 시스템의 교착상태 가능성을 보고하게 된다.\r\n- 자원이 여러 개라면 은행원 알고리즘처럼 시시각각 내용이 달라지는 자료구조를 사용한다.\r\n- 탐지 알고리즘은 다음과 같을 때 사용한다.\r\n    - 자원을 요청했는데 즉시 할당되지 못하고 있는 경우\r\n    - 일반적으로 CPU 사용률이 40% 이하로 떨어지는 경우\r\n\r\n\r\n### 교착상태 회복\r\n\r\n- 교착상태 일으킨 프로세스를 종료하거나 할당된 자원을 해제시켜 회복시키는 방법이 있다.\r\n- 프로세스 종료 방법\r\n    - 교착상태의 프로세스를 모두 중지한다.\r\n    - 교착상태가 제거될 때까지 하나씩 프로세스를 중지한다.\r\n- 자원 선점 방법\r\n    - 교착상태의 프로세스가 점유하고 있는 자원을 선점해 다른 프로세스에게 할당한다(해당 프로세스를 일시정지 시킨다)\r\n    - 우선 순위가 낮은 프로세스나 수행 횟수가 적은 프로세스 위주로 프로세스 자원을 선점한다.\r\n\r\n<br/>\r\n\r\n## 4. 교착상태 무시\r\n\r\n- Unix와 Windows를 포함한 대부분의 운영체제가 이 방법을 사용한다.\r\n- 교착상태 무시란 말 그대로 교착상태에 대해 아무런 대응도 하지 않는 것.\r\n- 교착상태는 자주 일어나지 않는데다가 예방 및 처리 비용이 많이 들기 때문에 이 방법은 꽤나 경제적일 수 있다.\r\n    - 발생하면 재부팅하면 된다.","excerpt":"1. 교착상태 특징 멀티 프로그래밍 환경에서는 여러 프로세스들이 한정된 자원을 사용하기 위해 경쟁하고 있으며, 한 프로세스가 자원을 요청했을 때 해당 자원이 사용 불가능한 상태라면 교착상태(Deadlock)가 발생하게 된다.\n즉, 요청한 자원을 다른…","fields":{"slug":"/deadlock/"},"frontmatter":{"date":"Oct 23, 2021","title":"교착상태(Deadlock)란?","tags":["os"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n공유된 자원에 여러 프로세스들이 동시에 접근했을 경우 데이터 무결성에 문제가 발생할 수 있다.\r\n\r\n이러한 문제를 해결하기 위해 동기화(Synchronization) 개념이 도입되었다. 즉 공유 데이터에 대하여 동시에 접근하려 할 때, 처리 순서에 상관없이 원하는 결과를 얻기 위함이다. 이를 데이터 일관성(Data Consistency)라고 한다.\r\n\r\n## 1. 경쟁 상태(Race Condition)\r\n\r\n- 공유된 자원에 대해 여러 프로세스가 동시에 접근을 시도할 때, 타이밍이나 순서 등이 결과값에 영향을 줄 수 있는 상태를 의미한다.\r\n    - 동시에 접근할 때 데이터의 일관성을 해치는 결과가 나타날 수 있음.\r\n- OS에서 Race Condition이 발생하는 경우 세 가지\r\n    1. 커널 안의 코드를 수행하는 중 인터럽트가 발생하는 경우\r\n\r\n        ![Untitled (92)](https://user-images.githubusercontent.com/62014888/146517086-3c1f061d-0b03-4e9c-af62-2ffadab5aa6c.png)\r\n\r\n        - 커널 안에 있는 변수를 증가시키는 중 인터럽트가 발생하고 인터럽트 처리 함수에서 해당 변수를 감소시킬 때 변수의 결과값에 문제가 생김.\r\n        - 사용자 프로세스는 해당 프로세스의 할당받은 메모리에만 존재할 수 있지만 커널은 서로 다른 프로세스가 공유하기 때문에 발생한다.\r\n        - 해결법: 작업을 할 때 인터럽트가 발생하더라도 작업이 완료된 후 인터럽트가 발생하도록 처리 순서를 부여한다.\r\n    2. 프로세스가 시스템 콜을 호출하여 커널 모드로 수행 중일 때 문맥교환이 발생하는 경우\r\n\r\n        ![Untitled (93)](https://user-images.githubusercontent.com/62014888/146517090-fb8e5d52-b95e-4cd6-af76-9bc1c6354cd9.png)\r\n\r\n        - 사용자 프로세스가 시스템 콜을 호출하면 커널 모드로 커널 안에 존재하는 변수를 수정할 수 있다. 할당된 CPU 사용기간이 만료되면 문맥교환이 발생하는데 새롭게 CPU를 할당받은 사용자 프로세스가 이전 프로세스와 동일한 시스템 콜을 호출하여 수정하고 있던 변수에 대한 작업을 수행할 때 결과적으로 변수 값에 문제가 발생하는 경우\r\n        - 해결법: 사용자 프로세스가 시스템 콜을 호출하여 커널 모드의 작업을 완료한 후 종료될 때 문맥교환이 발생할 수 있게 한다. 즉, 커널 모드에 있다면 CPU 제어권을 빼앗지 않는다.\r\n    3. 여러 프로세스의 공유 메모리 내의 커널 데이터에 접근하는 경우\r\n\r\n        ![Untitled (94)](https://user-images.githubusercontent.com/62014888/146517093-f43885e7-c251-4401-8e71-22bcc02f5013.png)\r\n\r\n        - CPU가 여러 개인 시스템에서 공유 메모리 속 데이터를 여러 프로세스가 접근할 때 발생하는 경우\r\n        - 해결법: 커널 안 데이터에 접근할 때 lock/unlock을 걸어 매 순간 데이터에 접근하는 프로세스는 1개로 한정한다.\r\n\r\n\r\n<br/>\r\n\r\n## 2. 임계영역 문제(The Critical-Section Problem)\r\n\r\n- 임계영역이란 OS에서 여러 프로세스가 데이터를 공유하면서 수행될 때, 각 프로세스에서 공유 데이터를 액세스하는 프로그램 코드 부분을 의미한다.\r\n    - 공유 자원의 독점을 보장해주는 역할을 수행함.\r\n- 임계영역 문제를 해결하기 위한 기본 조건 세 가지\r\n    1. 상호 배제(Mutual exclusion)\r\n        - 어떤 프로세스가 임계영역에서 실행 중이라면, 다른 프로세스는 임계영역에 접근할 수 없다.\r\n    2. 진행(Progress)\r\n        - 임계영역에서 실행 중인 프로세스가 없다면, 다른 프로세스가 접근할 수 있도록 한다.\r\n    3. 한정된 대기(Bounded Waiting)\r\n        - 다른 프로세스의 기아(Starvation)를 방지하기 위해, 한번 임계영역에 들어간 프로세스는 다음 번 임계영역에 들어갈 때 제한을 두어야 한다.\r\n\r\n<br/>\r\n\r\n## 3. 피터슨의 해결안(Peterson's Solution)\r\n\r\n- 임계영역 문제를 해결하는 기본 조건 세 가지를 충족하는 고전적 SW 기반 해결책으로 피터슨의 해결안이 있다.\r\n    - 이 해결방안은 임계영역과 나머지 영역을 오가며 실행하는 두 개의 프로세스로 한정한다.\r\n    - 두 프로세스는 아래의 두 데이터 항목을 공유한다.\r\n\r\n        ```java\r\n        int turn; //임계영역으로 진입할 순번\r\n        boolean flag[2]; //프로세스가 임계영역으로 진입할 준비 되었음을 의미\r\n        ```\r\n\r\n    - turn == i 이면 프로세스 Pi가 임계영역으로 실행될 수 있고 flag[i]가 true이면 Pi가 임계영역으로 진입할 준비 됨을 의미한다.\r\n    - 프로세스 Pi의 실행 구조\r\n\r\n        ```java\r\n        do {\r\n        \tflag[i] = true;\r\n        \tturn = j;\r\n        \twhile (flag[j] && turn == j);\r\n        \t//critical section\r\n        \tflag[i] = false;\r\n        \t//remainder section \r\n        } while(true);\r\n        ```\r\n\r\n        1. flag[i] = true에 의해 프로세스 Pi는 임계영역에 들어갈 준비가 됐다는 것을 알려주고 turn = j에 의해 프로세스 Pj가 실행될 차례라는 것을 알려줌.\r\n        2. flag[j] = true이고 turn == j 이면 프로세스 Pj가 임계영역에 들어갈 차례이므로, Pi는 무한 루프에 들어가 기다리게 됨.\r\n        3. 프로세스 Pj가 임계영역 작업을 마치고 flag[j] = false가 되면, 프로세스 Pi는 무한루프를 빠져나와 임계영역에 들어가게 됨.\r\n        4. 프로세스 Pi가 작업 완료 후 flag[i] = false로 설정하면, 다른 프로세스가 임계영역을 사용할 수 있게 됨.\r\n- 피터슨의 해결안이 세 가지 조건을 만족하는지 확인해보자.\r\n    1. 상호 배제\r\n        - flag와 turn을 이용해 한 개의 프로세스만 임계영역에 접근할 수 있도록 하였다.\r\n    2. 진행\r\n        - 하나의 프로세스가 임계영역에서 빠져나오면서 flag를 false로 만들어 버리고 다른 프로세스가 접근이 가능하도록 한다.\r\n    3. 한정된 대기\r\n        - 마찬가지로 하나의 프로세스가 임계영역을 빠져나오며 flag를 false로 만드니 다른 프로세스가 실행될 기회가 적어도 한번은 주어지게 된다.\r\n- 피터슨의 알고리즘의 문제점은 while (flag[j] && turn == j); 부분이다.\r\n    - 이 무한루프에 CPU 자원을 쓰고 있다보니 운영체제가 CPU를 효율적으로 활용하지 못하여 문제가 발생하는데 이를 Busy waiting이라고 한다.\r\n\r\n<br/>\r\n\r\n## 4. 세마포어(Semaphore) & 뮤텍스(Mutex)\r\n\r\n세마포어와 뮤텍스는 공유 자원 관리를 위해 상호 배제를 달성하는 기법들이다.\r\n\r\n### 1. 세마포어(Semaphore)\r\n\r\n- 세마포어는 멀티 프로그래밍 환경에서 공유 자원에 대한 접근을 제한하는 방법으로 현재 공유 자원에 접근할 수 있는 쓰레드, 프로세스의 수를 나타내는 값을 두어 상호 배제를 달성하는 기법이다.\r\n- 세마포어 P, V 연산\r\n    - P: 임계영역 들어가기 전에 수행 (프로세스 진입 여부를 자원의 개수(S)를 통해 결정)\r\n    - V: 임계영역에서 나올 때 수행 (자원 반납 알림, 대기 중인 프로세스를 깨우는 신호)\r\n    - 구현 방법\r\n\r\n        ```java\r\n        P(S);\r\n        //critical section\r\n        V(S); \r\n        ```\r\n\r\n        ```java\r\n        procedure P(S)\r\n        \twhile S=0 do wait\r\n        \tS := S-1\r\n        end P\r\n        \r\n        procedure V(S)\r\n        \tS := S+1\r\n        end V\r\n        ```\r\n\r\n    - 흐름\r\n\r\n      최초 S값은 1이고, 현재 해당 구역을 수행할 프로세스가 A, B 있다고 가정한다. (2개 이상도 가능)\r\n\r\n        1. 먼저 도착한 A가 P(S)를 실행하여 S를 0으로 만들고 임계영역에 들어감\r\n        2. 그 뒤에 도착한 B가 P(S)를 실행하지만 S가 0이므로 대기 상태\r\n        3. A가 임계영역 수행을 마치고 V(S)를 실행하면 S는 다시 1이 됨\r\n        4. B는 P(S)에서 while문을 빠져나올 수 있고, 임계영역으로 들어가 수행함.\r\n\r\n\r\n### 2. 뮤텍스(**Mu**tual Exclusion)\r\n\r\n- 임계영역을 가진 쓰레드들의 실행시간이 서로 겹치지 않고 단독으로 실행되게 하는 기술로 해당 접근을 조율하기 위해 lock과 unlock을 사용한다.\r\n    - lock: 현재 임계영역에 들어갈 권한을 얻어옴 (만약 다른 프로세스/쓰레드가 임계영역 수행 중이면 종료할 때까지 대기)\r\n    - unlock: 현재 임계영역을 모두 사용했음을 알림 (대기 중인 다른 프로세스/쓰레드가 임계영역에 진입할 수 있음)\r\n- 구현 방법\r\n\r\n    ```java\r\n    lock();\r\n    // critical section\r\n    unlock();\r\n    ```\r\n\r\n    ```java\r\n    mutex = 1;\r\n    \r\n    void lock() {\r\n    \twhile (mutex != 1) {\r\n    \t}\r\n    \tmutex = 0;\r\n    }\r\n    \r\n    void unlock() {\r\n    \tmutex = 1;\r\n    }\r\n    ```\r\n\r\n<br/>\r\n\r\n### 세마포어와 뮤텍스의 차이\r\n\r\n- 세마포어는 공유 자원에 세마포어의 변수만큼의 프로세스, 쓰레드가 접근할 수 있다.\r\n  반면, 뮤텍스는 오직 1개만의 프로세스, 쓰레드만 접근할 수 있다.\r\n- 현재 수행 중인 프로세스가 아닌 다른 프로세스(wait 하지 않는 프로세스)가 세마포어를 해제할 수 있다.\r\n  반면, 뮤텍스는 lock을 획득한 프로세스가 반드시 unlock 해야 한다.\r\n- 세마포어는 뮤텍스가 될 수 있지만 (S = 1인 경우), 뮤텍스는 세마포어가 될 수 없다.\r\n  뮤텍스를 상태가 0, 1 두 개인 이진 세마포어로 부르기도 한다.\r\n\r\n### 세마포어와 뮤텍스의 단점\r\n\r\n- Busy waiting이 발생한다.\r\n- 세마포어의 경우 큐 or 리스트를 활용하여 Busy waiting을 해결하는 방법이 있다고 한다.\r\n    - 임계영역 진입을 위해 무한루프를 돌며 대기하는 것 대신, 프로세스를 중지시키고 큐에 넣는다.\r\n    1. S ≤ 0 이면 waiting하는 프로세스를 중지시키고 waiting queue에 넣는다.\r\n    2. 어떤 프로세스가 임계영역에서 나오면 signal() 로 대기 큐에 있는 프로세스를 waiting queue에서 빼고 깨워 ready queue에 넣는다.\r\n\r\n<br/>\r\n\r\n## 5. 동기화 문제들\r\n\r\n- 유한 버퍼 문제(bounded-buffer problem)\r\n    - 여러 개의 프로세스를 어떻게 동기화할 것인가에 관한 고전적인 문제\r\n    - 유한한 개수의 데이터를 임시로 보관하는 버퍼에 여러 명의 생산자들과 소비자들이 접근하는 것.\r\n    - 생산자는 데이터가 생기면 버퍼에 저장하는데 저장할 공간이 없는 문제가 발생할 수 있음\r\n    - 소비자는 데이터를 가져가는데 소비할 데이터가 없는 문제가 발생할 수 있다.\r\n    - 세마포어 등으로 해결 가능\r\n- Readers-Writers 문제\r\n    - 여러 명의 Reader와 Writer들이 하나의 저장 공간(버퍼)을 공유하며 이를 접근할 때 발생하는 문제.\r\n    - 세마포어 등으로 해결 가능\r\n- 식사하는 철학자들 문제\r\n    - 여러 프로세스에게 제한된 자원을 할당하는 상황에서 발생할 수 있는 문제.\r\n    - 각각의 철학자들이 동시에 자신의 왼쪽에 있는 젓가락을 드는 경우 Deadlock과 Starvation이 발생할 수 있음.\r\n    - n명이 앉을 수 있는 테이블이면 n-1명만 앉게 하여 자원의 개수를 더 많이 두거나 한 철학자가 젓가락 두 개를 모두 집을 수 있을 때만 젓가락을 집는 것을 허용하도록 하거나 누군가는 왼쪽 젓가락을 먼저 잡지 않고 오른쪽 젓가락을 먼저 잡게 하여 해결하는 방법 등이 있다.\r\n\r\n\r\n<br/>\r\n\r\n## 참고링크\r\n\r\n- [https://hibee.tistory.com/297](https://hibee.tistory.com/297)\r\n- [https://dduddublog.tistory.com/25](https://dduddublog.tistory.com/25)\r\n","excerpt":"공유된 자원에 여러 프로세스들이 동시에 접근했을 경우 데이터 무결성에 문제가 발생할 수 있다. 이러한 문제를 해결하기 위해 동기화(Synchronization) 개념이 도입되었다. 즉 공유 데이터에 대하여 동시에 접근하려 할 때, 처리 순서에 상관없…","fields":{"slug":"/process-synchronization/"},"frontmatter":{"date":"Oct 21, 2021","title":"프로세스 동기화란?","tags":["os"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n'운영체제와 정보기술의 원리' 스터디를 진행하며 정리한 내용이다.\r\n\r\n---\r\n\r\n## 1. 디스크의 구조\r\n\r\n![Untitled (89)](https://user-images.githubusercontent.com/62014888/146330069-c04dca0f-956e-4bf8-9449-6595b493e114.png)\r\n\r\n- 디스크 외부에서는 디스크를 일정한 크기의 저장공간들로 이루어진 1차원 배열처럼 취급하게 되는데 이 일정한 크기의 저장공간을 논리블록(logical block)이라고 한다.\r\n    - 디스크에 데이터가 저장될 때에는 논리블록 단위로 저장\r\n    - 디스크 외부로 입출력이 일어날 때에도 논리블록 단위로 전송\r\n    - 논리블록에 저장된 데이터를 접근하기 위해서는 배열을 접근하는 것처럼 해당 블록의 인덱스 번호를 전달해야 함.\r\n    - 논리블록이 저장되는 디스크 내의 물리적 위치를 섹터(sector)라고 부르고 논리블록 하나가 섹터 하나와 1 대 1로 매핑되어 저장되는 것.\r\n- 디스크는 마그네틱의 원판으로 구성되어 있는데 각각의 원판은 트랙(track)으로 구성되고 각 트렉은 섹터로 나뉨.\r\n- 여러 개의 원판에서 상대적 위치가 동일한 트랙의 집합을 실린더(cylinder)라 부름.\r\n- 디스크에 데이터를 읽고 쓰기 위해서는 암(arm)이 해당 섹터가 위치한 실린더로 이동.\r\n\r\n## 2. 디스크 스케줄링\r\n\r\n- 디스크에 대한 접근시간(access time)은 몇 가지로 구분된다.\r\n    - 탐색시간(seek time) - 디스크 헤드를 해당 실린더 위치로 이동시키는 데 걸리는 시간.\r\n    - 회전지연시간(rotational latency) - 디스크가 회전해서 읽고 쓰려는 섹터가 헤드 위치에 도달하기까지 걸리는 시간\r\n    - 전송시간(transfer time) - 해당 섹터가 헤드 위치에 도달한 후 데이터를 실제로 섹터에 읽고 쓰는데 소요되는 시간.\r\n- 디스크 입출력의 효율을 높이기 위해서는 디스크 입출력에 소요되는 접근시간을 최소화해야 함.\r\n    - 회전지연시간과 전송시간은 상대적인 수치가 작을 뿐 아니라 운영체제 입장에서 통제하기 힘든 부분.\r\n    - 따라서 탐색시간을 줄이기 위해 헤드의 움직임을 최소화하는 스케줄링 작업을 함.\r\n- 디스크 스케줄링(disk scheduling)이란 효율적인 디스크 입출력을 위해 여러 섹터들에 대한 입출력 요청이 들어왔을 때 이들을 어떠한 순서로 처리할 것인지 결정하는 메커니즘을 뜻함.\r\n    - 가장 중요한 목표는 디스크 헤드의 이동거리를 줄이는 것.\r\n\r\n1. FCFS 스케줄링\r\n    - FCFS(First Come First Served) 스케줄링은 디스크에 먼저 들어온 요청을 먼저 처리하는 방식.\r\n    - FCFS 스케줄링이 적용되는 디스크에서 최악의 경우 입출력 요청이 디스크의 한쪽 끝과 반대쪽 끝에 번갈아 도착한다면 헤드는 디스크를 계속 왕복하며 일을 처리해야 하므로 탐색시간이 매우 비효율적으로 늘어나는 결과를 초래함.\r\n\r\n2. SSTF 스케줄링\r\n    - SSTF(Shortest Seek Time First) 스케줄링은 헤드의 현재 위치로부터 가장 가까운 위치에 있는 요청을 제일 먼저 처리하는 알고리즘.\r\n    - 헤드의 이동거리를 줄여 디스크 입출력의 효율성을 증가시키지만, 자칫 기아 현상(starvation)을 발생시킬 수 있음.\r\n        - 현재 헤드의 위치로부터 가까운 곳에서 지속적인 요청이 들어올 경우 멀리 떨어진 곳의 요청은 무한히 기다려야 하는 문제가 발생.\r\n\r\n3. SCAN 알고리즘\r\n    - SCAN 알고리즘은 헤드가 디스크 원판의 안쪽 끝과 바깥쪽 끝을 오가며, 그 경로에 존재하는 모든 요청을 처리함.\r\n        - 즉 디스크의 어떠한 위치에 요청이 들어오는가와 상관없이 헤드는 정해진 방향으로 이동하며 길목에 있는 요청들을 처리하며 지나가는 것.\r\n    - 엘리베이터에서 사용하는 스케줄링 알고리즘과 유사하여 SCAN 알고리즘을 엘레베이터 스케줄링 알고리즘이라고도 부름.\r\n    - SCAN 알고리즘에서는 FCFS처럼 불필요한 헤드의 이동이 발생하거나 SSTF처럼 일부 지역이 지나치게 오래 기다리는 현상이 발생하지 않는 효율성과 형평성을 모두 만족하는 알고리즘.\r\n    - 다만 모든 실린더 위치의 기다리는 시간이 공평한 것은 아님.\r\n        - 제일 안쪽이나 제일 바깥쪽 위치보다는 가운데 위치가 기다리는 평균시간이 더 짧음.\r\n\r\n4. C-SCAN 알고리즘\r\n    - C-SCAN(Circular-SCAN) 알고리즘은 SCAN처럼 헤드가 한쪽 끝에서 다른 쪽 끝으로 이동하며 가는 길목에 있는 모든 요청을 처리함.\r\n    - SCAN과는 달리 헤드가 다른 쪽 끝에 도달해 방향을 바꾼 후에는 요청을 처리하지 않고 곧바로 출발점으로 다시 이동만 함.\r\n    - 이 방식은 각 실린더 위치에 대해 SCAN보다 좀 더 균일한 탐색시간을 제공함.\r\n\r\n5. LOOK과 C-LOOK 알고리즘\r\n    - LOOK 알고리즘은 헤드가 한쪽 방향으로 이동하다가 그 방향에 더 이상 대기 중인 요청이 없으면 헤드의 이동 방향을 즉시 반대로 바꾸는 스케줄링 방식.\r\n    - C-LOOK 알고리즘은 전방에 요청이 없을 때 방향을 바꾼다는 측면에서는 LOOK과 유사하며, 한쪽 방향으로 이동할 때에만 요청을 처리한다는 점에서 C-SCAN과 유사함.\r\n\r\n\r\n## 3. 다중 디스크 환경에서의 스케줄링\r\n\r\n- 다중 디스크를 사용하면 시스템의 성능과 신뢰성을 동시에 향상시킬 수 있음.\r\n- 같은 데이터가 저장되어 있는 여러 개의 디스크 중 어느 디스크에서 요청을 처리할지 결정하는 스케줄링 문제가 발생함.\r\n- 다중 디스크에서의 스케줄링은 작업을 수행할 디스크를 결정하는 문제까지 포함함.\r\n- 이러한 시스템에서는 스케줄링의 목표에 따라 요청을 처리할 디스크를 결정하는 기준이 달라짐.\r\n    - 탐색시간을 줄이는 것이 목표라면 여러 디스크 중에서 헤드의 현재 위치가 요청한 데이터와 가장 가까운 디스크를 선택하는 방법을 사용\r\n    - 좀 더 거시적인 관점에서는 각 디스크 간의 부하균형(load balancing)을 이루도록 스케줄링하는 것이 중요\r\n- 최근에는 전력 소모를 줄이는 것이 또 다른 중요한 목표로 인식되고 있음\r\n    - 일부 디스크에 요청을 집중시키고 나머지 디스크는 회전을 정지시키는 것이 효과적.\r\n\r\n\r\n## 4. 디스크의 저전력 관리\r\n\r\n1. 비활성화 기법\r\n    - 디스크의 상태는 전력 소모를 기준으로 크게 네 가지로 나눌 수 있음\r\n        - 활동(active) 상태 - 현재 헤드가 데이터를 읽거나 쓰고 있는 상태\r\n        - 공회전(idle) 상태 - 디스크가 회전 중이지만 데이터를 읽거나 쓰지는 않는 상태\r\n        - 준비(standby) 상태 - 디스크가 회전하지 않지만 인터페이스가 활성화된 상태\r\n        - 휴면(sleep) 상태 - 디스크가 회전하지 않고 인터페이스도 비활성화된 상태\r\n    - 디스크가 회전 중인 상태를 활성 상태라고 부르고, 디스크가 정지한 상태를 비활성 상태라고 부르면 활성 상태보다 비활성 상태에서 전력 소모가 적으며 요청이 없을 경우 디스크를 정지시키는 것이 전력 절감 측면에서 효과적.\r\n    - 다만 각 상태로 전환할 때는 부가적인 전력 및 시간이 소모됨.\r\n        - 따라서 후속 요청까지의 시간 간격이 일정 시간(break-even time) 이상일 경우에만 디스크의 회전을 정지시키는 것이 전력 소모를 절감하는 데 효과적.\r\n        - 비활성화할 지점을 결정하기 위해 미래의 요청이 도착하는 시점과 간격을 정확히 예측하는 것이 중요함.\r\n    - 디스크를 비활성화하는 시점을 결정하는 방법으로는 세 가지가 있음\r\n        - 시간기반(timeout based) 기법 - 일정 시간 동안 디스크가 공회전 상태이면 장치를 정지시켰다가, 다시 요청이 왔을 때 디스크를 활성화함.\r\n        - 예측기반(prediction based) 기법 - 과거 요청을 관찰하여 다음 공회전 구간의 길이를 예측한 후 디스크를 비활성화할 시점을 결정함.\r\n        - 확률기반(stochastic based) 기법 - 디바이스의 상태변경 시간 간격을 구하기 위해 확률분포를 통해 요청을 모델링하고 마르코프 체인 등과 같은 통계적 모델을 이용함.\r\n\r\n2. 회전속도 조절 기법\r\n    - 디스크의 전력 소모를 줄이기 위한 방법으로 최근에는 디스크의 회전속도(Rotations Per Minute: RPM)를 가변적으로 조절하는 기법이 제안되었음.\r\n    - 디바이스 스준에서 이와 같은 기능이 지원됨에 따라 운영체제에서는 전력 소모를 최소화하기 위해 디스크의 회전속도를 관리하는 지능형 전력 관리 기법에 대한 연구가 이루어지고 있음.\r\n\r\n3. 디스크의 데이터 배치 기법\r\n    - 디스크의 용량은 매년 빠른 속도로 증가하고 있으나 디스크의 접근 속도는 기계적 메커니즘으로 인해 그다지 큰 발전이 없는 실정임.\r\n    - 대부분의 컴퓨터 시스템에서 디스크의 53% 이상이 빈 공간 상태로 남아 있다는 점에 착안해, 디스크 내에 데이터의 복제본을 많이 만들어 헤드 위치에서 가까운 복제본을 접근하도록 함으로써 빠른 응답시간과 전력 소모량 절감을 얻는 FS2 파일 시스템을 제안한 팀도 있음.\r\n\r\n4. 버퍼캐싱 및 사전인출 기법\r\n    - 미래에 요청될 데이터를 미리 알거나 어느 정도 예측할 수 있다면 디스크가 활성 상태일 때 헤드 위치로부터 가까운 데이터를 사전인출(prefetching) 함으로써 향후 디스크의 비활성화 가능성을 높여 전력 소모를 줄일 수 있음.\r\n    - 데드라인을 꼭 지켜야 하는 요청이 아닌 경우, 디스크의 활성 상태 여부에 따라 요청을 최대한 지연시키는 방식으로 전력 소모를 줄일 수 있음.\r\n\r\n5. 쓰기전략을 통한 저전력 디스크 기법\r\n    - 저장장치의 데이터에 대한 쓰기전략을 통해 전력 소모를 줄이는 기법도 제안되고 있음.\r\n    - 디스크가 활성 상태로 돌아왔을 때 쓰는 방식 또는 대상 디스크가 활성 상태가 아니면 일단 블록들을 로그 디스크에 썼다가 디스크가 활성 상태로 돌아왔을 때 디스크에 쓰기연산을 수행하는 방식 등이 있음.","excerpt":"'운영체제와 정보기술의 원리' 스터디를 진행하며 정리한 내용이다. 1. 디스크의 구조 Untitled (89) 디스크 외부에서는 디스크를 일정한 크기의 저장공간들로 이루어진 1차원 배열처럼 취급하게 되는데 이 일정한 크기의 저장공간을 논리블록(log…","fields":{"slug":"/os-it-principle-ch9/"},"frontmatter":{"date":"Oct 18, 2021","title":"[운영체제와 정보기술의 원리] 9. 디스크 관리","tags":["os","book","os-it-principle"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n'운영체제와 정보기술의 원리' 스터디를 진행하며 정리한 내용이다.\r\n\r\n---\r\n\r\n- 시분할 환경에서는 한정된 메모리 공간을 여러 프로그램이 조금씩 나누어서 사용하다보니 운영체제는 어떤 프로그램에게 어느 정도의 메모리를 할당할 것인가 하는 문제에 당면하게 됨.\r\n- 운영체제는 모든 프로그램들에게 공평하게 메모리를 할당하기보다는 몇몇 프로그램에게 집중적으로 할당한 후, 시간이 지나면 메모리를 회수해서 다른 프로그램들에게 다시 할당하는 방식을 채택.\r\n    - 프로세스의 빠른 수행을 위해 프로그램마다 최소한 확보해야 하는 메모리의 크기가 존재하기 때문\r\n- 메모리의 연장 공간으로 디스크의 스왑 영역이 사용될 수 있기 때문에 프로그램 입장에서는 물리적 메모리 크기에 대한 제약을 생각할 필요가 없어지고 나아가 운영체제는 자기 자신만이 메모리를 사용하는 것처럼 가정해 프로그램하는 것을 지원.\r\n    - 프로그램은 0번지부터 시작하는 자기 자신만의 메모리 주소 공간을 가정할 수 있는데, 이를 가상메모리(virtual memory)라고 부름.\r\n    - 이 공간 중 일부는 물리적 메모리에 적재되고 일부는 디스크 스왑 영역에 존재하게 됨.\r\n- 프로세스 주소 공간을 메모리로 적재하는 단위에 따라 가상메모리 기법은 요구 페이징(demand paging) 방식과 요구 세그먼테이션(demanding segmentation) 방식으로 구현될 수 있음.\r\n    - 대부분의 경우 요구 페이징 방식을 사용, 요구 세그먼테이션의 경우 대개 페이지드 세그먼테이션 기법을 사용하다보니 세부적인 구현은 요구 페이징 기법만이 사용됨.\r\n\r\n## 1. 요구 페이징\r\n\r\n- 요구 페이징이란 프로그램 실행 시 프로세스를 구성하는 모든 페이지를 한꺼번에 메모리에 올리는 것이 아니라 당장 사용될 페이지만을 올리는 방식.\r\n    - 특정 페이지에 대해 CPU의 요청이 들어온 후에야 해당 페이지를 메모리에 적재함.\r\n    - 메모리 사용량이 감소하고, 프로세스 전체를 메모리에 올리는데 소요되는 입출력 오버헤드도 줄어든다.\r\n    - 응답시간을 단축시킬 수 있으며, 시스템이 더 많은 프로세스를 수용할 수 있게 해준다.\r\n    - 프로그램이 물리적 메모리의 용량 제약을 벗어날 수 있도록 한다.\r\n- 요구 페이징에서는 유효-무효 비트(valid-invalid bit)를 두어 각 페이지가 메모리에 존재하는지 표시하게 된다.\r\n    - 이 비트는 각 프로세스를 구성하는 모든 페이지에 대해 존재해야 하므로 페이지 테이블의 각 항목별로 저장됨.\r\n    - CPU가 참조하려는 페이지가 현재 메모리에 올라와 있지 않아 유효-무효 비트가 무효로 세팅되어 있는 경우를 '페이지 부재(page fault)'가 일어났다고 함.\r\n\r\n    1. 요구 페이징의 페이지 부재 처리\r\n\r\n        ![Untitled (82)](https://user-images.githubusercontent.com/62014888/146327963-09bb65dc-c7be-4c3c-8846-0f1bdba13039.png)\r\n\r\n        - CPU가 무효 페이지에 접근하면 주소 변환을 담당하는 하드웨어인 MMU가 페이지 부재 트랩(page fault trap)을 발생시키게 됨.\r\n            - CPU 제어권이 커널모드로 전환되고, 운영체제의 페이지 부재 처리루틴(page fault handler)이 호출되어 페이지 부재를 처리하게 됨.\r\n        - 운영체제는 해당 페이지에 대한 접근이 적법한지를 먼저 체크하여 주소 영역에 속한 페이지 접근이 아니거나 접근 권한을 위반했을 경우 프로세스를 종료시킴.\r\n        - 적법한 것으로 판명된 경우 비어 있는 프레임을 할당받아 그 공간에 해당 페이지를 읽어온다.\r\n            - 비어 있는 프레임이 없다면 기존에 메모리에 있던 페이지 중 하나를 디스크로 쫓아내는데 이를 스왑 아웃이라고 한다.\r\n        - 요청된 페이지를 디스크로부터 메모리로 적재하기까지는 오랜 시간이 소요되므로 페이지 부재를 발생시킨 프로세스는 CPU를 빼앗기고 봉쇄 상태가 됨.\r\n            - CPU 레지스터 상태 및 프로그램 카운터값은 프로세스 제어블록에 저장해둠.\r\n        - 디스크 입출력이 끝나 인터럽트가 발생하면 페이지 테이블에서 해당 페이지를 유효 비트로 설정하고, 봉쇄되었던 프로세스를 준비 큐로 이동시킨다.\r\n        - 다시 CPU를 할당받으면 PCB에 저장한 값을 복원시켜 중단되었던 명령부터 실행을 재개함.\r\n\r\n    2. 요구 페이지의 성능\r\n        - 요구 페이징 기법의 성능에 가장 큰 영향을 미치는 요소는 페이지 부재의 발생 빈도임.\r\n            - 페이지 부재가 일어나면 디스크로부터 메모리로 읽어오는 막대한 오버헤드가 발생하기 때문.\r\n            - 페이지 부재가 적게 발생할수록 요구 페이징의 성능이 향상될 수 있음.\r\n        - 유효 접근시간(effective access time)\r\n          = (1-P) * 메모리 접근시간 + P * (페이지 부재 발생 처리 오버헤드 + 메모리에 빈 프레임이 없는 경우 스왑 아웃 오버헤드 + 요청된 페이지의 스왑 인 오버헤드 + 프로세스의 재시작 오버헤드)           \r\n            - 페이지 부재 발생비율 (page fault rate) 0 ≤ P ≤ 1  \r\n              P = 0: 페이지 부재가 한 번도 일어나지 않은 경우  \r\n              P = 1: 모든 참조 요청에서 페이지 부재가 발생한 경우\r\n\r\n\r\n## 2. 페이지 교체\r\n\r\n- 물리적 메모리에 빈 프레임이 존재하지 않아 메모리에 올라와 있는 페이지 중 하나를 디스크로 쫓아내 메모리에 빈 공간을 확보하는 작업이 필요한데 이것을 페이지 교체(page replacement)라고 함.\r\n- 페이지 교체를 할 때에 어떤 프레임에 있는 페이지를 쫓아낼 것인지 결정하는 알고리즘을 교체 알고리즘(replacement algorithm)이라고 하는데, 이 알고리즘의 목표는 페이지 부재율을 최소화하는 것이다.\r\n    - 그러므로 가까운 미래에 참조될 가능성이 가장 적은 페이지를 선택해서 내쫓는 것이 성능을 향상시킬 수 있는 방안임.\r\n- 페이지 교체 알고리즘의 성능은 주어진 페이지 참조열(page reference string)에 대해 페이지 부재율을 계산함으로써 평가할 수 있음.\r\n    - 페이지 참조열은 참조되는 페이지들의 번호를 시간 순서에 따라 나열한 것.\r\n\r\n1. 최적 페이지 교체\r\n    - 페이지 부재율을 최소화하기 위해서는 페이지 교체 시 물리적 메모리에 존재하는 페이지 중 가장 먼 미래에 참조될 페이지를 쫓아내면 됨.\r\n        - 이러한 최적의 알고리즘을 빌레디의 최적 알고리즘(Belady's optimal algorithm) 또는 MIN, OPT 등의 이름으로 부름.\r\n\r\n        ![Untitled (83)](https://user-images.githubusercontent.com/62014888/146327971-6d37c6f3-5348-453d-83b0-228ce144b60d.png)\r\n\r\n    - 페이지 5를 참조하려고 할 때에 페이지 부재가 발생하는데 이때 빌레디의 최적 알고리즘은 가장 먼 미래에 참조될 페이지를 선정하게 됨.\r\n    - 페이지 1, 2, 3, 4 중 가장 먼 미래에 참조되는 페이지가 4번 페이지이므로 이 알고리즘은 4를 내쫓고 그 자리에 페이지 5를 적재함.\r\n    - 이 알고리즘은 미래에 어떤 페이지가 어떠한 순서로 참조될지 미리 알고 있다는 전제하에 알고리즘을 운영하므로 실제 시스템에서 온라인으로 사용할 수 있는 알고리즘이 아님.\r\n        - 오프라인 알고리즘이라고 부른다.\r\n        - 이 알고리즘은 어떠한 알고리즘보다도 가장 적은 페이지 부재율을 보장하므로 다른 알고리즘의 성능에 대한 상한선을 제공함.\r\n        - 빌레디의 최적 알고리즘과 유사했다고 한다면, 이는 더 이상 그 시스템을 위한 교체 알고리즘의 연구가 필요하지 않음을 시사함.\r\n\r\n2. 선입선출 알고리즘\r\n    - 선입선출 알고리즘은 페이지 교체 시 물리적 메모리에 가장 먼저 올라온 페이지를 우선적으로 내쫓음.\r\n\r\n        ![Untitled (84)](https://user-images.githubusercontent.com/62014888/146327979-098e8811-525e-45d8-a102-b19cd008344b.png)\r\n\r\n    - 페이지의 향후 참조 가능성을 고려하지 않고, 물리적 메모리에 들어온 순서대로 내쫓을 대상을 선정하기 때문에 비효율적인 상황이 발생할 수 있음.\r\n        - 가장 먼저 물리적 메모리에 들어온 페이지가 계속해서 많은 참조가 이루어진다 하더라도 FIFO 알고리즘은 이 페이지를 내쫓게 되는 것.\r\n    - 메모리를 증가시켰음에도 불구하고 페이지 부재가 오히려 늘어나는 상황을 FIFO의 이상 현상(FIFO anomaly)이라고 부름.\r\n\r\n3. LRU 알고리즘\r\n    - 메모리 페이지의 참조 성향 중 중요한 한 가지 성질로 시간지역성(temporal locality)이라는 것이 있는데 이 성질은 최근에 참조된 페이지가 가까운 미래에 다시 참조될 가능성이 높은 성질을 뜻함.\r\n    - LRU(Least Recently Used) 알고리즘은 페이지 교체 시 가장 오래전에 참조가 이루어진 페이지를 쫓아낸다.\r\n      즉, 마지막 참조 시점이 가장 오래된 페이지를 교체하게 되는 것.\r\n\r\n        ![Untitled (85)](https://user-images.githubusercontent.com/62014888/146327981-eaf3732a-da52-4c6e-876b-852993629974.png)\r\n\r\n    - 페이지 5가 참조될 때 페이지 부재가 발생하고 페이지 3과 교체되는데, 이는 페이지 3이 가장 오래전에 참조된 페이지이기 때문.\r\n\r\n4. LFU 알고리즘\r\n    - LFU(Least Frequently Used) 알고리즘은 페이지의 참조 횟수로 교체시킬 페이지를 결정함.\r\n        - 즉 물리적 메모리 내에 존재하는 페이지 중에서 과거에 참조 횟수가 가장 적었던 페이지를 쫓아내고 그 자리에 새로 참조될 페이지를 적재한다.\r\n        - 최저 참조 횟수를 가진 페이지가 여러 개 존재하는 경우네는 임의로 하나를 선정해 그 페이지를 쫓아냄.\r\n        - 성능 향상을 위해서는 최저 참조 횟수를 가진 페이지들 중에서 상대적으로 더 오래전에 참조된 페이지를 쫓아내도록 구현하는 것이 효율적.\r\n    - LFU는 페이지의 참조 횟수를 계산하는 방식에 따라 Incache-LFU와 Perfect-LFU로 나뉨.\r\n        - Incache-LFU\r\n            - 페이지가 물리적 메모리에 올라온 후부터의 참조 횟수를 카운트하는 방식.\r\n            - 페이지가 메모리에서 쫓겨났다가 다시 들어온 경우 참조 횟수는 1부터 새롭게 시작.\r\n        - Perfect-LFU\r\n            - 메모리에 올라와있는지의 여부와 상관없이 그 페이지의 과거 총 참조 횟수를 카운트함.\r\n            - 페이지의 참조 횟수를 정확히 반영할 수 있다는 장점이 있지만, 메모리에 쫓겨난 페이지의 참조 기록까지 모두 보관하고 있어야 하므로 그 오버헤드가 상대적으로 더 크다고 할 수 있음.\r\n    - LFU 알고리즘은 LRU 알고리즘보다 오랜 시간 동안의 참조 기록을 반영할 수 있다는 장점이 있음.\r\n        - LRU는 직전에 참조된 시점만을 반영, LFU는 장기적인 시간 규모에서의 참조 성향을 고려하기 때문.\r\n    - LFU는 시간에 따른 페이지 참조 변화를 반영하지 못하고, LRU보다 구현이 복잡하다는 단점이 있음.\r\n\r\n    ![Untitled (86)](https://user-images.githubusercontent.com/62014888/146327986-0195ad12-cf48-4eba-bb40-816de47ad954.png)\r\n\r\n    - LRU 알고리즘은 1번 페이지가 참조 횟수가 가장 많았지만 그걸 인지하지 못한다.\r\n    - LFU 알고리즘은 4번 페이지가 지금부터 인기를 얻기 시작하는 페이지일 수도 있는데 그걸 인지하지 못한다.\r\n\r\n5. 클럭 알고리즘\r\n    - LRU, LFU 알고리즘은 페이지의 참조 시각 및 참조 횟수를 소프트웨어적으로 유지하고 비교해야 하므로 알고리즘의 운영에 시간적인 오버헤드가 발생함.\r\n    - 클럭 알고리즘(clock algorithm)은 하드웨어적인 지원을 통해 이와 같은 알고리즘의 운영 오버헤드를 줄인 방식.\r\n        - LRU를 근사시킨 알고리즘으로 NUR(Not Used Recently) 또는 NRU(Not Recently Used) 알고리즘으로도 불린다.\r\n    - 클럭 알고리즘은 오랫동안 참조되지 않은 페이지 중 하나를 교체함.\r\n        - 즉, 최근에 참조되지 않은 페이지를 교체 대상으로 선정한다는 측면에서 LRU와 유사하지만 교체되는 페이지의 참조 시점이 가장 오래되었다는 것을 보장하지는 못한다는 점에서 LRU를 근사시킨 알고리즘으로 볼 수 있다.\r\n    - 하드웨어적인 지원으로 동작하기 때문에 LRU에 비해 페이지 관리가 훨씬 빠르고 효율적이기에 대부분의 시스템에서 클럭 알고리즘을 채택함.\r\n\r\n    ![Untitled (87)](https://user-images.githubusercontent.com/62014888/146327990-e537f022-67d6-4a46-8252-cdec48519c13.png)\r\n\r\n    - 클럭 알고리즘은 교체할 페이지를 선정하기 위해 페이지 프레임들의 참조비트를 순차적으로 조사함.\r\n    - 프레임 내의 페이지가 참조될 때 하드웨어에 의해 1로 자동 세팅됨.\r\n    - 참조비트가 1인 페이지는 0으로 바꾼 후 그냥 지나가고 참조비트가 0인 페이지는 교체함.\r\n    - 모든 페이지 프레임을 다 조사한 경우 첫 번째 페이지 프레임부터 조사 작업을 반복한다.\r\n        - 즉 시곗바늘이 한 바퀴 도는 동안 다시 참조되지 않은 페이지를 교체하는 것임.\r\n    - 적어도 시곗바늘이 한 바퀴 도는데 소요되는 시간만큼 페이지를 메모리에 유지시켜둠으로써 페이지 부재율을 줄이도록 설계되었기 때문에 이 알고리즘을 2차 기회 알고리즘(second chance algorithm)이라고도 부름\r\n\r\n## 3. 페이지 프레임의 할당\r\n\r\n- 프로세스가 여러 개가 동시에 수행되는 상황에서는 각 프로세스에 얼마만큼의 메모리 공간을 할당할 것인지 결정해야 함.\r\n- 기본적인 할당 알고리즘(allocation algorithm)은 세 가지로 나누어볼 수 있음.\r\n    1. 균등할당(equal allocation) 방식\r\n        - 모든 프로세스에게 페이지 프레임을 균일하게 할당하는 방식\r\n    2. 비례할당(proportional allocation) 방식\r\n        - 프로세스의 크기에 비례해 페이지 프레임을 할당하는 방식\r\n        - 프로세스의 크기를 고려한 균등할당 방식으로 볼 수 있다\r\n    3. 우선순위 할당(priority allocation) 방식\r\n        - 프로세스의 우선순위에 따라 페이지 프레임을 다르게 할당하는 방식\r\n        - 프로세스 중 당장 CPU에서 실행될 프로세스와 그렇지 않은 프로세스를 구분하여 전자 쪽에 더 많은 페이지 프레임을 할당하는 방식.\r\n- 이와 같은 할당 알고리즘만으로는 프로세스 페이지 참조 특성을 제대로 반영하지 못할 우려가 있음\r\n    - 수행 중인 프로세스 수가 지나치게 많아 프로세스당 할당되는 메모리 양이 과도하게 적어질 수 있음.\r\n- 프로세스를 정상적으로 수행하기 위해서는 적어도 일정 수준 이상의 페이지 프레임을 각 프로세스에 할당해야 함.\r\n- 반복문을 실행 중인 프로세스의 경우 반복문을 구성하는 페이지들을 한꺼번에 메모리에 올려놓는 것이 유리함.\r\n    - 적게 할당하면 매 반복마다 적어도 한 번 이상의 페이지 부재가 발생하기 때문\r\n- 또한 프로세스에게 최소한으로 필요한 메모리 양은 시간에 따라 달라질 수 있음.\r\n- 종합적인 상황을 고려해 할당 페이지 프레임 수를 결정할 필요가 있으며, 경우에 따라 일부 프로세스에게 메모리를 할당하지 않는 방식으로 나머지 프로세스들에게 최소한의 메모리 요구량을 충족시킬 수 있어야 함.\r\n\r\n## 4. 전역교체와 지역교체\r\n\r\n- 교체할 페이지를 선정할 때, 교체 대상이 될 프레임의 범위를 어떻게 할지에 따라 교체 방법을 전역교체(global replacement)와 지역교체(local replacement)로 구분할 수 있음.\r\n- 전역교체 방법은 모든 페이지 프레임이 교체 대상이 될 수 있는 방법.\r\n    - 프로세스마다 메모리를 할당하는 것이 아니라 전체 메모리를 각 프로세스가 공유해서 사용하고 교체 알고리즘에 근거해서 할당되는 메모리 양이 가변적으로 변하는 방법.\r\n    - 페이지 교체 시 다른 프로세스에 할당된 프레임을 빼앗아올 수 있는 방식.\r\n    - 프로세스별 프레임 할당량을 조절하는 또 다른 방법이 될 수 있음.\r\n    - LRU, LFU, 클럭 등의 알고리즘을 물리적 메모리 내에 존재하는 전체 페이지 프레임들을 대상으로 적용하는 경우가 이러한 전역교체 방법이 됨.\r\n    - 워킹셋 알고리즘, PFF 알고리즘도 전역교체 방법으로 사용될 수 있음.\r\n- 지역교체 방법은 현재 수행 중인 프로세스에게 할당된 프레임 내에서만 교체 대상을 선정할 수 있는 방법\r\n    - 프로세스마다 페이지 프레임을 미리 할당하는 것을 전제로 한다.\r\n    - 프로세스별로 페이지 프레임을 할당하고, 교체할 페이지도 그 프로세스에게 할당된 프레임 내에서 선정하게 되는 것.\r\n    - LRU, LFU 등의 알고리즘을 프로세스별로 독자적으로 운영할 때에는 지역교체 방법이 됨.\r\n\r\n## 5. 스레싱\r\n\r\n- 프로세스가 최소한의 페이지 프레임을 할당받지 못할 경우 성능상의 심각한 문제가 발생할 수 있음.\r\n- 집중적으로 참조되는 페이지들의 집합을 메모리에 한꺼번에 적재하지 못하면 페이지 부재율이 크게 상승해 CPU 이용률이 급격히 떨어질 수 있기 때문이다.\r\n  이와 같은 현상을 스레싱(thrashing)이라고 부른다.\r\n- CPU 이용률이 낮다는 것은 준비 큐가 비는 경우가 발생한다는 뜻이여서 운영체제는 메모리에 올라가는 프로세스의 수를 늘리게 된다.\r\n- 메모리에 동시에 올라가 있는 프로세스의 수를 다중 프로그래밍의 정도(Multi-Programming Degree: MPD)라고 부르는데 CPU 이용률이 낮을 경우 운영체제는 MPD를 높이게 된다.\r\n- MPD가 과도하게 높아지면 각 프로세스에게 할당하는 메모리의 양이 지나치게 감소하게 된다.\r\n- 프로세스는 최소한의 페이지 프레임도 할당받지 못하는 상태가 되어 페이지 부재가 빈번히 발생하게 된다. 페이지 부재는 디스크 I/O 작업을 수반하므로 문맥교환을 통해 다른 프로세스에게 CPU가 이양된다.\r\n- 다른 프로세스 역시 페이지 부재가 발생할 수밖에 없고 또 다른 프로세스에게 CPU가 할당된다.\r\n- 모든 프로세스에게 다 페이지 부재를 발생시켜 시스템은 페이지 부재를 처리하느라 매우 분주해지고 CPU 이용률은 급격히 떨어지게 된다.\r\n- 이 상황에서 운영체제는 프로세스 수가 적다고 판단해 MPD를 높이기 위해 또 다른 프로세스를 메모리에 추가하게 된다.\r\n- 결과적으로 프로세스당 할당된 프레임 수는 더욱 감소하여 페이지 부재는 더욱 빈번히 발생하게 되고 CPU는 대부분의 시간에 일을 하지 않게되는데 이를 스레싱이라고 한다.\r\n- MPD를 적절히 조절해 CPU 이용률을 높이는 동시에 스레싱 발생을 방지하는 방법에는 워킹셋 알고리즘과 페이지 부재 빈도 알고리즘이 있음.\r\n1. 워킹셋 알고리즘(working-set algorithm)\r\n\r\n    ![Untitled (88)](https://user-images.githubusercontent.com/62014888/146328019-dc0c4b94-2d64-40c5-b1c2-75247c248eb4.png)\r\n    1. 프로세스는 일정 시간 동안 특정 주소 영역을 집중적으로 참조하는 경향이 있는데 이렇게 집중적으로 참조되는 페이지들의 집합을 지역성 집합(locality set)이라고 한다.\r\n    2. 워킹셋 알고리즘은 이러한 지역성 집합이 메모리에 동시에 올라갈 수 있도록 보장하는 메모리 관리 알고리즘을 뜻함.\r\n        - 프로세스가 원활히 수행되기 위해 한꺼번에 올라와 있어야 하는 페이지들의 집합을 워킹셋이라고 정의하고, 워킹셋 페이지들이 한꺼번에 메모리에 올라갈 수 있는 경우에만 할당한다.\r\n        - 그렇지 않을 경우 페이지 프레임들을 모두 반납시키고 디스크로 스왑 아웃시킨다.\r\n        - 이를 통해 MPD를 조절하고 스레싱을 방지하게 됨.\r\n    3. 한꺼번에 메모리에 올라가야 할 페이지들의 집합을 결정하기 위해 워킹셋 알고리즘은 워킹셋 윈도우를 사용한다.\r\n        - 페이지가 참조된 시점부터 워킹셋 윈도우 시간 동안은 메모리에 유지하고, 그 시점이 지나면 메모리에서 지워버리게 되는 것.\r\n    4. 워킹셋 알고리즘은 메모리에 올라와 있는 프로세스들의 워킹셋 크기의 합이 프레임 수보다 클 경우 일부 프로세스를 스왑 아웃시켜서 남은 프로세스의 워킹셋이 메모리에 모두 올라가는 것을 보장함.\r\n        - MPD를 줄이는 효과를 발생\r\n    5. 워킹셋을 모두 할당한 후에도 프레임이 남을 경우, 스왑 아웃되었던 프로세스를 다시 메모리에 올려서 워킹셋을 할당함으로써 MPD를 증가시킴.\r\n    6. 윈도우의 크기가 너무 낮으면 지역성 집합을 모두 수용하지 못할 우려가 있고, 반대로 윈도우의 크기가 너무 크면 여러 규모의 지역성 집합을 수용할 수 있는 반면 MPD가 감소해 CPU 이용률이 낮아질 우려가 있다.\r\n    7. 워킹셋의 크기는 시간이 흐름에 따라 변하기도 하므로 일종의 동적인 프레임 할당 기능까지 수행한다고 할 수 있다.\r\n2. 페이지 부재 빈도 알고리즘(Page Fault Frequency: PFF)\r\n    1. 프로세스의 페이지 부재율을 주기적으로 조사하고 이 값에 근거해서 각 프로세스에 할당할 메모리 양을 동적으로 조절한다.\r\n    2. 페이지 부재율이 상한값을 넘게 되면 프로세스에게 프레임을 추가로 더 할당한다.\r\n        - 빈 프레임이 없다면 일부 프로세스를 스왑 아웃시켜 프로세스 수를 조절함.\r\n    3. 페이지 부재율이 하한값 이하로 떨어지면 필요 이상으로 많은 프레임이 할당된 것으로 간주해 할당된 프레임의 수를 줄인다.\r\n        - 메모리 내에 존재하는 모든 프로세스에 필요한 프레임을 다 할당한 후에도 프레임이 남는 경우 스왑 아웃되었던 프로세스에게 프레임을 할당함으로써 MPD를 높인다.","excerpt":"'운영체제와 정보기술의 원리' 스터디를 진행하며 정리한 내용이다. 시분할 환경에서는 한정된 메모리 공간을 여러 프로그램이 조금씩 나누어서 사용하다보니 운영체제는 어떤 프로그램에게 어느 정도의 메모리를 할당할 것인가 하는 문제에 당면하게 됨. 운영체제…","fields":{"slug":"/os-it-principle-ch8/"},"frontmatter":{"date":"Oct 17, 2021","title":"[운영체제와 정보기술의 원리] 8. 가상메모리","tags":["os","book","os-it-principle"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n'운영체제와 정보기술의 원리' 스터디를 진행하며 정리한 내용이다.\r\n\r\n---\r\n- 컴퓨터에서는 byte 단위로 메모리 주소를 부여하기 때문에 32비트 주소 체계를 사용하면 2의 32제곱 바이트만큼의 메모리 공간에 서로 다른 주소를 할당할 수 있다.\r\n- 효율적인 운영을 위해 보통 4KB(= 2의 12제곱 byte) 단위로 묶어서 페이지(page)라는 하나의 행정구역을 만들어서 관리한다.\r\n\r\n## 1. 주소 바인딩\r\n\r\n- 프로그램이 실행을 위해 메모리에 적재되면 그 프로세스를 위한 독자적인 주소 공간이 생성되는데 이 주소를 논리적 주소(logical address) 혹은 가상 주소(virtual address)라고 부른다.\r\n    - CPU는 프로세스마다 독립적으로 갖는 논리적 주소에 근거해 명령을 실행함.\r\n    - 각 프로세스마다 독립적으로 할당되며 0번지부터 시작됨.\r\n- 물리적 주소(physical address)는 물리적 메모리에 실제로 올라가는 위치를 말한다.\r\n    - 물리적 메모리의 낮은 주소 영역에는 운영체제가 올라가고, 높은 주소 영역에는 사용자 프로세스들이 올라간다.\r\n- 프로세스가 실행되기 위해서는 해당 프로그램이 물리적 메모리에 올라가 있어야한다.\r\n  또한 CPU가 기계어 명령을 수행하기 위해 논리적 주소를 통해 메모리 참조를 하게 되면 해당 논리적 주소가 물리적 메모리의 어느 위치에 매핑되는지 확인해야 한다.\r\n    - 프로세스의 주소를 물리적 메모리 주소로 연결시켜주는 작업을 주소 바인딩(address binding)이라고 한다.\r\n- 주소 바인딩의 방식은 프로그램이 적재되는 물리적 메모리의 주소가 결정되는 시기에 따라 세 가지로 분류할 수 있음.\r\n    1. 물리적 메모리 주소가 프로그램을 컴파일할 때 결정되는 주소 바인딩 방식을 컴파일 타임 바인딩(compile time binding)이라고 부름.\r\n        - 컴파일 하는 시점에 해당 프로그램이 물리적 메모리의 몇 번지에 위치할 것인지 결정한다.\r\n        - 절대주소로 적재된다는 뜻에서 절대코드(absolute code)를 생성하는 바인딩 방식이라고도 말함.\r\n        - 물리적 메모리 위치를 변경하고 싶다면 다시 컴파일을 해야하기에 비현실적이고 현대의 시분할 컴퓨팅 환경에서는 잘 사용하지 않음.\r\n    2. 프로그램 실행이 시작될 때 물리적 메모리 주소가 결정되는 주소 바인딩 방식을 로드 타임 바인딩(load time binding)이라고 한다.\r\n        - 로더(loader)의 책임하에 물리적 메모리 주소가 부여되며 프로그램이 종료될 때까지 물리적 메모리상의 위치가 고정된다.\r\n            - 로더란 사용자 프로그램을 메모리에 적재시키는 프로그램\r\n        - 컴파일러가 재배치 가능 코드(relocatable code)를 생성한 경우에 가능한 주소 바인딩 방식\r\n    3. 실행시간 바인딩(execution time binding 또는 run time binding)은 프로그램이 실행을 시작한 후에도 그 프로그램이 위치한 물리적 메모리상의 주소가 변경될 수 있는 바인딩 방식.\r\n        - CPU가 주소를 참조할 때마다 해당 데이터가 물리적 메모리의 어느 위치에 존재하는지, 주소 매핑 테이블(address mapping table)을 이용해 바인딩을 점검해야 함.\r\n        - 기준 레지스터와 한계 레지스터를 포함해 MMU(Memory Management Unit: 메모리 관리 유닛)라는 하드웨어적인 지원이 뒷받침되어야 함.\r\n            - MMU는 논리적 주소를 물리적 주소로 매핑해주는 하드웨어 장치.\r\n- CPU가 특정 프로세스의 논리적 주소를 참조하려고 할 때 MMU 기법은 그 주소값에 기준 레지스터의 값을 더해 물리적 주소값을 얻어냄.\r\n    - 기준 레지스터는 재배치 레지스터(relocation register)라고도 부르며 그 프로세스의 물리적 메모리 시작 주소를 가지고 있음.\r\n    - MMU 기법에서 사용자 프로그램이나 CPU는 논리적 주소만 다룰 뿐, 물리적 주소는 알지 못하며 알 필요도 없음.\r\n- 동일한 주소값이라 하더라도 각 프로세스마다 서로 다른 내용을 담고 있게 되므로 CPU가 논리적 주소 100번지를 참조한다고 했을 때 현재 CPU에서 수행되고 있는 프로세스가 무엇인지에 따라 100번지가 가리키는 내용은 상이해진다.\r\n    - MMU 기법에서는 문맥교환으로 프로세스가 바뀔 때마다 재배치 레지스터 값을 그 프로세스에 해당되는 값으로 재설정함.\r\n- 다중 프로그래밍 환경에서 MMU 방식을 사용하여 주소 변환을 했을 때 해당 프로세스의 주소 공간을 벗어나는 경우가 발생할 수 있다.\r\n  이렇게 되면 메모리 보안(memory protection)이 이루어지지 않아 다른 프로그램 영역을 침범하거나 심지어 운영체제 메모리 영역을 변경해 시스템에 치명적인 결과를 초래할 수도 있음.\r\n    - 이를 방지하기 위해 한계 레지스터를 사용한다.\r\n- 한계 레지스터는 프로세스가 자신의 주소 공간을 넘어서는 메모리 참조를 하려고 하는지 체크하는 용도로 사용되며, 현재 CPU에서 수행 중인 프로세스의 논리적 주소의 최댓값, 즉 그 프로세스의 크기를 담고 있음.\r\n    - CPU가 메모리 참조 요청을 했을 때 그 주소가 한계 레지스터값보다 큰지를 먼저 체크해 물리적 메모리 영역에 대한 보안을 유지하게 됨.\r\n- 먼저 CPU가 요청한 프로세스의 논리적 주소값이 한계 레지스터 내에 저장된 그 프로세스의 크기보다 작은지 확인함\r\n    - 작다면 재배치 레지스터값을 더해 물리적 주소를 구한 다음 해당 물리적 메모리 위치에 접근하도록 허락함.\r\n    - 크다면 다른 프로세스 주소 영역에 접근하려는 시도이므로 트랩을 발생시켜 프로세스를 강제종료시킴.\r\n\r\n\r\n## 2. 메모리 관리와 관련된 용어\r\n\r\n1. 동적로딩(dynamic loading)\r\n    1. 다중 프로그래밍 환경에서 메모리 사용의 효율성을 높이기 위해 사용하는 기법 중 하나.\r\n    2. 프로세스가 시작될 때 주소 공간 전체를 메모리에 다 올려놓는 것이 아니라 해당 부분이 불릴 때 그 부분만을 메모리에 적재하는 방식을 사용함.\r\n       즉, 프로세스 내에서 실행에 필요한 부분이 실제로 불릴 때마다 메모리에 적재하는 것을 의미함.\r\n    3. 프로그램 자체에서 구현이 가능하며 운영체제가 라이브러리를 통해 지원할 수도 있음.\r\n2. 동적연결(dynamic linking)\r\n    1. 연결(linking)이란 프로그래머가 작성한 소스 코드를 컴파일하여 생성된 목적 파일(object file)과, 이미 컴파일된 라이브러리 파일(library file)들을 묶어 하나의 실행파일을 생성하는 과정을 말함.\r\n    2. 동적연결은 컴파일을 통해 생성된 목적 파일과 라이브러리 파일 사이의 연결을 프로그램 실행 시점까지 지연시키는 기법.\r\n        - 반대 개념인 정적연결(static linking)에서는 프로그래머가 작성한 코드와 라이브러리 코드가 모두 합쳐져서 실행파일이 생성됨.\r\n        - 실행파일 크기가 상대적으로 크며, 동일한 라이브러리를 각 프로세스가 개별적으로 메모리에 적재해야 하므로 물리적 메모리가 낭비되는 단점이 존재.\r\n    3. 동적연결은 프로그램이 실행되면서 라이브러리 함수를 호출할 때가 되어서야 라이브러리에 대한 연결이 이루어짐.\r\n    4. 실행파일의 라이브러리 호출 부분에 해당 라이브러리의 위치를 찾기 위한 스텁(stub)이라는 작은 코드를 둠.\r\n        - 라이브러리가 메모리에 이미 존재하면 그 주소의 메모리 위치에 직접 참조하며, 그렇지 않으면 디스크에서 동적 라이브러리 파일을 찾아 메모리에 적재한 후 수행함.\r\n    5. 메모리 사용의 효율성을 높일 수 있고 동적연결 기법은 운영체제의 지원을 필요로 함.\r\n3. 중첩(overlays)\r\n    1. 프로세스의 주소 공간을 분할해 실제 필요한 부분만을 메모리에 적재하는 기법.\r\n    2. 초창기 컴퓨터 시스템에서 물리적 메모리의 크기 제약으로 인해 하나의 프로세스조차도 메모리에 한꺼번에 올릴 수 없을 때, 프로세스의 주소 공간을 분할해서 당장 필요한 일부분을 메모리에 올려 실행하고 실행이 끝난 후 나머지 부분을 올려 실행하는 기법을 뜻함.\r\n    3. 동적로딩은 메모리에 더 많은 프로세스를 동시에 올려놓고 실행하기 위한 용도인 반면, 중첩은 단일 프로세스만을 메모리에 올려놓는 환경에서 메모리 용량보다 큰 프로세스를 실행하기 위한 어쩔 수 없는 선택이었다.\r\n    4. 운영체제 지원 없이 프로그래머에 의해 구현되어야 했으며 손수 구현했다고 해서 수작업 중첩(manual overlays)이라고도 부름.\r\n4. 스와핑(swapping)\r\n    1. 스와핑이란 메모리에 올라온 프로세스의 주소 공간 전체를 디스크의 스왑 영역에 일시적으로 내려놓는 것을 말한다.\r\n        - 스왑 역역은 백킹스토어(backing store)라고도 부르며, 디스크 내에 파일 시스템과는 별도로 존재하는 일정 영역을 말함.\r\n        - 파일 시스템은 비휘발성 저장공간임에 비해 스왑 영역은 프로세스가 수행 중인 동안에만 디스크에 일시적으로 저장하는 공간이므로 저장 기간이 상대적으로 짧은 저장공간임\r\n    2. 스왑 영역은 충분히 큰 저장공간이어야 하고 어느 정도의 접근 속도가 보장되어야 한다.\r\n    3. 스와핑은 프로세스가 종료되어 그 주소 공간을 디스크로 내쫓는 것이 아니라, 특정 이유로 수행 중인 프로세스의 주소 공간을 일시적으로 메모리에서 디스크로 내려놓는 것을 의미함.\r\n        - 디스크에서 메모리로 올리는 작업을 스왑 인(swap in), 메모리에서 디스크로 내리는 작업을 스왑 아웃(swap out)이라고 부름.\r\n    4. 스와핑은 스와퍼(swapper)라고 불리는 중기 스케줄러에 의해 스왑 아웃시킬 프로세스를 선정함.\r\n    5. 스와핑의 가장 중요한 역할은 메모리에 존재하는 프로세스의 수를 조절하는 것. 즉, 스와핑을 통해 다중 프로그래밍의 정도를 조절할 수 있다.\r\n    6. 컴파일 타임 바인딩 방식이나 로드 타임 바인딩 방식에서는 스왑 인될 때에 원래 존재하던 메모리 위치로 다시 올라가야 하지만 실행시간 바인딩 기법에서는 추후 빈 메모리 영역 아무 곳에나 올릴 수 있음.\r\n    7. 스와핑에 소요되는 시간은 디스크의 탐색시간(seek time)이나 회전지연시간(rotational latency)보다는 디스크 섹터에서 실제 데이터를 읽고 쓰는 전송시간(transfer time)이 대부분을 차지함.\r\n\r\n\r\n## 3. 물리적 메모리의 할당 방식\r\n\r\n- 물리적 메모리는 운영체제 상주 영역과 사용자 프로세스 영역으로 나뉘어 사용됨.\r\n    - 운영체제 상주 영역은 인터럽트 벡터와 함께 물리적 메모리의 낮은 주소 영역을 사용하며, 운영체제 커널이 이곳에 위치하게 됨.\r\n    - 사용자 프로세스 영역은 물리적 메모리의 높은 주소 영역을 사용하며 여러 사용자 프로세스들이 이곳에 적재되어 실행됨.\r\n- 사용자 프로세스 영역에서는 프로세스를 메모리에 올리는 방식에 따라 두 가지로 나누어 볼 수 있음.\r\n- 연속할당(contiguous allocation) 방식\r\n    - 각각의 프로세스를 물리적 메모리의 연속적인 공간에 올리는 방식.\r\n    - 물리적 메모리를 다수의 분할로 나누어 하나의 분할에 하나의 프로세스가 적재되도록 함.\r\n    - 고정분할(fixed partition allocation) 방식\r\n        - 물리적 메모리를 고정된 크기의 분할로 미리 나누어두는 방식\r\n    - 가변분할(variable partition allocation) 방식\r\n        - 미리 나누어놓지 않은 채 프로그램이 실행되고 종료되는 순서에 따라 분할을 관리하는 방식.\r\n- 불연속할당(noncontiguous allocation) 방식\r\n    - 하나의 프로세스를 물리적 메모리의 여러 영역에 분산해 적재하는 방식.\r\n    - 페이징 기법과 세그먼테이션 기법, 페이즈드 세그먼테이션 기법 등이 있음.\r\n\r\n1. 연속할당 방식\r\n    - 프로세스를 메모리에 올릴 때 그 주소 공간을 여러 개로 분할하지 않고 물리적 메모리의 한 곳에 연속적으로 적재하는 방식.\r\n    1. 고정분할 방식\r\n        - 물리적 메모리를 주어진 개수만큼의 영구적인 분할(partition)로 미리 나누어두고 각 분할에 하나의 프로세스를 적재해 실행시킬 수 있게 함.\r\n        - 분할의 크기는 모두 동일하게 할 수도 있고 서로 다르게 할 수도 있음.\r\n        - 하나의 분할에는 하나의 프로그램만을 적재할 수 있어 고정분할 방식은 동시에 메모리에 올릴 수 있는 프로그램의 수가 고정되어 있으며 수행 가능한 프로그램의 최대 크기 또한 제한된다는 점에서 가변분할 방식에 비해 융통성이 떨어짐.\r\n        - 외부조각과 내부조각이 발생할 수 있음.\r\n        - 외부조각\r\n            - 프로그램의 크기보다 분할의 크기가 작은 경우 해당 분할이 비어 있는데도 불구하고 프로그램을 적재하지 못하기 때문에 발생하는 메모리 공간.\r\n        - 내부조각\r\n            - 프로그램의 크기보다 분할의 크기가 큰 경우 해당 분할에 프로그램을 적재하고 남는 메모리 공간을 의미.\r\n    2. 가변분할 방식\r\n        - 메모리에 적재되는 프로그램의 크기에 따라 분할의 크기, 개수가 동적으로 변하는 방식.\r\n        - 내부조각은 발생하지 않으나 외부조각이 발생할 가능성이 있음.\r\n        - 가변분할 방식에서는 주소 공간의 크기가 n인 프로세스를 메모리에 올릴 때 물리적 메모리 내 가용 공간 중 어떤 위치에 올릴 것인지 결정하는 것이 문제이고 이를 동적 메모리 할당 문제(dynamic storage-allocation problem)이라고 부름.\r\n        - 가용 공간들을 좀 더 효율적으로 관리하기 위해 운영체제는 이미 사용 중인 메모리 공간과 사용하고 있지 않은 가용 공간에 대한 정보를 각각 유지하고 있음.\r\n        - 동적 메모리 할당 문제를 해결하는 대표적인 방법으로는 세 가지가 있음.\r\n            - 최초적합(first-fit) 방법\r\n                - 크기가 n 이상인 가용 공간 중 가장 먼저 찾아지는 곳에 프로세스를 할당하는 방법.\r\n                - 가용 공간을 모두 탐색하는 방법이 아니므로 시간적인 측면에서 효율적.\r\n            - 최적적합(best-fit) 방법\r\n                - 크기가 n 이상인 가장 작은 가용 공간을 찾아 그곳에 새로운 프로그램을 할당하는 방법.\r\n                - 가용 공간 리스트가 크기순으로 정렬되어 있지 않은 경우 모든 가용 공간 리스트를 탐색해야 하므로 시간적 오버헤드가 발생하고 다수의 매우 작은 가용 공간들이 생성될 수 있다는 단점이 있지만 공간적인 측면에서 효율적.\r\n            - 최악적합(worst-fit) 방법\r\n                - 가장 크기가 큰 곳에 새로운 프로그램을 할당하는 방법.\r\n                - 모든 가용 공간 리스트를 탐색해야 하는 오버헤드가 발생하고 상대적으로 더 큰 프로그램을 담을 수 있는 가용 공간을 빨리 소진한다는 문제점이 있음.\r\n        - 외부조각 문제를 해결하기 위해 컴팩션(compaction)이라는 방법이 있음.\r\n            - 물리적 메모리 중에서 프로세스에 의해 사용 중인 메모리 영역을 한쪽으로 몰고 가용 공간들을 다른 한쪽으로 모아서 하나의 큰 가용 공간을 만드는 방법.\r\n            - 현재 수행 중인 프로세스의 메모리상 위치를 상당 부분 이동시켜야 하므로 비용이 매우 많이 드는 작업.\r\n            - 수행 중인 프로세스 물리적 메모리 위치를 옮겨야 하므로 실행시간 바인딩 방식이 지원되는 환경에서만 수행될 수 있음.\r\n\r\n2. 불연속할당 기법\r\n    - 하나의 프로세스가 물리적 메모리의 여러 위치에 분산되어 올라갈 수 있는 메모리 할당 기법을 의미함.\r\n    - 페이징 기법, 세그먼테이션 기법, 페이지드 세그먼테이션 기법 등이 있음.\r\n\r\n\r\n## 4. 페이징 기법\r\n\r\n- 페이징(paging) 기법이란 프로세스의 주소 공간을 동일한 크기의 페이지 단위로 나누어 물리적 메모리의 서로 다른 위치에 페이지들을 저장하는 방식.\r\n- 페이징 기법에서는 물리적 메모리를 페이지와 동일한 크기의 프레임(frame)으로 미리 나누어둔다.\r\n    - 메모리에 올리는 단위가 동일한 크기의 페이지 단위이므로, 빈 프레임이 있으면 어떤 위치이든 사용될 수 있다.\r\n      따라서 동적 메모리 할당 문제가 발생하지 않는다.\r\n- 주소 변환 절차가 연속할당 방식에 비해 다소 복잡하다.\r\n    - 하나의 프로세스라 하더라도 페이지 단위로 물리적 메모리에 올리는 위치가 상이하므로, 논리적 주소를 물리적 주소로 변환하는 작업이 페이지 단위로 이루어져야 하기 때문이다.\r\n    - 페이지별 주소 변환 정보를 유지하고 있어야 하므로 모든 프로세스가 각각의 주소 변환을 위한 페이지 테이블을 가지며, 이 테이블은 프로세스가 가질 수 있는 페이지의 개수만큼 주소 변환 엔트리를 가지고 있게 된다.\r\n\r\n    ![Untitled (74)](https://user-images.githubusercontent.com/62014888/146325391-f9c3e38e-0fd4-4ace-9eec-f820553da91d.png)\r\n\r\n- 페이징 기법에서는 빈 공간은 어느 곳이든 활용할 수 있어서 외부조각 문제가 발생하지 않는다.\r\n  그러나 프로그램의 크기가 항상 페이지 크기의 배수가 된다는 보장이 없기 때문에 프로세스 주소 공간 중 제일 마지막에 위치한 페이지에서는 내부조각이 발생할 가능성이 있다.\r\n\r\n1. 주소 변환 기법\r\n    1. 페이징 기법에서는 CPU가 사용하는 논리적 주소를 페이지 번호(p)와 페이지 오프셋(d)으로 나누어 주소 변환(address translation)에 사용한다.\r\n    2. 페이지 번호는 각 페이지별 주소 변환 정보를 담고 있는 페이지 테이블 접근 시 인덱스(index)로 사용되고, 해당 인덱스의 항목(entry)에는 그 페이지의 물리적 메모리상의 기준 주소(base address), 즉 시작 위치가 저장된다.\r\n       따라서 p번째 페이지가 위치한 물리적 메모리의 시작 위치를 알고 싶다면 해당 프로세스 페이지 테이블에서 p번째 항목을 찾아보면 된다.\r\n    3. 페이지 오프셋은 하나의 페이지 내에서의 변위를 알려주므로 기준 주소값에 변위를 더함으로써 요청된 논리적 주소에 대응하는 물리적 주소를 알 수 있다.\r\n\r\n2. 페이지 테이블의 구현\r\n    1. 페이지 테이블은 페이징 기법에서 주소 변환을 하기 위한 자료구조로, 물리적 메모리에 위치하게 된다.\r\n    2. CPU에서 프로세스의 페이지 테이블에 접근하기 위해 운영체제는 2개의 레지스터를 사용하는데, 각각 페이지 테이블 기준 레지스터(page-table base register)와 페이지 테이블 길이 레지스터(page-table length register)로 불린다.\r\n        - 페이지 테이블 기준 레지스터는 메모리 내에서의 페이지 테이블의 시작 위치를 가리킴.\r\n        - 페이지 테이블 길이 레지스터는 페이지 테이블의 크기를 보관함.\r\n    3. 페이징 기법에서의 메모리 접근 연산은 주소 변환을 위해 페이지 테이블에 접근하는 것, 변환된 주소에서 실제 데이터에 접근하는 것, 이렇게 두 번의 메모리 접근을 필요로 함.\r\n        - 이러한 오버헤드를 줄이고 메모리 접근 속도를 향상시키기 위해 TLB(Translation Look-aside Buffer)라고 불리는 고속의 주소 변환용 하드웨어 캐시가 사용된다.\r\n    4. TLB는 비싸기 때문에 페이지 테이블의 모든 정보를 담을 수는 없으며, 빈번히 참조되는 페이지에 대한 주소 변환 정보만을 담게 됨.\r\n        - 요청된 페이지 번호가 TLB에 존재한다면 곧바로 대응하는 물리적 메모리의 프레임 번호를 얻을 수 있다.\r\n        - 존재하지 않는 경우에는 메인 메모리에 있는 페이지 테이블로부터 프레임 번호를 알아내야 한다.\r\n        - 주소 변환 정보는 프로세스별로 다 다르기 때문에 문맥교환 시 이전 프로세스의 주소 변환 정보를 담고 있던 TLB 내용은 모두 지워버려야 함.\r\n    5. 페이지 테이블과 TLB에 저장되어 있는 정보는 그 구조가 조금 다르다.\r\n        - 페이지 테이블에는 모든 페이지에 대한 주소 변환 정보가 페이지 번호에 따라 순차적으로 들어 있다.\r\n        - TLB는 모든 페이지에 대한 주소 변환 정보를 가지고 있지 않기 때문에 페이지 번호와 이에 대응하는 프레임 번호가 쌍으로 저장되어야 한다.\r\n    6. TLB를 통한 주소 변환을 위해서 TLB의 모든 항목(entry)을 다 찾아봐야 하는 오버헤드가 발생하는데 이를 줄이기 위해 병렬탐색(parallel search)이 가능한 연관 레지스터(associative register)를 사용함.\r\n        - 병렬탐색 기능이란 TLB 내의 모든 항목을 동시에 탐색할 수 있는 기능을 뜻함.\r\n\r\n3. 계층적 페이징\r\n    1. 페이지 테이블에 사용되는 메모리 공간의 낭비를 줄이기 위해 2단계 페이징(two-level paging) 기법을 사용함.\r\n    2. 2단계 페이징 기법에서는 주소 변환을 위해 외부 페이지 테이블과 내부 페이지 테이블의 두 단계에 걸친 페이지 테이블을 사용함.\r\n        - 사용 메모리 공간을 줄여 공간적인 이득을 볼 수 있지만, 접근 테이블 수가 증가하므로 시간적인 손해가 뒤따르게 됨.\r\n    3. 프로세스의 주소 공간이 커질수록 페이지 테이블의 크기도 커지므로 주소 변환을 위한 메모리 공간 낭비 역시 더 심각해지게 됨.\r\n        - 2단계를 넘어 3단계, 4단계에 이르는 다단계 페이지 테이블이 필요하게 됨.\r\n        - 다단계 페이지 테이블을 사용하면 페이지 테이블을 위해 사용되는 메모리 공간의 소모는 줄일 수 있지만 그만큼 메모리에 대한 접근 횟수가 많아지기 때문에 메모리 접근시간이 크게 늘어나는 문제가 발생할 수 있음\r\n        - 이에 시간적인 오버헤드를 줄이기 위해 TLB를 사용하는 것이 효과적.\r\n        - TLB를 사용하면 4단계로 구성해도 시간 오버헤드가 그다지 크지 않으면서 메모리 공간의 효율적인 사용 효과는 매우 클 것으로 기대할 수 있음.\r\n\r\n1. 역페이지 테이블\r\n    1. 역페이지 테이블(inverted page table) 기법은 물리적 메모리의 페이지 프레임 하나당 페이지 테이블에 하나씩의 항목을 두는 방식.\r\n        - 즉, 논리적 주소에 대해 페이지 테이블을 만드는 것이 아니라 물리적 주소에 대해 테이블을 만드는 것.\r\n        - 각 프로세스마다 페이지 테이블을 두지 않고, 시스템 전체에 페이지 테이블을 하나만 두는 방법.\r\n        - 페이지 테이블의 각 항목은 프로세스 번호(pid)와 그 프로세스 내의 논리적 페이지 번호(p)를 담고 있게 됨.\r\n    2. 역페이지 테이블에 주소 변환 요청이 들어오면, 그 주소를 담은 페이지가 물리적 메모리에 존재하는지 여부를 판단하기 위해 페이지 전체를 다 탐색해야 하는 어려움이 있음.\r\n        - 역페이지 테이블은 연관 레지스터에 보관해 테이블 전체 항목에 대한 병렬탐색을 가능하게 함으로써 시간적 효율성을 꾀하게 됨.\r\n\r\n2. 공유 페이지\r\n    1. 공유 코드(shared code)는 메모리 공간의 효율적인 사용을 위해 여러 프로세스에 의해 공통으로 사용될 수 있도록 작성된 코드를 말함.\r\n        - 재진입 가능 코드(re-entrant code), 순수 코드(pure code)라고도 불리며 읽기전용(read-only)의 특성을 가지고 있음.\r\n    2. 공유 페이지(shared page)란 공유 코드를 담고 있는 페이지를 말한다.\r\n        - 공유 페이지는 여러 프로세스에 의해 공유되는 페이지이므로 물리적 메모리에 하나만 적재되어 메모리를 좀 더 효율적으로 사용할 수 있게 한다.\r\n    3. 공유 코드는 읽기전용의 성질을 가져야 할 뿐 아니라 모든 프로세스의 논리적 주소 공간에서 동일한 위치에 존재해야 하는 제약점이 있다.\r\n       즉, 공유 페이지는 그 페이지를 공유하는 모든 프로세스의 주소 공간에서 동일한 페이지 번호를 가져야 한다.\r\n    4. 공유 페이지와 대비되는 개념으로 사유 페이지(private page)가 있는데, 이것은 프로세스들이 공유하지 않고 프로세스별로 독자적으로 사용하는 페이지를 말한다.\r\n        - 해당 프로세스의 논리적 주소 공간 중 어떠한 위치에 있어도 무방함.\r\n\r\n3. 메모리 보호\r\n    1. 페이지 테이블의 각 항목에는 주소 변환 정보뿐 아니라 메모리 보호를 위한 보호비트(protection bit)와 유효-무효 비트(valid-invalid bit)를 두고 있다.\r\n    2. 보호비트는 각 페이지에 대한 접근 권한의 내용을 담고 있다.\r\n        - 각 페이지에 대해 읽기-쓰기/읽기전용 등의 접근 권한을 설정하는 데에 사용됨.\r\n    3. 유효-무효 비트는 해당 페이지의 내용이 유효한지에 대한 내용을 담고 있다.\r\n        - '유효'로 세팅되어 있으면 해당 메모리 프레임에 그 페이지가 존재함을 뜻하며, 따라서 접근이 허용된다.\r\n        - '무효'로 세팅되어 있으면 프로세스가 그 주소 부분을 사용하지 않거나, 해당 페이지가 물맂걱 메모리에 올라와 있지 않고 백킹스토어에 존재해 해당 메모리 프레임에 유효한 접근 권한이 없다는 의미를 지닌다.\r\n\r\n\r\n## 5. 세그먼테이션\r\n\r\n- 세그먼테이션(segmentation) 기법은 프로세스의 주소 공간을 의미 단위의 세그먼트(segment)로 나누어 물리적 메모리에 올리는 기법이다.\r\n- 하나의 프로세스를 구성하는 주소 공간은 코드, 데이터, 스택 등의 의미 있는 단위들로 구성되는데 세그먼트는 이와 같이 주소 공간을 기능 단위 또는 의미 단위로 나눈 것을 뜻함.\r\n    - 프로세스 주소 공간 전체를 하나의 세그먼트로 볼 수도 있으며, 일반적으로는 코드, 데이터, 스택 등의 기능 단위로 세그먼트를 정의한다.\r\n    - 논리적인 단위로 나눈 것이기 때문에 그 크기가 균일하지 않다.\r\n- 페이징과 유사하나 의미 단위의 세그먼트로 나누어 관리하므로, 크기가 균일하지 않은 세그먼트들을 메모리에 적재하는 부가적인 관리 오버헤드가 뒤따르게 됨.\r\n- 논리적 주소가 <세그먼트 번호, 오프셋>으로 나뉘어 사용됨.\r\n    - 세그먼트 번호는 해당 주소가 프로세스 주소 공간 내에서 몇 번째 세그먼트에 속하는지를 나타냄.\r\n    - 오프셋은 그 세그먼트 내에서 얼마만큼 떨어져 있는지에 대한 정보를 나타냄.\r\n- 세그먼트 테이블의 각 항목은 기준점(base)과 한계점(limit)을 가지고 있음.\r\n    - 기준점은 물리적 메모리에서 그 세그먼트의 시작 위치를 나타냄\r\n    - 한계점은 그 세그먼트의 길이를 나타냄.\r\n    - 세그먼트의 길이가 균일하지 않으므로 길이 정보를 함께 보관하고 있는 것.\r\n- 세그먼테이션 기법에서도 세그먼트 테이블 기준 레지스터(Segment-Table Base Register: STBR)와 세그먼트 테이블 길이 레지스터(Segment-Table Length Register: STLR)로 사용하게 됨.\r\n    - 세그먼트 테이블 기준 레지스터는 현재 CPU에서 실행 중인 프로세스의 세그먼트 테이블이 메모리 어느 위치에 있는지 그 시작 주소를 담고 있음.\r\n    - 세그먼트 테이블 길이 레지스터는 그 프로세스의 주소 공간이 총 몇 개의 세그먼트로 구성되는지, 즉 세그먼트의 개수를 나타낸다.\r\n- 세그먼테이션 기법에서는 논리적 주소를 물리적 주소로 변환하기 전에 두 가지 사항을 먼저 확임함.\r\n    - 요청된 세그먼트 번호가 STLR에 저장된 값보다 작은 값인가 하는 점\r\n        - 만약 그렇지 않다면 존재하지 않는 세그먼트에 대한 접근 시도이므로 예외상황을 발생시켜 메모리 접근을 봉쇄해야 할 것.\r\n    - 논리적 주소의 오프셋값이 그 세그먼트의 길이보다 작은 값인가 하는 점.\r\n        - 세그먼트 테이블의 한계점과 요청된 논리적 주소의 오프셋값을 비교해 확인하게 됨.\r\n        - 만약 세그먼트 길이를 넘어서는 오프셋 위치에 대한 접근 시도라면 예외상황을 발생시킨다.\r\n- 페이징 기법과 마찬가지로 보호비트, 유효비트를 두고 공유 세그먼트(shared segment) 개념을 지원함.\r\n- 세그먼트는 의미 단위로 나누어져 있기 때문에 공유와 보안의 측면에서 페이징 기법에 비해 훨씬 효과적임.\r\n    - 주소 공간의 일부를 공유하거나 특정 주소 공간에 읽기전용 등의 접근 권한 제어를 하고자 할 경우, 이는 어떤 의미 단위로 이루어지지 단순히 크기 단위로 수행되지 않기 때문\r\n- 의미 단위로 나누기에 세그먼트의 길이가 균일하지 않아서 외부조각이 발생하게 되며, 어느 가용 공간에 할당할 것인지 결정하는 문제가 발생함.\r\n    - 가변분할 방식의 문제와 동일한 범주의 문제라 할 수 있다.\r\n    - 최초적합 방식과 최적적합 방식을 사용해 할당한다.\r\n\r\n\r\n## 6. 페이지드 세그먼테이션\r\n\r\n- 페이징과 세그먼테이션 두 기법의 장점만을 취하는 주소 변환 기법으로 페이지드 세그먼테이션(paged segmentation) 기법이 있다.\r\n- 세그먼테이션 기법과 마찬가지로 프로그램을 의미 단위의 세그먼트로 나눈다.\r\n    - 단, 반드시 동일한 크기 페이지들의 집합으로 구성되어야 하고 물리적 메모리에 적재하는 단위는 페이지 단위로 한다.\r\n    - 즉, 페이지드 세그먼테이션 기법에서는 하나의 세그먼트 크기를 페이지 크기의 배수가 되도록 함으로써 외부조각 문제를 해결하며, 동시에 세그먼트 단위로 공유나 보호가 이루어지도록 함으로써 페이징 기법의 약점을 해소한다.\r\n- 주소 변환을 위해 외부의 세그먼트 테이블과 내부의 페이지 테이블, 이렇게 두 단계의 테이블을 이용함.\r\n- 논리적 주소의 상위 비트인 세그먼트 번호를 통해 세그먼트 테이블의 해당 항목에 접근함.\r\n    - 세그먼트 항목에는 세그먼트 길이와 그 세그먼트의 페이지 테이블 시작 주소가 들어 있음.\r\n- 세그먼트 길이값과 오프셋값을 비교해서 오프셋이 크다면 트랩을 발생시킨다.\r\n- 그렇지 않을 경우 오프셋값을 다시 상위, 하위 비트로 나누어 상위 비트는 그 세그먼트 내에서의 페이지 번호로 사용하고 하위 비트는 페이지 내에서의 변위로 사용함.\r\n- 세그먼트 테이블의 항목을 통해 세그먼트를 위한 페이지 테이블의 시작 위치를 얻었으므로, 그 위치에서 페이지 번호만큼 떨어진 페이지 테이블 항목으로부터 물리적 메모리의 페이지 프레임 위치를 얻게 됨.\r\n- 이 위치에서 오프셋의 하위 비트값인 페이지 내 변위만큼 떨어진 곳이 바로 원하는 물리적 메모리 주소가 됨.","excerpt":"'운영체제와 정보기술의 원리' 스터디를 진행하며 정리한 내용이다. 컴퓨터에서는 byte 단위로 메모리 주소를 부여하기 때문에 32비트 주소 체계를 사용하면 2의 32제곱 바이트만큼의 메모리 공간에 서로 다른 주소를 할당할 수 있다. 효율적인 운영을 …","fields":{"slug":"/os-it-principle-ch7/"},"frontmatter":{"date":"Oct 16, 2021","title":"[운영체제와 정보기술의 원리] 7. 메모리 관리","tags":["os","book","os-it-principle"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n'운영체제와 정보기술의 원리' 스터디를 진행하며 정리한 내용이다.\r\n\r\n---\r\n\r\n- CPU는 프로그램의 기계어 명령을 실제로 수행하는 컴퓨터 내의 중앙처리장치.\r\n- 일반적으로 한 시스템 내에 하나씩밖에 없으므로 시분할 환경에서 매우 효율적으로 관리되어야 하는 자원.\r\n- 기계어 명령은 크게 CPU 내에서 수행되는 명령, 메모리 접근을 필요로 하는 명령, 입출력을 동반하는 명령으로 나누어볼 수 있음.\r\n    - CPU 내에서 수행되는 명령\r\n        1. Add 명령 - CPU 내의 레지스터에 있는 두 값을 더해 레지스터에 저장하는 명령. CPU 내에서 수행되므로 명령의 수행 속도가 빠르다.\r\n    - 메모리 접근을 수행하는 명령\r\n        1. Load 명령 - 메모리에 있는 데이터를 CPU로 읽어들이는 명령\r\n        2. Store 명령 - CPU에서 계산된 결괏값을 메모리에 저장하는 명령     \r\n       CPU 내에서 수행되는 명령보다는 오래 소요되지만 비교적 짧은 시간에 수행할 수 있음.   \r\n       CPU 내에서 수행되는 명령과 메모리 접근을 수행하는 명령은 일반명령에 해당함.\r\n    - 입출력을 동반하는 명령\r\n        - CPU나 메모리 접근 명령에 비해 대단히 오랜 시간이 소요됨.\r\n        - 특권명령으로 규정해 운영체제를 통해 서비스를 대행하도록 하고 있음.\r\n- 프로그램의 수행은 서로 다른 두 단계의 조합으로 이루어짐.\r\n    1. 사용자 프로그램이 CPU를 직접 가지고 빠른 명령을 수행하는 일련의 단계\r\n        - CPU 버스트라고 함.\r\n        - 프로그램이 I/O를 한 번 수행한 후 다음 번 I/O를 수행하기까지 직접 CPU를 가지고 명령을 수행하는 일련의 작업\r\n    2. I/O 요청이 발생해 커널에 의해 입출력 작업을 진행하는 비교적 느린 단계\r\n        - I/O 버스트라고 함.\r\n        - I/O 작업이 요청된 후 완료되어 다시 CPU 버스트로 돌아가기까지 일어나는 일련의 작업.\r\n- I/O 바운드 프로세스\r\n    - I/O 요청이 빈번해 CPU 버스트가 짧게 나타나는 프로세스\r\n    - 사용자로부터 인터랙션을 계속 받아가며 프로그램을 수행시키는 대화형 프로그램(interactive program)\r\n    - 짧은 CPU 버스트를 많이 가짐.\r\n- CPU 바운드 프로세스\r\n    - I/O 작업을 거의 수행하지 않아 CPU 버스트가 길게 나타나는 프로세스를 말함.\r\n    - 프로세스 수행의 상당 시간을 입출력 작업 없이 CPU 작업에 소모하는 계산 위주의 프로그램.\r\n    - 소수의 긴 CPU 버스트로 구성됨.\r\n- CPU 스케줄링은 CPU를 사용하는 패턴이 상이한 여러 프로그램이 동일한 시스템 내부에서 함께 실행되기 때문에 필요한 것.\r\n    - 시분할 시스템에서 CPU 버스트가 균일하지 않은 다양한 프로그램이 공존하므로 효율적인 CPU 스케줄링 기법이 반드시 필요함.\r\n- 프로세스들을 살펴보면 CPU를 한 번에 오래 사용하기보다는 잠깐 사용하고 I/O 작업을 수행하는 프로세스들이 많음.\r\n    - 이러한 CPU 버스트가 짧은 프로세스는 대화형 작업으로 사용자와 인터랙션을 해가며 프로그램을 수행시킴.\r\n    - CPU의 빠른 서비스를 필요로 하기에 (대화형 작업은 빠른 응답이 중요함) CPU 스케줄링을 할 때 CPU 버스트가 짧은 프로세스에게 우선적으로 CPU를 사용할 수 있도록 하는 스케줄링이 필요함.\r\n- 따라서 I/O 바운드 프로세스의 우선순위를 높여주는 것이 바람직하다.\r\n    - I/O 바운드 프로세스에게 먼저 CPU를 할당할 경우 CPU를 잠깐만 사용한 후 곧바로 I/O 장치의 이용률이 높아짐.\r\n    - CPU 바운드 프로세스에게 먼저 CPU를 할당하면 그 프로세스가 CPU를 다 사용할 때까지 I/O 바운드 프로세스는 응답시간이 길어질 뿐 아니라 해당 I/O 장치도 그 시간 동안 작업을 수행하지 않는 휴면 상태가 되기 때문에 비효율적.\r\n\r\n\r\n## 1. CPU 스케줄러\r\n\r\n- CPU 스케줄러는 준비 상태에 있는 프로세스들 중 어떠한 프로세스에게 CPU를 할당할지 결정하는 운영체제의 코드.\r\n- 타이머 인터럽트가 발생하면 CPU 스케줄러가 호출되고 준비 큐에서 CPU를 기다리는 프로세스 중 하나를 선택해 CPU를 할당하게 됨.\r\n- CPU 스케줄링이 필요한 경우\r\n    1. 실행 상태에 있던 프로세스가 I/O 요청 등에 의해 봉쇄 상태로 바뀌는 경우\r\n    2. 실행 상태에 있던 프로세스가 타이머 인터럽트 발생에 의해 준비 상태로 바뀌는 경우\r\n    3. I/O 요청으로 봉쇄 상태에 있던 프로세스의 I/O 작업이 완료되어 인터럽트가 발생하고 그 결과 이 프로세스의 상태가 준비 상태로 바뀌는 경우\r\n    4. CPU에서 실행 상태에 있는 프로세스가 종료되는 경우\r\n- CPU 스케줄링 방식에는 두 가지가 있음.\r\n    - 비선점형(nonpreemptive) 방식\r\n        - CPU를 획득한 프로세스가 스스로 CPU를 반납하기 전까지는 CPU를 빼앗기지 않는 방법을 말함.\r\n    - 선점형(preemptive) 방식\r\n        - 프로세스가 CPU를 계속 사용하기를 원하더라도 강제로 빼앗을 수 있는 스케줄링 방법을 말함.\r\n    - 위 네 가지 경우에서 1, 4는 비선점형 스케줄링, 2, 3은 선점형 스케줄링에 해당함.\r\n    - 3의 경우 I/O 작업이 완료된 프로세스가 인터럽트 당한 프로세스보다 우선순위가 높아 인터럽트 처리 후 수행되던 프로세스에게 CPU를 다시 할당하는 것이 아닌 문맥교환을 통해 I/O가 완료된 프로세스에게 CPU를 할당하는 경우가 해당됨.\r\n- CPU를 빼앗는 방법으로는 할당시간(time quantum)을 부여한 후 타이머 인터럽트를 발생시키는 방법이 대표적.\r\n\r\n## 2. 디스패처\r\n\r\n- 새롭게 선택된 프로세스가 CPU를 할당받고 작업을 수행할 수 있도록 환경설정을 하는 운영체제의 코드를 디스패처(dispatcher)라고 부름.\r\n- 디스패처는 현재 수행 중이던 프로세스의 문맥을 그 프로세스의 PCB에 저장하고, 새롭게 선택된 프로세스의 문맥을 PCB로부터 복원한 후 그 프로세스에게 CPU를 넘기는 과정을 수행함.\r\n- 새로운 프로세스의 문맥을 복원시킨 후엔 시스템의 상태를 사용자모드로 전환해 사용자 프로그램에게 CPU의 제어권을 넘기게 됨.\r\n    - 사용자 프로그램은 복원된 문맥 중 프로그램 카운터로부터 현재 수행할 주소를 찾을 수 있게 됨.\r\n- 디스패처가 하나의 프로세스를 정지시키고 다른 프로세스에게 CPU를 전달하기까지 걸리는 시간을 디스패치 지연시간(dispatch latency)이라고 하며, 디스패치 지연시간의 대부분은 문맥교환 오버헤드에 해당됨.\r\n\r\n## 3. 스케줄링의 성능 평가\r\n\r\n- 스케줄링 기법의 성능을 평가하기 위해 여러 지표들이 사용되는데, 이 지표들은 크게 시스템 관점의 지표와 사용자 관점의 지표로 나누어볼 수 있음.\r\n    - 시스템 관점의 지표로는 CPU 이용률과 처리량이 있음.\r\n    - 사용자 관점의 지표로는 소요시간, 대기시간, 응답시간 등 기다린 시간과 관련된 지표들이 있음.\r\n- CPU 이용률(CPU utilization)\r\n    - 전체 시간 중에서 CPU가 일을 한 시간의 비율을 나타냄.\r\n    - CPU는 고비용 자원이므로 CPU 이용률은 시스템 전체의 성능과 밀접하게 관련되어 있어 CPU가 일을 하지 않고 휴면(idle) 상태에 머무르는 시간을 최대한 줄이는 것이 스케줄링의 중요한 목표가 됨.\r\n- 처리량(throughput)\r\n    - 주어진 시간 동안 준비 큐에서 기다리고 있는 프로세스 중 몇 개를 끝마쳤는지(CPU 버스트를 완료한 프로세스의 개수)를 나타냄.\r\n    - CPU의 서비스를 원하는 프로세스 중 몇 개가 원하는 만큼의 CPU를 사용하고 이번 CPU 버스트를 끝내어 준비 큐를 떠났는지 측정하는 것이 처리량의 개념\r\n    - 더 많은 프로세스들이 CPU 작업을 완료하기 위해서는 CPU 버스트가 짧은 프로세스에게 우선적으로 CPU를 할당하는 것이 유리함.\r\n- 소요시간(turnaround time)\r\n    - 프로세스가 CPU를 요청한 시점부터 자신이 원하는 만큼의 CPU를 다 쓰고 CPU 버스트가 끝날 때까지 걸린 시간, 즉 준비 큐에서 기다린 시간과 실제로 CPU를 사용한 시간의 합을 뜻함.\r\n    - 프로그램이 시작해 종료하는 데까지 걸리는 시간이 아님을 주의.\r\n- 대기시간(waiting time)\r\n    - CPU 버스트 기간 중 프로세스가 준비 큐에서 CPU를 얻기 위해 기다린 시간의 합을 뜻함.\r\n    - 한 번의 CPU 버스트 중에도 준비 큐에서 기다린 시간이 여러 번 발생할 수 있음.\r\n- 응답시간(response time)\r\n    - 프로세스가 준비 큐에 들어온 후 첫 번째 CPU를 획득하기까지 기다린 시간을 뜻함.\r\n    - 타이머 인터럽트가 빈번히 발생할수록 각 프로세스가 CPU를 연속적으로 사용할 수 있는 시간이 짧아지므로 처음 CPU를 얻기까지 걸리는 시간을 줄어들게 되어 응답시간이 향상된다.\r\n    - 대화형 시스템에 적합한 성능 척도로서 사용자 입장에서 가장 중요한 성능 척도\r\n\r\n## 4. 스케줄링 알고리즘\r\n\r\n1. 선입선출 스케줄링(First-Come First-Served: FCFS)\r\n    - 프로세스가 준비 큐에 도착한 시간 순서대로 CPU를 할당하는 방식을 말함.\r\n    - CPU를 먼저 요청한 프로세스에게 CPU를 먼저 할당하고, 그 프로세스가 자발적으로 CPU를 반납할 때까지 빼앗지 않음.\r\n    - 합리적인 스케줄링 방식인 것 같지만 경우에 따라 비효율적인 결과를 초래하기도 함.\r\n        - CPU 버스트가 긴 프로세스가 먼저 도착할 경우 평균 대기시간이 길어지고 I/O 장치 이용률도 동반 하락하게 됨.\r\n    - CPU 버스트가 긴 프로세스가 먼저 도착할 경우 평균 대기시간이 길어지는 반면, CPU 버스트가 짧은 프로세스가 먼저 도착하게 되면 평균 대기시간이 짧아지게 됨.\r\n    - CPU 버스트가 짧은 프로세스가 CPU 버스트가 긴 프로세스보다 나중에 도착해 오랜 시간을 기다려야 하는 현상을 콘보이 현상(Convoy effect)라고 한다.\r\n\r\n2. 최단작업 우선 스케줄링(Shortest-Job First: SJF)\r\n    - CPU 버스트가 가장 짧은 프로세스에게 제일 먼저 CPU를 할당하는 방식.\r\n    - 프로세스들이 준비 큐에서 기다리는 전체적인 시간이 줄어들게 됨.\r\n    - 평균 대기시간을 가장 짧게 하는 최적 알고리즘(optimal algorithm)으로 알려져 있음.\r\n    - 비선점형 방식\r\n        - CPU를 획득하면 그 프로세스가 CPU를 자진 반납하기 전까지는 CPU를 빼앗지 않는 방식\r\n    - 선점형 방식\r\n        - 준비 큐에서 CPU 버스트가 가장 짧은 프로세스에게 CPU를 할당했다 하더라도, CPU 버스트가 더 짧은 프로세스가 도착할 경우 CPU를 빼앗아 더 짧은 프로세스에게 부여하는 방식을 말함.\r\n        - SRTF(Shortest Remaining Time First)라고도 부름.\r\n    - 프로세스들이 준비 큐에 도착하는 시간이 불규칙한 환경에서는 선점형 방식이 프로세스들의 평균 대기시간을 최소화하는 최적 알고리즘이 됨.\r\n    - 준비 큐에 한꺼번에 도착하고 그 후에 따로 도착하지 않는 환경에서는 비선점형 방식과 선점형 방식이 서로 같은 결과를 나타내기도 함.\r\n    - 일반적인 시분할 환경에서는 중간중간에 새로운 프로세스가 도착하는 경우가 발생하므로 선점형 방식이 평균 대기시간을 가장 많이 줄일 수 있는 방식이 됨.\r\n    - SJF 스케줄링 기법의 구현에서 현실적으로 어려운 부분은 프로세스의 CPU 버스트 시간을 미리 알 수 없다는 점.\r\n        - 예측을 통해 CPU 버스트 시간을 구한 후 예측치가 가장 짧은 프로세스에게 CPU를 할당하게 됨.\r\n        - CPU 버스트 시간의 예측은 과거의 CPU 버스트 시간을 통해 이루어짐.\r\n    - 계속 CPU 버스트가 짧은 프로세스에게만 CPU를 할당할 경우 CPU 버스트가 긴 프로세스는 준비 큐에 줄 서서 무한정 기다려야 하는 문제가 발생할 수 있기 때문에 항상 좋은 방식이라고는 말할 수 없다.\r\n    - CPU 버스트가 짧은 프로세스가 계속 도착할 경우 CPU 버스트가 긴 프로세스는 영원히 CPU를 할당받지 못할 수도 있는데 이 현상을 기아 현상(starvation)이라고 한다.\r\n\r\n3. 우선순위 스케줄링(priority scheduling)\r\n    - 준비 큐에서 기다리는 프로세스들 중 우선순위가 가장 높은 프로세스에게 제일 먼저 CPU를 할당하는 방식을 말함.\r\n    - 우선순위값이 작을수록 높은 우선순위를 가지는 것으로 가정.\r\n    - 우선순위를 결정하는 방식에는 여러 가지가 있는데 CPU 버스트 시간을 기준으로 하거나 시스템과 관련된 중요한 작업을 수행하는 프로세스 우선순위를 높게 부여할 수도 있다.\r\n    - 비선점형 방식\r\n        - CPU를 얻었으면 우선순위가 더 높은 프로세스가 도착하더라도 CPU를 자진 반납하기 전까지 선점하지 않는다.\r\n    - 선점형 방식\r\n        - 현재 CPU에서 수행 중인 프로세스보다 우선순위가 높은 프로세스가 도착하여 CPU를 선점해서 새롭게 도착한 프로세스에게 할당하는 경우\r\n    - 우선순위가 높은 프로세스가 계속 도착하는 상황에서 우선순위가 낮은 프로세스는 CPU를 얻지 못한 채 계속 기다려야 하는 기아 현상이 발생할 수 있음.\r\n        - 기다리는 시간이 길어지면 우선순위를 조금씩 높여, 언젠가는 가장 높은 우선순위가 되어 CPU를 할당받을 수 있게 해주는 노화(aging) 기법을 통해 해결할 수 있다.\r\n\r\n4. 라운드 로빈 스케줄링(Round Robin Scheduling)\r\n    - 각 프로세스가 CPU를 연속적으로 사용할 수 있는 시간이 특정 시간으로 제한되며, 이 시간이 경과하면 해당 프로세스로부터 CPU를 회수해 준비 큐에 줄 서 있는 다른 프로세스에게 CPU를 할당한다.\r\n    - 각 프로세스마다 한 번에 CPU를 연속적으로 사용할 수 있는 최대시간을 할당시간(time quantum)이라고 부름.\r\n    - 할당시간이 너무 길면 라운드 로빈 스케줄링은 FCFS와 같은 결과를 나타내게 됨.\r\n    - 할당시간이 너무 짧으면 CPU를 사용하는 프로세스가 빈번하게 교체되어 문맥교환의 오버헤드가 커짐.\r\n    - 따라서 일반적으로 할당시간을 수십 밀리초 정도의 규모로 설정하게 됨.\r\n        - 여러 프로세스가 동시에 수행되는 환경에서 대화형 프로세스가 CPU를 한 번 할당받기까지 지나치게 오래 기다리지 않을 정도의 시간 규모에 해당됨.\r\n    - 라운드 로빈 스케줄링은 여러 종류의 이질적인 프로세스가 같이 실행되는 환경에서 효과적.\r\n    - 할당시간이 만료되어 CPU를 회수하는 방법으로는 타이머 인터럽트를 사용하게 됨.\r\n    - 라운드 로빈 스케줄링의 기본적인 목적은 CPU 버스트 시간이 짧은 프로세스가 빨리 CPU를 얻을 수 있도록 하는 동시에, CPU 버스트 시간이 긴 프로세스가 불이익을 당하지 않도록 하는 것.\r\n    - 자신이 CPU를 쓰고자 하는 양이 적으면 소요시간이 짧아지고, 많으면 소요시간도 거기에 비례해서 길어진다.\r\n      대기시간 역시 비례해서 증가하므로 공정하다고 할 수 있음.\r\n    - 동일한 CPU 버스트 시간을 가지는 프로세스들이 도착했을 경우 FCFS에서는 CPU를 먼저 쓰고 나가는 프로세스의 소요시간 및 대기시간이 짧아지는 반면, 라운드 로빈 스케줄링에서는 CPU를 조금씩 같이 쓰고 거의 동시에 끝나게 되어 소요시간 및 대기시간이 가장 오래 기다린 프로세스에 맞춰지게 된다.\r\n      따라서 라운드 로빈 스케줄링의 평균 대기시간 및 평균 소요시간은 FCFS의 거의 두 배가 된다.\r\n    - 일반적인 시스템에서는 CPU 버스트 시간이 균일하지 않고 각자 다른 CPU 버스트 및 I/O 버스트를 가지는 경우가 대부분이다.\r\n        - 이 경우 라운드 로빈 스케줄링을 적용하면 CPU 버스트 시간이 짧은 프로세스는 빨리 끝마치고, 반대로 CPU 버스트 시간이 긴 프로세스는 상대적으로 오래 기다린다.\r\n        - FCFS는 CPU 버스트가 긴 프로세스가 먼저 도착하는 경우 소요시간의 편차가 크고 평균값드 극단적으로 상승하게 된다.\r\n\r\n5. 멀티레벨 큐(multi-level queue)\r\n    - 준비 큐를 여러 개로 분할해 관리하는 스케줄링 기법.\r\n      즉, 프로세스들이 CPU를 기다리기 위해 한 줄로 서는 것이 아니라 여러 줄로 서는 것.\r\n    - 멀티레벨 큐는 성격이 다른 프로세스들을 별도로 관리하고, 프로세스의 성격에 맞는 스케줄링을 적용하기 위해 준비 큐를 별도로 두게 됨.\r\n    - 일반적으로 멀티레벨 큐에서 준비 큐는 대화형 작업을 담기 위한 전위 큐(foreground queue)와 계산 위주의 작업을 담기 위한 후위 큐(background queue)로 분할하여 운영됨.\r\n        - 전위 큐에서는 응답시간을 짧게 하기 위해 라운드 로빈 스케줄링을 사용하는 반면, 계산 위주의 작업을 위한 후위 큐에서는 응답시간이 큰 의미를 가지지 않기 때문에 FCFS 스케줄링 기법을 사용해 문맥교환 오버헤드를 줄이도록 함.\r\n    - 여러 개의 준비 큐에 대해서 어느 큐에 먼저 CPU를 할당할 것인지 결정하는 스케줄링이 필요함.\r\n        - 고정 우선순위 방식(fixed priority scheduling)\r\n            - 큐에 고정적인 우선순위를 부여해 우선순위가 높은 큐를 먼저 서비스하고 우선순위가 낮은 큐는 우선순위가 높은 큐가 비어 있을 때에만 서비스하게 됨.\r\n            - 전위 큐에 있는 프로세스에게 우선적으로 CPU가 할당되고, 전위 큐가 비어 있는 경우에만 후위 큐 프로세스에 CPU 할당.\r\n        - 타임 슬라이스(time slice) 방식\r\n            - 큐에 대한 기아 현상을 해소할 수 있는 방식으로, 각 큐에 CPU 시간을 적절한 비율로 할당함.\r\n\r\n6. 멀티레벨 피드백 큐(Multilevel Feedback Queue)\r\n    - 멀티레벨 큐와 동일하나, 프로세스가 하나의 큐에서 다른 큐로 이동가능하다는 점이 다르다.\r\n    - 멀티레벨 피드백 큐를 정의하는 요소들로는 큐의 수, 각 큐의 스케줄링 알고리즘, 프로세스를 상위 큐로 승격시키는 기준, 프로세스를 하위 큐로 강등시키는 기준, 프로세스가 도착했을 때 들어갈 큐를 결정하는 기준 등이 있음.\r\n    - 프로세스의 CPU 작업시간을 다단계로 분류함으로써 작업시간이 짧은 프로세스일수록 더욱 빠른 서비스가 가능하도록 하고, 작업시간이 긴 프로세스에 대해서는 문맥교환 없이 CPU 작업에만 열중할 수 있는 FCFS 방식을 채택할 수 있게 함.\r\n\r\n7. 다중처리기 스케줄링\r\n    - CPU가 여러 개인 시스템을 다중처리기 시스템(multi-processor system)이라고 부른다.\r\n    - 다중처리기 스케줄링에서는 일부 CPU에 작업이 편중되는 현상을 방지하기 위해 각 CPU별 부하가 적절히 분산되도록 하는 부하균형(load balancing) 메커니즘을 필요로 한다.\r\n    - 대칭형 다중처리(symmetric multi-processing)\r\n        - 각 CPU가 각자 알아서 스케줄링을 결정하는 방식\r\n    - 비대칭형 다중처리(asymmetric multi-processing)\r\n        - 하나의 CPU가 다른 모든 CPU의 스케줄링 및 데이터 접근을 책임지고 나머지 CPU는 거기에 따라 움직이는 방식\r\n\r\n8. 실시간 스케줄링\r\n    - 실시간 시스템에서는 각 작업마다 주어진 데드라인이 있어 정해진 데드라인 안에 반드시 작업을 처리해야 함.\r\n    - 경성 실시간 시스템(hard real-time system)\r\n        - 미사일 발사, 원자로 제어 등 시간을 정확히 지켜야 하는 시스템.\r\n        - 정해진 시간 안에 반드시 작업이 완료되도록 스케줄링해야 함.\r\n    - 연성 실시간 시스템(soft real-time system)\r\n        - 데드라인이 존재하기는 하지만 데드라인을 지키지 못했다고 해서 위험한 상황이 발생하지는 않음. ex) 멀티미디어 스트리밍 시스템\r\n    - 데드라인이 얼마 남지 않은 요청을 먼저 처리하는 EDF(Earlist Deadline First) 스케줄링을 사용함.\r\n    - 연성 실시간 시스템처럼 일반 작업과 VOD 작업 등이 혼합된 환경에서는 데드라인이 존재하는 프로세스에게 일반 프로세스보다 높은 우선순위를 할당하는 방식도 사용함.\r\n\r\n\r\n## 5. 스케줄링 알고리즘의 평가\r\n\r\n- 큐잉모델(queueing model)\r\n    - 주로 이론가들이 수행하는 방식\r\n    - 확률분포를 통해 프로세스들의 도착률과 CPU 처리율을 입력값으로 주면 복잡한 수학적 계산을 통해 각종 성능지표인 CPU의 처리량, 프로세스 평균 대기시간 등을 구하게 됨.\r\n- 구현 및 실측(implementation & measurement)\r\n    - 구현가들이 수행할 수 있는 방식\r\n    - 커널의 CPU 스케줄링 수행 코드를 수정해서 커널을 컴파일한 후 시스템에 설치하는 과정을 필요로 함.\r\n      그 후 원래 커널과 스중한 커널에서 프로그램을 실행시켜보고 실행시간을 측정.\r\n- 시뮬레이션(simulation)\r\n    - 가상으로 CPU 스케줄링 프로그램을 작성한 후 프로그램의 CPU 요청을 입력값으로 넣어 어떤 결과가 나오는지를 확인하는 방법.","excerpt":"'운영체제와 정보기술의 원리' 스터디를 진행하며 정리한 내용이다. CPU는 프로그램의 기계어 명령을 실제로 수행하는 컴퓨터 내의 중앙처리장치. 일반적으로 한 시스템 내에 하나씩밖에 없으므로 시분할 환경에서 매우 효율적으로 관리되어야 하는 자원. 기계…","fields":{"slug":"/os-it-principle-ch6/"},"frontmatter":{"date":"Oct 15, 2021","title":"[운영체제와 정보기술의 원리] 6. CPU 스케줄링","tags":["os","book","os-it-principle"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n'운영체제와 정보기술의 원리' 스터디를 진행하며 정리한 내용이다.\r\n\r\n---\r\n\r\n## 1. 프로세스의 개념\r\n\r\n- 프로세스(process)란 실행 중인 프로그램(program in execution)을 뜻한다.\r\n- 디스크에 실행파일 형태로 존재하던 프로그램이 메모리에 올라가서 실행되기 시작하면 프로세스가 되며, 프로세스는 CPU를 획득해 자신의 코드를 수행하기도 하고, 때로는 CPU를 반환하고 입출력 작업을 수행하기도 함.\r\n- 일반적으로 잡(job)이라는 용어와 프로세스를 혼용해 사용하기도 함.\r\n- 프로세스의 문맥(context)이란 프로세스가 현재 어떤 상태에서 수행되고 있는지 정확히 규명하기 위해 필요한 정보를 의미한다.\r\n    - 시분할 시스템과 같은 환경에서는 CPU를 다시 획득해 명령의 수행을 재개하는 시점이 되면 이전의 CPU 보유 시기에 어느 부분까지 명령을 수행했는지 직전 수행 시점의 정확한 상태를 재현할 필요가 있고 이를 위해 필요한 정보가 문맥임.\r\n    - 문맥은 크게 세 가지로 분류가 가능함.\r\n    - 하드웨어 문맥\r\n        - CPU의 수행 상태를 나타내는 것으로 프로그램 카운터값과 각종 레지스터에 저장하고 있는 값들을 의미\r\n    - 프로세스의 주소 공간\r\n        - 코드, 데이터, 스택으로 구성되는 자기 자신만의 독자적인 주소 공간.\r\n    - 커널상의 문맥\r\n        - 프로세스를 관리하기 위한 자료구조인 PCB와 커널스택\r\n\r\n\r\n## 2. 프로세스의 상태\r\n\r\n- 프로세스의 상태는 실행(running), 준비(ready), 봉쇄(blocked, wait, sleep) 세 가지로 구분할 수 있음. + 시작(new), 완료(terminated) 상태\r\n\r\n    ![Untitled (72)](https://user-images.githubusercontent.com/62014888/146319298-3312417b-7b23-43dd-a479-18cba8948d1b.png)\r\n\r\n    - 실행 상태 - 프로세스가 CPU를 보유하고, 기계어 명령을 실행하고 있는 상태\r\n    - 준비 상태 - 프로세스가 CPU만 보유하면 당장 명령을 실행할 수 있지만 CPU를 할당받지 못한 상태\r\n    - 봉쇄 상태 - CPU를 할당받더라도 당장 명령을 실행할 수 없는 상태 ex) 입출력 작업\r\n    - 시작 상태 - 프로세스가 시작되어 그 프로세스를 위한 각종 자료구조는 생성되었지만 아직 메모리 획득을 승인받지 못한 상태\r\n    - 완료 상태 - 프로세스가 종료되었으나 운영체제가 그 프로세스와 관련된 자료구조를 완전히 정리하지 못한 상태\r\n- 실행시킬 프로세스를 변경하기 위해 원래 수행 중이던 프로세스의 문맥을 저장하고 새로운 프로세스의 문맥을 세팅하는 과정을 문맥교환(context switch)이라고 한다.\r\n    - ex) 타이머 인터럽트, 입출력 요청 등\r\n- 준비 상태에 있는 프로세스들 중에서 CPU를 할당받을 프로세스를 선택한 후 실제로 CPU 제어권을 넘겨받는 과정을 CPU 디스패치(dispatch)라고 한다.\r\n- 인터럽트가 발생하면 CPU는 어떤 프로세스를 실행하고 있다가 인터럽트를 확인하고 그에 대응하는 루틴을 실행함.\r\n  루틴이 진행되는 동안 CPU에서 수행되던 프로세스의 상태는 커널모드 실행 상태로 바뀜.\r\n  인터럽트 처리루틴이 직전에 실행 중이던 프로세스와는 무관한 업무를 담고 있기는 하지만 인터럽트 처리를 편의상 직전 프로세스의 문맥에서 실행된 것으로 간주함.\r\n\r\n## 3. 프로세스 제어블록\r\n\r\n- 프로세스 제어블록(PCB)이란 운영체제가 시스템 내의 프로세스들을 관리하기 위해 프로세스마다 유지하는 정보들을 담는 커널 내의 자료구조를 뜻함.\r\n- PCB는 다음과 같은 요소들로 구성되어 있음.\r\n    - 프로세스 상태 - CPU를 할당해도 되는지 여부를 결정하기 위해 필요\r\n    - 프로그램 카운터값 - 다음에 수행할 명령의 위치\r\n    - CPU 레지스터값 - CPU 연산을 위해 현 시점에 레지스터에 어떤 값을 저장하고 있는지를 나타냄.\r\n    - CPU 스케줄링 정보 - 프로세스의 CPU 스케줄링을 위해 필요한 정보\r\n    - 메모리 관리 정보 - 메모리 할당을 위해 필요한 정보\r\n    - 자원 사용 정보 - 자원 사용 요금을 계산해 청구하는 등의 용도로 사용.\r\n    - 입출력 상태 정보 - 프로세스가 오픈한 파일 정보 등 프로세스의 입출력 관련 상태 정보\r\n\r\n## 4. 문맥교환\r\n\r\n- 문맥교환이란 하나의 사용자 프로세스로부터 다른 사용자 프로세스로 CPU 제어권이 이양되는 과정을 뜻함.\r\n    - 문맥교환 중에 원래 CPU를 보유하고 있던 프로세스는 프로그램 카운터값 등 프로세스의 문맥을 자신의 PCB에 저장하고, 새롭게 CPU를 할당받을 프로세스는 예전에 저장했던 자신의 문맥을 PCB로부터 실제 하드웨어로 복원시키는 과정을 거친다.\r\n    - 타이머 인터럽트, 입출력 요청, 다른 조건을 충족하지 못해 CPU를 회수당하고 봉쇄 상태가 되는 경우 등에서 발생.\r\n- 시스템 콜(입출력 요청 시스템 콜이 아님)이나 인터럽트의 경우에도 CPU의 실행 위치 등 프로세스의 문맥 중 일부를 PCB에 저장하게 되지만 이러한 과정을 문맥교환이라고 하지는 않음.\r\n    - 사용자모드에서 커널모드로 바뀌는 것일뿐, CPU를 점유하는 프로세스가 다른 사용자 프로세스로 변경되는 과정이 아니기 때문.\r\n    - 모드 변경에 비해 문맥교환에는 훨씬 많은 오버헤드가 뒤따르게 됨.\r\n- 타이머 인터럽트,  입출력 요청 시스템 콜을 하여 봉쇄 상태에 들어가는 경우에는 문맥교환이 일어나지만, 그 밖의 인터럽트나 시스템 콜 발생 시에는 문맥교환이 일어나지 않고 실행 모드만이 변경될 뿐임.\r\n    - 사용자모드에서 커널모드로 바뀌어 시스템 콜이나 인터럽트를 처리하고, 다시 동일한 프로세스의 사용자모드로 돌아와 이전에 수행하던 작업을 계속 수행할 뿐.\r\n- 타이머에 CPU 할당시간을 아주 작게 세팅해 프로세스 간 문맥교환이 빈번하게 발생하도록 하면 오버헤드가 상당히 커지고 CPU 할당시간을 너무 크게 설정하면 시분할 시스템의 의미가 퇴색하게 되므로 적절한 CPU 할당시간을 정하는 것이 중요함.\r\n\r\n\r\n\r\n## 5. 프로세스를 스케줄링하기 위한 큐\r\n\r\n- 운영체제는 준비 상태에 있는 프로세스들을 줄 세우기 위해 준비 큐(ready queue)를 두고 준비 큐의 제일 앞에 줄 서 있는 프로세스에 제일 먼저 CPU를 할당함.\r\n    - 준비 큐에 프로세스를 줄 세우는 방법은 CPU 스케줄링 방법에 따라 달라짐.\r\n- 특정 자원을 기다리는 프로세스들을 줄 세우기 위해 자원별로 장치 큐(device queue)를 둔다.\r\n    - 디스크에 입출력 서비스를 요청한 프로세스들은 디스크 입출력 큐(disk I/O queue)에 줄 서게 됨.\r\n    - 인터럽트 처리루틴에 의해 디스크 입출력이 완료된 프로세스는 입출력 큐에서 빠져나와 CPU를 기다리는 준비 큐에 줄 서게 됨.\r\n- 하드웨어 자원을 기다리는 프로세스 외에도 소프트웨어 자원을 기다리는 경우에도 큐가 필요함.\r\n    - 공유 데이터에 대한 접근 권한은 소프트웨어 자원으로 분류될 수 있음.\r\n    - 공유 데이터라는 일종의 소프트웨어 자원을 앞서 접근 중인 프로세스가 다 사용하고 반납할 때까지는 다른 프로세스가 CPU를 할당받았다 하더라도 접근하지 말고 기다려야 하는 것.\r\n    - 따라서 여러 프로세스가 공유 데이터에 접근하려고 할 경우 기다리는 큐에 줄 서게 하고, 다른 프로세스가 데이터를 반납할 경우 큐에 줄 서 있는 순서대로 데이터의 접근 권한을 주는 방법을 사용하게 됨.\r\n- 프로세스의 상태 관리는 커널의 주소 영역 중 데이터 영역의 다양한 큐를 두어 수행하게 됨.\r\n- 준비 큐와 장치 큐 외에 작업 큐(job queue)를 추가로 유지함.\r\n    - 작업 큐는 시스템 내의 모든 프로세스를 관리하기 위한 큐로, 프로세스의 상태와 무관하게 현재 시스템 내에 있는 모든 프로세스가 작업 큐에 속하게 됨.\r\n      그러므로 작업 큐에 있다고 해서 반드시 메모리를 가지고 있는 것이 아님.\r\n    - 작업 큐가 가장 넓은 개념이고 준비 큐와 장치 큐에 있는 프로세스들은 모두 작업 큐에 속해있음.\r\n- 큐헤더는 큐의 가장 앞부분을 말하고 큐는 각 프로세스의 PCB를 연결 리스트 형태로 관리하며 포인터를 사용해 순서를 정함.\r\n\r\n## 6. 스케줄러\r\n\r\n- 스케줄러(scheduler)란 어떤 프로세스에게 자원을 할당할지를 결정하는 운영체제 커널의 코드를 지칭함.\r\n- 장기 스케줄러(long term scheduler)\r\n    - 작업 스케줄러(job scheduler)\r\n    - 어떤 프로세스를 준비 큐에 진입시킬지를 결정하는 역할을 함.\r\n    - 프로세스에게 메모리를 할당하는 문제에 관여하게 됨.\r\n    - 즉, 시작 상태의 프로세스들 중 어떠한 프로세를 준비 큐에 삽입할 것인지 결정하는 역할을 하게 되는 것.\r\n- 단기 스케줄러(short term scheduler)\r\n    - CPU 스케줄러\r\n    - 준비 상태의 프로세스 중에서 어떤 프로세스를 다음번에 실행 상태로 만들 것인지 결정함.\r\n    - 즉, 준비 큐에 있는 여러 프로세스들 중 어떠한 프로세스에게 CPU를 할당할 것인가를 단기 스케줄러가 결정함.\r\n    - 시분할 시스템에서는 타이머 인터럽트가 발생하면 단기 스케줄러가 호출됨.\r\n- 단기 스케줄러는 밀리초 정도의 시간 단위로 매우 빈번하게 호출되기 때문에 속도가 충분히 빨라야하는 반면에 장기 스케줄러는 수십 초 내지 수 분 단위로 가끔 호출되기 때문에 상대적으로 속도가 느린 것이 허용됨.\r\n- 장기 스케줄러는 메모리에 동시에 올라가 있는 프로세스의 수를 조절하는 역할을 함.\r\n- 현대 시분할 시스템에서 사용되는 운영체제에는 일반적으로 장기 스케줄러를 두지 않는 경우가 대부분임.\r\n    - 과거에는 자원이 매우 빈약했지만 현대에는 그렇지도 않아 프로세스가 시작 상태가 되면 곧바로 프로세스에 메모리를 할당해 준비 큐에 넣어주게 됨.\r\n- 중기 스케줄러(medium term scheduler)\r\n    - 너무 많은 프로세스에게 메모리를 할당해 시스템의 성능이 저하되는 경우 이를 해결하기 위해 메모리에 적재된 프로세스의 수를 동적으로 조절하기 위해 추가된 스케줄러.\r\n    - 메모리에 올라와 있는 프로세스 중 일부를 선정해 이들로부터 메모리를 통째로 빼앗아 그 내용을 디스크의 스왑 영역에 저장해두는데 이를 스왑 아웃(swap out)이라고 부름.\r\n    - 스왑 아웃시킬 0순위 프로세스는 봉쇄 상태에 있는 프로세스.\r\n        - 봉쇄 상태인 프로세스를 모두 스왑 아웃시킨 후에도 부족한 경우, 타이머 인터럽트가 발생해 준비 큐로 이동한 프로세스를 추가적으로 스왑 아웃시킴.\r\n    - 장기 스케줄러와 마찬가지로 메모리에 올라와 있는 프로세스의 수를 조절하는 역할을 수행\r\n- 중기 스케줄러의 등장으로 인해 프로세스의 상태에는 중지(suspended, stopped) 상태가 추가됨.\r\n\r\n    ![Untitled (73)](https://user-images.githubusercontent.com/62014888/146319301-1f078752-a9be-49ed-881e-3428129e795e.png)\r\n    \r\n    - 중지 상태는 외부적인 이유로 프로세스의 수행이 정지된 상태를 나타내며 외부에서 재개시키지 않는 이상 다시 활성화될 수 없으므로 메모리 자원이 당장 필요하지 않다.\r\n      따라서 메모리를 통째로 빼앗기고 디스크로 스왑 아웃됨.\r\n    - 중지 상태는 중지준비 상태와 중지봉쇄 상태로 세분화할 수 있음.\r\n    - 준비 상태에 있던 프로세스가 스왑 아웃되면 중지준비(suspended ready) 상태가 됨.\r\n    - 봉쇄 상태에 있던 프로세스가 스왑 아웃되면 중지봉쇄(suspended block) 상태가 됨.\r\n    - 중지봉쇄 상태이던 프로세스가 봉쇄되었던 조건을 만족하게 되면 중지준비 상태로 바뀜.\r\n\r\n\r\n## 7. 프로세스의 생성\r\n\r\n- 운영체제가 프로세스를 전부 생성한다고 생각할 수 있지만 사실은 그렇지 않음.\r\n- 최초의 프로세스는 운영체제가 직접 생성하지만 그다음부터는 이미 존재하는 프로세스가 다른 프로세스를 복제 생성하게 됨.\r\n    - 프로세스를 생성한 프로세스를 부모 프로세스라고 하고, 새롭게 생성된 프로세스를 자식 프로세스라고 함.\r\n- 프로세스의 세계는 자식이 먼저 죽고, 이에 대한 처리는 자식을 생성했던 부모 프로세스가 담당하는 방식으로 진행됨.\r\n- 생성된 프로세스가 작업을 수행하기 위해서는 자원이 필요한데 자원을 획득하는 방법은 운영체제 및 자원의 종류에 따라 상이함.\r\n    - 운영체제로부터 직접 자원을 할당\r\n    - 부모 프로세스와 자원을 공유해서 사용\r\n- 프로세스가 수행되는 모델도 부모와 자식이 공존하며 수행되는 모델과 자식이 종료될 때까지 부모가 기다리는 모델이 있음.\r\n    - 부모와 자식이 공존하며 수행되는 모델에서는 자식과 부모가 같이 CPU를 획득하기 위해 경쟁하는 관계가 됨.\r\n    - 부모가 자식의 종료를 기다리는 모델에서는 자식 프로세스가 종료될 때까지 부모 프로세스는 아무 일도 하지 않고 봉쇄 상태에 머물러 있다가, 자식 프로세스가 종료되면 그때 부모 프로세스가 준비 상태가 되어 다시 CPU를 얻을 권한이 생김.\r\n        - ex) 유닉스 명령어 입력창에 커맨드를 입력하는 경우\r\n- 프로세스가 생성되면 자신만의 독자적인 주소 공간을 갖게 됨.\r\n    - 자식 프로세스는 부모 프로세스와는 별도의 주소 공간을 가지게 됨.\r\n- 유닉스로 살펴보는 프로세스의 생성 절차\r\n    - fork() 시스템 콜을 통해 새로운 프로세스를 생성함.\r\n        - 자식 프로세스를 생성할 때 부모 프로세스의 내용을 그대로 복제 생성.\r\n          즉, 프로세스 ID를 제외한 모든 정보(운영체제 커널 내 정보, 주소 공간의 정보)를 그대로 복사함.\r\n        - 주소 공간은 다르지만 주소 공간 내에는 동일한 내용을 가지게 됨.\r\n    - fork()를 통해 생성된 자식 프로세스는 exec() 시스템 콜을 통해 새로운 프로그램으로 주소 공간을 덮어씌울 수 있음.\r\n- 프로세스의 종료는 두 가지로 나뉨.\r\n    1. 프로세스가 마지막 명령을 수행한 후 운영체제에 이를 알려주는 자발적 종료.\r\n        - 프로세스가 명령을 모두 수행한 후, 프로그램이 마쳐지는 코드 부분에 exit()라는 시스템 콜을 넣어주도록 되어 있음.\r\n    2. 부모 프로세스가 자식 프로세스의 수행을 강제로 종료시키는 비자발적 종료.\r\n        - 자식 프로세스가 할당 자원의 한계치를 넘어서는 많은 양의 자원을 요구할 때,\r\n          자식 프로세스에게 할당된 작업이 더 이상 필요하지 않을 때,\r\n          부모 프로세스가 종료되는 경우 등일 때 abort()라는 함수를 통해 이루어지게 됨.\r\n- 종료되는 프로세스의 자식 프로세스를 계속 실행시키기 위해서 종료되지 않을 다른 프로세스의 양자로 자식 프로세스를 보내는 방법도 있음.\r\n- 운영체제는 자식 프로세스의 생성을 위해 fork() 시스템 콜을 제공함.\r\n    - fork() 시스템 콜을 하게 되면 CPU 제어권이 커널로 넘어가게 되고, fork() 함수를 호출한 프로세스와 똑같은 프로세스가 하나 생성됨.\r\n    - fork()를 통해 생성된 프로세스는 부모 프로세스와 모든 문맥을 동일하게 가지고 있음.\r\n    - 단, 프로세스를 관리하기 위해서 사용하는 프로세스 식별자는 다른 식별자를 가지게 됨.\r\n    - fork()로 복제한 프로세스는 자기가 복제본이 아닌 원본이며, 자기를 복제해서 복제본이 생성되었다는 그런 기억을 갖게 됨.\r\n    - 단, fork() 함수의 결괏값으로 원본에게는 양수를 주고 복제본에게는 0을 주어서 조건문을 사용해 다른 작업을 하도록 프로그램을 작성할 수 있음.\r\n- 유닉스에서는 프로세스의 주소 공간에 새로운 프로그램을 덮어씌우는 exec() 시스템 콜을 지원함.\r\n    - exec()는 지금까지 수행했던 상태를 잊어버리고 그 주소 공간을 완전히 새로운 프로그램으로 덮어씌운 후 새로운 프로그램의 첫 부분부터 다시 실행을 시작하도록 하는 시스템 콜.\r\n- fork(), exec()는 특권명령에 해당하므로 시스템 콜을 통해서만 그 수행이 가능함.\r\n- 자식 프로세스가 종료되기를 기다리며 부모 프로세스가 봉쇄 상태에 머무르도록 할 때 사용되는 wait() 시스템 콜도 존재함.\r\n    - fork() 후에 wait()를 호출하면 커널은 자식 프로세스가 종료될 때까지 부모 프로세스를 봉쇄 상태에 머무르게 하고, 자식 프로세스가 종료되면 부모를 준비 상태로 변경시켜 작업을 재개할 수 있도록 함.\r\n    - 이를 통해 두 프로세스 간의 동기화(synchronization)가 가능해짐.\r\n    - 일반적인 봉쇄 상태에서처럼 자원을 기다리며 줄 서 있는 것이 아니라 자식 프로세스가 종료되기를 기다리며 수면 상태에 머무르게 되는 것으로, 자식 프로세스가 종료되는 순간 준비 큐에 재진입한다.\r\n\r\n## 8. 프로세스 간의 협력\r\n\r\n- 프로세스는 각자 자신만의 독립적인 주소 공간을 가지고 수행되며 다른 프로세스의 주소 공간을 참조하는 것은 허용되지 않음.\r\n- 경우에 따라서는 독립적인 프로세스들이 협력할 때 업무의 효율성이 증진될 수 있기 때문에 운영체제는 프로세스 간의 협력 메커니즘을 제공해 하나의 프로세스가 다른 프로세스의 수행에 영향을 미칠 수 있게 함.\r\n- 대표적인 메커니즘으로 IPC(Inter-Process Communication: 인터프로세스 커뮤니케이션)가 있음.\r\n    - IPC란 하나의 컴퓨터 안에서 실행 중인 서로 다른 프로세스 간에 발생하는 통신을 말함.\r\n    - 이러한 통신에는 의사소통 기능과 함께 동기화를 보장해주어야 함.\r\n        - 공유 데이터를 서로 다른 두 프로세스가 사용할 수 있다고 하면 데이터의 불일치 문제가 발생할 수 있기 때문.\r\n        - 하나의 프로세스가 공유 데이터의 값을 변경하는 동안 다른 프로세스는 접근할 수 없게 해야 함.\r\n    - 즉, IPC는 프로세스들 간의 통신과 동기화를 이루기 위한 메커니즘을 뜻함.\r\n    - IPC에는 대표적으로 두 가지 방법이 있는데 공유 데이터를 사용하는가, 그렇지 않는가에 따라 나뉘어진다.\r\n    - 메시지 전달 방식(message passing)\r\n        - 프로세스 간에 공유 데이터를 일체 사용하지 않고 메시지를 주고받으면서 통신하는 방식.\r\n        - 메시지 통신을 하는 시스템은 커널에 의해 send(message)와 receive(message)라는 두 가지 연산을 제공받게 됨.\r\n        - 프로세스끼리 메시지를 직접 주고받는다면 원치 않는 메시지로 인해 악영향을 미칠 수 있으므로 특권명령으로 규정해 커널만 가능하도록 하고 있음.\r\n        - 통신하기를 원하는 두 프로세스는 커뮤니케이션 링크를 생성한 후 send()와 receive()를 이용해서 메시지를 주고받게 됨.\r\n        - 메시지 전달 방식은 메세지 전송 대상이 다른 프로세스인지 아니면 메일박스라는 저장공간인지에 따라 다시 직접통신(direct communication)과 간접통신(indirect communication)으로 나뉨.\r\n          (인터페이스에 대한 차이일 뿐 내부 구현은 동일한 방식으로 이루어짐)\r\n        - 직접통신\r\n            - 통신하려는 프로세스의 이름을 명시적으로 표시함.\r\n            - 커뮤니케이션 링크는 자동적으로 생성되고 하나의 링크가 한 쌍의 프로세스에게 할당됨.\r\n            - 링크는 단방향일수 있으나 대부분은 양방향성임.\r\n        - 간접통신\r\n            - 메시지를 메일박스 또는 포트로부터 전달받음.\r\n            - 각 메일박스에는 고유의 ID가 있으며 메일박스를 공유하는 프로세스들만 서로 통신을 할 수 있음.\r\n            - 커뮤니케이션 링크는 프로세스 간 메일박스를 공유하는 경우에만 생성되고 하나의 링크가 여러 프로세스들에게 할당될 수 있으며 각 프로세스의 쌍은 여러 링크를 공유할 수 있음.\r\n            - 단방향성 또는 양방향성일 수 있음.\r\n            - 새로운 메일박스를 생성하는 연산, 메일박스를 통한 메시지의 send(), receive(), 메일박스를 삭제하는 연상 등이 사용될 수 있음.\r\n            - 만약 P1, P2, P3가 메일박스 A를 공유하는 경우 P1이 메시지를 보냈다면 P2, P3 중 어느 프로세스가 메시지를 받게 될까?\r\n                - 2개의 프로세스에게만 링크를 할당하는 방법이 사용되거나 링크에 대한 receive() 연산을 매 시점 하나의 프로세스만 수행할 수 있도록 하거나 시스템이 메시지 수신자를 임의로 결정해 누가 메시지를 받았는지 송신자에게 통신해주는 방식이 사용될 수 있다.\r\n    - 공유메모리 방식(shared memory)\r\n        - 프로세스들이 주소 공간의 일부를 공유하는 방식.\r\n        - 서로 다른 프로세스들이 그들의 주소 공간 중 일부를 공유할 수 있도록 함.\r\n        - 공유메모리 영역은 여러 프로세스가 읽고 쓰는 것이 가능함.\r\n        - 공유하다보니 데이터 일관성 문제가 유발될 수 있지만 커널이 이를 책임지지 않기에 프로세스들끼리 직접 동기화 문제를 책임져야 한다.","excerpt":"'운영체제와 정보기술의 원리' 스터디를 진행하며 정리한 내용이다. 1. 프로세스의 개념 프로세스(process)란 실행 중인 프로그램(program in execution)을 뜻한다. 디스크에 실행파일 형태로 존재하던 프로그램이 메모리에 올라가서 실…","fields":{"slug":"/os-it-principle-ch5/"},"frontmatter":{"date":"Oct 14, 2021","title":"[운영체제와 정보기술의 원리] 5. 프로세스 관리","tags":["os","book","os-it-principle"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n'운영체제와 정보기술의 원리' 스터디를 진행하며 정리한 내용이다.\r\n\r\n---\r\n\r\n## 1. 프로그램의 구조와 인터럽트\r\n\r\n- 컴퓨터 프로그램은 어떠한 프로그래밍 언어로 작성되었든 그 내부 구조는 함수들로 구성된다.\r\n- 프로그램의 주소 영역은 크게 코드(code), 데이터(data), 스택(stack) 영역으로 구분됨.\r\n    - 코드 영역 - 우리가 작성한 프로그램 함수들의 코드가 CPU에서 수행할 수 있는 기계어 명령 형태로 변환되어 저장되는 부분.\r\n    - 데이터 영역 - 전역 변수 등 프로그램이 사용하는 데이터를 저장하는 부분.\r\n    - 스택 영역 - 함수가 호출될 때 호출된 함수의 수행을 마치고 복귀할 주소 및 데이터를 임시로 저장하는 데에 사용되는 공간.\r\n- 하나의 함수가 수행되는 중에 다른 함수를 호출하고, 호출된 함수가 끝나면 다시 원래 호출했던 함수의 위치로 돌아가 프로그램을 계속 실행하게 됨.\r\n    - 인터럽트 동작 원리와 비슷함.\r\n\r\n\r\n## 2. 컴퓨터 시스템의 작동 개요\r\n\r\n- CPU는 빠른 속도로 처리하는 계산 능력은 가지고 있지만, 어떠한 작업을 수행해야 하는지 스스로 결정하는 능력은 갖추고 있지 못함.\r\n\r\n![Untitled (70)](https://user-images.githubusercontent.com/62014888/146313707-0e86811a-076c-4cd2-af7e-e2aa6ee3ec8b.png)\r\n\r\n- CPU가 수행해야 할 메모리 주소를 담고 있는 레지스터를 프로그램 카운터(Program Counter: PC)라고 부름.\r\n  즉 CPU는 매번 프로그램 카운터가 가리키는 메모리 위치의 명령을 처리하게 됨.\r\n    - 일반적으로 주소 이동이 없는 이상 프로그램 카운터는 항상 바로 다음 명령을 가리키게 되어 코드의 순차적인 수행이 이루어짐.\r\n- 메모리에는 사용자 프로그램들과 운영체제가 같이 올라가 수행됨.\r\n- 프로그램 카운터가 메모리 주소 중 운영체제가 존재하는 부분을 가리키고 있다면 현재 운영체제의 코드를 수행 중이며, 이 경우 CPU가 커널모드에서 수행 중이라는 뜻.\r\n- 프로그램 카운터가 사용자 프로그램이 존재하는 메모리 위치를 가리키고 있다면 그 메모리 위치에 올라가 있는 사용자 프로그램이 수행 중이며, 이 경우 사용자모드에서 CPU가 수행되고 있다는 뜻.\r\n- 일반명령\r\n    - 메모리에서 자료를 읽어와 CPU에서 계산하고 결과를 메모리에 쓰는 일련의 명령들을 말하는데, 이러한 일반명령은 모든 프로그램이 수행할 수 있음.\r\n- 특권명령\r\n    - 특권명령은 보안이 필요한 명령으로 입출력 장치, 타이머 등 각종 장치에 접근하는 명령임.\r\n    - 특권명령은 항상 운영체제만이 수행할 수 있도록 제한하고 있음.\r\n- 두 명령어의 실행가능성을 체크하기 위해 CPU 내에 모드비트를 둠.\r\n- 사용자 프로그램이 스스로 특권 명령을 수행할 수 없으므로 운영체제에게 시스템 콜을 통해 특권명령의 대행을 요청하게 됨.\r\n- 주변장치는 CPU의 도움이 필요한 경우 인터럽트를 사용해 서비스를 요청하는데 이를 위해 주변장치는 인터럽트 라인을 세팅함.\r\n  CPU는 매번 명령을 수행한 직후 인터럽트 라인을 체크해 서비스 요청이 들어왔는지 확인함.\r\n\r\n## 3. 프로그램의 실행\r\n\r\n- '프로그램이 실행되고 있다'는 것은 컴퓨터 시스템 차원에서 볼 때 크게 두 가지 중요한 의미를 가짐.\r\n    1. 디스크에 존재하던 실행파일이 메모리에 적재된다는 의미\r\n    2. 프로그램이 CPU를 할당받고 명령을 수행하고 있는 상태라는 의미\r\n- 실행파일이 메모리에 적재될 때, 프로그램의 주소 공간 중 당장 CPU의 수행에 필요한 부분은 메모리에 올려놓고 그렇지 않은 부분은 디스크 중 메모리 연장 공간으로 사용되는 스왑 영역에 내려놓음.\r\n- 각각의 프로그램마다 주소 공간을 별도로 가지며, 이를 가상메모리(virtual memory) 또는 논리적 메모리(logical memory)라고 부른다.\r\n- 운영체제도 하나의 프로그램이므로 운영체제 커널 역시 코드, 데이터, 스택의 주소 공간 구성을 가지고 있음.\r\n\r\n  ![Untitled (71)](https://user-images.githubusercontent.com/62014888/146313710-cb578ec8-8511-4625-8589-08ef87516473.png)\r\n\r\n    - 커널의 코드는 CPU, 메모리 등의 자원을 관리하기 위한 부분과 사용자에게 편리한 인터페이스를 제공하기 위한 부분이 주를 이룸.\r\n      시스템 콜 및 인터럽트를 처리하기 위한 부분도 포함함.\r\n    - 커널의 데이터 영역에는 각종 자원을 관리하기 위한 자료구조가 저장됨.\r\n        - CPU나 메모리와 같은 하드웨어 자원을 관리하기 위한 자료구조 + 프로세스 상태, CPU 사용 정보, 메모리 사용 정보 등을 유지하기 위한 PCB\r\n    - 커널의 스택 영역은 일반 스택 영역과 마찬가지로 함수호출 시의 복귀 주소를 저장하기 위한 용도로 사용된다.\r\n        - 다만, 현재 수행 중인 프로세스마다 별도의 스택을 두어 관리함.\r\n        - 프로세스가 시스템 콜을 호출하고 시스템 콜 내부에서 다른 함수를 호출하는 경우 그 복귀 주소는 커널 내의 주소가 되어 사용자 프로그램의 스택과는 별도의 저장공간이 필요하기 때문.\r\n        - 또한 커널은 일종의 공유 코드로서 모든 사용자 프로그램이 시스템 콜을 통해 커널의 함수를 접근할 수 있으므로, 일관성을 유지하기 위해서 현재 수행 중인 프로세스마다 별도의 스택을 두어 관리함.\r\n        - 프로그램 내의 함수호출 시 해당 프로그램의 스택에 복귀 주소를 저장하지만, 시스템 콜이나 인터럽트 발생으로 CPU의 수행 주체가 운영체제로 바뀌는 순간에는 직전에 수행되던 프로그램의 복귀 정보를 스택이 아닌 PCB에 저장한다.\r\n\r\n\r\n## 4. 사용자 프로그램이 사용하는 함수\r\n\r\n- 사용자 정의함수\r\n    - 프로그래머 본인이 직접 작성한 함수.\r\n- 라이브러리 함수\r\n    - 프로그래머 본인이 직접 작성하지는 않았지만 이미 누군가 작성해놓은 함수를 호출만 하여 사용하는 경우를 뜻함.\r\n    - 사용자 정의함수와 라이브러리 함수 모두 프로그램의 코드 영역에 기계어 명령 형태로 존재한다.\r\n      따라서 프로그램이 실행될 때에 해당 프로세스의 주소 공간에 포함되며, 또한 함수호출 시에도 자신의 주소 공간에 있는 스택을 사용하게 된다.\r\n- 커널 함수\r\n    - 운영체제 커널의 코드에 정의된 함수.\r\n    - 사용자 프로그램이 운영체제의 서비스를 요청하기 위해 호출하는 시스템 콜 함수와, 각종 하드웨어 및 소프트웨어가 CPU의 서비스를 요청하기 위해 발생시키는 인터럽트 처리함수가 있다.\r\n    - 운영체제 내에 있는 함수를 사용자 프로그램이 호출해서 사용하는 것.\r\n    - 시스템 콜은 운영체제라는 별개의 프로그램에 CPU를 넘겨서 실행하는 것으로 넘기기 위해서 CPU의 인터럽트 라인을 세팅하는 방법을 사용함.\r\n\r\n## 5. 인터럽트\r\n\r\n- 원칙적으로는 인터럽트 처리 중에 또 다른 인터럽트가 발생하는 것을 허용하지 않는다.\r\n    - 그 이유는 인터럽트 처리 중에 다른 인터럽트를 처리하면 데이터의 일관성이 유지되지 않는 문제가 발생할 수 있기 때문.\r\n- 단, 인터럽트마다 중요도가 다르기 때문에 상대적으로 낮은 중요도를 가진 인터럽트를 처리하는 도중에 중요도가 더 높은 인터럽트가 발생하는 것을 허락할 필요는 있음.\r\n    - 현재 처리 중이던 인터럽트 코드의 수행 지점을 저장하고 우선순위가 높은 인터럽트를 처리하게 됨.\r\n    - 처리가 끝나면 저장된 주소로 복귀하고 마저 수행함.\r\n\r\n## 6. 시스템 콜\r\n\r\n- 시스템 콜은 자신의 프로그램이 아닌, 커널이라는 다른 프로그램의 주소 공간에 존재하는 함수를 호출하는 것.\r\n- 주소 공간 자체가 다른 곳으로 이동해야 하므로 일반 함수호출과는 상이한 방법을 사용하는데 그 방법은 프로그램 자신이 인터럽트 라인에 인터럽트를 세팅하는 명령을 통해 이루어짐.\r\n- 디스크 파일 입출력이 이루어지는 과정을 통해 시스템 콜 사용의 예를 살펴보자.\r\n    - 사용자 프로그램이 디스크의 파일을 읽어와야할 경우 시스템 콜로 커널의 함수를 호출하게 됨.\r\n    - CPU의 제어권을 운영체제에 이양하게 되는데, 이는 인터럽트 라인을 세팅하는 명령을 통해 이루어짐.\r\n    - 인터럽트 라인이 세팅되면 CPU는 다음 명령을 수행하기 전에 인터럽트가 발생했는지 점검하고 인터럽트가 발생된 것을 인지하면 현재 수행 중인 프로그램을 잠시 멈추고 CPU 제어권을 운영체제로 이양시킴.\r\n    - 입출력 요청 인터럽트를 인지하게 되면 해당 서비스루틴으로 이동해 입출력 작업을 수행하게 되는데 이때 CPU는 디스크 컨트롤러에게 파일을 읽어오라는 명령을 하게 됨.\r\n    - 입출력 작업은 시간이 많이 소요가 되므로 CPU의 제어권은 다른 프로세스에게 이양함.\r\n    - 입출력 작업이 완료되면 디스크 컨트롤러가 CPU에게 인터럽트를 발생시켜 작업이 완료되었음을 알리게 됨.\r\n    - CPU는 현재 프로세스 수행을 멈추고 인터럽트 처리루틴으로 제어권이 넘어가고 이때 발생한 인터럽트는 하드웨어 인터럽트에 해당함.\r\n    - 디스크로부터 로컬버퍼로 읽어온 내용을 컴퓨터 내의 메모리로 복사한 후 디스크 입출력을 요청했던 프로세스에게 다시 CPU를 획득할 수 있는 권한을 줌(blocked state 해제)\r\n    - 해당 프로세스는 CPU를 기다리는 큐에 삽입되고 CPU 제어권은 인터럽트를 당한 프로세스로넘어감.\r\n- 중간에 CPU를 빼앗기는 경우는 크게 두 가지가 있음.\r\n    1. 타이머에 의해 인터럽트가 발생하는 경우\r\n    2. 입출력 요청을 위해 시스템 콜을 하는 경우\r\n\r\n## 7. 프로세스의 두 가지 실행 상태\r\n\r\n- 하나의 프로세스가 시작되어 수행을 완료하기까지 프로세스 자신의 주소 공간에 있는 코드만 실행되는 것이 아니라 커널의 주소 공간에 있는 코드도 실행됨.\r\n- 자신의 주소 공간에 정의된 코드를 실행하는 것을 사용자모드에서 실행 상태(user mode running)라 하고, 커널의 시스템 콜 함수를 실행하는 것을 커널모드에서의 실행 상태(kernel mode running)라 함.\r\n    - 시스템 콜을 통해 실행되는 것이 프로세스 코드가 아닌 운영체제 커널의 코드라 해도 시스템 콜이 수행되는 동안 커널이 실행 상태(running state)에 있다고 하지 않고 프로세스가 실행 상태에 있다고 말한다.\r\n    - 단, 구분지어서 '프로세스 A가 커널모드에서 실행 중'이라고 이야기함.\r\n- 정리하자면 프로그램은 다양한 함수호출을 하며 실행되는데, 이를 사용자모드, 커널모드의 실행 상태로 구분 지을 수 있음.\r\n  시스템 콜을 하는 경우 커널모드로 진입해 커널의 주소 공간에 정의된 함수를 실행하게 된다.\r\n  시스템 콜이 끝나면 다시 사용자모드로 복귀해 명령들을 계속 실행함.\r\n  프로그램 실행이 끝날 때는 커널모드로 진입해 프로그램을 종료함.","excerpt":"'운영체제와 정보기술의 원리' 스터디를 진행하며 정리한 내용이다. 1. 프로그램의 구조와 인터럽트 컴퓨터 프로그램은 어떠한 프로그래밍 언어로 작성되었든 그 내부 구조는 함수들로 구성된다. 프로그램의 주소 영역은 크게 코드(code), 데이터(data…","fields":{"slug":"/os-it-principle-ch4/"},"frontmatter":{"date":"Oct 13, 2021","title":"[운영체제와 정보기술의 원리] 4. 프로그램의 구조와 실행","tags":["os","book","os-it-principle"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n'운영체제와 정보기술의 원리' 스터디를 진행하며 정리한 내용이다.\r\n\r\n---\r\n\r\n## 1. 컴퓨터 시스템의 구조\r\n\r\n- 컴퓨터 내부장치인 CPU, 메모리와 컴퓨터 외부장치인 디스크, 키보드, 마우스, 모니터, 네트워크 장치 등으로 구성된다.\r\n- 컴퓨터는 외부장치에서 내부장치로 데이터를 읽어와 각종 연산을 수행한 후, 그 결과를 외부장치로 다시 내보내는 방식으로 업무를 처리함.\r\n    - 컴퓨터 내부로 데이터가 들어오는 것을 입력(input), 컴퓨터 외부장치로 데이터가 나가는 것을 출력(output)이라고 함.\r\n    - 컴퓨터 외부장치를 입출력 장치라고 부른다.\r\n- 메모리 및 입출력장치 등의 각 하드웨어 장치에는 컨트롤러라는 것이 붙어 있음.\r\n- 운영체제 중 항상 메모리에 올라가 있는 부분은 전체 운영체제 중 핵심적인 부분에 한정되며, 이 부분을 커널(kernel)이라고 부른다.\r\n\r\n## 2. CPU 연산과 I/O 연산\r\n\r\n- 입출력 장치들의 I/O 연산은 입출력 컨트롤러가 담당하고, 컴퓨터 내에서 수행되는 연산은 메인 CPU가 담당한다. 이때 입출력 장치와 메인 CPU는 동시 수행이 가능하다.\r\n- 각 장치마다 장치 컨트롤러는 장치로부터 들어오고 나가는 데이터를 임시로 저장하기 위한 작은 메모리를 가지고 있다.\r\n  이를 로컬버퍼(local buffer)라고 부른다.\r\n    - 디스크나 키보드 등에서 데이터를 읽어오는 경우, 우선 로컬버퍼에 데이터가 임시로 저장된 후 메모리에 전달됨.\r\n    - 로컬버퍼로 읽어오는 일은 컨트롤러가 담당한다.\r\n- 로컬버퍼로 읽어오는 작업이 끝났는지를 메인 CPU가 지속적으로 체크하는 것이 아니라 장치에 있는 컨트롤러가 인터럽트를 발생시켜 CPU에 보고하게 된다.\r\n    - CPU 옆에는 인터럽트 라인(interrupt line)이 있어서, 자신의 작업을 하던 중간에 인터럽트 라인에 신호가 들어오면 하던 일을 멈추고 인터럽트와 관련된 일을 먼저 처리함.\r\n    - CPU는 명령 하나를 수행할 때마다 인터럽트가 발생했는지 확인한다.\r\n      발생했으면 다음 명령을 수행하기 전에 인터럽트를 처리하게 되고, 그렇지 않으면 다음 명령을 계속 수행하게 되는 것.\r\n- 인터럽트는 키보드 입력 혹은 요청된 디스크 입출력 작업의 완료 등 CPU에 알려줄 필요가 있는 이벤트가 일어난 경우 컨트롤러가 발생시키는 것.\r\n\r\n## 3. 인터럽트의 일반적 기능\r\n\r\n- 운영체제 커널에는 인터럽트가 들어왔을 때 해야 할 일이 미리 다 프로그래밍되어 그 코드가 보관돼 있다.\r\n- 운영체제 커널 내에 있는 인터럽트 처리루틴은 다양한 인터럽트에 대해 각각 처리해야 할 업무들을 정의하고 있음.\r\n- 하드웨어 인터럽트와 소프트웨어 인터럽트가 있음.\r\n  인터럽트 라인에 신호를 보내서 인터럽트가 발생했음을 알려주는 방식은 둘 다 동일.\r\n    - 하드웨어 인터럽트는 컨트롤러 등 하드웨어 장치가 CPU의 인터럽트 라인을 세팅함.\r\n    - 소프트웨어 인터럽트는 소프트웨어가 그 일을 수행함.\r\n- 운영체제는 인터럽트 벡터(interrupt vector)를 가지고 있음.\r\n    - 인터럽트 벡터란 인터럽트 종류마다 번호를 정해서, 번호에 따라 처리해야 할 코드가 위치한 부분을 가리키고 있는 자료구조를 말함.\r\n    - 실제 처리해야 할 코드는 인터럽트 처리루틴(interrupt service routine) 또는 인터럽트 핸들러(interrupt handler)라고 불리는 다른 곳에 정의 됨.\r\n- 인터럽트 처리를 완료하고 나면 원래 수행하던 작업으로 돌아가 일을 계속해서 수행하게 되는데 운영체제는 이 돌아갈 위치에 대한 정보를 저장하기 위한 장소를 별도로 가지고 있다.\r\n- 통상적으로 인터럽트라고 하면 하드웨어 인터럽트를 의미하고, 소프트웨어 인터럽트는 트랩(trap)이라는 용어로 주로 불림.\r\n- 소프트웨어 인터럽트의 예로는 예외상황(exception)과 시스템 콜(system call)이 있음.\r\n    - 예외상황은 사용자 프로그램이 0으로 나누는 연산 등 비정상적인 작업을 시도하거나, 자신의 메모리 영역 바깥에 접근하려는 시도 등 권한이 없는 작업을 시도할 때 이에 대한 처리를 위해 발생시키는 인터럽트를 말함.\r\n    - 시스템 콜은 사용자 프로그램이 운영체제 내부에 정의된 코드를 실행하고 싶을 때 운영체제에 서비스를 요청하는 방법이라고 볼 수 있음.\r\n    - 둘 다 사용자 프로세스로부터 CPU의 제어권이 운영체제에 이양되어 처리된다.\r\n\r\n\r\n## 4. 인터럽트 핸들링\r\n\r\n- 인터럽트 핸들링이란 인터럽트가 발생한 경우에 처리해야 할 일의 절차를 의미한다.\r\n- 프로그램이 실행되고 있을 때 인터럽트가 발생하면 프로그램의 현재 상태를 먼저 저장한다.\r\n    - 현재 상태란 현재 CPU에서 실행 중인 명령의 메모리 주소를 포함해 몇 가지 부가적인 정보들.\r\n    - 원래 CPU에서 명령이 실행될 때 임시기억장치인 레지스터(register)에 데이터를 읽거나 쓰면서 작업하는데, 인터럽트가 발생하면 기존 레지스터값들이 지워지게 되므로 이러한 상태를 저장해두어야 하는 것.\r\n- 운영체제는 현재 시스템 내에서 실행되는 프로그램들을 관리하기 위해 프로세스 제어블록(Process Control Block: PCB)이라는 자료구조를 둔다.\r\n    - PCB는 각각의 프로그램마다 하나씩 존재하며 해당 프로그램의 어느 부분이 실행 중이었는지를 저장하고 있음.\r\n      구체적으로는 실행 중이던 코드의 메모리 주소, 레지스터값, 하드웨어 상태 등이 저장.\r\n    - 인터럽트가 발생하면 프로그램의 실행 상태를 PCB에 저장한 후 CPU의 제어권이 인터럽트 처리루틴으로 넘어가게 되며, 인터럽트 처리가 끝나면 저장된 상태를 PCB로부터 CPU 상에 복원해 인터럽트 당하기 직전의 위치부터 실행이 이어지게 되는 것\r\n- 오늘날의 컴퓨터에서 운영체제는 인터럽트가 발생할 때에만 실행된다.\r\n    - 운영체제가 직접 CPU를 점유하는 경우는 인터럽트에 의하지 않고는 발생하지 않는다.\r\n    - 그럼에도 불구하고 운영체제는 자원을 체계적이고 효율적으로 관리할 수 있다.\r\n\r\n## 5. 입출력 구조\r\n\r\n- 입출력(I/O)이란 컴퓨터 시스템이 컴퓨터 외부의 입출력 장치들과 데이터를 주고받는 것을 말한다.\r\n- 동기식 입출력(synchronous I/O)\r\n    - 어떤 프로그램이 입출력 요청을 했을 때 입출력 작업이 완료된 후에야 그 프로그램이 후속 작업을 수행할 수 있는 방식을 말한다.\r\n    - 동기식 입출력에서 CPU는 입출력 연산이 끝날 때까지 인터럽트를 기다리며 자원을 낭비하게 된다.\r\n    - 따라서 일반적으로 프로그램이 입출력을 수행 중인 경우 CPU를 다른 프로그램에게 이양해 CPU가 계속 쉬지 않고 일할 수 있도록 관리한다.\r\n    - 운영체제는 프로그램을 몇 가지 상태로 나누고 입출력 중인 프로그램의 경우 봉쇄 상태(blocked state)로 전환시킨다.\r\n      봉쇄 상태의 프로그램에게는 CPU를 할당하지 않고, CPU 할당 시 곧바로 명령을 수행할 수 있는 프로그램에만 CPU를 할당한다.\r\n    - 다수의 입출력 연산이 동시에 요청되거나 처리될 수 있다.\r\n        - 입출력 요청의 동기화를 위해 장치별로 큐(queue)를 두어 요청한 순서대로 처리할 수 있도록 한다.\r\n        - 요청들을 모으고 처리 순서를 바꾸어 입출력의 효율성을 높일 수도 있는데, 이러한 경우 동기화를 보장하기 위한 별도의 방안이 마련되어야 한다.\r\n    - 장치마다 큐헤더가 존재하고 컨트롤러는 이 큐 순서에 따라 매 시점 하나씩 자신에게 주어진 입출력 작업을 처리하게 된다.\r\n        - CPU의 수행 속도에 비해 컨트롤러의 수행 속도나 장치 자체의 작업 수행 능력은 매우 떨어진다.\r\n        - 입출력이 완료될 때까지 입출력과 관련 없는 프로그램을 수행하도록 하고, 요청된 입출력 연산이 완료되면 CPU에게 입출력이 완료되었음을 알려주는 방식으로 진행.\r\n- 비동기식 입출력\r\n    - 입출력 연산을 요청한 후에 연산이 끝나기를 기다리는 것이 아니라 CPU의 제어권을 입출력 연산을 호출한 그 프로그램에게 곧바로 다시 부여하는 방식.\r\n    - 비동기식 입출력은 데이터와 관련 없이 수행할 수 있는 작업을 먼저 수행하고, 읽어오는 데이터가 반드시 있어야 수행할 수 있는 일들은 입출력이 완료된 후에 수행함.\r\n    - 쓰기 작업이 완료되기 전에도 다음 명령을 수행할 수 있으므로 비동기식 입출력이 사용될 수 있음\r\n\r\n![Untitled (68)](https://user-images.githubusercontent.com/62014888/146133407-f5ee241d-0839-4e4f-99ee-59ab65031863.png)\r\n\r\n- 사용자가 I/O 요청을 하면 동기식 입출력에서는 먼저 운영체제의 커널로 CPU의 제어권이 넘어와서 입출력 처리와 관련된 커널의 코드가 수행됨.\r\n  이때 입출력을 호출한 프로세스의 상태를 봉쇄 상태로 바꾸어 입출력이 완료될 때까지 CPU를 할당받지 못하도록 함.\r\n  입출력이 완료되면 I/O 컨트롤러가 CPU에게 인터럽트를 발생시켜 입출력이 완료되었음을 알려줌.\r\n  프로세스의 봉쇄 상태를 해제시켜 CPU를 할당받을 수 있는 권한이 다시 생기게 됨\r\n- 비동기식 입출력에서는 CPU의 제어권이 입출력을 요청한 프로세스에게 곧바로 다시 주어지며, 입출력 연산이 완료되는 것과 무관하게 처리 가능한 작업부터 처리함.\r\n  비동기식 입출력에서도 입출력 연산이 완료되면 동기식과 마찬가지로 인터럽트를 통해 CPU에게 알려줌.\r\n  그 시점부터 읽어온 데이터를 필요로 하는 명령을 수행할 수 있게 됨.\r\n\r\n## 6. DMA\r\n\r\n- 원칙적으로 메모리는 CPU에 의해서만 접근할 수 있는 장치.\r\n- 따라서 CPU 외의 장치가 메모리의 데이터에 접근하기 위해서는 CPU에게 인터럽트를 발생시켜 CPU가 이를 대행하는 식으로만 가능함.\r\n- 이 비효율성을 극복하기 위해 CPU 이외에 메모리 접근이 가능한 장치를 하나 더 두는 경우가 많은데, 이와 같은 장치를 DMA(Direct Memory Access)라고 부른다.\r\n- DMA를 사용하면 로컬버퍼에서 메모리로 읽어오는 작업을 CPU가 담당하는 것이 아니라 DMA가 대행함으로써 CPU는 원래 하던 작업을 멈추고 인터럽트를 처리할 필요가 없어지는 것.\r\n- DMA는 바이트(byte) 단위가 아니라 블록(block)이라는 큰 단위로 정보를 메모리로 읽어온 후에 CPU에게 인터럽트를 발생시켜서 해당 작업의 완료를 알려준다.\r\n\r\n## 7. 저장장치의 구조\r\n\r\n- 주기억장치\r\n    - 보통 메모리라고 부르며 전원이 나가면 저장되었던 내용이 모두 사라져버리는 휘발성(volatile)의 RAM을 매체로 사용하는 경우가 대부분\r\n- 보조기억장치\r\n    - 전원이 나가도 저장된 내용을 기억할 수 있는 비휘발성(nonvolatile)의 마그네틱 디스크를 주로 사용함.\r\n    - 플래시 메모리, CD, 마그네틱 테이프 등이 사용됨.\r\n    - 용도는 크게 두 가지로 구분됨.\r\n        1. 파일 시스템용\r\n            - 전원이 나가도 유지해야 할 정보가 있으면 그것을 파일 형태로 보조기억장치에 저장함.\r\n        2. 메모리의 연장 공간인 스왑 영역(swap area)용\r\n            - 운영체제는 프로그램 수행에 당장 필요한 부분만 메모리에 올려놓고 그렇지 않은 부분은 스왑 영역에 내려놓게됨.\r\n            - 디스크에 내려놓는 일을 스왑 아웃(swap out)시킨다고 말하며, 스왑 아웃된 부분이 필요할 때에는 다시 메모리 영역에 올리게 된다.\r\n            - 스왑 영역으로는 하드디스크가 가장 널리 사용\r\n\r\n## 8. 저장장치의 계층 구조\r\n\r\n- 컴퓨터 시스템을 구성하는 저장장치는 빠른 저장장치부터 느린 저장장치까지 단계적인 계층 구조로 이루어진다.\r\n\r\n![Untitled (69)](https://user-images.githubusercontent.com/62014888/146133412-6743e514-8669-4f1d-b3da-7655796eb1c9.png)\r\n\r\n- 빠른 저장장치는 단위 공간당 가격이 높기 때문에 적은 용량을 사용한다.\r\n  따라서 당장 필요한 정보는 빠른 저장장치에 넣어두어 수행 속도를 높인다.\r\n- 느린 저장장치는 가격이 저렴해 대용량을 사용하는 반면 접근 속도가 느리다.\r\n  당장 필요하지 않은 정보는 상대적으로 느린 저장장치에 보관하게 된다.\r\n- 레지스터, 캐시 메모리, 메인 메모리 등은 휘발성 저장장치로 이 부분에 저장되는 정보는 전원이 나가면 그 내용이 사라짐.\r\n  그 밑에 저장장치 계층은 전원이 나가도 지워지지 않는 비휘발성 저장장치.\r\n- 상위 저장장치 계층으로 갈수록 접근 속도가 월등히 빠르지만 용량은 상대적으로 적다.\r\n    - 당장 필요한 정보만을 선별적으로 저장하면 하위에 있는 큰 용량의 저장장치를 가지고 있는 것과 비슷한 성능 효과를 낼 수 있다.\r\n    - 예로 캐시 메모리가 있다.\r\n      상대적으로 용량이 적은 빠른 저장장치를 이용해 느린 저장장치의 성능을 향상시키는 총체적 기법인 캐싱 기법을 사용한다.\r\n      반복되는 코드를 빠른 저장장치에 올려놓으면 적은 저장공간만으로도 전체 시스템의 평균적인 성능을 향상시킬 수 있다.\r\n\r\n\r\n## 9. 하드웨어의 보안\r\n\r\n- 다중 프로그래밍 환경에서는 각 프로그램이 다른 프로그램의 실행을 방해하거나 프로그램 간의 충돌을 일으키는 문제를 막기 위해 하드웨어에 대한 각종 보안 기법이 필요하다.\r\n- 커널모드\r\n    - 중요한 정보에 접근해 위험한 상황을 초래할 수 있는 연산은 커널모드에서 실행되도록 하여 일반 사용자 프로그램이 직접 위험한 명령을 수행할 수 없도록 함.\r\n    - 운영체제가 CPU의 제어권을 가지고 운영체제 코드를 실행하는 모드로서, 이 모드에서는 모든 종류의 명령을 다 실행할 수 있다.\r\n- 사용자모드\r\n    - 일반적인 연산만 사용자모드에서 사용자 프로그램이 수행하도록 통제하여 보안성을 확보함.\r\n    - 일반 사용자 프로그램이 실행되며 제한적인 명령만 수행함.\r\n- 사용자 프로그램이 프로그램 내 중요한 연산을 수행해버리면 제어가 아무런 소용이 없게 되므로 이를 막기 위해 하드웨어적 지원으로 CPU 내부에 모드비트(mode bit)를 두어 사용자 프로그램을 감시하게 됨.\r\n    - 모드비트가 0으로 세팅되어 있으면 커널모드로서 모든 명령을 수행할 수 있고, 모드비트가 1로 세팅되어 있으면 사용자모드로서 제한된 명령만을 수행할 수 있음.\r\n    - 시스템 보안과 관련된 명령들을 특권명령이라 지칭하는데, 특권명령은 모드비트가 0, 즉 커널모드에서 운영체제에 의해서만 수행할 수 있다.\r\n- 모든 입출력 명령은 특권명령으로 규정해서 사용자 프로그램이 직접 입출력을 하는 것을 차단한다.\r\n    - 사용자 프로그램이 입출력을 하고 싶으면 시스템 콜로 운영체제에 요청해야 한다.\r\n    - 그러면 인터럽트 하드웨어에 의해 모드비트가 0으로 세팅되어 운영체제가 입출력을 수행할 수 있게 된다.\r\n\r\n## 10. 메모리 보안\r\n\r\n- 여러 프로그램이 메모리에 동시에 올라가서 실행되기 때문에 하나의 프로그램이 다른 프로그램이나 운영체제가 위치한 메모리 영역을 침범할 수 있기에 메모리 보안도 필요하다.\r\n- 특히, 인터럽트 벡터와 인터럽트 처리루틴이 있는 곳은 각별한 보안이 필요하다.\r\n    - 운영체제만 수행할 수 있는 특권명령을 보안성이 침해되는 이상한 명령어로 변형할 수 있기 때문.\r\n- 2개의 레지스터를 사용해서 프로그램이 접근하려는 메모리 부분이 합법적인지 체크함으로써 메모리를 보호할 수 있다.\r\n    - 기준 레지스터(base register)\r\n        - 어떤 프로그램이 수행되는 동안 그 프로그램이 합법적으로 접근할 수 있는 메모리상의 가장 작은 주소를 보관하고 있다.\r\n    - 한계 레지스터(limit register)\r\n        - 프로그램이 기준 레지스터값부터 접근할 수 있는 메모리의 범위를 보관하고 있음.\r\n    - 어떤 프로그램이 실제 메모리에 올라가 있는 부분의 시작 주소와 그 프로그램의 길이를 각각 기준 레지스터와 한계 레지스터에 보관해 메모리 접근 연산이 있을 때마다 하드웨어적으로 현재 접근하려는 위치가 합법적 범위에 있는지 체크하게 됨.\r\n    - 사용자 프로그램은 기준 레지스터에 있는 주소부터 기준 레지스터 + 한계 레지스터값 사이의 주소 영역에만 접근할 수 있음.\r\n- 메모리 접근 연산은 사용자 프로그램이 CPU를 가지고 있는 동안 수행할 수 있는 연산이므로 특권명령은 아니지만, 사용자 프로그램이 메모리에 접근하기 전에 하드웨어적으로 그 접근이 합법적인지를 체크하여 메모리를 보호하게 됨.\r\n    - 운영체제만이 수행할 수 있는 입출력 연산과 메모리 접근 연산의 차이점.\r\n- 사용자모드인 경우, 기준 레지스터와 한계 레지스터를 사용해서 메모리를 보호하게 되고, 커널모드에서는 메모리에 무제한으로 접근하는 것이 가능함.\r\n\r\n## 11. CPU 보호\r\n\r\n- 특정 프로그램이 CPU를 독점되는 것을 막기 위해 운영체제는 타이머(timer)라는 하드웨어를 사용함.\r\n- 타이머는 정해진 시간이 지나면 인터럽트를 발생시켜 운영체제가 CPU의 제어권을 획득할 수 있도록 하는 역할을 수행함.\r\n- 타이머는 일정한 시간 단위로 세팅될 수 있으며 매 클럭 틱(clock tick) 때마다 1씩 감소하여 0이 되는 순간 인터럽트를 발생하게 됨.\r\n    - 세팅하는 명령을 로드 타이머(load timer)라고 하며 특권명령에 속함.\r\n- 타이머는 시분할 시스템에서 현재 시간을 계산하기 위해서도 사용됨.\r\n\r\n## 12. 시스템 콜을 이용한 입출력 수행\r\n\r\n- 사용자 프로그램이 디스크 파일에 데이터를 쓰거나 읽어오는 행위, 키보드 입력하고 결과 출력하는 행위 등은 모두 특권명령인 입출력 명령에 해당하므로 사용자 프로그램이 직접 수행할 수 없음.\r\n- 사용자 프로그램은 시스템 콜이라는 서비스 대행 요청을 하여 입출력을 수행함.\r\n    - 시스템 콜은 일종의 소프트웨어적인 인터럽트\r\n    - 시스템 콜을 하면 트랩이 발생해 CPU 제어권이 운영체제로 넘어감.\r\n    - 운영체제는 해당 시스템 콜을 처리하기 위한 루틴으로 가서 정의된 명령을 수행함.\r\n    - 예를 들어 디스크 컨트롤러에게 입출력 요청을 수행하도록 명령하고, 추후에 디스트 컨트롤러가 입출력 수행을 마치면 CPU에게 인터럽트를 발생시켜 입출력이 완료되었음을 알려줌으로써 해당 프로그램이 다시 CPU를 할당받을 수 있도록 함.","excerpt":"'운영체제와 정보기술의 원리' 스터디를 진행하며 정리한 내용이다. 1. 컴퓨터 시스템의 구조 컴퓨터 내부장치인 CPU, 메모리와 컴퓨터 외부장치인 디스크, 키보드, 마우스, 모니터, 네트워크 장치 등으로 구성된다. 컴퓨터는 외부장치에서 내부장치로 데…","fields":{"slug":"/os-it-principle-ch3/"},"frontmatter":{"date":"Oct 12, 2021","title":"[운영체제와 정보기술의 원리] 3. 컴퓨터 시스템의 동작 원리","tags":["os","book","os-it-principle"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n'운영체제와 정보기술의 원리' 스터디를 진행하며 정리한 내용이다.\r\n\r\n---\r\n\r\n## 1. 운영체제의 정의\r\n\r\n- 운영체제란 컴퓨터 하드웨어 바로 윗단에 설치되는 소프트웨어\r\n\r\n    ![Untitled (67)](https://user-images.githubusercontent.com/62014888/146131511-acf8ab22-cc9e-4d2f-a88e-5e3cb9439c46.png)\r\n\r\n    - 운영체제에 시스템이라는 용어가 사용된 것은 하드웨어가 운영체제와 한 몸이 되어야만 사용자에게 쓰일 수 있는 진정한 컴퓨터 시스템이 되기 때문.\r\n    - 사용자 입장에서는 하드웨어 자체를 다룬다는 것이 쉽지 않으므로, 하드웨어 위에 기본적으로 운영체제를 탑재해 전원을 켰을 때 손쉽게 사용할 수 있는 상태가 되도록 하는 것.\r\n- 운영체제도 하나의 소프트웨어로서 전원이 켜짐과 동시에 메모리에 올라감\r\n    - 운영체제 중 항상 필요한 부분만을 전원이 켜짐과 동시에 메모리에 올려놓고 그렇지 않은 부분은 필요할 때 메모리로 올려서 사용하게 됨.\r\n        - 메모리에 상주하는 부분을 커널(kernel)이라고 부름.\r\n          좁은 의미의 운영체제. 핵심적인 부분을 뜻함.\r\n        - 넓은 의미의 운영체제는 커널뿐 아니라 시스템을 위한 유틸리티들을 광범위하게 포함하는 개념. ex) MS 윈도우 환경에서 파일을 복사하는 프로그램 등\r\n\r\n\r\n## 2. 운영체제의 기능\r\n\r\n- 운영체제의 두 가지 주요 기능은 컴퓨터 시스템 내의 자원(resource)을 효율적으로 관리하는 것과 컴퓨터 시스템을 편리하게 사용할 수 있는 환경을 제공하는 것.\r\n    - 두 기능 중 중요한 핵심 기능은 컴퓨터 시스템 내의 자원을 효율적으로 관리하는 것.\r\n      그래서 운영체제를 자원관리자라고 부르기도 한다.\r\n    - 운영체제는 사용자 및 프로그램들 간에 자원이 형평성 있게 분배되도록 하는 균형자 역할도 함께 수행해야함.\r\n    - 효율성 + 형평성\r\n- 이밖에도 사용자와 운영체제 자신을 보호하는 역할을 담당함.\r\n\r\n## 3. 운영체제의 분류\r\n\r\n- 운영체제는 동시 작업을 지원하는지의 여부에 따라 단일작업(single tasking)용 운영체제와 다중작업(multi tasking)용 운영체제로 나누어볼 수 있다.\r\n    - 단일작업용 운영체제는 한 번에 하나의 프로그램만 실행시킬 수 있는 운영체제.\r\n      초창기 운영체제는 대개 단일작업용 운영체제에 해당.\r\n      ex) 도스(Disk Operating System: DOS)\r\n    - 최근에는 대부분의 운영체제가 동시에 2개 이상의 프로그램을 처리할 수 있는 다중작업을 지원함.\r\n      ex) MS 윈도우, 유닉스 환경 등\r\n- 운영체제가 다중작업을 처리할 때에는 여러 프로그램이 CPU와 메모리를 공유하게 됨.\r\n    - 여러 프로그램들이 CPU에 번갈아 실행되면 사용자 입장에서는 여러 프로그램이 동시에 실행되는 것처럼 보임.\r\n    - CPU의 작업시간을 여러 프로그램들이 조금씩 나누어 쓰는 시스템을 시분할 시스템(time sharing system)이라고 부름.\r\n- 메모리 공간을 분할하여 여러 프로그램들을 동시에 메모리에 올려놓고 처리하는 시스템을 다중 프로그래밍 시스템(multi-programming system)이라고 부른다.\r\n- 다중작업용 운영체제의 경우 각 프로그램에 대한 키보드 입력의 결과를 곧바로 화면에 보여주는데 이를 대화형 시스템(interactive system)이라고도 부름.\r\n- 다중처리기 시스템(multi-processor system)은 하나의 컴퓨터 안에 CPU가 여러 개 설치된 경우를 뜻함.\r\n\r\n- 다중 사용자에 대한 동시 지원 여부\r\n    - 한 번에 한명의 사용자만이 사용하도록 허용하는 운영체제를 단일 사용자용 운영체제\r\n        - DOS(단일작업), MS 윈도우(다중작업) 등\r\n    - 여러 사용자가 동시에 접속해 사용할 수 있게 하는 운영체제를 다중 사용자용 운영체제\r\n        - 이메일 서버나 웹서버 등 흔히 서버라고 부르는 컴퓨터.\r\n\r\n- 작업을 처리하는 방식에 따라.\r\n    - 일괄처리(batch processing) 방식\r\n        - 요청된 작업을 일정량씩 모아서 한꺼번에 처리하는 방식\r\n        - 처리해야 할 작업들을 모아 일정량이 쌓이면 일괄적으로 처리하고, 모든 작업이 완전히 종료된 후에 결과를 얻을 수 있음.\r\n        - 사용자 입장에서는 응답시간이 길다는 단점이 있음.\r\n        - ex) 펀치 카드(punch card) 처리 시스템\r\n    - 시분할 방식\r\n        - 여러 작업을 수행할 때 컴퓨터의 처리 능력을 일정한 시간 단위로 분할해 사용하는 방식.\r\n        - 사용자들은 일괄처리 방식에 비해 짧은 응답시간을 갖게 된다.\r\n        - 사용자 요청에 대한 결과를 곧바로 얻을 수 있는 시스템을 대화형 시스템이라고 표현하며, 이는 시분할 방식의 대표적인 특징.\r\n    - 실시간(real time) 운영체제\r\n        - 정해진 시간 안에 어떠한 일이 반드시 처리됨을 보장해야 하는 시스템에서 사용.\r\n        - ex) 원자로, 공장 제어 시스템, 미사일 제어 시스템 등\r\n        - 경성 실시간 시스템(hard realtime system) - 주어진 시간을 지키지 못할 경우 매우 위험한 결과를 초래할 가능성이 있는 로켓, 원자로 제어 시스템 등을 말함.\r\n        - 연성 실시간 시스템(soft realtime system) - 멀티미디어 스트리밍 시스템과 같이 데이터가 정해진 시간 단위로 전달되어야 올바른 기능을 수행할 수 있는 시스템.\r\n\r\n\r\n## 4. 운영체제의 예\r\n\r\n- MS 윈도우\r\n    - 마이크로소프트에서 이전에 개발한 MS-DOS와 윈도우 3.1 등을 한층 발전시킨, 개인용 컴퓨터를 위한 운영체제\r\n    - 윈도우 XP부터 인터페이스 측면에서 그래픽 환경과 아이콘 방식을 기본적으로 채택\r\n    - 시스템에 새로운 하드웨어를 장착하면 운영체제가 자동으로 그 하드웨어를 감지하여 그에 맞게 설정되는 기능인 플러그 앤 플레이(plug and play) 제공.\r\n- 유닉스\r\n    - 프로그램 개발 환경을 위해 설계된 운영체제로서 이식성(portability)이 좋고, 운영체제 커널의 크기가 작으며, 소스 코드(source code)가 공개되었다는 점 등으로 인해 학계를 바탕으로 많은 연구와 함께 그 사용이 확대되어 이제는 가장 널리 사용되는 운영체제 중 하나로 자리 잡음.\r\n    - 리눅스(Linux)의 등장으로 대형 서버뿐 아니라 개인용 컴퓨터에서도 유닉스를 널리 사용할 수 있게 됨.\r\n\r\n\r\n## 5. 운영체제의 자원 관리 기능\r\n\r\n- 운영체제의 가장 핵심적인 기능은 자원을 효율적으로 관리하는 것.\r\n- 자원은 하드웨어 자원과 소프트웨어 자원으로 나뉨\r\n    - 하드웨어 자원 - CPU와 메모리(memory)를 비롯해 주변장치 또는 입출력 장치라 불리는 장치들로 구성됨.\r\n\r\n- CPU 관리하는 방법\r\n- CPU가 하나밖에 없는 가장 기본적인 컴퓨터 구조에서도 여러 개의 프로세스가 동시에 수행될 수 있으므로 매 시점 어떠한 프로세스에 CPU를 할당해 작업을 처리할 것인지 결정하는 일이 필요함.\r\n    - 이를 CPU 스케줄링(CPU scheduling) 이라고 한다.\r\n    - CPU 스케줄링의 목표는 CPU를 가장 효율적으로 사용하면서도, 특정 프로세스가 불이익을 당하지 않도록 하는 것.\r\n    - 선입선출 기법(First Come First Served)\r\n        - CPU를 사용하기 위해 도착한 프로세스들 중 먼저 온 것을 먼저 처리해주는 방식.\r\n        - CPU 자체의 효율적인 사용 측면에서는 문제가 없지만 전체 시스템 입장에서는 비효율적인 결과를 초래할 가능성이 있다.\r\n    - 라운드 로빈 기법(Round Robin)\r\n        - CPU를 한 번 할당받아 사용할 수 있는 시간을 일정하게 고정된 시간으로 제한함.\r\n        - 일반적으로 1회 할당시간은 밀리초 단위를 사용해 다수의 사용자가 동시에 접속할 때에도 각자 1초 이하의 응답시간을 보장받을 수 있게 된다.\r\n    - 우선순위 스케줄링(priority)\r\n        - CPU 사용을 위해 대기 중인 프로세스들에 우선순위를 부여하고 우선순위가 높은 프로세스에 CPU를 먼저 할당한다.\r\n        - 상대적으로 더 중요한 프로세스의 우선순위를 높게 하여 CPU를 먼저 획득할 수 있도록 한다.\r\n        - 지나치게 오래 기다리는 프로세스가 발생하지 않도록, 기다린 시간이 늘어날수록 우선순위를 점차 높여주는 방안도 활용될 수 있음\r\n- 중요 관리 대상으로 메모리도 있다.\r\n- 메모리는 CPU가 직접 접근할 수 있는 컴퓨터 내부의 기억장치로 한정된 메모리 공간에 여러 프로그램을 수용하려면 효율적인 관리 메커니즘이 필요함.\r\n- 메모리의 어떤 부분이 어떤 프로그램에 의해 사용되고 있는지를 파악하여 이를 유지하게 되는데, 이러한 정보는 주소(address)를 통해 관리됨.\r\n- 프로그램에 메모리가 필요할 때 할당하고, 더 이상 필요하지 않을 때 회수하는데 이를 잘 판단해 전체 메모리 공간이 효율적으로 사용될 수 있도록 해야 하며, 각 프로세스가 자신의 메모리 영역에만 접근할 수 있도록 관리해야 함.\r\n    - 고정분할 방식(fixed partition)\r\n        - 물리적 메모리를 몇 개의 분할로 미리 나누어 관리. 나뉜 분할에는 하나의 프로그램이 적재될 수 있음.\r\n        - 융통성이 없다. 최대 프로그램의 수가 분할 개수로 한정되어 있고 분할의 크기보다 큰 프로그램은 적재가 불가능.\r\n        - 효율적인 사용 측면에서 바람직하지 않음.\r\n          분할의 크기보다 작은 프로그램이 적재될 경우 내부조각(internal fragmentation)이라는 비효율적으로 낭비되는 공간이 생김.\r\n    - 가변분할 방식(variable partition)\r\n        - 매 시점 프로그램의 크기에 맞게 메모리를 분할해서 사용하는 방식\r\n        - 물리적 메모리의 크기보다 더 큰 프로그램의 실행은 여전히 불가능.\r\n        - 프로그램에는 할당되지는 않았지만 그 크기가 작아 프로그램을 올리지 못하는 메모리 영역인 외부조각(external fragmentation)이 발생할 수 있다.\r\n    - 가상메모리 기법(virtual memory)\r\n        - 현대의 범용 컴퓨터 환경에서 가장 널리 사용되는 메모리 관리 기법\r\n        - 물리적 메모리보다 더 큰 프로그램이 실행되는 것을 지원함.\r\n        - 가상메모리 기법에서는 물리적 메모리의 크기와 상관없이, 사용할 수 있는 메모리의 크기가 충분히 크다고 가정하고 프로그램을 개발할 수 있음.\r\n            - 현재 사용되고 있는 부분만 메모리에 올리고, 나머지는 하드디스크와 같은 보조기억장치에 저장해두었다가 필요할 때 적재하는 방식을 취함.\r\n        - 동일한 단위로 메모리를 나누는 기법을 페이징(paging) 기법이라고 함.\r\n\r\n- 주변장치 및 입출력 장치\r\n- CPU나 메모리와 달리 인터럽트(interrupt)라는 메커니즘을 통해 관리가 이루어진다.\r\n- 주변장치들은 CPU의 서비스가 필요한 경우에 신호를 발생시켜 서비스를 요청함. 이때 발생시키는 신호를 인터럽트라고 한다.\r\n- CPU는 작업을 수행하다 인터럽트가 발생하면 하던 일을 멈추고 인터럽트에 의한 요청 서비스를 수행한다.\r\n- ex) 키보드 입력\r\n- 인터럽트는 요청하는 장치와 발생 상황에 따라 다양한 종류가 있기 때문에 운영체제는 인터럽트의 종류마다 서로 다른 인터럽트 처리루틴을 가지고 있다.\r\n    - 이는 운영체제 커널 내에 존재하는 코드.\r\n    - 인터럽트가 발생하면 운영체제는 해당하는 인터럽트 처리루틴을 찾아서 정의된 코드에 따라 일을 수행하게 된다.\r\n- 주변장치들은 각 장치마다 그 장치에서 일어나는 업무를 관리하기 위한 일종의 작은 CPU인 컨트롤러(controller)를 가지고 있음.\r\n    - 컨트롤러는 해당 장치에 대한 업무를 처리하고, 이를 메인 CPU에 인터럽트를 발생시켜 보고하는 역할을 한다.","excerpt":"'운영체제와 정보기술의 원리' 스터디를 진행하며 정리한 내용이다. 1. 운영체제의 정의 운영체제란 컴퓨터 하드웨어 바로 윗단에 설치되는 소프트웨어 Untitled (67) 운영체제에 시스템이라는 용어가 사용된 것은 하드웨어가 운영체제와 한 몸이 되어…","fields":{"slug":"/os-it-principle-ch2/"},"frontmatter":{"date":"Oct 11, 2021","title":"[운영체제와 정보기술의 원리] 2. 운영체제의 개요","tags":["os","book","os-it-principle"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n'성공과 실패를 결정하는 1%의 네트워크 원리' 스터디를 진행하며 정리한 내용이다.\r\n\r\n---\r\n\r\n## 01 서버의 개요\r\n\r\n1. 클라이언트와 서버의 차이점\r\n    - 공통점\r\n        - 네트워크에 관한 부분, 즉 LAN 어댑터, 프로토콜 스택, Socket 라이브러리 등의 기능은 클라이언트와 조금도 다르지 않다.\r\n    - 차이점\r\n        - 서버 머신은 용도에 따라 다양한 종류가 있고, 하드웨어나 OS 부분은 클라이언트와 다른 것도 있다.\r\n        - Socket 라이브러리의 사용법이 조금 다르다.\r\n            - 접속 동작을 할 때 클라이언트에서 접속 동작을 수행하고, 서버는 그것을 기다리는 형태가 되므로\r\n        - 서버의 애플리케이션은 동시에 다수의 클라이언트 PC와 대화한다.\r\n\r\n2. 서버 애플리케이션의 구조\r\n    - 클라이언트가 접속할 때마다 새로 서버 프로그램을 작동하여 서버 애플리케이션이 클라이언트와 1 대 1로 대화하는 방법을 선택하는 것이 일반적.\r\n\r\n         ![Untitled - 2021-12-23T150332 464](https://user-images.githubusercontent.com/62014888/147195768-475ee490-66d1-4f05-b9c7-ac0034fd4b59.png)\r\n\r\n        - 서버 프로그램을 접속을 기다리는 부분과 클라이언트와 대화하는 부분 둘로 나누어 만든다.\r\n        - 서버 프로그램을 작동해서 설정 파일 읽기 등의 초기화 동작을 마쳤을 때 접속을 기다리는 부분을 실행한다.\r\n          소켓을 작성하고 소켓을 클라이언트에서의 접속 동작을 기다리는 상태로 만든 채 쉬는 상태가 된다.\r\n        - 클라이언트가 접속했을 때 다시 작동하여 접속을 기다린다.\r\n        - 클라이언트와 대화하는 부분을 작동시켜서 그곳에 접속이 끝난 소켓을 건네주고 동작을 계속하면 클라이언트와 대화하는 부분은 접속이 끝난 소켓을 사용하여 클라이언트와 대화하기 시작한다.\r\n        - 대화가 끝나면 연결을 끊고 이 부분을 종료한다.\r\n    - 클라이언트와 대화하는 부분은 새 클라이언트가 접속할 때마다 잇달아 기동되므로 한 대의 클라이언트와 1 대 1로 대응한다.\r\n    - 서버 OS는 멀티태스트 또는 멀티스레드라는 기능으로 다수의 프로그램을 동시에 함께 작동할 수 있는데, 이 성질을 이용한 프로그래밍 기법임.\r\n    - 클라이언트가 접속했을 때 새로 프로그램을 기동하는 부분에서 다소 시간이 걸리고, 응답 시간이 추가로 소요된다는 단점이 있음.\r\n        - 미리 몇 개의 부분을 작동시켜 두고 클라이언트가 접속했을 때 클라이언트의 상대를 처리하지 않는 비어있는 것을 찾아 여기에 접속한 소켓을 건네주어 클라이언트와 대화를 계속하는 방법도 있음. (스레드풀)\r\n\r\n3. 서버측의 소켓과 포트 번호\r\n    - 데이터를 송, 수신하는 동작의 관점에서 보면 클라이언트와 서버라는 상태로 역할을 고정시키는 것은 좋은 방법이라고 할 수 없음.\r\n        - 클라이언트에서 서버에 액세스한다는 형태의 애플리케이션이 다수이지만, 다른 형태로 액세스하는 애플리케이션도 있음.\r\n        - 역할을 결정하지 말고 좌우 대칭으로 어디에서나 자유롭게 데이터를 송신할 수 있도록 해두는 방법이 좋음 (TCP 배경에는 이러한 개념이 있음)\r\n    - 다만, 접속 동작은 좌우 대칭으로 만들 수 없다.\r\n        - 데이터 송, 수신 동작의 시점에서 보았을 때 접속하는 측이 클라이언트, 접속을 기다리는 측이 서버이다.\r\n    - Socket 라이브러리를 호출하는 부분에서 서버측의 구체적인 동작은 이러하다.\r\n\r\n      ![Untitled - 2021-12-23T150346 650](https://user-images.githubusercontent.com/62014888/147195771-c3b7646e-4285-470a-b7de-16eeade63e7e.png)\r\n\r\n        - socket을 호출하여 소켓을 만든다.\r\n        - bind를 호출하여 소켓에 포트 번호를 기록한다.\r\n            - 구체적인 번호는 규칙에 의해 서버 애플리케이션마다 결정되어 있고, 웹 서버의 경우는 80번으로 되어 있다.\r\n        - listen을 호출하여 소켓에 접속하기를 기다리는 상태라는 제어 정보를 기록한다.\r\n        - accept를 호출하여 접속을 접수한다.\r\n            - 패킷이 도착하지 않았는데도 접속 접수 동작을 실행하는 이유는 이렇게 하지 않으면 패킷이 도착할 때 그제서야 접속 접수 동작을 실행하기 때문.\r\n        - 패킷이 도착하면 응답 패킷을 반송하여 접속 접수 동작을 실행\r\n        - 접속 대기의 소켓을 복사하여 새로운 소켓을 만들고, 접속 상대의 정보를 비록한 제어 정보를 새 소켓에 기록한다.\r\n          새 소켓이 클라이언트측의 소켓과 연결된다.\r\n        - 그 후 클라이언트와 대화하는 부분을 기동.\r\n\r\n   - 접속 대기 상태인 소켓이 계속 존재나는 이유는 접속 대기 소켓에 그대로 접속하게 되면 이 소켓이 없어져 버리므로 다음에 다른 클라이언트가 접속하면 곤란해지기 때문.\r\n   - 클라이언트측에서 회답이 돌아왔을 때 다른 포트 번호의 소켓이 오면 접속 패킷을 보낸 상대로부터 돌아왔는지 아닌지를 판별할 수 없기에 새로 만든 소켓에도 접속 대기 소켓과 같은 포트 번호를 할당해야 함.\r\n       - 소켓을 지정할 때 클라이언트측의 IP 주소, 클라이언트측의 포트 번호, 서버측의 IP 주소, 서버측의 포트 번호 네 가지 정보를 사용함.\r\n   - 그렇다면 이 네 가지 정보를 사용하면 되니까 디스크립트는 필요없지 않을까?\r\n       - 소켓을 식별하기 위해 디스크립터를 사용하는 이유가 두 가지 있음\r\n           1. 접속 대기의 소켓에는 클라이언트측의 IP 주소와 포트 번호가 기록되어 있지 않기 때문.\r\n           2. 디스크립터라는 한 개의 정보로 식별하는 쪽이 간단하기 때문.\r\n\r\n<br/>\r\n\r\n## 02 서버의 수신 동작\r\n\r\n1. LAN 어댑터에서 수신 신호를 디지털 데이터로 변환한다.\r\n    - 패킷의 신호를 LAN 어댑터에서 수신하고 디지털 데이터로 바꾼다.\r\n        - LAN을 흐르는 패킷의 신호는 1,0으로 이루어진 디지털 데이터의 신호와 타이밍을 나타내는 클록 신호를 합성한 것이므로 클록 신호를 추출하고 클록 신호에서 타이밍을 계산하면서 신호를 읽어오면, 1,0 디지털 데이터로 바꿀 수 있다.\r\n    - 패킷의 맨 마지막에 있는 프레임 체크 시퀀스(FCS)라는 오류 검사용 데이터를 이용하여 오류 유무를 검사한다.\r\n        - FCS가 일치하지 않으면 데이터가 변했다는 뜻이니 패킷을 버린다.\r\n    - MAC 헤더에 있는 수신처 MAC 주소를 조사하여 패킷이 자신을 수신처로 하여 보낸 것인지 판단한다.\r\n        - 아닌 경우 패킷을 버린다.\r\n    - 디지털 데이터로 되돌린 것을 LAN 어댑터 내부의 버퍼 메모리에 저장한다.\r\n    - 서버 CPU는 패킷을 알아차리지 못하니 인터럽트라는 방법을 사용하여 LAN 어댑터에서 CPU로 패킷의 도착을 알린다.\r\n    - LAN 드라이버가 MAC 헤더로부터 프로토콜을 판단하여 프로토콜 스택에 패킷을 건네준다.\r\n\r\n2. IP 담당 부분의 수신 동작\r\n    - IP 담당 부분이 동작하여 IP 헤더를 점검해 수신처 IP 주소가 자신을 대상으로 하는지 조사한다.\r\n        - 서버에서 라우터와 같이 패킷을 중계하는 기능이 유효하게 된 경우 자신을 대상으로 하지 않은 패킷이 도착할 수도 있으니 다시 패킷을 중계한다.\r\n    - 자신을 대상으로 한 것이 확인되면 조각 나누기에 의해 패킷이 분할되었는지 조사한다.\r\n        - 분할되어 있으면 메모리에 저장했다 전부 도착하면 원래 패킷으로 복원한다.\r\n        - 분할되어 있지 않으면 패킷 조립 동작은 필요 없으므로 패킷을 받은 것이 된다.\r\n    - IP 헤더의 프로토콜 번호 항목을 조사하여 해당하는 담당 부분에 패킷을 건네준다. (TCP 또는 UDP)\r\n\r\n3. TCP 담당 부분이 접속 패킷을 수신했을 때의 동작\r\n    - 패킷의 TCP 헤더에 있는 SYN이라는 컨트롤 비트가 1로 되어 있으면 접속 동작의 패킷이다.\r\n    - 도착한 패킷의 수신처 포트 번호를 조사하여 이 번호와 같은 번호를 할당한 접속 대기 상태의 소켓이 있는지 확인한다.\r\n        - 없으면 오류 통지 패킷을 클라이언트에 반송함.\r\n    - 있으면 패킷을 복사하여 새 소켓을 만들고 여기에 송신처 IP 주소, 포트 번호, 시퀀스 번호의 초기값, 윈도우 값 등 필요한 정보를 기록한다.\r\n    - 동시에 송신 버퍼나 수신 버퍼로 사용하는 메모리 영역을 확보함.\r\n    - 패킷을 받았음을 나타내는 ACK 번호, 시퀀스 번호 초기값, 윈도우 값 등의 항목을 기록한 TCP 헤더를 만들고, 이를 IP 담당 부분에 의뢰하여 클라이언트에 반송함.\r\n    - 클라이언트가 이를 받았으면 ACK 번호를 보내고 접속 동작은 완료됨.\r\n\r\n4. TCP 담당 부분이 데이터 패킷을 수신했을 때의 동작\r\n    - IP 헤더의 송신처 IP 주소, 수신처 IP 주소, TCP 헤더의 수신처 포트 번호, 송신처 포트 번호라는 4개의 정보가 모두 합치되는 소켓을 찾는다.\r\n    - 소켓을 발견하면 패킷에 기록되어 있는 데이터 송, 수신 진행 상황과 도착한 패킷의 TCP 헤더의 정보를 결합하여 데이터 송, 수신 동작이 올바르게 진행되고 있는지 점검한다.\r\n        - 구체적으로 시퀀스 번호를 사용해서 조사함.\r\n    - 제대로 도착한 것이면 데이터 조각을 수신 버퍼에 저장하고 지난 번 패킷에서 수신한 데이터 조각의 다음에 연결되어 분할되기 전 상태로 되돌린다.\r\n    - 수신 확인 응답용 TCP 헤더를 만든다. 여기에 수신 패킷의 시퀀스 번호, 데이터 조각의 길이로부터 계산한 ACK 번호를 기록하고, IP 담당 부분에 의뢰하여 클라이언트에 반송한다.\r\n    - read를 호출하여 수신한 데이터를 받아온 부분에서 애플리케이션에 건네준다.\r\n\r\n5. TCP 담당 부분의 연결 끊기 동작\r\n    - 웹의 경우 HTTP 프로토콜의 버전에 따라 다른데 HTTP 1.0이라면 서버에서 연결 끊기 동작을 시작한다.\r\n    - 서버측에서 close를 호출하고, TCP 담당 부분이 FIN이라는 컨트롤 비트에 1을 설정한 TCP 헤더를 만든 후 IP 담당 부분에 의뢰하여 클라이언트에 보낸다.\r\n    - 클라이언트에 도착하면 클라이언트는 ACK 번호를 반송한다.\r\n    - 클라이언트가 close를 계속 호출하고,  FIN을 1로 한 TCP 헤더를 서버에 보낸 후 서버가 ACK 번호를 반송하면 연결 끊기 동작은 끝남.\r\n    - 연결 끊기 동작이 끝나면 잠시 기다렸다가 소켓을 말소함.\r\n\r\n<br/>\r\n\r\n## 03 웹 서버 소프트웨어가 리퀘스트 메시지의 의미를 해석하여 요구에 응한다.\r\n\r\n1. 조회의 URI를 실제 파일명으로 변환한다.\r\n    - 웹 서버의 경우 read에서 받은 데이터의 내용이 HTTP 리퀘스트 메시지가 된다.\r\n    - 받은 리퀘스트 메시지에 기록되어 있는 내용에 따라 적절한 처리를 실행하여 응답 메시지를 만들고, write를 통해 이것을 클라이언트에 반송한다는 형태로 작동함.\r\n        - 메소드나 URI의 내용에 따라 웹 서버 내부의 동작이 달라짐\r\n    - 단순히 URI에 기록되어 있는 파일을 디스크에서 읽는 것은 아니다.\r\n        - 디스크의 파일을 전부 액세스할 수 있게 되므로 웹 서버의 디스크가 무방비 상태로 노출되어 위험하기 때문.\r\n    - 웹 서버에서 공개하는 디렉토리는 가상으로 만든 디렉토리이고, 이 가상의 디렉토리 구조에서의 경로명을 URI에 써야함.\r\n    - 파일을 읽어올 때는 가상의 디렉토리와 실제 디렉토리의 대응 관계를 조사하고, 실제 디렉토리의 경로명으로 변환한 후 파일을 읽어 데이터를 반송함.\r\n    - 파일명을 바꿔쓰는 규칙을 서버측에 설정하고 규칙에 따라 파일명을 바꿔쓰고 나서 파일에 액세스하는 웹 서버 애플리케이션도 있다.\r\n\r\n2. CGI 프로그램을 작동하는 경우\r\n    - 프로그램 파일의 이름을 URI에 쓸 수도 있다.\r\n    - 이 경우에는 해당 프로그램을 작동시켜서 프로그램이 출력하는 데이터를 클라이언트에 반송한다.\r\n    - CGI라는 타입의 프로그램은 다음과 같이 동작한다.\r\n\r\n      ![Untitled - 2021-12-23T150356 613](https://user-images.githubusercontent.com/62014888/147195775-87cdd31e-4cc7-4989-aa0e-13b825168a34.png)\r\n\r\n        - 무언가의 데이터를 리퀘스트 메시지 안에 넣어 브라우저에서 웹 서버로 보낸다.\r\n        - 웹 서버에서 URI 파일명을 조사하여 프로그램인지 판단한다.\r\n        - 파일이 프로그램인 것을 알고 있으면 웹 서버는 프로그램을 작동시키도록 OS에 의뢰한다.\r\n        - 작동시킨 프로그램이 데이터를 처리하여 무언가의 출력 데이터를 웹 서버에 돌려준다.\r\n        - 출력 데이터는 보통 HTML 태그를 내장한 HTML 문서로 되어 있으므로 웹 서버는 이것을 그대로 응답 메시지로 클라이언트에 반송한다.\r\n\r\n3. 웹 서버로 수행하는 액세스 제어\r\n    - 웹 서버 동작을 실행할 때 사전에 설정해 둔 조건에 해당하는지 조사하고, 조건에 해당하는 경우 그 동작을 금지하거나 조건에 해당하는 경우만 동작을 실행한다는 기능도 있다.\r\n      이와 같이 조건에 따라 액세스 동작 여부를 설정하는 기능을 액세스 제어라고 한다.\r\n    - 웹 서버에서 설정하는 조건은 주로 다음과 같다.\r\n    1. 클라이언트의 주소\r\n    2. 클라이언트의 도메인명\r\n    3. 사용자명과 패스워드\r\n    - 클라이언트의 IP 주소가 조건으로 설정되어 있는 경우는 accept로 접속을 접수했을 때 클라이언트의 IP 주소를 알 수 있으므로 이것을 점검하기만 한다.\r\n    - 클라이언트의 도메인명이 조건으로 설정되어 있는 경우에는 IP 주소에서 도메인명을 조사하는데, 이 때 DNS 서버를 이용한다.\r\n        - 이 방법은 DNS 서버의 조회 메시지가 왕래하는 만큼 시간이 걸리며, 그만큼 응답 시간이 길어진다.\r\n    - 사용자명과 패스워드가 설정된 경우\r\n        - 보통의 리퀘스트 메시지에는 사용자명과 패스워드가 없으니 웹 서버는 사용자명과 패스워드를 기록하거나 리퀘스트 메시지를 보내도록 응답 메시지에서 클라이언트에 통지한다.\r\n        - 브라우저는 사용자명과 패스워드를 입력하는 화면을 표시한다.\r\n        - 리퀘스트 메시지에 기록하고, 다시 한 번 서버에 액세스 한다.\r\n        - 통지된 사용자명과 패스워드와 사전에 설정한 것을 대조하여 액세스 가능 여부를 판단하고, 액세스를 허가하는 경우에는 데이터를 반송한다.\r\n\r\n4. 응답 메시지를 되돌려 보낸다.\r\n    - 리퀘스트 메시지에 대해 적절하게 처리하고 처리가 완료되면 응답 메시지를 반송한다.\r\n    - 웹 서버가 write를 호출하여 응답 메시지를 프로토콜 스택에 건네준다.\r\n    - 디스크립터를 통지하여 상대를 지정한다.\r\n        - 소켓에는 통신의 상태가 전부 기록되어 있고, 여기에 통신 상대의 정보도 있으므로 디스크립터만 통지하면 된다.\r\n\r\n<br/>\r\n\r\n## 04 웹 브라우저가 응답 메시지를 받아 화면에 표시한다.\r\n\r\n1. 응답 데이터의 형식을 보고 본질을 판단한다.\r\n    - 화면 표시 동작은 응답 메시지에 저장된 데이터가 어떤 종류인지를 조사하는 곳부터 시작한다.\r\n    - 데이터의 종류를 판단하는 근거는 몇 가지가 있는데, 응답 메시지의 맨 앞부분에 있는 'Content-Type'이라는 헤더 파일의 값으로 판단하는 것이 원칙.\r\n\r\n   ![Untitled - 2021-12-23T150400 438](https://user-images.githubusercontent.com/62014888/147195780-7ee23433-d5dd-4761-b3de-6d7bd8ab8f2d.png)\r\n\r\n\r\n   - 압축 기술이나 부호화 기술에 따라 원래 데이터를 변환하고 나서 메시지에 저장한 경우에는 어떤 변환을 했는지를 Content-Encoding 필드에 기록해야 한다.\r\n   - 웹 서버가 Content-Type의 값을 정확하게 설정해야 하는데 현실은 그렇지 않은 경우도 있다.\r\n   그러므로 원칙에 따라 Content-Type을 조사만 해서는 데이터의 종류를 정확하게 판단할 수 없는 경우도 있다.\r\n      - 다른 판단 근거를 사용하여 종합적으로 데이터의 종류를 판단하는 경우도 있다.\r\n         확장자나 데이터 내용의 포맷 등에서 종합적으로 판단하는 것.\r\n\r\n2. 브라우저 화면에 웹 페이지를 표시하여 액세스를 완료한다.\r\n    - HTML 문서, 일반 텍스트, 화상이라는 기본적인 데이터는 브라우저 자체가 화면 표시 기능을 가지고 있으므로 브라우저가 자체에서 화면 표시 동작을 실행한다.\r\n        - 실제 화면 표시 동작은 OS가 담당하므로 OS에 대해 화면의 어떤 위치에, 어떤 문자를, 어떤 글꼴로 표시할지 지시하는 것.\r\n    - 웹 페이지에 화상 등을 내재한 것의 경우 태그를 사용해 화상이 내장되었음을 나타낸다. 이 태그를 발견하면 브라우저는 화상 데이터의 파일을 서버에서 읽어온다.\r\n    - 데이터가 반송되면 태그가 쓰여있던 장소에 화상 데이터를 내장시킨다.\r\n    - HTML 문서나 화상과 같이 브라우저가 자체에서  표시 기능을 가지고 있는 경우에는 이렇게 해서 OS에 지시를 내리며 화면에 표시한다.\r\n    - 자체에 표시할 수 없는 경우 해당 애플리케이션을 호출한다.","excerpt":"'성공과 실패를 결정하는 1%의 네트워크 원리' 스터디를 진행하며 정리한 내용이다. 01 서버의 개요 클라이언트와 서버의 차이점 공통점 네트워크에 관한 부분, 즉 LAN 어댑터, 프로토콜 스택, Socket 라이브러리 등의 기능은 클라이언트와 조금도…","fields":{"slug":"/1per-network-ch6/"},"frontmatter":{"date":"Oct 08, 2021","title":"[성공과 실패를 결정하는 1%의 네트워크 원리] 6장","tags":["network","book","1per-network"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n'성공과 실패를 결정하는 1%의 네트워크 원리' 스터디를 진행하며 정리한 내용이다.\r\n\r\n---\r\n\r\n## 01 웹 서버의 설치 장소\r\n\r\n1. 사내에 웹 서버를 설치하는 경우\r\n\r\n   인터넷을 빠져나와 서버에 도착할 때까지의 여정은 서버의 설치 장소에 따라 다름.\r\n\r\n   ![Untitled - 2021-12-22T173836 683](https://user-images.githubusercontent.com/62014888/147062527-9556bf58-a1c6-4505-8b3c-cc4dd3cbb3fb.png)\r\n\r\n    1. 라우터에서 직접 연결하는 경우\r\n        - 이전에는 이런 형태로 서버를 설치하는 경우가 많았지만, 현재는 주류에서 밀려났음.\r\n            - IP 주소의 부족\r\n            - 보안상의 이유\r\n    2. 방화벽으로 분리하는 경우\r\n        - 방화벽은 특정 서버에서 동작하는 특정 애플리케이션에 액세스하는 패킷만 통과시키고, 그 외의 패킷을 차단하는 역할을 함.\r\n            - 보안 구멍이 있어도 위험성이 적어짐\r\n            - 위험성이 완전히 없어지지는 않았음. 액세스를 허가한 애플리케이션에 보안 구멍이 있으면 공격받을 위험성이 남아있음.\r\n\r\n2. 데이터센터에 웹 서버를 설치하는 경우\r\n\r\n   1. 통신 회사의 데이터센터에 설치하는 경우\r\n\r\n    - 프로바이더 등이 운영하는 데이터센터라는 시설에 서버를 가지고 들어가서 설치하거나 프로바이더가 소유하는 서버를 빌려쓰는 형태로 운영하는 경우도 있음\r\n    - 회사 안보다 안전성이 높으며 기기의 가동 상태 감시, 방화병 설치 운영, 부정 침입 감시라는 부가 서비스를 제공하는 경우가 있어 안전성도 높음.\r\n    - 패킷은 라우터에서 중계되고 최종적으로 서버에 도착한다는 점은 달라지지 않음.\r\n\r\n<br/>\r\n\r\n## 02 방화벽의 원리와 동작\r\n\r\n1. 패킷 필터링형이 주류이다.\r\n    - 방화벽의 기본이 되는 개념은 특정 서버와 해당 서버 안의 특정 애플리케이션에 액세스하는 패킷만 통과시키고, 그 외의 패킷을 차단한다.\r\n        - 통과시킬 패킷과 차단할 패킷을 선별하는 것은 간단한 일이 아니다.\r\n    - 성능, 가격, 사용 편의성 등의 이유로 지금은 패킷 필터링형이 가장 많이 보급되었다.\r\n\r\n2. 패킷 필터링의 조건 설정 개념\r\n    - 패킷의 헤더에는 통신 동작을 제어하는 제어 정보가 들어있으므로 이것을 조사하면 여러 가지 사항을 알 수 있다.\r\n\r\n   ![Untitled - 2021-12-22T173845 973](https://user-images.githubusercontent.com/62014888/147062533-41369835-8073-4908-8e50-1f11fb8b8a74.png)\r\n\r\n   - 현재 예시로 인터넷에서 웹 서버에 대한 액세스를 허가하지 않으면 웹 서버에서 인터넷의 액세스를 금지하도록 패킷을 차단한다. (부정 소프트웨어가 있어 감염 방지)\r\n   - 인터넷에서 보내오는 패킷은 시점을 지정할 수 없지만, 종점은 웹 서버가 된다.\r\n   시점(송신처 IP 주소)은 어디라도 상관없으므로 종점(수신처 IP 주소)이 웹 서버의 IP 주소에 일치하는 패킷은 통과시킨다는 조건을 설정하면 된다.\r\n   - 패킷을 받으면 수신 확인 응답의 구조가 작용하므로 웹 서버에서 인터넷측으로 흐르는 패킷도 있다.\r\n\r\n3. 애플리케이션을 한정할 때 포트 번호를 사용한다\r\n    - 인터넷과 웹 서버 사이를 흐르는 패킷은 전부 통과되므로 웹 이외의 애플리케이션의 패킷을 전부 차단하는 쪽이 좋다.\r\n    - 애플리케이션을 한정할 때는 TCP 헤더나 UDP 헤더에 있는 포트 번호를 조건으로 추가한다.\r\n      이 경우에는 웹 서버 포트 번호인 80번.\r\n\r\n4. 컨트롤 비트로 접속 방향을 판단한다.\r\n    - TCP 헤더에 있는 컨트롤 비트를 조사해서 최초의 패킷과 두 번째 이후의 패킷을 판별할 수 있다.\r\n    - 최초의 패킷이 웹 서버측에서 인터넷측으로 흘러갈 경우 이것을 차단하도록 설정할 수 있다.\r\n        - 표의 2행과 같이 SYN 1, ACK 0일 때 차단한다면 웹 서버가 기점이 되어 인터넷에 액세스하려고 해도 접속 동작이 틀림 없이 실패한다.\r\n    - 인터넷에서 웹 서버에 액세스하는 패킷은 최초의 패킷은 1행의 조건을 만족하므로 패킷 필터링을 통과한다.\r\n      두 번째 패킷은 송신처가 웹 서버를 나타내지만 TCP 컨트롤 비트 조건이 2행과 합치되지 않아 3행을 통과한다.\r\n\r\n   ![Untitled - 2021-12-22T173850 266](https://user-images.githubusercontent.com/62014888/147062544-3b8c23b7-ac17-4a6a-b318-2f6ad13d8da5.png)\r\n\r\n   ![Untitled - 2021-12-22T173900 213](https://user-images.githubusercontent.com/62014888/147062551-b504b1f4-53ce-47e2-81f0-f2e4442ec6a1.png)\r\n\r\n    - 수신처 IP 주소, 송신처 IP 주소, 수신처 포트 번호, 송신처 포트 번호, TCP 컨트롤 비트를 조건으로 사용하고, 통신의 시점, 종점, 애플리케이션의 종류, 액세스 방향을 판별하는 방법을 설명했는데, 조건으로 사용하는 항목은 위와 같이 많다.\r\n      이것을 조합하면 대상이 되는 패킷을 찾아낼 수 있다.\r\n      이렇게 해서 허가하는 액세스 동작에서 흐르는 패킷과 그 외의 패킷을 완전히 선별할 수 있을 때까지 조건을 추가하고 액세스를 허가하는 패킷만 통과시키고, 그 외는 차단하도록 조건을 설정한다.\r\n    - DNS 서버에 조회 동작은 UDP를 사용하다보니 (접속 단계 동작이 없다) 통과시키는 것과 차단하는 것을 완전히 선별할 수 없다.\r\n      이와 같이 UDP를 사용하는 애플리케이션은 패킷을 전부 통과시키거나, 불편을 감수하고 애플리케이션을 전면적으로 차단하는 방법을 선택해야 한다.\r\n\r\n5. 사내 LAN에서 공개 서버용 LAN으로 조건을 설정한다.\r\n    - 인터넷과 공개 서버용 LAN을 왕래하는 패킷의 조건을 설정할 뿐만 아니라 사내 LAN과 인터넷 또는 사내 LAN과 공개 서버용 LAN을 왕래하는 패킷의 조건도 설정해야 한다.\r\n        - 이때 조건이 서로 악영향을 끼치지 않도록 주의해야 한다.\r\n        - 예를 들면 사내 LAN과 공개 서버용 LAN 사이를 자유로이 왕래할 수 있도록 수신처 IP 주소가 공개 서버용 LAN과 일치하는 패킷을 전부 통과시켰다고 가정하자.\r\n          이때 깜빡하고 송신처 IP 주소를 사내 LAN으로 설정해두지 않으면 인터넷에서 흐르는 패킷이 전부 공개 서버용 LAN으로 유입되므로 위험한 상태에 빠질 수 있다.\r\n\r\n6. 밖에서 사내 LAN으로 액세스할 수 없다.\r\n    - 패킷 필터링형 방화벽은 패킷을 통과시킬지, 차단시킬지를 판단할 뿐만 아니라 주소 변환의 기능도 가지고 있으므로 설정도 필요하다.\r\n        - 즉, 인터넷과 사내 LAN을 왕래하는 패킷은 주소 변환을 해야 하므로 설정이 필요하다.\r\n        - 주소 변환을 이용하면 당연히 인터넷측에서 사내 LAN에는 액세스할 수 없게 된다.\r\n        - 따라서 사내 LAN에 대한 액세스를 금지하도록 패킷 필터링의 조건을 설정할 필요가 없다.\r\n\r\n7. 방화벽을 통과한다.\r\n    - 방화벽에는 여러 가지 조건이 설정되어 있어 여기에 패킷이 도착하면 조건에 해당하는지 판정하고, 통과시킬지와 차단할지를 결정함.\r\n    - 판정한 후 차단하는 대상이 되면 패킷을 버리고, 버린 기록을 남김.\r\n        - 패킷 필터링 기능을 가진 라우터를 방화벽으로 사용하는 경우 패킷을 버린 기록을 남기는 일이 드물다. 라우터는 메모리 용량이 작기 때문.\r\n    - 통과시킨다는 판정을 내린 후 패킷을 중계하는데, 이 중계 동작은 라우터의 동작과 같다.\r\n    - 판정 조건이 복잡해지거나 패킷을 버린 기록을 남길 때는 전용 하드웨어나 소프트웨어를 사용하고 그게 아닐 경우 패킷 필터링 기능을 가진 라우터를 방화벽으로 사용할 수 있다.\r\n\r\n8. 방화벽으로 막을 수 없는 공격\r\n    - 방화벽은 시점과 종점을 보고 통과시킬지, 차단할지 판단하기에 이는 위험한 패킷을 전부 판단할 수 있는 것은 아니다.\r\n    - 특수한 데이터를 포함한 패킷을 받으면 웹 서버가 다운된다는 상황에서 시점과 종점이 일치한 패킷을 통과시켰다가 웹 서버가 다운될 수 있다.\r\n\r\n      이 상황에서 두 가지 대처법이 있다.\r\n\r\n        - 버그를 고쳐서 다운되지 않도록 하는 것.\r\n            - 보안 정보 구멍을 수집하여 항상 새로운 버전으로 갱신하는 것이 중요\r\n        - 패킷의 내용을 조사하여 위험한 데이터가 포함되어 있는 경우에 패킷을 차단하도록 장치나 소프트웨어를 방화벽과는 별도로 준비하는 방법.\r\n\r\n<br/>\r\n\r\n## 03 복수 서버에 리퀘스트를 분배한 서버의 부하 분산\r\n\r\n1. 처리 능력이 부족하면 복수 서버로 부하 분산된다.\r\n    - 복수의 서버를 사용하여 처리를 분담하는 방법으로 서버 한 대당 처리량을 줄이는 것이 효과적.\r\n        - 이를 분산 처리라고 하는데, 처리를 분담하는 방식은 여러 가지이다.\r\n    - 가장 간단한 방법은 단순히 여러 대의 웹 서버를 설치하고 한 대가 담당하는 사용자 수를 줄이는 방법.\r\n        - DNS 서버에서 분배하는 방법이 가장 간단함.\r\n\r\n            ![Untitled - 2021-12-22T173904 618](https://user-images.githubusercontent.com/62014888/147062560-efd66c78-bc7b-4cbe-b712-4ff587c2f084.png)\r\n\r\n            - DNS 서버에 같은 이름으로 여러 대의 웹 서버를 등록함.\r\n            - DNS 서버는 조회가 있을 때마다 차례대로 IP 주소를 되돌려주는 라운드 로빈 방식을 사용해서 복수의 서버에 균등하게 액세스를 분산시킬 수 있음.\r\n            - 웹 서버가 고장난 경우 DNS 서버는 웹 서버가 동작하지 않는지 확인하지 못해 정지해도 상관없이 IP 주소를 회답해 버린다. (최근에는 많은 브라우저가 회답한 IP 주소의 맨 앞에서 액세스에 실패한다면 다음 IP 주소를 시도한다)\r\n            - 또한 라운드 로빈에서 차례대로 웹 서버를 분배할 때 복수의 페이지를 사용하는 애플리케이션의 경우 웹 서버가 변하면 대화가 도중에 끊길 수 있다.\r\n\r\n2. 부하 분산 장치를 이용해 복수의 웹 서버로 분할된다\r\n    - 위와 같은 좋지 않은 상태를 피하기 위해 부하 분산 장치 또는 로드 밸러서 등으로 부르는 기기가 고안되었다.\r\n\r\n   ![Untitled - 2021-12-22T173909 361](https://user-images.githubusercontent.com/62014888/147062592-f0e5c1f0-6d4e-420e-9de6-d0abc6fa06d1.png)\r\n\r\n    - DNS 서버에 웹 서버 대신 부하 분산 장치를 등록한다.\r\n        - 클라이언트는 부하 분산 장치가 웹 서버라고 생각하여 여기에 리퀘스트 메시지를 보내야 할지 판단하고, 웹 서버에 리퀘스트 메시지를 전송한다.\r\n          (부하 분산 장치는 캐시 서버와 비슷한 장치 또는 캐시 서버를 발전시킨 것이라고 생각해도 좋다)\r\n    - 대화가 복수의 페이지에 걸쳐있는지에 따라 어느 웹 서버에 전송할지 판단 기준이 달라진다.\r\n        - 복수 페이지에 걸쳐있지 않다면 웹 서버의 부하 상태가 판단 근거가 될 것이다.\r\n        - 복수 페이지에 걸쳐있다면 웹 서버의 부하에 관계 없이 이전의 리퀘스트와 같은 웹 서버에 전송해야 한다.\r\n            - HTTP 프로토콜은 의도적으로 웹 서버에 액세스할 때마다 TCP 접속 동작이 수행되도록 만들어짐.\r\n            - 송신처 IP 주소도 프록시를 사용하다 보니 클라이언트가 누구인지 몰라 판별할 수 없음.\r\n            - 양식에 입력한 데이터를 보낼 때 그 안에 전후의 관련을 나타내는 정보를 부가하거나 HTTP 사양을 확장하여 전후 관계를 판단하기 위한 정보를 HTTP 헤더 필드에 부가하는 방법을 사용한다.\r\n            - 부하 분산 장치는 이 정보를 조사해서 일련의 동작이라면 이전과 같은 웹 서버에 리퀘스트를 전송하고, 그렇지 않으면 부하가 적은 웹 서버에 전송하도록 동작한다.\r\n\r\n<br/>\r\n\r\n## 04 캐시 서버를 이용한 서버의 부하 분산\r\n\r\n1. 캐시 서버의 이용\r\n    - 캐시 서버는 프록시라는 구조를 사용하여 데이터를 캐시에 저장하는 서버.\r\n        - 프록시는 웹 서버와 클라이언트 사이에 들어가서 웹 서버에 대한 액세스 동작을 중개함.\r\n        - 웹 서버에서 받은 데이터를 디스크에 저장해 두고 웹 서버를 대신하여 데이터를 클라이언트에 반송하는 기능을 캐시라고 부름. 캐시 서버는 이 기능을 이용.\r\n        - 웹 서버보다 빨리 데이터를 송신할 수 있음.\r\n        - 언제든지 캐시의 데이터를 이용할 수 있는 것은 아니지만 액세스 동작의 일정 부분은 웹 서버를 번거롭게 하지 않고 캐시 서버에서 처리할 수 있음.\r\n          또한 얼마라도 캐시 서버에서 액세스 동작을 고속화할 수 있으면 전체 성능이 향상된다고 생각.\r\n\r\n2. 캐시 서버는 갱신일로 콘텐츠를 관리한다\r\n\r\n   ![Untitled - 2021-12-23T144649 049](https://user-images.githubusercontent.com/62014888/147194188-81c1a52a-8538-4393-97b3-a6d8f77fcb8e.png)\r\n\r\n    - 캐시 서버를 웹 서버 대신 DNS 서버에 등록한다.\r\n    - 클라이언트에서 캐시 서버로 리퀘스트 메시지를 보낸다.\r\n    - 캐시 서버는 리퀘스트 메시지의 내용을 조사하고, 데이터가 자신의 캐시에 저장되었는지 조사한다.\r\n\r\n    1) 데이터가 캐시에 저장되어 있지 않은 경우\r\n\r\n    - 캐시 서버를 경유한 것을 나타내는 'Via'라는 헤더 필드를 추가하여 웹 서버에 리퀘스트를 전송한다.\r\n    - 웹 서버가 한 대밖에 없으면 웹 서버의 도메인명이나 IP 주소를 캐시 서버에 설정해 두고 무조건 거기에 전송하는 방법을 취한다.\r\n      그게 아니면 몇 가지 방법 중 리퀘스트 메시지의 URI에 쓰여 있는 디렉토리로 판단하는 방법이 있다.  \r\n      URI가 /dir1/ → www1.lab.cyber.co.kr  \r\n      URI가 /dir2/ → www2.lab.cyber.co.kr\r\n    - 전송 대상의 웹 서버에 캐시 서버가 클라이언트가 되어 리퀘스트 메시지를 보낸다.\r\n    - 웹 서버에서 캐시 서버에 응답 메시지가 돌아오므로 캐시 서버가 그것을 받는다.\r\n    - 응답 메시지에 캐시 서버를 경유한 것을 나타내는 'Via' 헤더 필드를 부가하며, 클라이언트에 대해 웹 서버가 되어 응답 메시지를 전송한다.\r\n    - 응답 메시지를 캐시에 저장한 일시를 기록한다\r\n\r\n    2) 데이터가 캐시에 저장되어 있는 경우\r\n\r\n    - 웹 서버측에서 데이터가 변경되었는지 조사하기 위한 'If-Modified-Since'라는 헤더 필드를 추가하여 'Via'와 함께 웹 서버에 전송한다.\r\n    - 웹 서버는 'If-Modified-Since' 헤더 필드의 값과 페이지 데이터의 최종 갱신 일시를 비교하여 변경이 없으면 '304 Not Modified'와 함께 응답 메시지를 반송한다.\r\n        - 페이지 데이터를 반송하는 것보다 부담이 적어지고, 응답 메시지도 짧다.\r\n    - 데이터가 변경된 경우에는 캐시에 데이터가 저장되어 있지 않은 경우와 같다.\r\n\r\n\r\n3. 프록시의 원점은 포워드 프록시이다.\r\n    - 지금까지는 웹 서버측에 두고 캐시 기능을 사용하는 프록시를 설명한 것.\r\n    - 클라이언트측에 캐시 서버를 두는 방법도 있다.\r\n    - 프록시는 원래 클라이언트측에 두는 방법에서 시작되었고 이 유형이 프록시의 원형으로, 포워드 프록시라고 한다.\r\n        - 처음 등장했을 때 캐시를 이용하는 것이 목적이었지만 방화벽을 실현한다는 중요한 목적이 하나 더 있었다.\r\n        - 프록시에서 리퀘스트 메시지를 일단 받아서 인터넷을 향해 전송하면 필요한 것을 통과시킬 수 있다는 개념.\r\n            - 리퀘스트의 내용을 조사한 후 전송하였다. 패킷 필터링형 방화벽이라면 IP 주소나 포트 번호만 사용하므로 이렇게까지 자세히 조건을 설정하는 것은 불가능.\r\n        - 보통 브라우저의 설정 화면에 준비되어 있는 프록시 서버라는 항목에 포워드 프록시의 IP 주소를 설정한다.\r\n            - 설정하면 URL의 내용에 상관없이 리퀘스트 전부 포워드 프록시에 보내고 URL 그대로 리퀘스트 URL에 기록한다.\r\n        - 서버측에 두는 캐시 서버와 같이 전송 대상의 웹 서버를 사전에 설정해 둘 필요는 없고, 모든 웹 서버에 전송할 수 있다.\r\n\r\n4. 포워드 프록시를 개량한 리버스 프록시\r\n    - 포워드 프록시는 브라우저에 대한 설정이 꼭 필요한게 특징이다.\r\n        - 브라우저의 설정이 번거롭고 잘못 설정할 경우 브라우저가 제대로 작동하지 않는 장애의 원인이 되기도 함.\r\n        - 인터넷에 공개하는 웹 서버는 누가 액세스하는지 알 수 없고, 브라우저에 프록시를 설정할 수 없기 때문에 웹 서버의 바로 앞에 프록시를 두는 방법을 선택하지 않음\r\n        - 브라우저에 프록시를 설정하지 않아도 사용할 수 있도록 개량되었음.\r\n          URI에 쓰여있는 디렉토리명과 전송 대상의 웹 서버를 대응시키도록 함.\r\n        - 서버측에 설치하는 캐시 서버에 채택하고 있는 방식으로, 리버스 프록시라고 부름.\r\n\r\n5. 트랜스페어런트 프록시\r\n    - 캐시 서버에서 전송 대상을 판단하는 방법, 즉 리퀘스트 메시지에서 패킷의 헤더를 조사하는 방법이 있음.\r\n    - 패킷 IP 헤더를 조사하여 액세스 대상 웹 서버를 알 수 있는데 이를 사용하는 것이 트랜스페어런트 프록시라고 부른다.\r\n        - HTTP 1.1 버전에서는 웹 서버를 나타내는 'Host'라는 헤더 필드가 추가됨.\r\n    - 이를 이용하면 보통의 리퀘스트 메시지를 전송할 수 있으므로 포워드 프록시처럼 브라우저에 설정할 필요가 없고 전송 대상을 캐시 서버에 설정할 필요도 없으며, 어느 웹 서버에서나 전송할 수 있다.\r\n        - 포워드 프록시와 리버스 프록시의 좋은 점만 모은 형태다.\r\n    - DNS 서버에 등록하는 것이 아니기에 (DNS 서버에 등록하면 프록시 자체가 액세스 대상이 되어 수신처 IP 주소로 전송 대상의 웹 서버를 판단한다는 중요한 구조를 이용할 수 없다) 리퀘스트 메시지를 건네주는 방법을 주의해야 한다.\r\n        - 브라우저에서 웹 서버로 리퀘스트 메시지가 흘러가는 길에 프록시를 설치하고 메시지가 통과할 때 가로챈다.\r\n    - 트랜스페어런트 프록시를 사용하면 사용자가 프록시의 존재를 알아차릴 필요가 거의 없다. 따라서 HTTP 메시지를 전송한다는 구조에 대한 관심이 적어지고 캐시를 이용한다는 측면에서 비중이 높아지고 있다.\r\n\r\n<br/>\r\n\r\n## 05 콘텐츠 배포 서비스\r\n\r\n1. 콘텐츠 배포 서비스를 이용한 부하 분산\r\n\r\n   ![Untitled - 2021-12-22T174113 839](https://user-images.githubusercontent.com/62014888/147062877-0827f642-859a-4441-8708-086cadc71411.png)\r\n\r\n    - 서버측에 캐시 서버를 두는 방법은 웹 서버의 부하를 경감하는 효과는 있지만, 인터넷을 흐르는 트래픽을 억제하는 효과는 없다.\r\n    - 클라이언트측에 캐시 서버를 두는 방법은 패킷의 흐름이 안정되어 트래픽이 줄어들지만 웹 서버 운영자가 제어할 수 없다.\r\n      용량을 높이고 싶어도 그럴 수 없으며 심지어 클라이언트측에 캐시 서버가 있다고 단정할 수 없다.\r\n    - 양쪽의 좋은 점을 취한 웹 서버 운영자가 제어할 수 있는 캐시 서버를 클라이언트측의 프로바이더에 두는 방법이 있다.\r\n        - 이를 위해 캐시 서버를 설치하고, 이것을 웹 서버 운영자에게 대출하는 서비스를 제공하는 사업자가 등장했는데, 이 종류의 서비스를 콘텐츠 배포 서비스(CDS)라고 한다.\r\n        - CDSP가 설치한 캐시 서버를 다수의 웹 서버 운영자가 공동으로 이용할 수 있어 한 회사당 비용을 절감할 수 있다.\r\n\r\n2. 가장 가까운 캐시 서버의 관점\r\n    - 콘텐츠 배포 서비스를 사용하는 경우 인터넷 전체에 설치된 다수의 캐시 서버를 이용한다.\r\n    - 이 상황에서는 다수가 있는 캐시 서버 중에서 가장 가까운 캐시 서버를 찾아내고, 클라이언트가 여기에 액세스하도록 중재하는 구조가 필요하다.\r\n    - 이를 위해 DNS 서버가 웹 서버의 IP 주소를 회답할 때 가장 가까운 캐시 서버의 IP 주소를 회답하도록 DNS 서버를 세밀하게 설정하는 방법이 있다.\r\n        - DNS 서버에 복수의 IP를 등록시켜 라운드 로빈이 아닌 클라이언트와 캐시 서버의 거리를 판단하여 클라이언트에 가장 가까운 캐시 서버 IP 주소를 회답하도록 설정한다.\r\n        - 서버측의 DNS 서버에 캐시 서버 라우터의 경로표를 입수해서 정보를 모아둔다.\r\n        - 경로표를 사용해 클라이언트측의 DNS 서버에 이르는 경로 정보를 조사한다.\r\n            - 라우터에서 클라이언트측의 DNS 서버까지의 경로를 알 수 있고 인터넷 내부의 경로 정보에는 어떤 프로바이더를 지나는지 경로가 기록되어 있으므로 대략적인 거리를 알 수 있음.\r\n        - 이것을 모든 라우터에 대해 조사하고 비교하면 어느 라우터가 클라이언트측의 DNS 서버에 가장 가까운지 알 수 있다.\r\n        - 실제로 클라이언트측의 DNS 서버와 클라이언트가 같은 장소에 있는 것은 아니지만 웬만큼 정확하게 거리를 측정할 수 있다.\r\n\r\n3. 리피터용 서버로 액세스 대상을 분배한다.\r\n    - 'Location' 헤더를 통해 리다이렉트를 사용해 액세스 대상을 가장 가까운 캐시 서버로 돌리는 방법도 있다.\r\n        - 리다이렉트용 서버를 웹 서버측의 DNS 서버에 등록한다.\r\n        - 클라이언트는 리다이렉트용 서버에 HTTP 리퀘스트 메시지를 보낸다.\r\n        - 리다이렉트용 서버에는 DNS 서버와 같이 라우터에서 모든 경로 정보가 있어 가장 가까운 캐시 서버를 찾아낸다.\r\n        - Location 헤더를 붙여 응답을 돌려보내면 클라이언트는 캐시 서버에 다시 액세스한다.\r\n    - HTTP 메시지의 대화가 증가해 오버헤드가 많지만 장점도 있다.\r\n        - 클라이언트가 보내는 HTTP 메시지의 송신처 IP 주소를 바탕으로 거리를 판단하므로 정밀도가 높다.\r\n          (클라이언트측의 DNS 서버와 캐시 서버의 거리를 계산하는 것이 아니므로)\r\n    - 패킷의 왕복 시간을 통해 캐시 서버까지의 거리를 계산하여 최적의 캐시 서버에 액세스하도록 스크립트 프로그램을 내장한 페이지를 반송하는 방법도 있다.\r\n        - 이 페이지에는 몇 개의 캐시 서버에 시험적으로 패킷을 보내고 왕복 시간을 계측한 후 가장 왕복 시간이 짧은 캐시 서버에 리퀘스트를 다시 보낸다는 내용의 리퀘스트 프로그램을 내장해 둔다.\r\n\r\n4. 캐시 내용의 갱신 방법에서 성능의 차이가 난다\r\n    - 웹 서버에서 원래 데이터를 갱신할 경우 이것을 즉시 캐시 서버에 반영하면 성능이 올라간다.\r\n        - 캐시의 데이터는 항상 최신 상태를 유지할 수 있으므로 원래 데이터의 갱신을 확인할 필요가 없게 되고, 최초의 액세스 동작에도 캐시 데이터를 이용할 수 있다.\r\n        - 콘텐츠 배포 서비스에 이용하는 캐시 서버에는 이러한 대책이 내장되어 있음.\r\n    - 동적으로 페이지를 만드는 경우 캐시 서버에 데이터를 저장해 두면 안된다. 이 경우 페이지 전체를 캐시에 저장하지 않고 매번 페이지의 내용이 달라지는 부분과 달라지지 않는 부분을 구분하고 변하지 않는 부분만 캐시에 저장해야 한다.","excerpt":"'성공과 실패를 결정하는 1%의 네트워크 원리' 스터디를 진행하며 정리한 내용이다. 01 웹 서버의 설치 장소 사내에 웹 서버를 설치하는 경우 인터넷을 빠져나와 서버에 도착할 때까지의 여정은 서버의 설치 장소에 따라 다름. Untitled - 202…","fields":{"slug":"/1per-network-ch5/"},"frontmatter":{"date":"Oct 05, 2021","title":"[성공과 실패를 결정하는 1%의 네트워크 원리] 5장","tags":["network","book","1per-network"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n## 프로젝트 로깅 문제\r\n\r\n- 현재 보또보 프로젝트에서는 로깅을 위해 Logback을 사용하고 있다.\r\n- 기본적으로 스프링에서 생기는 로그 + HTTP 요청 응답 로그 + JPA로 생기는 쿼리와 바인딩 데이터 로그를 남기기로 했다.\r\n- Local, Test 환경에서는 콘솔에 로그를 출력시키기만 했고 Dev, Prod 환경에서는 INFO, WARN, ERROR 로그, HTTP 요청 응답 로그, 쿼리 + 바인딩 데이터 로그를 파일로 남기기로 했다.\r\n    - 더 자세한 것은 [보또보 위키](https://github.com/woowacourse-teams/2021-botobo/wiki/로깅-전략) 를 참고하자!  \r\n\r\n- 문제는 쿼리 + 바인딩 데이터 로그에서 시작되었다.\r\n- 다양한 문제집 보기라는 보또보 사이트에서 제공해주는 기능이 있다.\r\n  이 기능은 사이트 내 등록이 되어있는 문제집 중 랜덤으로 100개를 제공해주는 기능이다.\r\n- 100개의 문제집을 조회하기 위해서는 하나의 조회문에서 파생되는 여러 조회문이 있었고 (한방 쿼리를 사용하기에는 연관관계가 너무 많고 N+1 문제를 해결하기 위해 Batch Size를 설정했다) 그러다보니 쿼리문 + 바인딩된 데이터 로그가 정말 많이 발생하게 되었다.\r\n\r\n그 결과 한번 서비스를 접근해서 100개의 문제집을 제공 받기까지 사용자 입장에서 시간이 너무 오래걸렸다.\r\n- 일단 Prod 서버에는 쿼리 + 바인딩 데이터 로그를 남기지 않기기로 했다.\r\n  우리가 이 로그를 남기기로 했는 이유는 최대한 로그를 많이 남기는게 에러를 추적하기 용이하다 + 한번 로그를 다 남겨보자 였다.\r\n  검색해보니 이 로그는 보통 테스트하는 환경에서 남기고 실제 운영 서버에서는 남기지 않는 경우가 많다기에 Prod 서버에서는 남기지 않기로 하였고 그 결과 로딩 시간이 단축되는 현상을 볼 수 있었다.\r\n\r\n하지만 여전히 Dev 서버에는 로그를 남기고 있었기에 어떻게 하면 로그를 남기면서 성능을 향상시킬 수 있을까 고민했다.\r\n\r\n## 비동기 로깅\r\n\r\n- 현재 Logback에서 로그를 동기로 남기고 있었고 비동기로 남기면 성능이 향상될 수 있다는 이야기를 들었고 이에 비동기로 로깅을 변경해보기로 했다.\r\n\r\n```xml\r\n<included>\r\n    <property name=\"QUERY_LOG_PATH\" value=\"logs/query\"/>\r\n    <property name=\"QUERY_LOG_FILE_NAME\" value=\"query\"/>\r\n\r\n    <appender name=\"QUERY_FILE\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\">\r\n        <filter class=\"ch.qos.logback.classic.filter.LevelFilter\">\r\n            <level>TRACE</level>\r\n        </filter>\r\n\r\n        <encoder>\r\n            <pattern>\r\n                %d{yyyy-MM-dd HH:mm:ss} %n    > %msg%n\r\n            </pattern>\r\n        </encoder>\r\n\r\n        <rollingPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy\">\r\n            <fileNamePattern>${QUERY_LOG_PATH}/${QUERY_LOG_FILE_NAME}.%d{yyyy-MM-dd}_%i.log</fileNamePattern>\r\n            <maxFileSize>3MB</maxFileSize>\r\n            <maxHistory>100</maxHistory>\r\n        </rollingPolicy>\r\n    </appender>\r\n\r\n\t\t// AsyncAppender 설정\r\n    <appender name=\"QUERY_FILE_ASYNC\" class=\"ch.qos.logback.classic.AsyncAppender\">\r\n        <appender-ref ref=\"QUERY_FILE\" />\r\n        <queueSize>512</queueSize>\r\n        <discardingThreshold>0</discardingThreshold>\r\n        <includeCallerData>false</includeCallerData>\r\n        <neverBlock>true</neverBlock>\r\n        <maxFlushTime>1000</maxFlushTime>\r\n    </appender>\r\n\r\n    <logger name=\"org.hibernate.SQL\" level=\"DEBUG\" additivity=\"false\">\r\n        <appender-ref ref=\"QUERY_FILE_ASYNC\"/>\r\n    </logger>\r\n    <logger name=\"org.hibernate.type.descriptor.sql.BasicBinder\" level=\"TRACE\" additivity=\"false\">\r\n        <appender-ref ref=\"QUERY_FILE_ASYNC\"/>\r\n    </logger>\r\n    <logger name=\"org.hibernate.type.descriptor.sql.BasicExtractor\" level=\"TRACE\" additivity=\"false\">\r\n        <appender-ref ref=\"QUERY_FILE_ASYNC\"/>\r\n    </logger>\r\n\r\n</included>\r\n```\r\n\r\n- 적용 방법은 생각보다 간단했다.\r\n    - 파일로 남기는 설정인 RollingFileAppender를 AsyncAppender로 감싸기만 하면 되었다.\r\n\r\n- 각각의 AsyncAppender 설정 옵션은 이렇다.\r\n    1. queueSize\r\n        - async로 동작하기 위해서는 log들을 BlockingQueue를 이용해 버퍼에 저장해 둔다. 버퍼에 저장해두는 queue의 사이즈를 의미하며 해당 queue 사이즈의 80%가 초과하게 되면 WARN, ERROR를 제외하고 drop한다. 따라서 적절한 queueSize를 사용해야 하며 default는 256이다.\r\n          밑에 사이트를 바탕으로 512로 설정하였다.\r\n\r\n            ![Untitled - 2021-12-18T135152 434](https://user-images.githubusercontent.com/62014888/146629449-4622b679-2300-4e54-b6e1-59e1633bf6e7.png)\r\n\r\n            - [https://dzone.com/articles/how-instantly-improve-your-0](https://dzone.com/articles/how-instantly-improve-your-0)\r\n    2. discardingThreshold\r\n        - 기본적으로 blocking queue에 20% 용량이 남아 있으면 TRACE, DEBUG 및 INFO 수준의 이벤트를 삭제하고 WARN 및 ERROR 수준의 이벤트만 유지한다. 이 값을 0으로 설정하면 모든 이벤트를 유지한다. default는 20이다.\r\n          INFO 로그를 삭제하고 싶지않아서 0으로 설정했다.\r\n    3. includeCallData\r\n        - 발신자의 정보(class명, 줄번호 등)가 추가되어 수집 서버로 전송여부를 결정한다. true 설정 시 성능 저하를 일으킬 수 있다. default는 false이다. 성능 문제로 인해 false를 권장하지만 false로 설정할 경우에는 class, method, line 수 등을 로그에서 확인할 수 없다. 실제로 false로 설정했을 때 ?.?.? 이런 형식으로 로그가 남는 결과를 볼 수 있었다.\r\n    4. maxFlushTime\r\n        - LoggerContext가 정지하면 AsyncAppender의 stop 메서드는 작업 스레드가 timeout 될 때까지 대기한다. maxFlushTime을 사용하면 timeout 시간을 밀리초로 설정할 수 있다. 해당 시간안에 처리하지 못한 이벤트는 삭제된다. defult는 1000이다.\r\n    5. neverBlock\r\n        - queue에 가득차게 되는 경우 다른 쓰레드의 작업들이 blocking 상태에 빠지게 되는데 해당 옵션을 true하게 되면 blocking 상태에 빠지지 않고 log를 drop하며 계속 진행할 수 있게 해준다. 로그의 버퍼가 꽉 차서 application이 blocking되지 않기 위해 반드시 true를 적용하는 것을 권장한다. default는 false이다.\r\n\r\n\r\n## 비동기 적용 결과\r\n\r\n- 적용하고 성능 테스트를 해보았다.\r\n- 생각보다 결과가 흥미로웠다.\r\n- 성능 테스트 도구로 k6를 사용했다. 설정은 다음과 같다.\r\n    - VUSER는 100명\r\n    - 1분동안 진행\r\n    - 모든 요청의 99% 이상의 소요시간이 1500ms 이내에 들어야 한다.\r\n    - 모든 요청은 다양한 문제집 보기 서비스에 접근하여 100개의 문제집을 조회하도록 하였다.\r\n\r\n- 비동기 로깅 적용 전\r\n\r\n    ![Screen_Shot_2021-09-29_at_5 51 26_PM (1)](https://user-images.githubusercontent.com/62014888/146629455-3582b1e2-4a26-460a-b855-59c80dfdca25.png)\r\n\r\n\r\n주목할 점은 http&#95;req&#95;duration, http&#95;req&#95;failed, \r\nhttp_reqs이다.\r\n\r\nhttp&#95;req&#95;duration은 평균적으로 한번의 요청당 얼마만큼의 시간이 소요되었는지를 알 수 있는데 평균 31초가 걸렸다고 적혀있다.\r\n\r\nhttp&#95;req&#95;failed는 요청 실패율,\r\nhttp_reqs는 총 요청 수를 나타낸다.\r\n73.50%의 실패율과 요청 수가 151개로 측정되었다.\r\n\r\n- 비동기 로깅 적용 후\r\n\r\n    ![Screen_Shot_2021-09-29_at_6 26 02_PM (1)](https://user-images.githubusercontent.com/62014888/146629461-807d2b5d-df69-4bb8-bfc0-55c35f37824a.png)\r\n\r\n\r\n로깅 전과 비교해보면 확실하게 성능이 좋아졌다는 것을 볼 수 있다.\r\n\r\n요청 소요 시간도 평균 4.85초로 줄어들었으며 실패율도 0%, 그에 따라 요청 수도 680개로 이를 모두 처리했다는 결과를 볼 수 있었다.\r\n\r\n## 그렇다면 꼭 비동기로 로깅을 해야할까?\r\n\r\n- 그렇다면 앞으로 모든 로깅을 비동기로 처리해야할까?\r\n- 일단 이렇게 비동기로 로깅을 처리하게 되면 단점들이 몇 가지 있다고 한다.\r\n    - queueSize를 너무 작게 하는 경우 WARN, ERROR를 제외하고 로그의 손실을 가져올 수 있다.\r\n    - 버퍼를 이용하니 메모리의 사용량이 증가하고 CPU 사용량 또한 증가한다.\r\n    - 중간에 서버가 다운되는 경우 버퍼에 로그가 남아 있으면 버퍼가 로그를 다 쓰기 전에 종료되어 손실이 발생한다.\r\n- 개인적인 생각으로 어느 정도 규모가 있고 로그를 많이 남겨야 하는 서비스에서는 비동기로 로깅을 하지 않을 이유는 없다고 생각한다. 비동기로 로그를 남기는게 성능상 이점을 더 챙겨올 수 있고 로그 손실 이슈에 경우는 설정만 잘 해놓으면 어느 정도 방지할 수도 있으니 말이다.\r\n- 그리고 Logback 비동기를 좀 찾아보니 Log4j2 비동기가 훨씬 더 성능상 좋은거 같았다.\r\n  로깅을 남기면서 성능상의 이점을 더 챙기려면 Log4j2를 가지고 가는 것도 좋은것 같으니 필요하면 찾아보도록 하자.\r\n\r\n![Untitled - 2021-12-18T135205 226](https://user-images.githubusercontent.com/62014888/146629463-64520617-fa7d-403c-89de-d421d8f5a663.png)\r\n\r\n[https://logging.apache.org/log4j/2.x/performance.html](https://logging.apache.org/log4j/2.x/performance.html)\r\n\r\n## 마무리\r\n\r\n- 로깅을 비동기로 바꿨을 뿐인데 이렇게 눈에 띄는 성능 차이를 보일 줄은 몰랐다.\r\n- 생각보다 성능 테스트를 하는게 재밌었다.\r\n- 다만 아쉬운점은 테스트용 서버를 따로 구축해서 테스트를 한 것이 아닌 기존 Dev 서버에서 진행했다는 점.\r\n  Redis를 도입하게 될 경우도 생각하면 테스트용 서버를 하나 만들어서 대량의 데이터를 넣어두고 VUSER를 더 높인 테스트를 진행해봐야겠다.","excerpt":"프로젝트 로깅 문제 현재 보또보 프로젝트에서는 로깅을 위해 Logback을 사용하고 있다. 기본적으로 스프링에서 생기는 로그 + HTTP 요청 응답 로그 + JPA로 생기는 쿼리와 바인딩 데이터 로그를 남기기로 했다. Local, Test 환경에서는…","fields":{"slug":"/async-logging/"},"frontmatter":{"date":"Oct 02, 2021","title":"로깅이 성능에 미치는 영향과 비동기 로깅","tags":["spring","logback"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n'성공과 실패를 결정하는 1%의 네트워크 원리' 스터디를 진행하며 정리한 내용이다.\r\n\r\n---\r\n\r\n## 01 케이블과 리피터, 허브 속을 신호가 흘러간다\r\n\r\n1. 하나하나의 패킷이 독립된 것으로 동작한다.\r\n    - 중계 동작은 패킷의 헤더에 기록된 제어 정보와 중계 장치의 내부에 있는 중계 대상을 등록한 표로 목적지를 판단하고 목적지에 가까워지도록 하여 패킷을 중계한다는 형태\r\n        - 내용은 보질 않기에 애플리케이션 데이터나 TCP 프로토콜의 제어 정보의 내용은 패킷을 운반하는 동작에 영향을 주지 않는다.\r\n        - 따라서 모든 패킷은 아무 관련도 없는 별개의 것으로 간주하고 목적지를 향해 중계된다.\r\n\r\n2. LAN 케이블은 신호를 약화시키지 않는 것이 핵심이다.\r\n    - 이더넷 신호의 실체는 플러스와 마이너스의 전압이므로 LAN 어댑처의 PHY(MAU) 회로의 플러스와 마이너스 신호 단자에서 신호가 나온다고 생각.\r\n    - 신호는 케이블 속을 흘러 리피터 허브의 커넥터 부분에 도착하고, 이 부분은 단순히 전기 신호카 케이블을 통해 전달되는 것뿐.\r\n    - 케이블을 통과하는 사이에 신호의 에너지가 조금씩 떨어지므로 케이블의 길이가 길어질수록 신호가 약해짐.\r\n\r\n3. '꼼'은 잡음을 방지하기 위한 방법이다.\r\n    - LAN 케이블로 사용하는 트위스트 페어 케이블(꼰 선쌍)에는 이러한 잡음의 영향을 억제하는 대책이 마련되어 있는데, 이것이 '꼼'이다.\r\n        - 신호선을 마주 꼬아서 잡음을 막을 수 있다.\r\n\r\n4. 리피터 허브는 연결되어 있는 전체 케이블에 신호를 송신한다.\r\n    - 신호가 리피터 허브에 도달하면 LAN 전체에 신호가 흩어진다.\r\n    - 리피터 허브에서 PHY(MAU) 회로의 수신부에 도달한 신호는 여기부터 리피터 회로에 들어간다. 리피터 회로의 기본은 들어오는 신호를 리피터 허브의 커넥터 부분에 뿌리는 데 있다.\r\n    - 리피터 회로의 기본은 신호를 그대로 뿌리는 것이므로 잡음의 영향을 받아 변형되고, 데이터가 변화한 것 같은 신호라도 그대로 흘려버린다.\r\n        - 다음 기기에 도달하여 디지털 데이터로 변환되고, FCS를 검사하는 곳에서 데이터 변화가 판명된 후 변화된 패킷은 폐기한다.\r\n          패킷을 폐기하면 수신 확인 응답을 되돌려주지 않으므로 프로토콜 스택의 TCP 담당 부분이 패킷을 다시 보낸다.\r\n\r\n<br/>\r\n\r\n## 02 스위칭 허브의 패킷 중계 동작\r\n\r\n1. 스위칭 허브는 주소 테이블로 중계한다\r\n    - 스위칭 허브는 이더넷의 패킷을 그대로 목적지를 향해 중계하도록 만들어져 있다.\r\n    - 신호가 커넥터 부분에 도달하여 PHY(MAU) 회로에서 수신되는 부분까지는 리피터 허브와 같다.\r\n    - PHY(MAU) 회로에서 케이블을 흐르는 신호의 형식부터 공통의 신호 형식으로 변환한 후 신호는 MAC 회로에 들어간다.\r\n    - 디지털 데이터로 변환한 후 패킷의 맨 끝에 있는 FCS를 대조하여 오류의 유무를 검사하고, 문제가 없으면 버퍼 메모리에 저장한다.\r\n    - 커넥터와 안쪽에 있는 회로 부분은 포트라고 부르므로 스위칭 허브의 각 포트는 PC의 LAN 어댑터와 거의 같다.\r\n        - LAN 어댑터는 MAC 주소가 할당되어 있어 수신한 패킷의 수신처 MAC 주소가 자신에게 해당하지 않는 경우에는 패킷을 폐기한다.\r\n          반면, 스위칭 허브의 포트는 수신처 MAC 주소를 검사하지 않고 모든 패킷을 버퍼 메모리에 저장하기 때문에 MAC 주소가 할당되어 있지 않다.\r\n    - MAC 주소표를 이용해 MAC 주소가 일치하는지 확인하고 일치하면 스위치 회로를 경유하여 패킷을 송신측 포트에 보낸다.\r\n        - 스위치 회로는 전자 회로로 만든 것으로 스위치의 전자적 개폐를 통해 신호가 흐르는 대상을 제어한다.\r\n    - 송신측의 포트에 패킷을 운반하면 MAC 회로나 PHY(MAU) 회로가 송신 동작을 실행하고 케이블에 신호가 흘러간다.\r\n        - 누군가가 송신 중이면 송신 동작이 끝나거나 아무도 송신하지 않으면 소켓을 디지털 데이터에서 신호로 변환하여 송신함.\r\n        - 송신 동작 중에 다른 기기가 보낸 신호가 수신측에 들어오면 패킷을 충돌하므로 재밍 신호를 보낸 후 송신 동작을 중지하고 잠시 기다렸다 다시 보냄.\r\n\r\n2. MAC 주소 테이블을 등록 및 갱신한다.\r\n    - 스위칭 허브는 패킷을 중계할 때 MAC 주소표의 내용을 갱신하는 동작도 실행한다.\r\n    - 갱신 동작은 두 종류가 있다.\r\n        1. 패킷을 수신했을 때 송신처 MAC 주소를 조사하고, 이것을 수신한 입력 포트 번호와 하나의 세트로 MAC 주소표에 등록한다.\r\n        2. MAC 주소표에 등록되어 있는 내용을 지운다.\r\n            - MAC 주소표에 등록한 정보는 그대로 두는 것이 아니라 사용하지 않고 일정 시간이 경과하면 삭제하는 것.\r\n    - MAC 주소표의 내용은 스위칭 허브 자체가 스스로 등록하거나 삭제하므로 수동으로 등록 및 삭제할 필요가 없다.\r\n\r\n3. 예외적인 동작\r\n    - 스위칭 허브는 패킷을 수신한 포트와 송신하는 포트가 같을 경우 패킷을 중계하지 않고 폐기함.\r\n    - MAC 주소표에 수신처 MAC 주소와 일치하는 주소가 등록되어 있지 않은 경우 어느 포트에 송신해야 할지 판단할 수 없으므로 패킷을 수신한 포트 이외의 전체 포트에게 패킷을 송신한다.\r\n        - 수신처 MAC 주소가 브로드캐스트 주소인 경우에도 수신 포트를 제외하고 모든 포트에서 패킷을 송신함.\r\n\r\n4. 전이중 모드에서 송신과 수신을 동시에 실행한다.\r\n    - 전이중 모드, 즉 송신과 수신을 동시에 실행할 수 있는 성질도 리피터 허브에는 없는 스위칭 허브의 특징이다.\r\n\r\n5. 최적의 전송 속도로 보내는 자동 조정\r\n    - 전이중 모드가 등장한 후 접속한 상대가 전이중 모드를 지원하는지 검출하고 동작 모드를 자동으로 전환하는 기능이 나왔다.\r\n    - 동작 모드뿐만 아니라 상대의 전송 속도를 검출하여 전송 속도도 자동으로 전환하는데, 이 기능을 자동 조정이라고 함.\r\n\r\n6. 스위칭 허브는 복수의 중계 동작을 동시에 실행한다.\r\n    - 스위칭 허브는 수신처 MAC 주소의 기기가 존재하는 포트 이외에는 송신 동작을 실행하지 않으므로 다른 포트는 빈 상태가 된다.\r\n        - 비어있으므로 여기에서 별도의 패킷을 흘릴 수 있으며, 이렇게 해서 동시에 여러 개의 패킷을 중계할 수 있다.\r\n    - 리피터 허브는 들어온 신호를 모든 포트에서 뿌리므로 동시에 두 개 이상의 신호가 들어오면 패킷이 충돌하기 때문에 복수의 신호를 동시에 흘릴 수 없다.\r\n        - 기기 전체에서 중계할 수 있는 패킷의 수는 스위칭 허브쪽이 리피터 허브쪽보다 많다.\r\n\r\n\r\n<br/>\r\n\r\n## 03 라우터의 패킷 중계 동작\r\n\r\n1. 라우터의 기본\r\n    - 리피터 허브나 스위칭 허브를 경유한 패킷은 결국 라우터에 도착하고, 라우터에서 다음 라우터로 중계될 것이다.\r\n    - 라우터의 내부 구조는 중계 부분과 포트 부분으로 구성되어 있다.\r\n        - 중계 부분 - 패킷이 중계 대상을 판단하는 동작을 담당함. IP 담당 부분이라고 생각.\r\n        - 포트 부분 - 패킷을 송, 수신하는 동작을 담당함. LAN 어댑터라고 생각.\r\n          통신 기술의 하드 웨어를 장착하면 다양한 통신 기술을 지원할 수 있음.\r\n        - 포트 부분에서 패킷을 수신하는데, 이 동작은 포트 부분의 통신 기술 규칙을 따름. 포트 부분이 이더넷이라면 이더넷의 규칙을, 무선 LAN이라면 무선 LAN의 규칙을, 통신 회선이면 통신 회선의 규칙을 따름.\r\n          중계 부분에서 받은 패킷의 IP 패킷에 기록되어 있는 수신처 IP 주소와 중계 대상을 등록한 표를 대조하여 중계 대상을 판단함.\r\n        - 포트 부분이 패킷의 송신처 또는 수신처가 되어 패킷을 송, 수신함.\r\n          예를 들어 포트가 이더넷인 경우 라우터의 포트에는 MAC 주소가 할당되어 이더넷의 송신처, 수신처가 됨. 포트에는 IP 주소도 할당됨.\r\n          스위칭 허브는 돌아온 패킷을 전송만 할뿐 자신이 송신처나 수신처가 되지는 않음.\r\n\r\n2. 경로표에 등록된 정보\r\n\r\n   스위칭 허브는 MAC 헤더에 기록되어 있는 수신처 MAC 주소로 중계 대상을 판단하지만, 라우터는 IP 헤더에 기재되어 있는 수신처 IP 주소로 중계 대상을 판단함.\r\n\r\n    - 라우터의 테이블은 라우팅 테이블 또는 경로표라고 부른다.\r\n        - 맨 왼쪽에는 수신처의 정보가 들어있는 수신처 항목이 있다.\r\n            - 수신처의 정보는 서브넷 자체를 나타내는 주소, 즉 네트워크 번호 부분의 비트에만 값이 있고, 호스트 번호 부분의 비트 값은 0으로 되어 있는 IP 주소가 들어있다고 생각하자.\r\n            - 네트워크 번호의 부분만 조사함.\r\n        - 주소 비교 동작을 실행할 때 네트워크 번호의 비트 수를 판단하기 위해 넷마스크 항목도 있음.\r\n        - '수신처' 항목에는 서브넷을 나타내는 IP 주소가 등록되었다고 했지만, 그렇지 않은 경우도 있음.\r\n          실제 서브넷에 할당된 넷마스크의 값과 경로표에 등록된 넷마스크 값이 다를 수 있음.\r\n            - 주소 집약이라는 개념을 이용하면 몇 개의 서브넷을 모아서 한 개의 서브넷으로 간주한 후 묶은 서브넷을 경로표에 등록할 수 있음.\r\n                - 10.10.1.0/24, 10.10.2.0/24, 10.10.3.0/24 3개의 서브넷이 라우터 A와 연결되는 상태에서 라우터 B가 이 서브넷에 패킷을 건네주려고 할 때 라우터 B의 경로표에 3개의 서브넷을 별도로 등록하는 것이 원칙.\r\n                  하지만 다 라우터 A에 패킷을 중계하는 것은 바뀌지 않으므로 통합한 10.10.0.0/16이라는 서브넷이 있는 것으로 간주.\r\n            - 한 개의 서브넷을 세분화하여 경로표에 등록하고, 복수의 서브넷이 있는 것처럼 보이는 경우도 있음.\r\n            - '수신처' 항목에 등록된 네트워크 번호가 실제와 다르더라도 라우터는 제대로 동작하므로 걱정할 필요는 없다.\r\n            - 호스트 번호 부분에 값이 들어있는 개별 컴퓨터를 나타내는 주소를 '수신처'에 등록도 가능. → 넷마스크 값을 255.255.255.255 즉, 32 비트를 전부 1로 만들면 됨.\r\n        - '게이트웨이' 항목과 '인터페이스' 항목은 패킷의 중계 대상을 나타냄.\r\n            - '인터페이스' 항목에 등록되어 있는 인터페이스(포트)에서 '게이트웨이' 항목에 등록되어 있는 IP 주소를 가진 라우터에 대해 패킷을 중계함\r\n        - 메트릭은 수신처 IP 주소에 기록되어 있는 목적지가 가까운지, 먼지를 나타냄.\r\n            - 수가 작으면 목적지가 가까이에 있고, 이 수가 크면 먼 것을 나타냄.\r\n        - 라우터가 경로표에 경로 정보를 등록하거나 갱신하는 동작은 패킷을 중계하는 동작과 분리되어 있음. 즉, 패킷을 중계할 때 경로표의 내용에 손대지 않음.\r\n\r\n          경로 정보 등록 방법\r\n\r\n            1. 사람이 수동으로 경로 정보를 등록/갱신\r\n            2. 라우터 프로토콜이라는 구조를 사용하여 라우터들끼리 경로 정보를 교환하고 라우터가 자체에게 경로표에 등록 (RIP, OSPF, BGP 등등)\r\n\r\n3. 라우터의 패킷 수신 동작\r\n    - 이더넷의 포트에서의 패킷 수신 동작에 초점을 맞추어서 설명\r\n        - LAN 어댑터와 거의 같다\r\n    - 신호가 커넥터 부분에 도착하면 PHY(MAU) 회로, MAC 회로에서 신호를 디지털 데이터로 변환함.\r\n    - 패킷 끝부분의 FCS를 대조하여 오류의 유무를 점검하고, 정상이면 MAC 헤더의 수신처 MAC 주소가 자신에게 해당하는지 조사하여 해당하면 패킷을 수신 버퍼 메모리에 저장함.\r\n        - 수신처 MAC 주소에 자신이 해당하지 않을 경우에는 패킷을 폐기함.\r\n\r\n4. 경로표를 검색하여 출력 포트를 발견한다.\r\n    - 라우터 패킷 수신 동작이 끝나면 맨 앞의 MAC 헤더를 폐기함. MAC 헤더의 수신처 MAC 주소 항목에 라우터의 포트에 할당한 MAC 주소가 기록되어 있음.\r\n    - IP 헤더의 내용을 보고 패킷 중계 동작에 들어감.\r\n\r\n        ![Untitled - 2021-12-22T173052 198](https://user-images.githubusercontent.com/62014888/147061439-732256e7-aaca-44ca-8a54-9d79eadc1f2b.png)\r\n\r\n        - 중계 대상을 조사할 때 가장 먼저 수신한 패킷의 수신처 IP 주소와 경로표의 '수신처' 항목을 조사하여 해당하는 행을 찾음.\r\n            - '넷마스크' 항목에 등록된 값에서 네트워크 번호의 비트 수를 판단하여 네트워크 번호 부분만 비교함.\r\n                - 복수의 후보가 발견되면 네트워크 번호의 비트 수가 가장 긴 것을 찾는다.\r\n                - 네트워크 번호의 비트 수가 길면 호스트 번호의 비트 수가 짧아지는데 이 뜻은 호스트 번호로 할당 가능한 번호의 수가 적다는 뜻.\r\n                - 이는 서브넷에 접속 가능한 대수가 적다는 뜻이므로 서브넷이 작다는 것과 같은 의미이며, 그만큼 범위가 축소됨.\r\n            - 네트워크 번호의 길이가 같다면 가깝다는 뜻으로 메트릭 값이 작은 쪽을 중계 대상으로 선택함.\r\n        - 행이 한 개도 발견되지 않으면 패킷을 폐기하고 ICMP 메시지로 송신처에 이 사실을 통지한다.\r\n            - 라우터는 규모가 크기에 중계 대상을 모르는 패킷을 뿌린다면 대량의 패킷이 뿌려져 네트워크가 혼잡해짐.\r\n\r\n5. 해당하는 경로가 없는 경우에 선택하는 기본 경로\r\n    - '넷마스크' 항목이 0.0.0.0이라는 것은 패킷의 수신처 IP 주소와 경로표의 '수신처' 항목을 비교할 때의 비트 수가 0이라는 것이므로 비교 동작을 실행하지 않아도 됨.\r\n    - 이 행의 '게이트웨이' 항목에 인터넷으로 나가는 라우터를 등록해 두면 다른 행에 해당하는 것이 없는 경우에는 패킷을 그곳으로 중계함.\r\n        - 이 행을 기본 경로라고 하며, 여기에 등록한 라우터를 기본 게이트웨이라고 함.\r\n\r\n6. 패킷은 유효 기간이 있다.\r\n    - 중계 대상을 찾아내면 패킷을 출력측의 포트로 옮기고 여기에서 송신하는데, 그 전에 몇 가지 할 일이 있다.\r\n    - TTL(Time To Live, 생존 기간)이라는 IP 헤더의 필드를 갱신하는 것이다.\r\n        - 라우터를 경유할 때마다 이 값을 1씩 줄이다가 숫자가 0이 되면 패킷을 폐기함.\r\n        - 송신처가 처음 패킷을 송신할 때 64 또는 128이라는 값을 설정함.\r\n        - 인터넷은 지구의 반대편까지 액세스해도 경유하는 라우터 수가 많아야 수십개 정도.\r\n\r\n7. 큰 패킷은 조각 나누기 기능으로 분할한다\r\n    - 라우터 포트 부분은 이더넷뿐만 아니라 이더넷 이외의 LAN이나 통신 회선의 경우도 있다.\r\n        - 회선이나 LAN 종류에 따라 패킷의 최대 길이가 달라지므로 출력 포트측의 패킷의 최대 길이가 입력측보다 작은 경우도 있다.\r\n        - 어느 경우든지 중계하는 패킷의 크기가 출력측의 패킷 최대 길이를 초과하면 그대로는 패킷을 송신할 수 없다.\r\n    - IP 프로토콜에서 규정된 조각 나누기(fragmentation)라는 방법을 사용하여 패킷을 분할하고, 패킷의 길이를 짧게 만든 후 중계한다.\r\n        - TCP가 데이터를 조각으로 분할하는 것과 다름.\r\n        - TCP 데이터 분할은 패킷에 데이터를 저장하기 전에 이루어지고 조각 나누기쪽은 패킷이 만들어진 후에 패킷을 분할하는 것.\r\n    - 출력측의 MTU를 조사하여 중계하는 패킷을 그대로 출력측에서 송신할 수 있는지 조사한다.\r\n        - MTU가 충분히 커서 분할하지 않아도 송신할 수 있으면 분할하지 않음.\r\n        - MTU가 작은 경우에는 여기에 저장할 수 있는 크기로 패킷을 분할하는데, 그 전에 IP 헤더의 플래그 필드를 조사하여 분할해도 좋을지 확인함.\r\n    - 플래그 필드가 분할 불가로 되어 있으면 분할할 수 없으므로 패킷을 폐기하고 ICMP 메시지로 송신처에 통지한다.\r\n    - 그렇지 않으면 출력측 MTU에 맞춰 데이터 부분을 맨 앞부분부터 차례대로 잘라낸다.\r\n        - TCP 헤더 이후의 부분을 분할 대상 데이터로 간주한다.\r\n        - 데이터를 분할하면 IP 헤더를 덧붙이는데 내용은 원래 패킷 IP 헤더를 그대로 복사한 것이라고 생각하면 된다. 단, 일부 필드는 고쳐쓰는데 분할한 핵심 정보를 IP 헤더에 기록하기 위해서이다.\r\n\r\n8. 라우터의 송신 동작은 컴퓨터와 같다.\r\n    - 송신 동작은 출력측의 포트에 따라 다르다.\r\n        - 이더넷이라면 이더넷의 규칙에 따라 패킷을 신호로 변환하여 송신하고, ADSL이라면 ADSL의 규칙에 따라 송신한다는 식.\r\n    - 출력측의 포트가 이더넷인 경우의 송신 동작\r\n        - MAC 헤더의 맨 앞에 있는 수신처 MAC 주소 필드에 값을 설정하기 위해 경로표의 '게이트웨이' 항목에서 패킷을 건네줄 상대를 판단한다.\r\n            - '게이트웨이' 항목에 IP 주소가 쓰여있으면 이 IP 주소로, 비어있으면 IP 헤더의 수신처 IP 주소가 건네줄 상대가 된다.\r\n            - ARP로 IP 주소에서 MAC 주소를 조사하고 결과를 MAC 주소로 설정.\r\n              먼저 ARP 캐시를 찾아보고 없으면 ARP로 조회함.\r\n        - 송신처 MAC 주소 필드는 출력측의 포트에 할당된 MAC 주소를 설정함. 타입 필드에 0800(16진수)을 설정함.\r\n        - 송신 패킷을 전기 신호로 변환하여 포트에서 송신함.\r\n            - 반이중 모드라면 케이블에 신호가 흐르지 않는 것을 확인 후 신호를 송출, 충돌할 경우 잠시 기다린 다음에 다시 보냄.\r\n            - 전이중 모드라면 케이블 신호를 확인하지 않고 그대로 신호를 송신.\r\n        - 출력측 포트가 이더넷이라면 패킷은 스위칭 허브를 경유하여 다음 라우터에 도달함.\r\n        - 라우터가 그 다음 라우터에 패킷을 중계.\r\n        - 반복하고 최종적으로 목적지에 도착함.\r\n\r\n9. 라우터와 스위칭 허브의 관계\r\n    - 이때까지 MAC 헤더를 부가한다고 표현했지만 이더넷의 패킷 데이터 부분에 IP의 패킷을 넣는다고 표현하는 것이 원래의 개념에 가깝다.\r\n        - 즉, MAC 헤더를 부가하여 패킷을 송신한다는 것은 이더넷의 패킷 데이터 부분에 IP의 패킷을 넣고 이더넷의 원리로 다음 라우터까지 운반한다는 것.\r\n    - IP라는 구조는 스스로 패킷을 운반하는 수단이 없으므로 패킷을 운반할 때에 이더넷에 의뢰하여 운반한다.\r\n    - 즉 라우터는 패킷을 운반하는 일을 스위칭 허브에 의뢰한다.\r\n        - 실제 라우터는 스위칭 허브를 내장한 기종이 있다보니 설명이 적당하지 않은 경우도 있지만 '순수한' 라우터라는 것에 집중하자.\r\n    - 통신 상대까지 패킷을 전달하는 전체의 동작은 IP(라우터)가 당담하고, 이 동작을 할 때 다음 라우터까지 패킷을 운반하는 부분은 이더넷(스위칭 허브)이 담당한다.\r\n    - 이더넷이 아닌 다른 다양한 통신 기술을 사용해도 마찬가지다. 요컨대 이 통신 기술에 의뢰하여 패킷을 운반하는 것.\r\n      다양한 통신 기술을 적재적소에 구분하여 사용할 수 있다는 특징 덕분에 인터넷이라는 거대한 네트워크가 만들어진 것.\r\n\r\n\r\n<br/>\r\n\r\n## 04 라우터의 부가 기능\r\n\r\n1. 주소 변환으로 IP 주소를 효율적으로 이용한다.\r\n    - 인터넷이 일반에게 공개되자 급속하게 접속 대수가 늘어나기 시작하면서 고유한 주소가 고갈될 것이라는 예측이 나왔음.\r\n    - 이 문제를 해결하기 위하여 사내의 기기에 할당하는 주소는 다른 회사와 중복되어도 좋다고 하기로 함.\r\n    - 특정 주소를 사내용으로 사용한다는 규칙을 세웠고 이 규칙에 기초한 사내용 주소는 프라이비트 주소(private address), 이전의 고유한 주소는 글로벌 주소(global address)라고 부름.\r\n        - 프라이비트 주소 규칙은 아래의 범위로 한정한다는 것뿐\r\n          10.0.0.0 ~ 10.255.255.255\r\n          172.16.0.0 ~ 172.31.255.255\r\n          192.168.0.0 ~ 192.168.255.255\r\n\r\n    - 사내 네트워크는 완전히 독립되어 있는 것이 아니라 인터넷을 통해 많은 회사에 연결되므로 패킷이 사내와 인터넷을 왕래하면 여기저기에 같은 주소가 있게 되어 패킷을 정확히 운반할 수 없게 됨.\r\n\r\n        ![Untitled - 2021-12-22T173056 321](https://user-images.githubusercontent.com/62014888/147061441-59628a54-e5ec-479c-b5d5-ba3f1450ca7c.png)\r\n\r\n    - 위와 같이 구성해서 사내의 네트워크를 인터넷에 공개하는 서버를 접속하는 부분과 사내용 네트워크의 두 가지로 나눴음.\r\n    - 사내 네트워크에는 인터넷과 직접 패킷을 주고받지 않도록 특별한 구조를 사용하여 접속하는데, 이 구조가 주소 변환이다.\r\n\r\n2. 주소 변환의 기본 동작\r\n    - 주소 변환의 구조는 패킷을 중계할 때 IP 헤더에 기재된 IP 주소와 포트 번호를 바꿔쓰는 것이다.\r\n\r\n        ![Untitled - 2021-12-22T173059 190](https://user-images.githubusercontent.com/62014888/147061451-6b753eb5-940e-44c0-932d-b436679190fd.png)\r\n\r\n    - TCP 접속 동작에서 최초로 흐르는 패킷을 인터넷에 중계할 때 송신처의 IP 주소를 프라이비트 주소에서 글로벌 주소로 바꿔쓴다.\r\n        - 글로벌 주소는 주소 변환 장치의 인터넷측에 있는 포트에 할당된 주소로, 이것과 동시에 포트 번호도 바꾸어 씀.\r\n        - 포트 번호쪽은 미사용 번호로 주소 변환 장치가 적당히 선택하여 사용함.\r\n    - 바꿔쓰기 전의 프라이비트 주소와 포트 번호, 바꿔쓴 후의 글로벌 주소와 포트 번호를 한 세트로 하여 주소 변환 장치 내부에 있는 대응표에 기록해둠.\r\n    - 인터넷에 송출하고 패킷은 서버에 도착하며 여기에서 회신 패킷이 돌아온다. 이 때 회신 패킷의 수신처는 바꿔쓴 글로벌 주소와 포트 번호로 되어 있을 것이다. 이 글로벌 주소는 주소 변환 장치에 할당되어 있으므로 회신 패킷은 주소 변환 장치에 되돌아온다.\r\n    - 주소 변환 장치는 주소 대응표를 통해 프라이비트 주소와 포트 번호로 바꾸고 사내 네트워크에 패킷을 보낸다.\r\n    - 데이터 송, 수신이 끝나고 연결 끊기 동작의 패킷이 흐르다 인터넷에 대한 접속 동작이 끝나면 대응표에 등록한 것을 삭제한다.\r\n    - 인터넷에서 보면 주소 변환 장치가 통신 상대로 되어 있는 것으로 보인다.\r\n\r\n3. 포트 번호를 바꿔쓰는 이유\r\n    - 포트 번호를 바꾸지 않고 주소만 바꾸면 프라이비트 주소와 글로벌 주소가 1대1로 대응해서 인터넷에 접속하는 대수만큼 글로벌 주소가 필요함.\r\n    - 포트 번호를 바꿔쓰면 한 개의 글로벌 주소를 수만 개의 프라이비트 주소에 대응시킬 수 있어서 효율이 높아짐.\r\n\r\n4. 인터넷에서 회사로 액세스한다\r\n    - 사내에서 인터넷으로 액세스하는 패킷을 중계할 때에는 대응표에 등록되어 있지 않아도 패킷을 중계할 수 있음.\r\n    - 인터넷에서 사내로 패킷을 중계할 때는 대응표에 등록되어 있지 않으면 중계할 수 없음.\r\n        - 인터넷에서 액세스하지 않는 기기에는 인터넷측에서 패킷을 송신할 수 없다는 얘기\r\n        - 액세스 중이라고 해도 통신에 사용하는 포트 번호 이외의 포트에 패킷을 보낼 수 없음.\r\n        - 즉 사내에서 의도적으로 인터넷에 액세스하지 않는 한 인터넷측에서 사내에 패킷을 보낼 수 없다.\r\n        - 부정 침입을 방지하는 효과를 가짐\r\n    - 사내에 액세스하고 싶은 경우에 사전에 수동으로 대응표에 등록해 두면 됨.\r\n        - 사내에 있는 프라이비트 주소를 할당한 서버를 공개할 수도 있다.\r\n\r\n5. 라우터의 패킷 필터링 기능\r\n    - 패킷을 중계할 때 MAC 헤더, IP 헤더, TCP 헤더에 기록되어 있는 내용을 조사하여 그것이 사전에 설정한 조건에 합치되면 패킷을 중계하거나 폐기하는 동작이 패킷 필터링 기능임.\r\n        - 대부분 방화벽이라는 기기나 소프트웨어는 이 원리를 이용하여 부정 침입을 방지.\r\n        - 단, 부정 침입과 정상 액세스를 분간하여 부정 침입만 차단하도록 조건을 설정하는 것은 간단하지 않다.","excerpt":"'성공과 실패를 결정하는 1%의 네트워크 원리' 스터디를 진행하며 정리한 내용이다. 01 케이블과 리피터, 허브 속을 신호가 흘러간다 하나하나의 패킷이 독립된 것으로 동작한다. 중계 동작은 패킷의 헤더에 기록된 제어 정보와 중계 장치의 내부에 있는 …","fields":{"slug":"/1per-network-ch3/"},"frontmatter":{"date":"Oct 01, 2021","title":"[성공과 실패를 결정하는 1%의 네트워크 원리] 3장","tags":["network","book","1per-network"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n## Cross Join?\r\n\r\n- JPA 빌더인 QueryDSL을 사용하다보면 Join 쿼리 작성할 때 주의하지 않으면 Cross Join이 발생한다고 한다.\r\n- 예전에 이동욱님 글에서 한번 본 적이 있었는데 당시에는 QueryDSL을 사용하고 있지 않던 터라 그냥 넘어갔던 기억이 있다.\r\n- 이번에 이렇게 Cross Join 문제를 겪고 나서야 해결한 뒤 정신차리고 글을 작성한다.\r\n\r\nCross Join (교차 조인) 은 카디션 곱이라고도 하며 조인되는 두 테이블에서 곱집합을 반환한다.\r\n\r\n이 말은 집합에서 나올 수 있는 모든 경우를 이야기 한다.\r\n\r\n예로 들면 A 집합 {a, b, c}, B 집합 {1, 2, 3, 4} 가 있고 두 집합이 Cross Join이 된다면 A x B로 다음과 같이 총 12개의 집합이 나오게 된다.\r\n{a, 1}, {a, 2}, {a, 3}, {a, 4}, {b, 1} .... {c, 4}\r\n\r\n그러다보니 일반적인 Join 보다 성능상 이슈가 발생하게 된다.\r\n\r\n<br/>\r\n\r\n## 문제 상황\r\n\r\n- 그렇다면 우리 프로젝트에서는 어떤 상황에서 발생했을까?\r\n\r\n- 기존의 검색 기능은 문제집을 검색했을 때 문제집 이름에 포함이 되는 결과를 보여주었다.\r\n- 그런데 태그 이름이 일치하는 문제집도 보여주자는 의견이 나왔고 현재 프로젝트 특성 상 그게 논리적으로도 맞다고 봐 이에 맞춰 기능을 추가하기로 했다.\r\n\r\n- 검색에 쓰이는 동적 쿼리는 QueryDSL을 통해 만들어주고 있었고 기존의 코드는 다음과 같다.\r\n\r\n```java\r\npublic Page<Workbook> searchAll(WorkbookSearchParameter parameter, List<Long> tags,\r\n                                    List<Long> users, Pageable pageable) {\r\n        QueryResults<Workbook> results = jpaQueryFactory.selectFrom(workbook)\r\n                .innerJoin(workbook.user, user).fetchJoin()\r\n                .innerJoin(workbook.cards.cards, card)\r\n                .leftJoin(workbook.workbookTags, workbookTag)\r\n                .leftJoin(workbook.hearts.hearts, heart)\r\n                .where(containKeyword(parameter.getSearchKeyword()),\r\n                        containTags(tags),\r\n                        containUsers(users),\r\n                        openedTrue())\r\n                .groupBy(workbook.id)\r\n                .orderBy(findCriteria(parameter.getSearchCriteria()), workbook.id.asc())\r\n                .offset(pageable.getOffset())\r\n                .limit(pageable.getPageSize())\r\n                .fetchResults();\r\n        return new PageImpl<>(results.getResults(), pageable, results.getTotal());\r\n }\r\n\r\nprivate BooleanExpression containKeyword(SearchKeyword searchKeyword) {\r\n        if (searchKeyword == null) {\r\n            return null;\r\n        }\r\n        String keyword = searchKeyword.getValue();\r\n        return workbook\r\n\t\t\t\t\t\t\t\t\t.name\r\n\t\t\t\t\t\t\t\t\t.lower()\r\n\t\t\t\t\t\t\t\t\t.contains(keyword);\r\n }\r\n```\r\n\r\n- containKeyword 부분이 현재 문제집 이름에 포함이 되는 값만 조회하도록 되어있었고 여기에 태그 이름이 일치하는 경우도 추가하기로 했다.\r\n\r\n```java\r\n private BooleanExpression containKeyword(SearchKeyword searchKeyword) {\r\n        if (searchKeyword == null) {\r\n            return null;\r\n        }\r\n        String keyword = searchKeyword.getValue();\r\n        return containsKeywordInWorkbookName(keyword)\r\n                .or(containsKeywordInWorkbookTag(keyword));\r\n    }\r\n\r\n    private BooleanExpression containsKeywordInWorkbookName(String keyword) {\r\n        return workbook.name.lower().contains(keyword);\r\n    }\r\n\r\n    private BooleanExpression containsKeywordInWorkbookTag(String keyword) {\r\n        StringPath tagName = workbookTag.tag.tagName.value;\r\n        return tagName.eq(keyword);\r\n    }\r\n}\r\n```\r\n\r\n- 지금보니 메서드 이름을 수정하거나 코드 포맷팅을 해줘야 할거같다..\r\n- 아무튼 이런 식으로 or을 사용해서 가져오도록 했고\r\n\r\n![Untitled (19)](https://user-images.githubusercontent.com/62014888/145753361-17a52122-7dd3-452e-86d3-09c1afaf4145.png)\r\n\r\n\r\n\r\n- 실제로도 원하는 위치에 or가 있어서 잘 가져오는 줄 알았는데 테스트 코드에서 실패했다.\r\n\r\n```java\r\n@Test\r\n@DisplayName(\"검색어를 입력하고 좋아요순으로 정렬한다. 좋아요가 같다면 id순으로 정렬한다.\")\r\nvoid searchAllFromKeywordAndHeartDesc() {\r\n    // given\r\n    WorkbookSearchParameter parameter = WorkbookSearchParameter.builder()\r\n            .searchKeyword(\"문제\")\r\n            .searchCriteria(\"heart\")\r\n            .build();\r\n\r\n    // when\r\n    Page<Workbook> workbooks = workbookSearchRepository.searchAll(parameter, null, null, parameter.toPageRequest());\r\n    List<Workbook> workbookList = workbooks.toList();\r\n    \r\n    // then\r\n    assertThat(workbookList).hasSize(7);\r\n    assertThat(workbookList).extracting(Workbook::getName)\r\n            .containsExactly(\"좋아요가 많아 문제다.\",\r\n                    \"Java 문제집0\",\r\n                    \"Javascript 문제집0\",\r\n                    \"Java 문제집1\",\r\n                    \"Javascript 문제집1\",\r\n                    \"Java 문제집2\",\r\n                    \"Javascript 문제집2\");\r\n}\r\n```\r\n\r\n![Untitled (20)](https://user-images.githubusercontent.com/62014888/145753391-420df9f4-5d75-4f91-a11b-2c30e5f86d46.png)\r\n\r\n- 7개를 가져와야 하는데 6개 밖에 가져오지 못했고 이것저것 실험해보니 태그가 포함되지 않은 문제집이 조회가 되지 않는다는 것을 알게 되었다.\r\n\r\n![Untitled (21)](https://user-images.githubusercontent.com/62014888/145753398-c02cc4e8-5111-4618-acb9-70c64e12b5ad.png)\r\n\r\n- 또한 그 위를 보니 이런식으로 tag가 Cross Join이 되어있는 것을 발견했다.\r\n- 현재 Workbook과 Tag 사이의 중간 테이블인 WorkbookTag는 Left Outer Join이 되어있는데 Tag는 아무런 Join이 되어있지 않았다.\r\n- 즉, 연관관계를 맺고 있지만 Join이 되어있지 않은 상태에서 접근하려고 하니 JPA가 자동으로 Cross Join을 해주었고 이런 결과를 보여주게 된 것이다.\r\n\r\n<br/>\r\n\r\n\r\n## 해결\r\n\r\n- 이동욱님의 글에서 적혀있듯이 암묵적으로 Join이 된 것을 명시적으로 해주면 된다.\r\n\r\n```java\r\npublic Page<Workbook> searchAll(WorkbookSearchParameter parameter, List<Long> tags,\r\n                                    List<Long> users, Pageable pageable) {\r\n        QueryResults<Workbook> results = jpaQueryFactory.selectFrom(workbook)\r\n                .innerJoin(workbook.user, user).fetchJoin()\r\n                .innerJoin(workbook.cards.cards, card)\r\n                .leftJoin(workbook.workbookTags, workbookTag)\r\n                .leftJoin(workbookTag.tag, tag) // leftJoin을 추가했다.\r\n                .leftJoin(workbook.hearts.hearts, heart)\r\n                .where(containKeyword(parameter.getSearchKeyword()),\r\n                        containTags(tags),\r\n                        containUsers(users),\r\n                        openedTrue())\r\n                .groupBy(workbook.id)\r\n                .orderBy(findCriteria(parameter.getSearchCriteria()), workbook.id.asc())\r\n                .offset(pageable.getOffset())\r\n                .limit(pageable.getPageSize())\r\n                .fetchResults();\r\n        return new PageImpl<>(results.getResults(), pageable, results.getTotal());\r\n    }\r\n```\r\n\r\n- 참고로 Inner Join으로 하여도 Cross Join과 같은 결과를 받았다.\r\n- 그럼 왜 Inner Join, Cross Join을 사용하면 태그가 없는 문제집을 들고오질 않을까?\r\n- 간단하게 그림으로 보자.\r\n\r\n    ![Untitled (22)](https://user-images.githubusercontent.com/62014888/145753448-87e9b1e8-b999-4ead-9720-498000750d83.png)\r\n\r\n- 발그림이긴 한데 간단하게 요약하면 Workbook과 WorkbookTag가 이미 Left Outer Join이 되어있는 시점에서 WorkbookTag와 Tag를 Inner Join이나 Cross Join을 하려고 하니 태그가 존재하지 않는 문제집은 아예 가져오질 못하는 것이다.\r\n- 나는 Workbook과 WorkbookTag가 이미 Left Outer Join이 되어있는 시점에서 WorkbookTag와 Tag가 Inner Join이 되어도 괜찮지 않을까 생각했는데 잘못되었다는 것을 그림을 통해 알 수 있었다.\r\n\r\n![Untitled (23)](https://user-images.githubusercontent.com/62014888/145753556-587f276a-8f8d-4cca-b584-ef8536420a71.png)\r\n\r\n![Untitled (24)](https://user-images.githubusercontent.com/62014888/145753559-df10dbb0-9abd-449f-aa54-173d4383c1ca.png)\r\n\r\n- 결과적으로 원하는 쿼리문이 나왔고 테스트를 통과하는 모습을 볼 수 있었다.\r\n\r\n<br/>\r\n\r\n\r\n## 마무리\r\n\r\n- JPA를 사용하는데 특히 QueryDSL을 사용한다면 Cross Join을 조심하자.\r\n    - 모든 집합을 가져오다보니 원하지 않는 값까지 들고 올 수도 있다.\r\n- 의도하여 Cross Join을 하지 않는 이상 암묵적 Join은 모두 명시적 Join으로 바꾸도록 하자!\r\n\r\n<br/>\r\n\r\n## 참고\r\n\r\n\r\n- [https://jojoldu.tistory.com/533](https://jojoldu.tistory.com/533)\r\n- [https://clairdelunes.tistory.com/22](https://clairdelunes.tistory.com/22)","excerpt":"Cross Join? JPA 빌더인 QueryDSL을 사용하다보면 Join 쿼리 작성할 때 주의하지 않으면 Cross Join이 발생한다고 한다. 예전에 이동욱님 글에서 한번 본 적이 있었는데 당시에는 QueryDSL을 사용하고 있지 않던 터라 그냥…","fields":{"slug":"/cross-join/"},"frontmatter":{"date":"Sep 30, 2021","title":"Cross Join 살펴보기","tags":["database","join"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n'성공과 실패를 결정하는 1%의 네트워크 원리' 스터디를 진행하며 정리한 내용이다.\r\n\r\n---\r\n\r\n## 01 소켓을 작성한다.\r\n\r\n1. 프로토콜 스택의 내부 구성\r\n\r\n    ![KakaoTalk_20210929_220830699](https://user-images.githubusercontent.com/62014888/146672256-0ba0e544-4e99-47d3-9a52-bf6310e33bbf.jpg)\r\n\r\n    - 네트워크 애플리케이션\r\n        - 브라우저, 메일러, 웹 서버, 메일 서버 등의 프로그램\r\n        - 여기부터 아래로 향하여 데이터 송, 수신 등의 일을 의뢰함.\r\n        - 브라우저뿐만 아니라 어떤 애플리케이션도 송, 수신 동작은 거의 비슷함.\r\n    - Socket 라이브러리\r\n        - DNS 서버에 조회하는 동작을 실행하는 리졸버가 내장되어 있음. (1장에서 설명함)\r\n    - 프로토콜 스택\r\n        - TCP\r\n            - 브라우저나 메일 등의 일반적인 애플리케이션은 TCP를 사용하여 데이터를 송, 수신함.\r\n        - UDP\r\n            - DNS 서버에 대한 조회 등에서 짧은 제어용 데이터를 송, 수신하는 경우 UDP를 사용함.\r\n        - IP\r\n            - 패킷 송, 수신 동작을 제어하는 부분.\r\n            - 인터넷에서 데이터를 운반할 때는 데이터를 작게 나누어 패킷이라는 형태로 운반하는데, 이 패킷을 통신 상대까지 운반하는 것이 IP의 주 역할.\r\n            - ICMP - 패킷을 운반할 때 발생하는 오류를 통지하거나 제어용 메시지를 통지할 때 사용함.\r\n            - ARP - IP 주소에 대응하는 이더넷의 MAC 주소를 조사할 때 사용함.\r\n    \r\n        - LAN 드라이버\r\n            - LAN 어댑터의 하드웨어를 제어함.\r\n        - LAN 어댑터\r\n            - 실제 송, 수신 동작, 즉 케이블에 대해 신호를 송, 수신하는 동작을 실행함.\r\n\r\n<br/>\r\n\r\n2. 소켓의 실체는 통신 제어용 제어 정보\r\n    - 프로토콜 스택은 내부에 제어 정보를 기록하는 메모리 영역을 가지고 있음.\r\n        - 여기에 통신 동작을 제어하기 위한 제어 정보를 기록함.\r\n        - 대표적으로 통신 상대의 IP 주소는 무엇인가, 포트 번호는 몇 번인가, 통신 동작이 어떤 진행 상태에 있는가\r\n        - 소켓은 개념적인 것이라 실체가 없으므로 굳이 말하자면 이 제어 정보가 소켓의 실체라고 할 수 있다!  \r\n          또는 제어 정보를 기록한 메모리 영역이 소켓의 실체라고 생각해도 좋다.\r\n    - 프로토콜 스택은 이 제어 정보를 참조하면서 동작함.\r\n        - 소켓에는 응답이 돌아오는지의 여부와 송신 동작 후의 경과 시간 등이 기록되어 있음.\r\n        - 프로토콜 스택은 이 정보를 보고 포기하거나 다시 보내는 동작을 실행함.\r\n    - 소켓에는 통신 동작을 제어하기 위한 여러 가지 제어 정보가 기록되어 있다.\r\n        - 프로토콜 스택은 이것을 참조하여 다음에 무엇을 해야 하는지를 판단.\r\n    - 윈도우의 경우 netstat 명령으로 소켓의 내용을 화면에 표시할 수 있다.\r\n\r\n<br/>\r\n\r\n3. Socket를 호출했을 때의 동작\r\n    1. 소켓을 만드는 단계\r\n        - socket을 호출하여 소켓을 만들 것을 의뢰하면 프로토콜 스택은 의뢰에 따라 한 개의 소켓을 만든다.\r\n        - 프로토콜 스택이 최초로 하는 일은 소켓 한 개 분량의 메모리 영역을 확보하는 것.\r\n            - 소켓의 제어 정보를 기록하는 메모리 영역은 처음부터 존재하는 것이 아니므로 먼저 그것을 확보해 두어야 한다.\r\n    2. 소켓을 나타내는 디스크립터를 애플리케이션에 알려줌.\r\n        - 애플리케이션은 이후 프로토콜 스택에 데이터 송, 수신 동작을 의뢰할 때 디스크립터를 통지한다.\r\n\r\n<br/>\r\n\r\n## 02 서버에 접속한다\r\n\r\n1. 접속의 의미\r\n    - 소켓을 만든 직후에 애플리케이션에서 데이터 송신 의뢰가 오면 프로토콜 스택은 어떻게 될까?\r\n        - 만든 직후에는 아무 것도 기록되어 있지 않으므로 통신 상대가 누구인지도 모름.\r\n        - 브라우저가 알고 있는 정보만으로는 부족.\r\n        - **서버의 IP 주소나 포트 번호를 프로토콜 스택에 알리는 동작**이 필요한데, 이것이 접속 동작의 한 가지 역할.\r\n    - 그럼 서버측은 어떨까?\r\n        - 서버측도 소켓이 만들어졌지만 통신 상대를 알 수 없음.\r\n        - 클라이언트에서 정보를 알려서 통신하려는 클라이언트가 있다는 것을 서버측에 전달함.\r\n        - **클라이언트측에서 서버측에 통신 동작의 개시를 전달하는 것**도 접속 동작의 역할 중 하나.\r\n    - 접속 동작의 첫 번째 동작은 통신 상대와의 사이에 제어 정보를 주고받아 소켓에 필요한 정보를 기록하고 데이터 송, 수신이 가능한 상태로 만드는 것.\r\n        - 송, 수신하는 데이터를 일시적으로 저장하는 메모리 영역이 필요한데, 이 메모리 명역을 '버퍼 메모리'라고 부른다. 버퍼 메모리의 확보도 접속 동작을 할 때 실행되는데, 이것이 '접속' 한다는 동작의 의미.\r\n\r\n<br/>\r\n\r\n2. 맨 앞부분에 제어 정보를 기록한 헤더를 배치한다.\r\n    - 제어 정보는 크게 두 종류가 있다.\r\n        1. 클라이언트와 서버가 서로 연락을 절충하기 위해 주고받는 제어 정보.\r\n            - 접속 동작뿐만 아니라 데이터를 송, 수신하는 동작이나 연결을 끊는 동작도 포함하여 통신 동작 전체에 어떤 정보가 필요한지 검토하여 내용을 TCP 프로토콜의 사양으로 규정하고 있다.\r\n            - 제어 정보는 패킷의 맨 앞부분에 부가하는데 배치하는 곳부터 헤더라고 부른다.\r\n                - 이더넷, IP에도 같은 제어 정보가 있고 헤더라고 부르기에 TCP 헤더, IP 헤더와 같이 알 수 있도록 써야함.\r\n            - 헤더의 각 항목의 의미를 알면 통신 동작을 알았다고 해도 좋을 정도로 중요함.\r\n        2. 소켓에 기록하여 프로토콜 스택의 동작을 제어하기 위한 정보.\r\n            - 애플리케이션에서 통지되는 정보, 통신 상대로부터 받은 정보 등이 수시로 기록됨.\r\n            - 소켓의 제어 정보는 프로토콜 스택의 프로그램과 일체화되어 있다고 해도 좋다.\r\n            - 프로토콜 스택이 어떤 정보를 필요로 하는지는 프로토콜 스택을 만드는 사람에 따라 달라진다.\r\n            - 소켓에 기록한 제어 정보는 상대측에서 볼 수 없다.\r\n\r\n<br/>\r\n\r\n3. 접속 동작의 실제\r\n    - connect 호출에서 서버 IP 주소, 포트 번호를 쓰면 프로토콜 스택의 TCP 담당 부분에 전달된다.\r\n        - TCP 담당 부분은 서버의 TCP 담당 부분과의 사이에 제어 정보를 주고받는다.\r\n        - 단계는 다음과 같다.\r\n            1. 데이터 송, 수신 동작의 개시를 나타내는 제어 정보를 기록한 헤더를 만든다.\r\n                - 헤더에서 다수의 항목이 있는데 중요한 것은 송신처와 수신처의 포트 번호\r\n                    - 이를 통해 송신처가 되는 클라이언트측의 소켓과 수신처가 되는 서버측의 소켓을 지정할 수 있다.\r\n                - 접속해야하는 소켓이 어느 것인지 확실히 하고 컨트롤 비트인 SYN을 1로 만든다.\r\n            2. IP 담당 부분에 건네주어 송신하도록 의뢰한다.\r\n            3. IP 담당 부분이 패킷 송신 동작을 실행하고 서버에 도착하면 서버측의 IP 담당 부분이 이것을 받고 TCP 담당 부분에 건네준다.\r\n                - TCP 담당 부분이 TCP 헤더를 조사하여 수신처 포트 번호에 해당하는 소켓을 찾아낸다.\r\n                - 해당하는 소켓이 발견되면 필요한 정보를 기록하고 접속 동작이 진행중이라는 상태가 된다.\r\n            4. 이 과정이 끝나면 서버의 TCP 담당 부분은 응답을 돌려보낸다.\r\n            5. 서버에서도 클라이언트와 마찬가지로 송신처, 수신처의 포트 번호나 SYN 비트 등을 설정한 TCP 헤더를 만든다.\r\n                - ACK라는 컨트롤 비트도 1로 만든다.\r\n                    - 패킷을 받은 것을 알리기 위한 동작.\r\n            6. TCP 헤더를 IP 담당 부분에 건네주어 클라이언트에 반송하도록 의뢰한다.\r\n            7. 패킷이 클라이언트에 돌아오고 IP 담당 부분을 경유하여 TCP 담당 부분에 도착함.\r\n            8. TCP 헤더를 조사하여 서버측의 접속 동작이 성공했는지 확인한다.\r\n                - SYN이 1이면 접속 성공이므로 소켓에 서버의 IP 주소나 포트 번호 등과 함께 소켓에 접속 완료를 나타내는 제어 정보를 기록한다.\r\n            9. 패킷이 도착한 것을 서버에 알리기 위해 ACK 비트를 1로 만든 TCP 헤더를 반송한다.\r\n            10. 서버에 도착하면 접속 동작의 대화가 끝난다.\r\n    - 송, 수신할 수 있는 상태가 되면 파이프와 같은 것으로 소켓이 연결되었다고 생각할 수 있다.\r\n        - 실제로 무엇인가 연결된 것은 아니지만 이렇게 생각하는 것이 네트워크 업계의 습관\r\n        - 이 파이프와 같은 것을 커넥션이라고 함.\r\n        - close를 호출하여 연결을 끊을 때까지 계속 존재한다.\r\n        - connect 실행이 끝나면 애플리케이션을 제어할 수 있게 된다.\r\n\r\n<br/>\r\n\r\n## 03 데이터를 송, 수신한다\r\n\r\n1. 프로토콜 스택에 HTTP 리퀘스트 메시지를 넘긴다\r\n    - 데이터 송, 수신 동작은 애플리케이션이 write를 호출하여 송신 데이터를 프로토콜 스택에 건네주는 곳부터 시작된다.\r\n        - 프로토콜 스택은 데이터의 내용이 무엇인지 알지 못한다.\r\n        - 받은 데이터를 곧바로 송신하는 것이 아니라 자체 내부에 있는 송신용 버퍼 메모리 영역에 저장하고 애플리케이션이 다음 데이터를 건네주기를 기다린다.\r\n            - 건네주는 데이터의 길이는 애플리케이션의 사정에 따라 결정되기에 받은 데이터를 곧바로 보내버리면 작은 패킷을 보낼 수도 있어 네트워크 이용 효율이 저하됨.\r\n            - 어느 정도 데이터를 저장하고 송, 수신 동작을 하는데 정도는 OS의 종류나 버전에 따라 달라지나 다음과 같은 요소로 판단함.\r\n                1. 한 패킷에 저장할 수 있는 데이터의 크기\r\n                    - MTU: 패킷 한 개로 운반할 수 있는 디지털 데이터의 최대 길이. 이더넷에서는 보통 1500바이트\r\n                    - MSS: 헤더를 제외하고 한 개의 패킷으로 운반할 수 있는 TCP 데이터의 최대 길이\r\n                2. 타이밍\r\n                    - 애플리케이션의 송신 속도가 느려질 때 MSS에 가깝게 데이터를 저장하면 송신 동작이 지연되므로 적당한 곳에서 송신 동작을 실행해야 한다.\r\n                    - 프로토콜 스택 내부에 타이머가 있어서 일정 시간 이상 경과하면 패킷으로 송신함.\r\n            - 전자를 중시하면 패킷 길이가 길어져서 네트워크의 이용 효율이 높아지지만 버퍼에 머무는 시간만큼 송신 동작이 지연될 우려가 있다.\r\n            - 후자를 중시하면 지연은 적어지지만 이용 효율이 떨어진다.\r\n            - 어떻게 판단해야 할지는 프로토콜 스택을 만드는 개발자에 맡겨져 있다.\r\n        - 애플리케이션측에서도 송신 타이밍을 제어하는 여지를 남겨두었다.\r\n            - '버퍼에 머물지 않고 바로 송신할 것' 이라고 옵션을 지정하면 프로토콜 스택은 버퍼에 머물지 않고 송신 동작을 실행한다.\r\n\r\n<br/>\r\n\r\n2. 데이터가 클 때는 분할하여 보낸다.\r\n    - 긴 데이터를 보낼 경우 송신 버퍼에 저장된 데이터는 MSS의 길이를 초과하므로 다음 데이터를 기다릴 필요가 없다.\r\n    - 송신 버퍼에 들어있는 데이터를 맨 앞부터 차례대로 MSS 크기의 맞게 분할하고, 분할한 조각을 한 개씩 패킷에 넣어 송신한다.\r\n\r\n<br/>\r\n\r\n3. ACK 번호를 사용하여 패킷이 도착했는지 확인한다.\r\n    - TCP에는 송신한 패킷이 상대에게 올바르게 도착했는지 확인하고, 도착하지 않았으면 다시 송신하는 기능이 있으므로 패킷을 송신한 후에는 확인 동작으로 넘어간다.\r\n    - TCP 담당 부분은 데이터를 조각으로 분할할 때 조각이 통신 개시부터 따져서 몇 번째 바이트에 해당하는지 세어둔다.\r\n        - 데이터 조각을 송신할 때 세어둔 값을 TCP 헤더에 기록하는데, **시퀀스 번호**라는 항목에 해당됨.\r\n    - 송신하는 데이터의 크기도 수신측에 전달하지만 여기에서는 헤더에 기록하여 수신측에 알리지 않는다.\r\n        - 패킷 전체 길이 - 헤더 길이 = 데이터의 크기\r\n        - 이 방법으로 크기를 산출한다.\r\n    - 시퀀스 번호를 이용해 누락이 없는 것을 확인하면 수신측인 그 이전에 수신한 데이터와 합쳐서 몇 번째 바이트까지 수신한 것인지 계산하고, 그 값을 TCP 헤더의 **ACK 번호**에 기록하여 송신측에 알려준다.\r\n        - ACK 번호를 되돌려주는 동작을 **수신 확인 응답**이라고 부른다.\r\n    - 실제로 시퀀스 번호의 시작은 난수를 바탕으로 산출한 초기값임.\r\n        - SYN이라는 제어 비트를 1로 하여 서버에 보낼 때 초기값을 통지함.\r\n    - 이 흐름을 양방향으로 나타내려면 좌우를 역전시키면 된다.\r\n\r\n        ![KakaoTalk_20210929_235842088](https://user-images.githubusercontent.com/62014888/146672259-638de78b-79a0-4591-8a9d-68a13b161762.jpg)\r\n\r\n        ![KakaoTalk_20210930_000015267](https://user-images.githubusercontent.com/62014888/146672260-f02f07a3-7587-479a-a490-f9c6a0c1d2ea.jpg)\r\n\r\n    - TCP는 이 방법으로 상대가 데이터를 받은 것을 확인하는데, 확인할 때까지 송신한 패킷을 송신용 버퍼 메모리 영역에 보관해둔다.\r\n      ACK 번호가 돌아오지 않으면 패킷을 다시 보낸다.\r\n    - 이를 이용해 네트워크의 어디에서 오류가 발생했더라도 그것을 전부 검출하여 회복 처리(패킷을 다시 보내는 것)를 취할 수 있다. 또한 그렇기에 다른 곳에서 오류를 회복 조치할 필요가 없다.\r\n    - TCP가 아무리 보내도 데이터가 도착하지 않는 경우 (케이블 분리, 서버 다운 등) 몇 번 다시 보낸 후 데이터 송신 동작을 강제로 종료하고 애플리케이션에 오류를 통지함.\r\n\r\n<br/>\r\n\r\n4. 패킷 평균 왕복 시간으로 ACK 번호의 대기 시간을 조정한다.\r\n    - ACK 번호가 돌아오는 것을 기다리는 시간을 타임아웃 값이라고 한다.\r\n    - 대기 시간을 적절한 값으로 설정해야 하는데 간단하지 않다.\r\n        - TCP는 ACK 번호가 돌아오는 시간을 계측해 두는데 지연되면 대응하여 대기 시간도 늘리고 반대로 ACK 번호가 곧바로 돌아오면 대기 시간을 짧게 설정한다.\r\n\r\n<br/>\r\n\r\n5. 윈도우 제어 방식으로 효율적으로 ACK 번호를 관리한다.\r\n    - ACK 번호가 돌아올 때까지의 시간 동안 아무 일도 하지 않고 기다리는 것은 시간 낭비\r\n    - TCP는 윈도우 제어라는 방식에 따라 송신과 ACK 번호 통지의 동작을 실행함.\r\n        - 한 개의 패킷을 보낸 후 ACK 번호를 기다리지 않고 차례대로 연속해서 복수의 패킷을 보내는 방법.\r\n        - 수신측의 능력을 초과하여 패킷을 보내는 사태가 일어날 수 있다.\r\n            - 수신측에서 송신측에 수신 가능한 데이터 양을 통지하고, 수신측은 이 양을 초과하지 않도록 송신 동작을 실행하는 방법으로 이를 피할 수 있다.\r\n\r\n                ![KakaoTalk_20210930_001659647](https://user-images.githubusercontent.com/62014888/146672263-5d508004-a1ed-4c01-ad86-eaf982349c84.jpg)\r\n\r\n            - 수신 버퍼에 빈 부분이 생기면 TCP 헤더의 윈도우 필드에 이것을 송신측에 알림.\r\n              수신 가능한 데이터 양의 최대값을 윈도우 사이즈라고 부름.\r\n\r\n<br/>\r\n\r\n6. ACK 번호와 윈도우를 합승한다.\r\n    - 이론 상으로 보면 송신측에 보낸 데이터가 수신측에 도착하여 수신 동작이 정상적으로 완료되었을 때 ACK 번호를 송신측에 통지한다.\r\n      잠시 후 데이터를 애플리케이션에 건네주었을 때 윈도우를 송신측에 통지하는 상태가 된다.\r\n        - 수신측에서 송신측에 보내는 패킷이 많아져서 효율성이 저하됨.\r\n    - 실제로는 수신측은 ACK 번호나 윈도우를 통지할 때 소켓을 바로 보내지 않고 잠시 기다린다.\r\n      기다리는 사이에 다음 통지 동작이 일어나면 양쪽을 상승시켜서 한 개의 패킷으로 묶어서 보낸다.\r\n        - 복수의 ACK 번호 통지도 연속해서 일어나면 최후의 것만 통지함.\r\n        - 윈도우 통지도 마찬가지.\r\n\r\n<br/>\r\n\r\n7. HTTP 응답 메시지를 수신한다.\r\n    - 응답 메시지가 돌아오기를 기다리고 응답 메시지가 돌아오면 그것을 수신한다.\r\n    - 응답 메시지를 받기 위해 read 프로그램을 호출함.\r\n        - 프로토콜 스택은 수신 버퍼에서 수신 데이터를 추출하여 애플리케이션에 건네준다.\r\n        - 응답 메시지가 올 때까지 시간이 걸리므로 잠시 보류한다.\r\n        - 응답 메시지 패킷이 도착했을 때 그것을 수신하여 애플리케이션에 건네주는 작업을 재개한다.\r\n\r\n<br/>\r\n\r\n## 04 서버에서 연결을 끊어 소켓을 말소한다.\r\n\r\n1. 데이터 보내기를 완료했을 때 연결을 끊는다.\r\n    - 데이터 송, 수신을 종료하는 것은 애플리케이션이 송신해야 하는 데이터를 전부 송신 완료했다고 판단했을 때.\r\n        - 웹이라면 브라우저가 리퀘스트 메시지를 보내고 서버가 응답하여 데이터 보내기에 서버측이 연결 끊기 단계에 들어감. (HTTP 1.1의 경우 클라이언트에서 연결 끊기 동작에 들어갈 수도 있다)\r\n        - 클라이언트측이 데이터 보내기를 완료했다고 하는 식의 애플리케이션은 클라이언트측에서 끊기 단계에 들어감.\r\n        - 어느 쪽에서 먼저 연결 끊기 단계에 들어가도 좋게 만들어져 있다.\r\n\r\n    - 서버측에서 연결 끊기 단계에 들어갈 때\r\n\r\n        ![KakaoTalk_20210930_221658537](https://user-images.githubusercontent.com/62014888/146672266-2dff9c8f-59fd-4461-86de-6cdad2d12119.jpg)\r\n\r\n        1. 서버측 Socket 라이브러리 close 호출\r\n        2. 서버측 프로토콜 스택이 TCP 헤더를 만들고 연결 끊기 정보 설정\r\n            - 컨트롤 비트의 FIN 비트 1 설정\r\n        3. IP 담당 부분에 의뢰하여 클라이언트에 송신해 달라고 함\r\n            - 이와 동시에 서버측의 소켓에 연결 끊기 동작에 들어갔다는 정보를 기록\r\n        4. FIN에 1 설정한 TCP 헤더가 도착하면 클라이언트측 프로토콜 스택은 자신의 소켓에 서버측이 연결 끊기 동작에 들어갔다는 것을 기록\r\n        5. ACK 번호를 서버측에 반송\r\n        6. 애플리케이션이 데이터를 가지러 올 때까지 기다림.\r\n        7. 애플리케이션이 read를 호출하면 데이터를 건네지 않고 서버에서 보낸 데이터를 전부 수신 완료했다는 사실을 클라이언트측의 애플리케이션에게 알림.\r\n        8. 클라이언트측의 애플리케이션이 close를 호출하여 데이터 송, 수신 동작을 끝냄.\r\n        9. 클라이언트측 프로토콜 스택은 FIN 비트에 1 설정한 TCP 헤더 만들고 IP 담당 부분에 의뢰하여 서버에 송신함.\r\n        10. 서버에서 ACK 번호가 돌아오면 서버와의 대화 종료.\r\n\r\n<br/>\r\n\r\n2. 소켓을 말소한다.\r\n    - 소켓을 바로 말소하지 않고 기다리는 이유\r\n        - 클라이언트가 먼저 FIN을 송신했을 때 마지막에 서버가 FIN을 송신하고 클라이언트가 ACK 번호를 송신하게 된다.\r\n        - 이 때 서버측에서 클라이언트에서 보낸 ACK 번호가 오지 않았다고 생각하여 FIN을 다시 보낼 때가 있다.\r\n        - 만약 바로 클라이언트측에서 소켓을 말소했을 경우 기존 소켓의 포트 번호가 새 소켓에 할당될 수도 있기에 FIN 비트가 새 소켓으로 향하게 되어 연결 끊기 동작에 들어가는 경우가 발생.\r\n\r\n<br/>\r\n\r\n3. 데이터 송, 수신 동작을 정리한다\r\n\r\n    ![KakaoTalk_20210930_223154192](https://user-images.githubusercontent.com/62014888/146672268-121083ea-44ee-43d2-87b6-83a398948aa5.jpg)\r\n    \r\n    1. 소켓 작성 단계\r\n        - 보통 서버측에서 소켓을 만들고 접속 대기 상태로 만든다.\r\n        - 클라이언트측은 사용자가 조치를 취하여 서버에 액세스하는 동작이 시작될 때 패킷을 작성하지만 이 단계에서는 패킷을 주고받지 않는다.\r\n    2. 접속 동작\r\n        1. 클라이언트가 SYN이 1인 TCP 헤더를 만들어 서버에 보낸다.\r\n            - 시퀀스 번호 초기값과 윈도우 값도 기록되어 있음\r\n        2. 서버에서 SYN 1인 TCP 헤더가 돌아온다.\r\n            - 시퀀스 번호 초기값과 윈도우 값, ACK 번호가 기록되어 있음\r\n        3. 클라이언트에서 ACK 번호를 보낸다.\r\n    3. 데이터 송, 수신 동작\r\n        1. 클라이언트에서 리퀘스트 메시지가 분할된 데이터와 시퀀스 번호를 보낸다.\r\n        2. 서버에 ACK 번호를 보낸다.\r\n            - 최초가 아닌 진행 중일때는 윈도우 값도 기록하여 보낸다.\r\n        3. 리퀘스트 메시지를 다 보내면 서버가 응답 메시지를 반송한다.\r\n            - 위 설명과 반대로 진행됨\r\n    4. 연결 끊기 동작\r\n        1. 웹의 경우 서버에서 연결 끊기 동작에 들어감.\r\n        2. 서버에서 FIN을 1로 만든 TCP 헤더 보냄\r\n        3. 클라이언트에서 ACK 번호를 보냄\r\n        4. 클라이언트에서 FIN을 1로 만든 TCP 헤더를 보냄\r\n        5. 서버에서 ACK 번호를 보내고 잠시 후 소켓이 말소.\r\n\r\n<br/>\r\n\r\n## 05 IP와 이더넷의 패킷 송, 수신 동작\r\n\r\n1. 패킷의 기본\r\n    - 패킷은 '헤더'와 '데이터'의 두 부분으로 구성\r\n        - 헤더에는 수신처를 나타내는 주소 등의 제어 정보가 들어있음\r\n        - 그 뒤에 의뢰처에서 의뢰한 데이터가 있음\r\n    - 패킷의 송신처 기기가 패킷을 만들고 헤더와 데이터를 넣은 후 가까운 중계 장치에 송신함.\r\n    - 중계 장치가 패킷을 표를 이용해 분석하고  (중계 장치 안에는 어느 수신처가 있는지가 기록된 표와 같은 것이 있음) 이 내용을 결합하여 목적지에 송신하면 다음 중계 장치에 도착함\r\n    - 이것이 반복되어 최종적으로 수신처에 패킷이 도착함.\r\n    - 송신처가 수신처가 될 수 있기에 명확하게 구별하지 않고 하나로 묶어서 '엔드노드'라고 부름\r\n\r\n    - 허브는 이더넷의 규칙에 따라 패킷을 운반, 라우터는 IP 규칙에 따라 운반.\r\n        - 라우터 - IP 목적지를 확인하여 다음 IP 중계 장치를 나타낸다.\r\n        - 허브 - 서브넷 안에 있는 이더넷이 중계 장치까지 패킷을 운반한다.\r\n\r\n    - TCP/IP 패킷에는 두 개의 헤더가 붙어있다.\r\n        - MAC 헤더(이더넷용 헤더)\r\n        - IP 헤더(IP용 헤더)\r\n    - 다음과 같이 역할을 분담하여 패킷을 운반\r\n        1. 송신처에서 액세스 대상 서버 IP 주소를 IP 헤더의 수신처에 기록\r\n        2. IP는 수신처가 어느 방향에 있는지 조사하고, 그 방향에 있는 다음 라우터를 조사.\r\n        3. 이 라우터에 패킷이 도착하도록 이더넷에 의뢰하는데 이때 다음 라우터에 할당된 이더넷의 주소(MAC 주소)를 조사하고, 그것을 MAC 헤더에 기록함. 이렇게 해서 이더넷에게 어느 라우터에 패킷을 도착하면 좋은지를 전달함.\r\n        4. 패킷을 송신하면 이더넷의 원리에 따라 움직이는 허브에 도착함.\r\n            - 허브에는 패킷의 목적지를 판단하기 위한 표(이더넷용 표)가 있어 패킷의 목적지를 판단하여 중계함\r\n            - 허브가 복수면 순차적으로 경유하여 패킷이 진행됨.\r\n        5. 패킷은 다음 라우터에 도착함.\r\n            - 라우터에는 IP용 표가 있어서 어느 라우터에 패킷을 중계하면 좋을지가 결정됨.\r\n            - 다음 라우터에게 패킷을 건네주기 위해 라우터의 MAC 주소를 조사하고 MAC 헤더에 기록함.\r\n        6. MAC 헤더를 바꾸어 쓰고 패킷을 다음 라우터에 송신함.\r\n        7. 다시 또 허브를 경유하여 R2에 패킷이 도착. 이것을 반복하면 패킷은 목적지에 도착.\r\n    - 이렇게 복잡하게 역할을 분담한 이유가 있다.\r\n        - 이더넷 부분은 무선 LAN, ADSL, FTTH 등 다른 것으로 대체할 수 있다. IP와 조합하여 역할을 분담해서 통신 기술을 적재적소에 구분하여 사용할 수 있기에 이더넷과 같은 거대한 네트워크를 구축하려면 이와 같은 유연성이 꼭 필요하다.\r\n\r\n<br/>\r\n\r\n2. 패킷 송, 수신 동작의 개요\r\n    1. TCP 담당 부분이 IP 담당 부분에 패킷 송신을 의뢰함.\r\n        - 데이터의 조각에 TCP 헤더를 부가한 것을 건네줌. (이것이 패킷에 들어가는 내용물이며 통신 상대의 IP 주소를 나타냄)\r\n    2. IP 담당 부분은 IP 헤더와 MAC 헤더를 부가함.\r\n        - IP 헤더 - IP용 헤더, IP 주소를 씀\r\n        - MAC 헤더 - 이더넷용 헤더, MAC 주소를 씀\r\n    3. 만든 패킷을 네트워크용 하드웨어(이더넷, 무선 LAN 등)에 건네줌\r\n        - 통칭 LAN 어댑터\r\n        - 이 때 패킷의 모습은 0, 1 비트가 이어진 디지털 데이터.\r\n        - LAN 어댑터에 의해 전기나 빛의 신호 상태로 바뀌 케이블에 송출됨.\r\n    4. 신호는 허브나 라우터 등의 중계 장치에 도착하고, 중계 장치가 상대가 있는 곳까지 패킷을 전달함.\r\n    5. 상대에게 패킷이 도착하면 회답이 돌아온다.\r\n        - 송신 동작의 반대라고 생각.\r\n        - 케이블에서 신호의 모습을 한 패킷이 들어오면 LAN 어댑터에서 디지털 데이터로 바꿔주고 이를 IP 담당 부분에게 건네줌. IP 담당 부분이 MAC 헤더와 IP 헤더 뒤의 내용물을 TCP 담당 부분에게 건네줌\r\n\r\n    - IP 패킷 송, 수신 동작은 패킷의 역할에 관계없이 모두 같다. 내용을 보지 않고 TCP 동작 단계도 신경쓰지 않는다. 그저 의뢰받은 내용물을 패킷의 모습으로 만들어 상대에게 송신하거나 전달한 패킷을 수신할 뿐이다.\r\n\r\n<br/>\r\n\r\n3. 수신처 IP 주소를 기록한 IP 헤더를 만든다.\r\n    - IP 담당 부분은 TCP 담당 부분에서 패킷 송, 수신 의뢰를 받으면 IP 헤더를 만들어 TCP 헤더의 앞에 붙인다.\r\n        - 가장 중요한 것은 수신처 IP 주소\r\n            - IP 주소가 잘못되어도 상관없다. 판단하지 않고 그대로 헤더를 설정한다.\r\n              잘못되면 애플리케이션측에 책임이 있는 것으로 간주한다.\r\n        - 송신처 주소도 설정함\r\n            - IP 주소는 사실 컴퓨터에 할당되는 것이 아니라 LAN 어댑터에 할당 되는 것.\r\n            - 여러 개의 LAN 어댑터를 장착하면 각 LAN 어댑터에 서로 다른 IP 주소가 할당됨.\r\n            - 여러 개 IP 중 어느 IP 주소를 설정해야할지 판단하는 것\r\n              == LAN 어댑터 중 어느 LAN 어댑터를 사용하여 패킷을 송신해야 하는지를 판단하는 것\r\n              == 패킷을 건네주는 상대의 라우터를 결정하는 것\r\n    - 패킷을 건네줄 상대를 판단하는 방법은 라우터가 IP용 표(경로표)를 사용하여 다음 라우터를 결정하는 동작과 같음.\r\n        - 소켓에 기록된 수신처 IP 주소를 경로표의 왼쪽 끝에 있는 Network Destination 항목과 비교하여 어느 행에 해당하는지 찾아냄 (IP 주소의 왼쪽 부분이 일치하는 것을 찾아낸다)\r\n        - Interface 항목과 Gateway 항목을 조사한다.\r\n            - Interface 항목은 LAN 어댑터 등의 네트워크용 인터페이스를 나타냄. 인터페이스에서 패킷을 송신하면 상대에게 패킷을 전해줄 수 있다는 의미\r\n            - Gateway 항목은 다음 라우터의 IP 주소를 기록하게 되어 있어서 IP 주소를 가진 라우터에 패킷을 건네주면 라우터가 목적지에 패킷을 중계해 준다는 것을 나타냄.\r\n        - 맨 위 행에는 목적지와 넷마스크가 0.0.0.0으로 등록되어 있음. 이것은 소위 기본 게이트웨이를 나타내며, 일치하는 것이 없으면 이 행이 해당하는 것으로 간주.\r\n        - 이렇게 해서 어느 LAN 어댑터에 패킷을 송신해야 하는지 알고 나서 LAN 어댑터에 할당되어 있는 IP 주소를 IP 헤더의 송신처 IP 주소로 설정함\r\n    - 프로토콜 번호라는 필드에도 패킷에 들어간 내용물이 어디에서 의뢰받은 것인지를 나타내는 값을 설정함.\r\n        - TCP는 06, UDP는 17. 값은 규칙에 결정되어 있음\r\n\r\n<br/>\r\n\r\n4. 이더넷용 MAC 헤더를 만든다.\r\n    - 이더넷은 TCP/IP 개념이 통용되지 않는다.\r\n        - TCP/IP와 다른 구조로 패킷의 수신처를 판단하며, 이 구조를 따르지 않으면 이더넷 패킷을 운반할 수 없다.\r\n        - 이더넷의 수신처 판단 구조로 사용하는 것이 MAC 헤더\r\n    - MAC 헤더의 맨 앞에는 수신처 MAC 주소와 송신처 MAC 주소가 있다.\r\n        - 각각 패킷을 전달하는 상대와 송신한 송신처의 MAC 주소를 나타냄.\r\n        - IP 주소와 달리 그룹화 개념이 없고 48비트를 한 개의 값으로 생각함.\r\n    - 3개의 이더 타입(EtherType)이라는 항목은 IP 헤더의 프로토콜과 비슷함.\r\n        - 이더 타입까지가 MAC 헤더고 그 뒤로 이어지는 것이 패킷의 내용물로 생각함.\r\n    - 송신처 MAC 주소는 자체의 LAN 어댑터의 MAC 주소를 설정함.\r\n        - 어댑터 제조할 때 ROM에 기록되어 있는 값\r\n        - 송신처 IP 주소를 설정할 때 어느 LAN 어댑터에서 송신할지를 판단하고 나서 LAN 어댑터에 할당된 MAC 주소를 설정함.\r\n    - 수신처 MAC 주소는 다소 복잡함.\r\n        - 패킷을 건네주는 상대의 MAC 주소를 기록해야함.\r\n        - 패킷을 건네줄 상대는 경로표에 기록되어 있음 (Gateway 항목)\r\n        - 다만 이것은 IP 주소이기에 MAC 주소를 조사하는 동작을 실행함.\r\n\r\n<br/>\r\n\r\n5. ARP로 수신처 라우터의 MAC 주소를 조사한다.\r\n    - 이더넷에는 연결되어 있는 전원에게 패킷을 전달하는 브로드캐스트라는 구조가 있는데 이를 이용해 IP 주소를 가지고 있으면 MAC 주소를 달라는 요청을 하고 해당하면 응답을 보내준다.\r\n        - 상대가 자신과 같은 네트워크에 존재하면 이것으로 MAC 주소를 알 수 있다.\r\n    - ARP 캐시라는 메모리 영역에 조사한 결과를 보존하여 다시 이용한다.\r\n        - ARP 캐시의 내용과 현실 사이에 일치하지 않을 수 있기에 시간이 되면 삭제하게 되어 있음\r\n    - MAC 헤더를 IP 헤더 앞에 붙이면 패킷이 완성되는데 이까지가 IP 담당 부분의 역할.\r\n        - IP 이외의 특수한 패킷도 한 개의 LAN 어댑터로 대응할 수 있다.\r\n\r\n<br/>\r\n\r\n6. 이더넷의 기본\r\n    - 이더넷은 다수의 컴퓨터가 여러 상대와 자유롭게 적은 비용으로 통신하기 위해 고안된 통신 기술\r\n\r\n        ![KakaoTalk_20211001_003010059](https://user-images.githubusercontent.com/62014888/146672481-e15a53e9-a2ab-4f44-bd4b-94378e66aab1.jpg)\r\n\r\n    - 이더넷의 원형\r\n        - 네트워크의 실체는 케이블만 있음.\r\n        - 컴퓨터가 신호를 송신하면 케이블을 통해 네트워크 전체에 신호가 흐르고 전원에게 신호가 도착함.\r\n        - 이 동작만으로는 도착한 신호가 누구에게 갈 것인지 판단할 수 없어 신호의 맨 앞부분에 수신처 주소를 써둔다.\r\n    - 리피터 허브를 이용한 파생형\r\n        - 모습은 바뀌었지만 신호가 전원에게 전달한다는 기본적인 성질은 변하지 않았다.\r\n    - 스위칭 허브를 이용한 형태\r\n        - 현재는 이더넷이라 말하면 이 형태를 가리킴.\r\n        - 전원에게 전달되는 것이 아닌 수신처 MAC 주소로 나타내는 원하는 기기가 존재하는 부분에만 신호가 흐름.\r\n        - 수신처 MAC 주소의 상대에게 패킷이 전달되는 점은 변하지 않았으므로 MAC 헤더의 개념은 그대로임.\r\n    - MAC 헤더의 수신처 MAC 주소에 기억된 상대에게 패킷을 전달하고, 송신처 MAC 주소로 송신처를 나타낸 후 이더 타입으로 패킷의 내용물을 나타낸다는 세 가지 성질은 지금도 변하지 않았고 이 세 가지 성질을 가진 것이 이더넷이라고 생각하자.\r\n    - 이더넷도 IP와 마찬가지로 패킷의 내용물을 보지 않으므로 송, 수신 동작은 TCP 동작 단계에 상관없이 모든 것이 공통.\r\n\r\n<br/>\r\n\r\n7. 서버의 응답 패킷을 IP에서 TCP로 넘긴다.\r\n\r\n    - 서버에서 반송된 패킷의 타입이 0800이면 패킷의 내용이 IP 프로토콜의 데이터라는 뜻이므로 LAN 드라이버는 TCP/IP의 프로토콜 스택에 패킷을 건넬 것이다.\r\n    - IP 담당 부분은 헤더 부분부터 조사하여 문제가 없는지 확인하고 수신처 IP 주소를 조사한다.\r\n    - 만약 수신처 IP 주소가 자신의 주소와 다르면 ICMP라는 메시지를 사용하여 통신 상대에게 오류를 통지하게 되어 있다.\r\n    - 수신처 IP 주소가 올바르면 이것을 수신하지만, 한 가지 할 일이 더 있다.\r\n        - IP 프로토콜에는 조각 나누기(fragmentation)라는 기능이 있다.\r\n            - 패킷을 짧게 하기 위해 하나의 패킷을 여러 개로 분할하는 것.\r\n        - 수신한 패킷이 분할된 것이면 IP 담당 부분은 그것을 원래 패킷으로 되돌린다.\r\n            - 분할된 패킷은 IP 헤더에 **플래그**라는 항목을 보면 알 수 있는데 분할된 것이면 IP 담당 부분 내부의 메모리에 일시적으로 보관한다.\r\n            - IP 헤더에 **ID 정보**에 같은 값을 가진 패킷이 도착하기를 기다린다. 분할된 패킷은 모두 같은 값.\r\n            - **프래그먼트 오프셋**이라는 항목에는 패킷이 원래 패킷의 어느 위치에 있었는지를 나타내는 정보가 있다.\r\n            - 이 정보들을 바탕으로 분할된 패킷이 전부 도착하면 원래의 모습으로 되돌리는 동작인 **리어셈블링**을 한다.\r\n        - 리어셈블링이 끝나면 패킷을 TCP 담당 부분에 건네준다.\r\n        - IP 헤더에 기록된 수신처 IP 주소와 송신처 IP 주소, TCP 헤더에 기록된 수신처 포트 번호 및 송신처 포트 번호의 네 가지 항목을 조사하여 해당하는 소켓을 찾는다.\r\n        - 해당하는 소켓을 찾아내면 상황에 따라 적절한 동작을 실행\r\n    - TCP 담당 부분에서 IP 헤더를 이용해 소켓을 찾는게 어색할 수도 있으나 만약 IP 담당 부분에서 IP 헤더를 처리해서 TCP 담당 부분으로 IP 주소를 넘기는 방식이면 프로그램의 실행 효율이 저하됨. 그러므로 이런 방식으로 진행한다.\r\n\r\n<br/>\r\n\r\n## 06 UDP 프로토콜을 이용한 송, 수신 동작\r\n\r\n1. 수정 송신이 필요없는 데이터의 송신은 UDP가 효율적이다.\r\n    - DNS 서버에 IP 주소를 조회할 때도 UDP 프로토콜을 사용한다.\r\n    - TCP가 복잡한 원리를 사용할 이유는 데이터를 확실하면서도 효율적으로 전달하기 위해서이다.\r\n    - 데이터를 보낸 후 오류로 다시 보낼 때 효율적으로 보내기 위해서는 도착한 패킷은 다시 보내지 않고 오류로 도착하지 않은 패킷만 다시 보내는 구조가 필요하다. TCP가 이 일을 한다.\r\n    - TCP의 복잡한 구조를 사용하지 않으면 제어용 패킷을 보낼 필요가 없음.\r\n      수신 확인 응답 패킷도 필요없다.\r\n\r\n<br/>\r\n\r\n2. 제어용 짧은 데이터\r\n    - DNS 서버에 대한 조회 등 제어용으로 실행하는 정보 교환은 한 개의 패킷으로 끝나는 경우가 많으므로 TCP가 아닌 UDP를 사용한다.\r\n    - UDP에는 TCP와 같은 수신 확인이나 윈도우가 없어서 송, 수신 전에 제어 정보를 주고받을 필요가 없고, 접속이나 연결 끊기 단계가 없다.\r\n    - 애플리케이션에서 송신 데이터를 받으면 UDP 헤더를 부가하고 이것을 IP에 의뢰하여 송신하기만 한다.\r\n    - 수신도 IP 헤더의 수신처 IP 주소, 송신처 IP 주소, UDP 헤더의 수신처 포트 번호, 송신처 포트 번호라는 네 항목과 소켓에 기록된 정보를 결합하여 데이터를 건네주기만 하면 된다.\r\n    - 오류가 발생하여 패킷이 없어져도 모른 체한다.\r\n        - 오류가 발생하면 회답이 돌아오지 않으므로 데이터를 한 번 더 다시 보내면 그만이다.\r\n        - 복잡한 동작이 필요하지 않아 애플리케이션의 부담이 커지지도 않는다.\r\n\r\n<br/>\r\n\r\n3. 음성 및 동영상 데이터\r\n    - 음성이나 영상의 데이터를 보낼 때도 UDP를 사용한다.\r\n    - TCP와 같이 수신 확인 응답에 의해 오류를 검출하여 다시 보내는 방법이라면 시간이 걸리고 다시 보내도 재생 타이밍이 맞지 않을 수 있다.\r\n    - 다시 보낼 필요가 없거나 다시 보내도 쓸모가 없으면 단순히 UDP로 데이터를 보내는 쪽이 더 효율적이다.\r\n\r\n\r\n다음 장에서는 케이블에서 나간 패킷이 리피터 허브, 스위칭 허브, 라우터라는 기기를 경유하여 인터넷으로 나가는 부분까지 탐험한다.","excerpt":"'성공과 실패를 결정하는 1%의 네트워크 원리' 스터디를 진행하며 정리한 내용이다. 01 소켓을 작성한다. 프로토콜 스택의 내부 구성 KakaoTalk_20210929_220830699 네트워크 애플리케이션 브라우저, 메일러, 웹 서버, 메일 서버 …","fields":{"slug":"/1per-network-ch2/"},"frontmatter":{"date":"Sep 29, 2021","title":"[성공과 실패를 결정하는 1%의 네트워크 원리] 2장","tags":["network","os","1per-network"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n## Master & Slave DB 설치\r\n\r\n```sql\r\nsudo apt update\r\nsudo apt install mariadb-server\r\n```\r\n\r\n<br/>\r\n\r\n\r\n## Master DB 설정\r\n\r\n```sql\r\nCREATE DATABASE db_name DEFAULT CHARACTER SET utf8 COLLATE utf8_general_ci;\r\n```\r\n\r\n```sql\r\n//user 생성\r\n//% 로 설정하면 외부에서도 접근 가능\r\ncreate user 'username'@'%' identified by 'password';\r\n```\r\n\r\n```sql\r\n//해당 계정에 전체 권한이 열림\r\ngrant all privileges on {database}.* to 'username'@'%';\r\nflush privileges;\r\n\r\n//replication에 대한 권한만 설정하려면 이렇게\r\n//위와 같이 {database}.*를 하면 예외가 발생함\r\n//ERROR 1221 (HY000): Incorrect usage of DB GRANT and GLOBAL PRIVILEGES\r\ngrant replication slave on *.* to 'username'@'%';\r\nflush privileges;\r\n\r\n```\r\n\r\n- 아래 파일에서 설정 수정\r\n\r\n![Untitled (55)](https://user-images.githubusercontent.com/62014888/145997271-1f67dad3-851b-44e9-84f0-ee87d8711454.png)\r\n![Untitled (56)](https://user-images.githubusercontent.com/62014888/145997280-91f6c056-bf02-4d98-90a5-5c77fbd28098.png)\r\n- mariadb 재시작\r\n\r\n```sql\r\nsudo service mysqld restart\r\n```\r\n\r\n- master db의 File과 Position 값을 slave db에 설정해야함\r\n\r\n![Untitled (57)](https://user-images.githubusercontent.com/62014888/145997291-21ba5552-5a50-4a44-981a-77d66e50550e.png)\r\n\r\n- File은 replica(slave db)가 master db의 데이터를 읽을 binary 파일이고 Position은 읽기 시작할 위치를 뜻함.\r\n- 즉 slave에서 File과 Position을 설정하면 master의 어떤 파일의 어떤 위치부터 읽겠다는 뜻.\r\n  보통 비동기 방식으로 이 파일을 읽어 slave에서 반영한다.\r\n\r\n<br/>\r\n\r\n\r\n## Slave DB 설정\r\n\r\n- 같은 계정을 만들어주고 권한도 주어야한다.\r\n\r\n```java\r\n//user 생성\r\n//% 로 설정하면 외부에서도 접근 가능\r\ncreate user 'username'@'%' identified by 'password';\r\n```\r\n\r\n- master db와 마찬가지로 해당 파일을 수정\r\n\r\n![Untitled (59)](https://user-images.githubusercontent.com/62014888/145997298-4673eda1-4b80-41d2-9d00-f860447b516c.png)\r\n\r\n- 다만 master에 server-id를 1을 주었던과는 달리 slave에는 2를 주면 된다.\r\n\r\n  만약 slave를 더 추가한다면 3, 4.. 이런식으로 숫자를 증가시켜주면 됨.\r\n\r\n\r\n![Untitled (58)](https://user-images.githubusercontent.com/62014888/145997304-ef075203-3a33-4a24-83b2-69a939caf75b.png)\r\n\r\n- 재시작을 꼭 해주자\r\n\r\n  안해주니 server-id가 설정해달라고 에러가 떴다. 당연한거긴 한데..ㅠㅠ\r\n\r\n\r\n```sql\r\nsudo service mysqld restart\r\n```\r\n\r\n- master db의 정보를 추가해준다.\r\n\r\n  master db ip, 포트, 유저 이름, 비밀번호, File, Position 값을 추가해준다\r\n\r\n\r\n```sql\r\nCHANGE MASTER TO MASTER_HOST='{master_db_ip}', \r\nMASTER_PORT={master_db_port}, \r\nMASTER_USER='{master_db_user_name}', \r\nMASTER_PASSWORD='{master_db_user_password}', \r\nMASTER_LOG_FILE='{master_db_file}', \r\nMASTER_LOG_POS={master_db_position};\r\n```\r\n\r\n```sql\r\nstart slave;\r\n```\r\n\r\n```sql\r\n//\\G 라고 입력하면 이쁘게 출력이 된다\r\nshow slave status\\G;\r\n```\r\n\r\n![Untitled (60)](https://user-images.githubusercontent.com/62014888/145997633-237cebd9-8647-4433-8ccd-ef7d3b34ebe0.png)\r\n\r\n- 각 줄에 대한 의미는 [https://myinfrabox.tistory.com/24](https://myinfrabox.tistory.com/24) 여기를 참고하자.\r\n\r\n<br/>\r\n\r\n\r\n### 주의 사항\r\n\r\n- 처음에 9000으로 포트를 바꿨는데 계속 connection refused가 발생하였다.\r\n\r\n  찾아보니 [https://blog.daum.net/techtip/12415217](https://blog.daum.net/techtip/12415217) 9000 포트가 mariadb 설정에 의해서 127.0.0.1에 대해서만 열려있었다.\r\n\r\n\r\n![Untitled (61)](https://user-images.githubusercontent.com/62014888/145997646-b7962502-c668-4c58-8e3b-cd3ae17a7dc0.png)\r\n\r\n- 그래서 bind-address를 주석 처리해두었다.\r\n\r\n![Untitled (62)](https://user-images.githubusercontent.com/62014888/145997657-db661a67-ef6a-4502-80f9-34a83ad31399.png)\r\n\r\n- 이렇게 master와 slave가 연결이 된 시점에서 master의 db에 데이터가 insert되면 slave에도 insert되는 것을 볼 수 있다.\r\n\r\n<br/>\r\n\r\n\r\n## SpringBoot DB Configuration\r\n\r\n- 방금까지 한 작업은 각각의 DB 서버에 있는 master와 slave db를 서로 연결시켜준 것이다.\r\n  연결을 시켜줌으로써 master db에 insert, update 등의 처리가 발생하면 slave db에도 같이 적용이 되는 것이다.\r\n- 그렇다면 애플리케이션에서는 무슨 작업을 해주어야할까?\r\n  사실 db가 연결이 되었다고 해서 우리가 직접 master db 서버에 가서 쿼리문을 실행시키지 않는다.\r\n  결국 db에 접근을 하는 것은 애플리케이션에서 하는 것이므로 master와 slave에 맞는 datasource를 선택하고 connection을 하여 쿼리를 처리하도록 코드를 구현해야한다.\r\n\r\n1. yml에 datasource 설정\r\n- 그렇다면 우선 datasource 설정부터 해보자.\r\n- 예제 코드이므로 간단하게 application.yml에 datasource 정보를 기입한다.\r\n\r\n  (실제 프로젝트를 진행하면 profile에 따라 설정을 나누기에 더 복잡해질 것이다.)\r\n\r\n\r\n![Inked화면 캡처 2021-09-28 143308_LI](https://user-images.githubusercontent.com/62014888/145997667-a40ab100-3635-46e9-9191-460381aed504.jpg)\r\n\r\n2. DatasourceConfig 설정\r\n\r\n```java\r\n// 1\r\n@EnableAutoConfiguration(exclude = DataSourceAutoConfiguration.class)\r\n@Configuration\r\npublic class DataSourceConfig {\r\n\r\n\t  // 2\r\n    private final JpaProperties jpaProperties;\r\n\r\n    public DataSourceConfig(JpaProperties jpaProperties) {\r\n        this.jpaProperties = jpaProperties;\r\n    }\r\n\r\n    // 3\r\n    @Bean\r\n    public DataSource dataSource() {\r\n        return new LazyConnectionDataSourceProxy(routingDataSource());\r\n    }\r\n\r\n    // 4\r\n    @Bean\r\n    public DataSource routingDataSource() {\r\n        DataSource masterDataSource = masterDatasource();\r\n        RoutingDataSource routingDataSource = new RoutingDataSource();\r\n        routingDataSource.setDefaultTargetDataSource(masterDataSource);\r\n\r\n        Map<Object, Object> dataSources = Map.of(\r\n                \"master\", masterDataSource,\r\n                \"slave\", slaveDatasource()\r\n        );\r\n        routingDataSource.setTargetDataSources(dataSources);\r\n        return routingDataSource;\r\n    }\r\n\r\n    // 4\r\n    @Bean\r\n    @ConfigurationProperties(prefix = \"datasource.master\")\r\n    public DataSource masterDatasource() {\r\n        return DataSourceBuilder.create()\r\n                .type(HikariDataSource.class)\r\n                .build();\r\n    }\r\n\r\n    // 4\r\n    @Bean\r\n    @ConfigurationProperties(prefix = \"datasource.slave\")\r\n    public DataSource slaveDatasource() {\r\n        return DataSourceBuilder.create()\r\n                .type(HikariDataSource.class)\r\n                .build();\r\n    }\r\n\r\n    // 5\r\n    @Bean\r\n    public LocalContainerEntityManagerFactoryBean entityManagerFactory() {\r\n        HibernateProperties hibernateProperties = new HibernateProperties();\r\n        final Map<String, Object> properties = hibernateProperties.determineHibernateProperties(\r\n                jpaProperties.getProperties(), new HibernateSettings()\r\n        );\r\n        HibernateJpaVendorAdapter hibernateJpaVendorAdapter = new HibernateJpaVendorAdapter();\r\n        final EntityManagerFactoryBuilder entityManagerFactoryBuilder = new EntityManagerFactoryBuilder(hibernateJpaVendorAdapter, properties, null);\r\n        return entityManagerFactoryBuilder\r\n                .dataSource(dataSource())\r\n                .packages(\"com.study.playground.replication\")\r\n                .build();\r\n    }\r\n\r\n    // 6\r\n    @Bean\r\n    public PlatformTransactionManager transactionManager(EntityManagerFactory entityManagerFactory) {\r\n        return new JpaTransactionManager(entityManagerFactory);\r\n    }\r\n\r\n}\r\n```\r\n\r\n```java\r\n// 4\r\npublic class RoutingDataSource extends AbstractRoutingDataSource {\r\n\r\n    private static final Logger log = LoggerFactory.getLogger(RoutingDataSource.class);\r\n\r\n    @Override\r\n    protected Object determineCurrentLookupKey() {\r\n        if (TransactionSynchronizationManager.isCurrentTransactionReadOnly()) {\r\n            log.info(\"current db slave\");\r\n            return \"slave\";\r\n        }\r\n        log.info(\"current db master\");\r\n        return \"master\";\r\n    }\r\n}\r\n```\r\n\r\n- 원래는 한 개의 datasource만 사용하므로 spring.datasource~ 라고 yml에 기입을 하면 spring에서 자동으로 datasource를 설정해준다.\r\n- 하지만 두 개를 사용하며 상황에 따라 master 또는 slave db로 연결이 되어야한다. 그러므로 yml에 기입한 datasource 정보를 이용해 직접 설정을 해주어야 한다.\r\n\r\n- 위 코드에서 명시한 번호 순서대로 어떤 역할을 맡고 있는지 명시해보겠다.\r\n    1. 자동으로 datasource를 설정해주는 DataSourceAutoConfiguration을 해제해준다.\r\n    2. yml에 명시해 둔 jpa properties 설정이 자동으로 들어온다.\r\n\r\n  ![Untitled (63)](https://user-images.githubusercontent.com/62014888/145997680-f52bbc10-20d2-4679-a46e-c69d67ef41b9.png)\r\n\r\n    3. Spring은 기본적으로 트랜잭션을 시작할 때 쿼리 실행 전에 datasource를 정해놓는다.\r\n   따라서 트랜잭션이 시작되면 같은 datasource만을 이용한다. 다만 우리는 쿼리 실행할 때 datasource를 결정해줘야하기 때문에 미리 datasource를 정하지 않도록 프록시 datasource인 LazyConnectionDataSourceProxy를 사용하여 실제 쿼리가 실행될 때 connection을 가져오도록 한 것이다.\r\n    4. yml에 명시해둔 datasource를 빈으로 등록시킨다. RoutingDataSource의 경우 AbstractRoutingDataSource을 구현한 클래스인데 AbstractRoutingDataSource는 여러 datasource를 등록해 상황에 맞게 원하는 datasource를 사용할 수 있는 추상 클래스라고 생각하면 된다.\r\n   이 때 determineCurrentLookupKey() 이라는 메서드를 구현하면 되는데 @Transactional(readOnly=?)에 맞춰서 readOnly가 true면 slave를 false면 master를 key로 반환하여 등록된 datasources map에서 value를 반환하게 된다.\r\n    5. EntitiyManagerFactory 설정이다. 원래는 datasource가 자동연결되면서 JPA에 대한 설정도 되지만 우리는 직접 해야한다.\r\n   이 때 Hibernate 설정도 해주게 되는데 앞서 말했듯이 직접 설정을 하다보니 기본적으로 DataSourceAutoConfiguration에서 해주는 네이밍 전략과 같은 설정도 해주어야한다. yml에 같이 명시를 해주어도 되지만 위의 예제와 같이 HibernateProperties를 만들고 determineHibernateProperties() 메서드를 실행하면 기본 설정 + yml에 명시해준 jpa 설정이 같이 합쳐진 properties가 만들어지고 이를 사용해주면 된다.\r\n    6. 마찬가지로 TransactionManager도 직접 설정해준다.\r\n\r\n<br/>\r\n\r\n\r\n## Replication Test\r\n\r\n- 테스트 코드를 통해 insert할 때 master db로 연결하고 select할 때 slave db로 연결되는지 확인해보자.\r\n- @Transactional의 readOnly 설정에 의해 datasource를 고르는 것으로 알고 Controller와 Service를 다 만들어서 인수테스트로 진행할까 했는데 신기하게도 Repository의 save와 findById 만으로도 readOnly 분기를 탈 수 있다.\r\n- 정확히는 잘 모르겠지만 논리적으로 봤을 때 하나의 트랜잭션에서 하나의 find를 사용하면 당연히 readOnly가 true이니 가능한게 아닌가 싶기도 하다.\r\n\r\n```java\r\n@SpringBootTest\r\n@AutoConfigureTestDatabase(replace = AutoConfigureTestDatabase.Replace.NONE) //datasource 자동연결을 막아준다.\r\npublic class ReplicationTest {\r\n\r\n    @Autowired\r\n    private UserRepository userRepository;\r\n\r\n    private User user;\r\n\r\n    @BeforeEach\r\n    void setUp() {\r\n        user = new User(\"oz\", 500);\r\n    }\r\n\r\n    @Test\r\n    @DisplayName(\"save를 하면 master db에 데이터를 insert 한다.\")\r\n    void insert() {\r\n        // given\r\n        Logger logger = (Logger) LoggerFactory.getLogger(RoutingDataSource.class);\r\n        ListAppender<ILoggingEvent> listAppender = new ListAppender<>();\r\n        logger.addAppender(listAppender);\r\n        listAppender.start();\r\n\r\n        // when\r\n        userRepository.save(user);\r\n\r\n        // then\r\n        final List<ILoggingEvent> list = listAppender.list;\r\n        assertThat(list).hasSize(1);\r\n        assertThat(list)\r\n                .extracting(ILoggingEvent::getFormattedMessage)\r\n                .anyMatch(log -> log.equals(\"current db master\"));\r\n    }\r\n\r\n    @Test\r\n    @DisplayName(\"find를 하면 slave db의 데이터를 select 한다.\")\r\n    void find() {\r\n        // given\r\n        userRepository.save(user);\r\n\r\n        Logger logger = (Logger) LoggerFactory.getLogger(RoutingDataSource.class);\r\n        ListAppender<ILoggingEvent> listAppender = new ListAppender<>();\r\n        logger.addAppender(listAppender);\r\n        listAppender.start();\r\n\r\n        // when\r\n        User findUser = userRepository.findById(user.getId())\r\n                .orElseThrow(IllegalStateException::new);\r\n\r\n        // then\r\n        final List<ILoggingEvent> list = listAppender.list;\r\n        assertThat(list).hasSize(1);\r\n        assertThat(list)\r\n                .extracting(ILoggingEvent::getFormattedMessage)\r\n                .anyMatch(log -> log.equals(\"current db slave\"));\r\n        assertThat(findUser).isEqualTo(user);\r\n    }\r\n\r\n}\r\n```\r\n\r\n- RoutingDataSource에서 readOnly 인지에 따라 master, slave db를 사용하기 전에 로그를 남기도록 하였고 이 로그를 이용해 테스트를 진행했다.\r\n\r\n<br/>\r\n\r\n\r\n## 왜 Replication을 적용할까?\r\n\r\n- 프로젝트 규모가 커짐에 따라 DB를 사용할 일은 더 많아질 것이다.\r\n  이 때 DB에서 고민할 것들이 몇 가지가 있을 것이다.\r\n\r\n1. 데이터의 백업\r\n2. 부하 분산\r\n\r\nReplication을 통해 이를 모두 수행할 수 있다.\r\n- master db로 데이터 쓰기 및 업데이트 작업을 하면 연결된 slave db들 모두 쓰기 및 업데이트 작업이 일어나므로 데이터의 백업을 할 수 있다.\r\n- readOnly 속성을 통해 쓰기 및 업데이트 작업은 master db에서 읽기 작업은 slave db 중 하나에서 행함으로써 부하 분산을 할 수 있다.\r\n\r\n<br/>\r\n\r\n## 마무리\r\n\r\n- [보고 또 보고](https://github.com/woowacourse-teams/2021-botobo) 프로젝트에서 Replication을 적용시켰기에 학습하기 위해 한번 따라해보았다.\r\n- Replication을 적용하면 여러 장점이 있지만 서버를 만들거나 적용하는데 쏟는 시간 또한 다 비용이기에 도입할 때는 충분히 고려해야할 것 같다.\r\n- master와 slave 사이의 데이터가 불일치할 수 있는 문제 또한 생각해봐야할 것 같다. \r\n\r\n\r\n## 참고\r\n\r\n- [https://prolog.techcourse.co.kr/posts/1665](https://prolog.techcourse.co.kr/posts/1665)\r\n- [https://velog.io/@max9106/DB-Spring-Replication](https://velog.io/@max9106/DB-Spring-Replication)\r\n- [https://github.com/woowacourse-teams/2021-botobo/wiki/DB-Replication을-위한-데이터베이스-환경-설정-(Master,-Slave)](https://github.com/woowacourse-teams/2021-botobo/wiki/DB-Replication%EC%9D%84-%EC%9C%84%ED%95%9C-%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B2%A0%EC%9D%B4%EC%8A%A4-%ED%99%98%EA%B2%BD-%EC%84%A4%EC%A0%95-(Master,-Slave))","excerpt":"Master & Slave DB 설치 Master DB 설정 아래 파일에서 설정 수정 Untitled (55)\nUntitled (56) mariadb 재시작 master db의 File과 Position 값을 slave db에 설정해야함 Untitl…","fields":{"slug":"/replication/"},"frontmatter":{"date":"Sep 29, 2021","title":"DB Replication 따라해보기","tags":["database","replication"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n## 기존 검색 API\r\n\r\n**/api/search/workbooks?type=name&criteria=date&order=desc&keyword=JAVA&start=0&size=10**\r\n\r\n- type: name, tag, user 중 택 1 (검색할 때 종류)\r\n- criteria: date, name, count, like 중 택 1 (조회할 때 정렬 기준)\r\n- order: asc (오름차순), desc (내림차순)\r\n- keyword: 검색어\r\n- start: 페이징 시작점\r\n- size: 가져올 문제집 개수\r\n\r\n보또보 기존 검색 api이다.\r\n\r\n문제집 이름으로 검색, 태그로 검색, 유저명으로 검색 이렇게 3개로 나누어져있었고 검색을 실시간으로 할 수 있었다.\r\n\r\n태그나 유저로 검색된 결과에서 최신순, 이름순, 카드개수순, 좋아요순으로 정렬이 가능했다.\r\n\r\n![Untitled (8)](https://user-images.githubusercontent.com/62014888/140268421-87b1995d-7311-449b-bffd-f7d504dd5218.png)\r\n\r\n<br/>\r\n\r\n## 새로운 검색 API\r\n\r\n**/api/search/workbooks?keyword=JAVA&tags=1&users=1&criteria=date&start=0&size=10**\r\n\r\n- criteria: date, name, count, like 중 택 1 (조회할 때 정렬 기준)\r\n- keyword: 검색어\r\n- tags: 태그 id (원하는 태그들로 필터링)\r\n- users: 유저 id (원하는 유저들로 필터링)\r\n- start: 페이징 시작점\r\n- size: 가져올 문제집 개수\r\n\r\n보또보 새로운 검색 api이다.\r\n\r\n다른 검색 사이트 + 프롤로그 검색을 참고했다.\r\n\r\n프롤로그의 태그로 필터링 하는 기능을 보고 우리도 태그 또는 유저 검색 기능을 필터링으로 바꾸자는 의견이 나와서 이를 적용시키고 싶었다.\r\n\r\n하지만 실시간으로 검색된 결과에 태그나 유저로 필터링을 하는 것이 뭔가 어색한 것 같았고 실제 다른 검색 사이트에서도 검색된 결과 페이지에서 필터링을 주로 한다는 것을 발견할 수 있었다.\r\n\r\n그래서 검색어에 대한 결과를 실시간으로 보여주는 것이 아닌 검색을 한 결과 페이지에서 보여주기로 했으며 태그, 유저 검색은 삭제하고 문제집 검색만 남기기로 했다. 문제집 이름으로 검색된 결과를 바탕으로 해당 문제집들의 태그, 유저로 필터링을 할 수 있고 최신순, 이름순, 카드개수순, 좋아요순으로 정렬이 가능하도록 했다.\r\n\r\n\r\n\r\n![Untitled (9)](https://user-images.githubusercontent.com/62014888/140268459-3ee4e7b5-416b-44a7-80d2-80d395729c81.png)\r\n\r\n<br/>\r\n\r\n## Criteria? QueryDSL?\r\n\r\n기존의 검색 기능은 동적 쿼리 구현을 위해 JPQL 빌더로 criteria를 사용하고 specification을 이용하여 쿼리 조건을 처리하였다.\r\n\r\n### Criteria\r\n\r\nCriteria는 JPQL을 자바 코드로 작성하도록 도와주는 빌더 클래스 API다.\r\n\r\nCriteria를 사용하면 문자가 아닌 코드로 JPQL을 작성하므로 문법 오류를 컴파일 단계에서 잡을 수 있고 문자 기반의 JPQL보다 동적 쿼리를 안전하게 생성할 수 있다는 장점이 있다. 하지만 코드가 복잡하고 장황해서 직관적으로 이해가 힘들다는 단점도 있다.\r\n\r\n뿐만 아니라 문법 오류를 컴파일 단계에서 잡을 수 있다곤 하지만 사용하다보면 필드명을 문자로 적어야 해서 실수를 한다면 컴파일 단계에서 잡을 수가 없게 된다.\r\n\r\n![화면 캡처 2021-09-27 120432](https://user-images.githubusercontent.com/62014888/140268498-b1127b99-6866-4889-b517-a6298564f637.jpg)\r\n\r\n물론 이를 위해 메타 모델 API를 사용하면 된다고 한다.\r\n\r\n다만, 메타 모델 API를 사용하려면 메타 모텔 클래스를 만들어야 하는데 이는 코드 자동 생성기가 있어 만들어 준다고 한다. 이러한 코드 생성기는 빌드 도구를 사용해서 실행한다.\r\n\r\n<br/>\r\n\r\n### Specification\r\n\r\nSpecification은 검색 조건을 추상화한 객체다.\r\n\r\n즉, 검색 조건에 대해 Specification을 생성하고, 이를 통해 다양한 조건의 검색을 할 수 있다는 뜻이다.\r\n\r\n우리 프로젝트로 예를 들면 어떤 타입의 검색어인지 어떤 순서로 정렬할 것인지를 Criteria를 이용해 만들고 이러한 다양한 검색 조건을 Specification으로 생성한 뒤 Repository 메서드 인자로 넘겨주어서 사용했다.\r\n\r\n<br/>\r\n\r\n## QueryDSL 특징\r\n\r\nCriteria는 위에서 말한 특징들의 장점을 확실하게 가지고 있다.\r\n\r\n하지만 너무 복잡하고 어렵다는 가장 큰 단점이 있다.\r\n\r\n작성된 코드를 보면 그 복잡성으로 인해 어떤 JPQL이 생성될지 파악하기가 쉽지 않다.\r\n\r\n쿼리를 문자가 아닌 코드로 작성해도, 쉽고 간결하며 그 모양도 쿼리와 비슷하게 개발할 수 있는 JPQL 빌더가 바로 QueryDSL이다.\r\n\r\n<br/>\r\n\r\n## Why use QueryDSL?\r\n\r\n일단 어떤 기술을 적용하기 전에 반드시 '왜 적용하는가?' 에 대해 짚고 넘어가야 한다고 생각한다.\r\n\r\n사실 이미 중간곰이랑 피케이가 Criteria, Specification으로 검색 기능을 잘 구현 해놓았기에 처음에는 QueryDSL을 적용할 필요가 있을까 싶었다.\r\n\r\n하지만 곰곰히 생각한 끝에 QueryDSL로 변경하기로 했다.\r\n\r\n그 이유는 두 가지이다.\r\n\r\n1. 기존의 Criteria, Specification를 적용한 코드를 내가 구현한게 아니기에 어차피 처음부터 공부했어야 했다. 둘 다 그렇게 해야하는거면 QueryDSL을 적용해보는 것도 괜찮겠다고 생각했다.\r\n\r\n2. 가독성 및 컴파일 오류다.\r\n\r\n아무래도 Criteria로 작성한 코드는 한번에 의미를 파악하기 어려웠고 따라서 기존 코드에서 새롭게 바뀐 API대로 적용시키는게 생각보다 어려울 것 같았다.\r\n\r\n또한 메타 모델 API를 사용하지 않는 이상 문자열 그대로 코드를 작성해야 하니 컴파일 단계에서 오류를 완전히 잡아주지 못하였다.\r\n\r\n이러한 이유들로 Criteria에서 QueryDSL로 변경하며 새로운 검색 API를 적용시키기로 하였다.\r\n\r\n<br/>\r\n\r\n## QueryDSL 설정\r\n\r\n```groovy\r\nplugins {\r\n\t\t//1\r\n    id \"com.ewerk.gradle.plugins.querydsl\" version \"1.0.10\"\r\n}\r\n\r\ndependencies {\r\n    //2\r\n    implementation 'com.querydsl:querydsl-jpa'\r\n}\r\n\r\n//3\r\ndef querydslDir = \"$buildDir/generated/querydsl\"\r\n\r\n//4\r\nquerydsl {\r\n    jpa = true\r\n    querydslSourcesDir = querydslDir\r\n}\r\n\r\n//5\r\nsourceSets {\r\n    main.java.srcDir querydslDir\r\n}\r\n\r\n//6\r\nconfigurations {\r\n    querydsl.extendsFrom compileClasspath\r\n}\r\n\r\n//7\r\ncompileQuerydsl {\r\n    options.annotationProcessorPath = configurations.querydsl\r\n}\r\n```\r\n\r\n빌드툴로 gradle을 사용했다.\r\n\r\n신기하게도 QueryDSL 공식 문서를 보면 maven이나 ant로 설정하는 방법은 나오지만 gradle에서 설정하는 방법은 나오지 않는다. 그래서 검색을 통해 해결하였다.\r\n\r\n설정들을 위에서부터 하나씩 설명하자면 이렇다.\r\n\r\n1. Q클래스 생성을 위한 QueryDSL 플러그인을 추가한다.\r\n2. QueryDSL 의존성을 추가한다.\r\n3. Q클래스가 저장되는 위치를 뜻한다. Q클래스는 자동으로 생성되는 파일들이라 .gitignore에 추가하여 깃헙에 올리지 않도록 하는것이 좋은데 build 디렉토리에 있는 파일들은 모두 올라가지 않고 있는 중이라 이렇게 설정하였다.\r\n4. jpa true로 하면 빌드할 때 자동으로 Q클래스가 생성된다. querydslSourcesDir는 Q클래스가 어디에 생성할지 결정한다.\r\n5. 빌드할 때 Q클래스가 생성된 위치를 나타낸다.\r\n6. gradle 6.x 버전에서 이 코드를 작성해야 정상작동한다고 한다. compile로 걸린 JPA 의존성에 접근하도록 해준다.\r\n7. annotation processor의 경로를 설정해주어 빌드 시 Q클래스가 생성되도록 해준다.\r\n\r\ncomplieQuerydsl을 실행해주면 이렇게 원하는 위치에 Q클래스가 잘 생성된 모습을 볼 수 있다.\r\n\r\n![Untitled (10)](https://user-images.githubusercontent.com/62014888/140268538-abad940c-0956-4877-b423-b80ed149b34c.png)\r\n\r\n<br/>\r\n\r\n## 기존 코드와 변경된 코드 비교\r\n\r\n```java\r\n@EqualsAndHashCode\r\n@Getter\r\n@NoArgsConstructor\r\n@AllArgsConstructor(access = AccessLevel.PRIVATE)\r\npublic class WorkbookSearchParameter {\r\n\r\n    private static final int MINIMUM_START_PAGE = 0;\r\n    private static final int DEFAULT_START_PAGE = 0;\r\n    private static final int MINIMUM_PAGE_SIZE = 1;\r\n    private static final int MAXIMUM_PAGE_SIZE = 100;\r\n    private static final int DEFAULT_PAGE_SIZE = 20;\r\n\r\n    private SearchKeyword searchKeyword;\r\n    private SearchCriteria searchCriteria;\r\n    private int start;\r\n    private int size;\r\n\r\n    private WorkbookSearchParameter(SearchCriteria searchCriteria, SearchKeyword searchKeyword, int start, int size) {\r\n        this.start = start;\r\n        this.size = size;\r\n        this.searchKeyword = searchKeyword;\r\n        this.searchCriteria = searchCriteria;\r\n    }\r\n\r\n    public static WorkbookSearchParameter ofRequest(String searchCriteria,\r\n                                                    String searchKeyword,\r\n                                                    String start, String size) {\r\n        return of(\r\n                SearchCriteria.of(searchCriteria),\r\n                SearchKeyword.of(searchKeyword),\r\n                initializeStartValue(start),\r\n                initializeSizeValue(size)\r\n        );\r\n    }\r\n\r\n    public static WorkbookSearchParameter of(SearchCriteria searchCriteria,\r\n                                             SearchKeyword searchKeyword,\r\n                                             int start, int size) {\r\n        return new WorkbookSearchParameter(\r\n                searchCriteria,\r\n                searchKeyword,\r\n                start,\r\n                size\r\n        );\r\n    }\r\n\r\n    private static int initializeStartValue(String start) {\r\n        try {\r\n            int value = Integer.parseInt(start);\r\n            if (value < MINIMUM_START_PAGE) {\r\n                throw new InvalidPageStartException();\r\n            }\r\n            return value;\r\n        } catch (NumberFormatException e) {\r\n            return DEFAULT_START_PAGE;\r\n        }\r\n    }\r\n\r\n    private static int initializeSizeValue(String size) {\r\n        try {\r\n            int value = Integer.parseInt(size);\r\n            if (value < MINIMUM_PAGE_SIZE || value > MAXIMUM_PAGE_SIZE) {\r\n                throw new InvalidPageSizeException();\r\n            }\r\n            return value;\r\n        } catch (NumberFormatException e) {\r\n            return DEFAULT_PAGE_SIZE;\r\n        }\r\n    }\r\n\r\n    public PageRequest toPageRequest() {\r\n        return PageRequest.of(start, size);\r\n    }\r\n}\r\n\r\n```\r\n\r\n기존 코드에서는 검색 조건 파라미터 값을 가지고 있으며 Specification을 이용해 검색 조건을 처리하는 클래스인 WorkbookSearchParameter이다.\r\n\r\n여기에 타입, 정렬 기준 등을 처리해주는 SearchCriteria, SearchType, SearchOrder 등이 있다.\r\n\r\n```java\r\n@EqualsAndHashCode\r\n@Getter\r\n@NoArgsConstructor\r\n@AllArgsConstructor(access = AccessLevel.PRIVATE)\r\npublic class WorkbookSearchParameter {\r\n\r\n    private static final int MINIMUM_START_PAGE = 0;\r\n    private static final int DEFAULT_START_PAGE = 0;\r\n    private static final int MINIMUM_PAGE_SIZE = 1;\r\n    private static final int MAXIMUM_PAGE_SIZE = 100;\r\n    private static final int DEFAULT_PAGE_SIZE = 20;\r\n\r\n    private SearchKeyword searchKeyword;\r\n    private SearchCriteria searchCriteria;\r\n    private int start;\r\n    private int size;\r\n\r\n    @Builder\r\n    private WorkbookSearchParameter(String searchCriteria, String searchKeyword, String start, String size) {\r\n        this.start = initializeStartValue(start);\r\n        this.size = initializeSizeValue(size);\r\n        this.searchKeyword = SearchKeyword.of(searchKeyword);\r\n        this.searchCriteria = SearchCriteria.of(searchCriteria);\r\n    }\r\n\r\n    private int initializeStartValue(String start) {\r\n        try {\r\n            int value = Integer.parseInt(start);\r\n            if (value < MINIMUM_START_PAGE) {\r\n                throw new InvalidPageStartException();\r\n            }\r\n            return value;\r\n        } catch (NumberFormatException e) {\r\n            return DEFAULT_START_PAGE;\r\n        }\r\n    }\r\n\r\n    private int initializeSizeValue(String size) {\r\n        try {\r\n            int value = Integer.parseInt(size);\r\n            if (value < MINIMUM_PAGE_SIZE || value > MAXIMUM_PAGE_SIZE) {\r\n                throw new InvalidPageSizeException();\r\n            }\r\n            return value;\r\n        } catch (NumberFormatException e) {\r\n            return DEFAULT_PAGE_SIZE;\r\n        }\r\n    }\r\n\r\n    public PageRequest toPageRequest() {\r\n        return PageRequest.of(start, size);\r\n    }\r\n}\r\n```\r\n\r\n```java\r\n@RequiredArgsConstructor\r\n@Repository\r\npublic class WorkbookSearchRepository {\r\n\r\n    private final JPAQueryFactory jpaQueryFactory;\r\n\r\n    public Page<Workbook> searchAll(WorkbookSearchParameter parameter,\r\n                                    List<Long> tags,\r\n                                    List<Long> users,\r\n                                    Pageable pageable) {\r\n        QueryResults<Workbook> results = queryBy(parameter, tags, users)\r\n                .offset(pageable.getOffset())\r\n                .limit(pageable.getPageSize())\r\n                .fetchResults();\r\n        return new PageImpl<>(results.getResults(), pageable, results.getTotal());\r\n    }\r\n\r\n    public List<Workbook> searchAll(WorkbookSearchParameter parameter) {\r\n        return queryBy(parameter)\r\n                .limit(parameter.getSize())\r\n                .fetch();\r\n    }\r\n\r\n    private JPAQuery<Workbook> queryBy(WorkbookSearchParameter parameter) {\r\n        return queryBy(parameter, Collections.emptyList(), Collections.emptyList());\r\n    }\r\n\r\n    private JPAQuery<Workbook> queryBy(WorkbookSearchParameter parameter, List<Long> tags, List<Long> users) {\r\n        return jpaQueryFactory.selectFrom(workbook)\r\n                .innerJoin(workbook.user, user).fetchJoin()\r\n                .innerJoin(workbook.cards.cards, card)\r\n                .leftJoin(workbook.workbookTags, workbookTag)\r\n                .leftJoin(workbookTag.tag, tag)\r\n                .leftJoin(workbook.hearts.hearts, heart)\r\n                .where(containKeyword(parameter.getSearchKeyword()),\r\n                        containTags(tags),\r\n                        containUsers(users),\r\n                        openedTrue())\r\n                .groupBy(workbook.id)\r\n                .orderBy(findCriteria(parameter.getSearchCriteria()), workbook.id.asc());\r\n    }\r\n\r\n    private BooleanExpression containKeyword(SearchKeyword searchKeyword) {\r\n        if (searchKeyword == null) {\r\n            return null;\r\n        }\r\n        String keyword = searchKeyword.getValue();\r\n        return containsKeywordInWorkbookName(keyword)\r\n                .or(equalsKeywordInWorkbookTag(keyword));\r\n    }\r\n\r\n    private BooleanExpression containsKeywordInWorkbookName(String keyword) {\r\n        return workbook.name.lower().contains(keyword);\r\n    }\r\n\r\n    private BooleanExpression equalsKeywordInWorkbookTag(String keyword) {\r\n        return workbook.workbookTags.any().tag.tagName.value.eq(keyword);\r\n    }\r\n\r\n    private BooleanExpression containTags(List<Long> tags) {\r\n        if (tags == null || tags.isEmpty()) {\r\n            return null;\r\n        }\r\n        return workbookTag\r\n                .tag\r\n                .id\r\n                .in(tags);\r\n    }\r\n\r\n    private BooleanExpression containUsers(List<Long> users) {\r\n        if (users == null || users.isEmpty()) {\r\n            return null;\r\n        }\r\n        return user\r\n                .id\r\n                .in(users);\r\n    }\r\n\r\n    private BooleanExpression openedTrue() {\r\n        return workbook.opened.isTrue();\r\n    }\r\n\r\n    private OrderSpecifier<?> findCriteria(SearchCriteria searchCriteria) {\r\n        if (searchCriteria == SearchCriteria.DATE) {\r\n            return workbook.createdAt.desc();\r\n        }\r\n        if (searchCriteria == SearchCriteria.NAME) {\r\n            return workbook.name.asc();\r\n        }\r\n        if (searchCriteria == SearchCriteria.COUNT) {\r\n            return card.countDistinct().desc();\r\n        }\r\n        return heart.countDistinct().desc();\r\n    }\r\n}\r\n\r\n```\r\n\r\nQueryDSL로 바꾸면서 기존의 WorkbookSearchParameter는 파라미터로 들어온 값만 가지고 있고 이 값을 이용해 QueryDSL 전용 Repository에서 조회를 처리했다.\r\n\r\nconfiguration으로 JPAQueryFactory를 빈으로 등록한 뒤 이를 이용해 동적 쿼리를 작성하는 방식이다.\r\n\r\n디테일한 부분은 설명하기 아직 지식이 부족하지만 대략적으로 JPAQueryFactory를 사용해 동적 쿼리를 만드는데 파라미터로 넘겨온 값을 where 내에 있는 메서드들을 이용해 BooleanExpression을 반환받도록 하여 조건에 맞게 쿼리를 만들 수 있다.\r\n\r\n물론 이와 함께 paging도 가능하다!\r\n\r\nCriteria와 비교하면 상대적으로 가독성이 좋다는 것을 알 수 있다.\r\n\r\n<br/>\r\n\r\n## 주의할 점\r\n\r\n적용하다 생긴 트러블 슈팅을 공유한다.\r\n\r\n1. 소나큐브와 함께 사용하다 보니 테스트 커버리지를 통과하지 못해 빌드할 때 에러가 발생했다.\r\n\r\n   Q클래스도 테스트 커버리지 검증을 하다보니 발생하는 에러였는데 이를 위해 테스트 커버리지 검증에서 Q클래스를 제외시켰다.\r\n\r\n   역시나 검색을 해보니 이런 상황을 맞이한 분들이 있으셔서 이 블로그를 참고하였다.\r\n   [https://velog.io/@lxxjn0/코드-분석-도구-적용기-2편-JaCoCo-적용하기](https://velog.io/@lxxjn0/%EC%BD%94%EB%93%9C-%EB%B6%84%EC%84%9D-%EB%8F%84%EA%B5%AC-%EC%A0%81%EC%9A%A9%EA%B8%B0-2%ED%8E%B8-JaCoCo-%EC%A0%81%EC%9A%A9%ED%95%98%EA%B8%B0)\r\n\r\n    ```groovy\r\n    jacocoTestCoverageVerification {\r\n        def Qdomains = []\r\n    \r\n        for (qPattern in '*.QA'..'*.QZ') {\r\n            Qdomains.add(qPattern + '*')\r\n        }\r\n    \r\n        violationRules {\r\n            rule {\r\n                enabled = true\r\n                element = 'CLASS'\r\n    \r\n                limit {\r\n                    counter = 'BRANCH'\r\n                    value = 'COVEREDRATIO'\r\n                    minimum = 0.80\r\n                }\r\n    \r\n                limit {\r\n                    counter = 'LINE'\r\n                    value = 'COVEREDRATIO'\r\n                    minimum = 0.80\r\n                }\r\n    \r\n                excludes = [\r\n                        //제외될 다른 클래스들\r\n                ] + Qdomains\r\n            }\r\n        }\r\n    }\r\n    ```\r\n\r\n<br/>\r\n\r\n2. distinct와 orderBy가 동시에 적용되지 않는 현상이 발생했다.\r\n\r\n   찾아보니 H2 문법 문제였고 MySQL에서는 같이 사용해도 적용이 되었다.\r\n\r\n   그래서 일단은 workbook의 id로 groupBy를 해서 distinct를 사용하지 않는 방향으로 수정했다. 프로젝트를 진행하며 Flyway를 적용할 때도 그렇고 이번에도 그렇고 local과 test에서는 H2를 사용하고 dev와 prod에서는 Mariadb를 사용하다 보니 H2와 MySQL의 문법 차이 때문에 여러 번 syntax 에러를 경험하는 일이 많았다.\r\n\r\n   그리하여 다음 스프린트 때는 이 차이를 해소시킬 방법을 찾아볼 생각이다.\r\n\r\n<br/>\r\n\r\n3. 이건 우리가 겪은 트러블 슈팅은 아니지만 gradle에서 QueryDSL 설정과 관련해서 많이들 이슈가 있다고 한다. 현재 우리가 적용시킨 설정 방법은 플러그인을 사용해서 Q클래스를 만드는데 이때 gradle 버전이 업그레이드 됨에 따라 여러 가지 설정을 추가해주어야 했다.\r\n   그래서 이 플러그인을 걷어내기 위해 gradle AnnotationProcessor를 사용하여 처리하는 방법이 있다고 한다.\r\n   이게 궁금하다면 [http://honeymon.io/tech/2020/07/09/gradle-annotation-processor-with-querydsl.html](http://honeymon.io/tech/2020/07/09/gradle-annotation-processor-with-querydsl.html) 블로그를 참고하도록 하자.","excerpt":"기존 검색 API /api/search/workbooks?type=name&criteria=date&order=desc&keyword=JAVA&start=0&size=10 type: name, tag, user 중 택 1 (검색할 때 종류) crit…","fields":{"slug":"/criteria-querydsl/"},"frontmatter":{"date":"Sep 27, 2021","title":"Criteria -> QueryDSL 마이그레이션 해보기","tags":["jpql"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n'성공과 실패를 결정하는 1%의 네트워크 원리' 스터디를 진행하며 정리한 내용이다.\r\n\r\n---\r\n\r\n## 01 HTTP 리퀘스트 메시지를 작성한다.\r\n\r\n1. 탐험의 여행은 URL 입력부터 시작한다.\r\n    - URL은 http: 뿐만 아니라 ftp:, file:, mailto: 로 시작하는 것 등 여러 가지가 있다.\r\n    - 브라우저는 몇 개의 클라이언트 기능을 겸비한 복합적인 클라이언트 소프트웨어.\r\n    - 그렇기 때문에 몇 개가 있는 기능 중의 어느 것을 사용하여 데이터에 엑세스하면 좋을 것인지를 판단하는 재료가 필요하다. 그래서 웹 서버에 액세스할 때는 http:, FTP 서버라면 ftp: 라는 식으로 여러 종류의 URL이 준비되어 있는 것.\r\n    - 웹 서버나 FTP 서버에 액세스하는 경우에는 서버의 도메인명이나 액세스하는 파일의 경로명 등을 URL에 포함, 메일의 경우에는 보내는 상대의 메일 주소를 URL에 포함시킴.\r\n    - 필요에 따라 사용자명이나 패스워드, 서버측 포트 번호 등을 쓸 수도 있다.\r\n    - 액세스 대상이 웹 서버라면 HTTP라는 프로토콜, FTP 서버라면 FTP라는 프로토콜을 사용함. 그러므로 여기에는 액세스할 때의 프로토콜 종류가 쓰여있다고 생각하면 됨.\r\n    - 단, file: 로 시작하는 URL과 같이 액세스할 때 네트워크를 사용하지 않는 것도 있으므로 프로토콜을 나타낸다고 단언할 수는 없음. 액세스 방법이라는 식으로 생각하는 것이 좋다.\r\n\r\n<br/>\r\n\r\n2. 브라우저는 먼저 URL을 해독한다.\r\n    - URL의 요소\r\n        - http: (URL의 맨 앞에는 데이터 출처에 액세스하는 방법, 즉 프로토콜을 기록) + // (//는 나중에 이어지는 무자열이 서버의 이름임을 나타냄) + 웹 서버 명 + / + 디렉토리명 + / + ..... + 파일명 (데이터 출처의 경로명을 나타냄, 생략 가능)\r\n\r\n<br/>\r\n\r\n3. 파일명을 생략한 경우\r\n    - URL 규칙에는 파일명을 생략해도 좋음\r\n    - 하지만 파일명을 쓰지 않으면 어느 파일에 액세스해야 할지 모른다.\r\n    - 파일명을 생략할 때를 대비해 미리 서버측에서 설정을 해둔다.\r\n        - 대부분은 index.html, default.htm\r\n    - http://www.oz.kr/\r\n        - 도메인명만 쓴 URL을 볼 수 있는데 이것도 파일명을 생략한 것.\r\n        - 끝에 /가 있으므로 /라는 디렉토리 (루트 디렉토리)가 지정되고 파일명은 생략된 것.\r\n    - http://www.oz.kr\r\n        - 디렉토리명까지 생략.\r\n        - 이렇게 쓰는 방법도 인정되고 있다.\r\n        - 경로명이 아무 것도 없는 경우에는 루트 디렉토리의 아래에 있는 미리 설정된 파일명의 파일, 즉 /index.html 또는 /default.htm 이라는 파일에 액세스하면 혼란이 없기 때문.\r\n    - http://www.oz.kr/whatisthis\r\n        - 맨 끝이 /가 없으므로 whatisthis를 파일명으로 보는 것이 맞을 것 같다.\r\n        - 하지만 실제로는 파일명을 생략하는 규칙을 정확히 이해하지 못하고 디렉토리의 끝에 있는 /까지 생략해 버리는 경우가 있다.\r\n        - 그래서 이 경우는 다음과 같이 취급하는 것이 통례.\r\n        - 웹 서버에 whatisthis라는 파일이 있으면 whatisthis를 파일명으로 보고 whatisthis 디렉토리가 있으면 whatisthis를 디렉토리명으로 본다는 것.\r\n\r\n<br/>\r\n\r\n4. HTTP의 기본 개념\r\n    - HTTP 프로토콜은 클라이언트와 서버가 주고받는 메시지의 내용이나 순서를 정한 것.\r\n    - 클라이언트에서 서버를 향해 리퀘스트 메시지를 보낸다. 리퀘스트 메시지 안에는 무엇을, 어떻게 해서 하겠다는 내용이 쓰여있음.\r\n    - '무엇을'에 해당하는 것이 URI. 보통 페이지 데이터를 저장한 파일의 이름이나 CGI 프로그램의 파일명을 URI로 쓴다.\r\n        - URI는 여기에 http:로 시작하는 URL을 그대로 쓸 수도 있다.\r\n        - 즉 여기에는 다양한 액세스 대상을 쓸 수 있으며, 이러한 액세스 대상을 통칭하는 말이 URI이다.\r\n    - '어떻게 해서'에 해당하는 것은 메소드.\r\n        - 이 메소드에 의해 웹 서버에 어떤 동작을 하고 싶은지를 전달한다.\r\n    - HTTP 메시지에는 보충 정보를 나타내는 헤더 파일도 있음.\r\n    - 리퀘스트 메시지가 웹 서버에 도착하면 웹 서버는 그 속에 쓰여있는 내용을 해독한다.\r\n    - 그리고 URI와 메시지를 조사하여 '무엇을', '어떻게 하는지' 판단한 후 요구에 따라 동작하고, 결과 데이터를 응답 메시지에 저장한다.\r\n    - 응답 메시지의 맨 앞부분에는 실행 결과가 정상 종료되었는지 또는 이상이 발생했는지를 나타내는 스테이터스 코드가 있음.\r\n    - 헤더 파일과 페이지의 데이터가 이어지고 이 응답 메시지를 클라이언트에 반송한다.\r\n    - 그러면 이것이 클라이언트에 도착하여 브라우저가 메시지 안에서 데이터를 추출하여 화면에 표시하면서 HTTP의 동작은 끝난다.\r\n    - 보통 웹 서버에 액세스하여 페이지의 데이터를 읽을 때 사용하는 것이 GET 메소드.\r\n        - 메소드에 'GET'이라 쓰고 URI에 '/dir1/file1.html'과 같이 쓰이면 '/dir1/file1.html' 이라는 파일의 데이터를 읽으라는 의미.\r\n    - POST는 폼에 데이터를 사용해서 웹 서버에 송신하는 경우에 사용.\r\n    - GET과 POST만 있다면 페이지 데이터를 웹 서버에서 읽거나 페이지에 있는 필드에 입력한 데이터를 웹 서버에 보내는 사용법만 가능함. 하지만 PUT이나 DELETE를 사용하면 클라이언트에서 웹 서버의 파일을 바꿔쓰거나 삭제하는 것도 가능함.\r\n    - 이 기능을 잘 사용하면 웹 서버를 파일 서버 대신 사용할 수도 있다.\r\n\r\n<br/>\r\n\r\n5. HTTP 리퀘스트 메시지를 만든다.\r\n    - URL을 해독하고 웹 서버와 파일명을 판단하면 브라우저는 이것을 바탕으로 HTTP의 리퀘스트 메시지를 만듦.\r\n    - 실제 HTTP 메시지를 쓰는 방법, 즉 포맷이 결정되어 있으므로 브라우저는 이 포맷에 맞게 리퀘스트 메시지를 만든다.\r\n    - 리퀘스트 메시지의 첫 번째 행에 있는 리퀘스트 라인을 쓴다.\r\n    - 이 행에서 중요한 것은 맨 앞에 있는 메소드.\r\n    - 응답 메시지의 메시지 본문의 내용은 서버에서 클라이언트에 송신하는 데이터.\r\n    - 파일에서 읽은 데이터나 CGI 애플리케이션이 출력한 데이터가 들어간다. 메시지 본문은 바이너리 데이터로 취급함.\r\n    - 브라우저가 웹 서버에 리퀘스트 메시지를 보내는 장면은 이것만이 아님.\r\n        - 하이퍼링크를 클릭하거나 폼에 데이터 기입하여 '송신' 버튼을 누를 떄와 같은 몇 가지 장면도 있음.\r\n    - 부가적인 자세한 정보가 필요한 경우도 있는데, 이것을 써 두는 것이 메시지 헤더의 역할.\r\n    - 날짜, 클라이언트측이 취급하는 데이터 종류, 언어, 압축 형식, 클라이언트나 서버의 소프트웨어 명칭과 버전, 데이터의 유효 기간이나 최종 변경 일시 등\r\n    - 메시지 헤더를 쓰면 그 뒤에 아무 것도 쓰지 않은 하나의 공백 행을 넣고 그 뒤에 송신할 데이터를 쓴다. 이 부분이 메시지 본문.\r\n\r\n<br/>\r\n\r\n6. 리퀘스트 메시지를 보내면 응답이 되돌아온다.\r\n    - 응답의 경우는 정상 종료했는지, 아니면 오류가 발생했는지, 즉 리퀘스트의 실행 결과를 나타내는 스테이터스 코드와 응답 문구를 첫 번째 행에 써야한다.\r\n    - 응답 문구 쪽은 문장으로 쓰여있으며 사람에게 실행 결과를 알리는 것이 목적.\r\n    - 영상 등을 포함한 경우에는 문장 안에 영상 파일을 나타내는 태그라는 제어 정보가 포함되어 있음.\r\n    - 브라우저는 태그를 탐색하고 영상을 포함하고 있는 의미의 태그를 만나면 영상용 공백을 비워두고 문장을 표시함. 이 후 다시 한 번 웹 서버에 액세스하여 태그에 쓰여있는 영상 파일을 웹 서버에서 읽어와서 방금 전에 비워둔 공백에 표시함. 이 경우 문장 파일을 읽을 때와 마찬가지로 URI 부분에 영상 파일의 이름을 쓴 리퀘스트 메시지를 만들어 보낸다.\r\n    - 리퀘스트 메시지에 쓰는 URI는 한 개만으로 결정되어 있으므로 파일을 한 번에 한 개씩만 읽을 수 있기 때문에 파일을 따로따로 읽어야 한다.\r\n    - 한 문장에 3개의 영상이 포함되어 있다 → 4회 리퀘스트 메시지를 보낸다.\r\n    - 필요한 파일을 판단하고 이것을 읽은 후 레이아웃을 정하여 화면에 표시하는 상태로 전체의 동작을 조정하는 것도 브라우저의 역할.\r\n\r\n<br/>\r\n\r\n## 02 웹 서버의 IP 주소를 DNS 서버에 조회한다.\r\n\r\n1. IP 주소의 기본\r\n    - HTTP의 메시지를 만들면 다음에는 이것을 OS에 의뢰하여 액세스 대상의 웹 서버에게 송신한다. \r\n    - 브라우저는 URL을 해독하거나 HTTP 메시지를 만들지만, 메시지를 네트워크에 송출하는 기능은 없으므로 OS에 의뢰하여 송신하는 것.\r\n        - 이때 URL 안에 쓰여있는 서버의 도메인명에서 IP 주소를 조사해야 함.\r\n    - TCP/IP는 서브넷이라는 작은 네트워크를 라우터로 접속하여 전체 네트워크가 만들어진다고 생각할 수 있다.\r\n        - 서브넷이란 허브에 몇 대의 PC가 접속된 것.\r\n        - 한 개의 단위로 생각하여 '서브넷'이라고 부르는데 라우터에서 연결하면 네트워크 전체가 완성된다.\r\n    - 동에 해당하는 번호를 서브넷에 할당, 번지에 해당하는 번호를 컴퓨터에 할당하는 것이 네트워크의 주소이다.\r\n        - 이 동에 해당하는 번호를 **네트워크 번호**라 하고, 번지에 해당하는 번호를 **호스트 번호**라 하며, 이 두 주소를 합쳐서 **IP 주소**라고 한다.\r\n    - 같은 IP 주소를 복수의 기기에 할당할 수 있는데, 이런 경우에는 네트워크가 올바르게 작동하지 않고 문제를 일으킨다.\r\n    - 송신측이 메시지를 보내면 서브넷 안에 잇는 허브가 운반하고 (패킷 형태로 운반), 송신측에서 가장 가까운 라우터까지 도착한다. 그리고 라우터가 메시지를 보낸 상대를 확인하여 다음 라우터를 판단한고, 거기에 보내도록 지시하여 송신 동작을 실행한 후 다시 서브넷의 허브가 라우터까지 메시지를 보낸다. 이런 동작을 반복하여 최종적으로 상대의 데이터가 도착한다는 원리. 이것이 TCP/IP와 IP 주소의 기본적인 개념.\r\n    - 실제 IP 주소는 32비트의 디지털 데이터.\r\n    - 네트워크를 구축할 때 사용자가 직접 내역을 결정할 수 있다.\r\n    - 이 내역을 나타내는 정보가 필요에 따라 IP 주소에 덧붙이는데, 이 정보를 '넷마스크'라고 한다.\r\n        - 넷마스크는 IP 주소에서 32비트 부분의 디지털 데이터이며, 왼쪽에 1이 나열되고 오른쪽에 0이 나열된 값이 된다.\r\n        - 넷마스크가 1인 부분은 네트워크 번호를 나타내고, 넷마스크가 0인 부분은 호스트 번호를 나타낸다.\r\n        - 호스트 번호 부분의 비트 값이 모두 0 또는 1인 경우는 특별한 의미를 가진다.\r\n        - 호스트 번호 부분이 모두 0인 IP 주소는 각각의 기기를 나타내는 것이 아니라 서브넷 자체를 나타낸다.\r\n        - 호스트 번호 부분이 모두 1이면 서브넷에 있는 기기 전체에 패킷을 보내는 브로드캐스트를 나타낸다.\r\n\r\n<br/>    \r\n\r\n2. 도메인명과 IP 주소를 구분하여 사용하는 이유\r\n    - IP 주소는 기억하기 어렵다.\r\n    - 그렇다면 IP 주소 대신에 이름으로 상대를 지정하여 통신한다면?\r\n    - 실행 효율이라는 관점에서 좋은 방법이라고 할 수 없다.\r\n    - IP 주소는 32비트, 즉 4바이트에 해당하는데 도메인명은 적어도 수십 바이트부터 최대 255바이트나 있다.\r\n    - 라우터가 부하되어 데이터를 운반하는 동작에 더 많은 시간이 걸리면서 네트워크 속도가 느려진다.\r\n    - 사람은 이름을 사용하고, 라우터는 IP 주소를 사용한다는 방법이 고안되었고, 현재 이 방법이 정착되어 있다.\r\n    - 이름을 알면 IP 주소를 알 수 있다거나 IP 주소를 알면 이름을 알 수 있다는 원리를 사용하여 양쪽의 차이를 해소하면 모두 좋아지는데, 그 원리가 DNS(Domain Name System)이다.\r\n\r\n<br/>\r\n\r\n3. Socket 라이브러리가 IP 주소를 찾는 기능을 제공한다.\r\n    - IP 주소를 조사하는 방법은 간단하다.\r\n    - 가장 가까운 DNS 서버에 'www.oz.kr'이라는 서버의 IP 주소를 가르쳐 주세요라고 질문하는 것.\r\n    - DNS 서버에 조회한다는 것은 DNS 서버에 조회 메시지를 보내고, 거기에서 반송되는 응답 메시지를 받는다는 것. 이것은 DNS 서버에 대해 클라이언트로 동작한다고도 말할 수 있다.\r\n    - DNS 클라이언트에 해당하는 것을 DNS 리졸버 또는 단순히 리졸버라고 부른다.\r\n    - DNS의 원리를 사용하여 IP 주소를 조사하는 것을 네임 리졸루션(이름 확인)이라고 하는데, 이 리졸루션을 실행하는 것이 리졸버이다.\r\n    - 리졸버의 실체는 Socket 라이브러리에 들어있는 부품화한 프로그램이다.\r\n    - 라이브러리는 다양한 애플리케이션에서 이용할 수 있도록 부품화한 여러 개의 프로그램을 모아놓은 것으로 프로그램의 부품집이라고 생각하면 된다.\r\n    - Socket 라이브러리는 OS에 포함되어 있는 네트워크 기능을 애플리케이션에서 호출하기 위한 부품을 모아놓은 것.\r\n    - 리졸버는 그 속에 들어있는 프로그램 부품의 하나이다.\r\n\r\n<br/>\r\n\r\n4. 리졸버를 이용하여 DNS 서버를 조회한다.\r\n    - 브라우저 등의 애플리케이션 프로그램을 만들 때 리졸버의 프로그램명(gethostbyname)과 웹 서버의 이름(www.oz.kr)을 쓰기만 하면 리졸버를 호출할 수 있다.\r\n    - 리졸버를 호출하면 리졸버가 DNS 서버에 조회 메시지를 보내고, DNS 서버에서 응답 메시지가 돌아온다.\r\n\r\n<br/>\r\n\r\n5. 리졸버 내부의 작동\r\n    - 네트워크 애플리케이션이 리졸버를 호출하면 제어가 리졸버의 내부로 넘어간다.\r\n    - 별도의 프로그램을 호출하여 호출처의 프로그램이 쉬고 있는 상태가 되면, 호출한 대상 프로그램이 움직이기 시작하는 것을 '제어가 넘어간다'고 한다.\r\n    - 리졸버에 제어가 넘어가면 여기서에 DNS 서버에 문의하기 위한 메시지를 만든다. 브라우저가 리퀘스트 메시지를 만드는 것과 유사함.\r\n    - 메시지 송신 동작은 리졸버가 스스로 실행하는 것이 아니라 OS의 내부에 포함된 프로토콜 스택 (OS 내부에 내장된 네트워크 제어용 소프트웨어) 을 호출하여 실행을 의뢰한다.\r\n    - 리졸버가 프로토콜 스택을 호출하면 제어가 리졸버에게 넘어가고 여기에서 메시지를 보내는 동작을 실행하여 LAN 어댑터를 통해 메시지가 DNS 서버를 항해 송신하게 된다.\r\n    - 조회 메시지가 DNS 서버에 도착하고 DNS 서버는 메시지를 토대로 조사하여 답을 찾는다.\r\n    - 액세스 대상의 웹 서버가 DNS 서버에 등록되어 있으면 답을 응답 메시지에 써서 클라이언트에게 반송한다.\r\n    - 메시지는 네트워크를 통해 클라이언트측에 도착하고, 프로토콜 스택을 경유하여 리졸버에 건네져서 리졸버가 내용을 해독한 후 여기에서 IP 주소를 추출하여 애플리케이션에 IP 주소를 건네준다.\r\n    - 실제로는 리졸버를 호출할 때 지정한 메모리 영역에 IP 주소를 저장한다.\r\n    - 컴퓨터의 내부는 다층 구조로 되어있다.\r\n    - 층을 이루도록 다수의 프로그램이 존재하고, 서로 역할을 분담하고 있다.\r\n    - 상위 계층에서 무엇인가 일을 의뢰했을 때 그 일을 스스로 전부 실행하지 않고 하위 계층에 실행을 의뢰하면서 처리를 진행한다.\r\n    - DNS 서버의 IP 주소는 TCP/IP 설정 항목의 하나하나로 컴퓨터에 미리 설정되어 있다.\r\n\r\n<br/>\r\n\r\n## 03. 전 세계의 DNS 서버가 연대한다\r\n\r\n1. DNS 서버의 기본 동작\r\n    - 클라이언트에서 보내는 조회 메시지 (요청 메시지라고 생각하면 될 듯)\r\n        - 이름 - 서버나 메일 배송 목적지와 같은 이름\r\n        - 클래스 - 인터넷 이외에도 네트워크에서의 이용까지 검토하여 식별용으로 클래스라는 정보를 준비했지만 현재는 인터넷 이외의 네트워크는 소멸되었으므로 항상 'IN'이라는 값이 됨.\r\n        - 타입 - 이름에 어떤 타입(종류)의 정보가 지원되는지를 나타냄.\r\n            - A - 이름에 IP 주소가 지원되는 것을 나타냄.\r\n            - MX - 이름에 메일 배송 목적지가 지원되는 것을 나타냄.\r\n                - 타입이 MX인 경우에는 메일 서버의 우선 순위와 메일 서버의 이름을 회답함. 메일 서버의 등록된 주소 또한 같이 반환.\r\n\r\n<br/>\r\n\r\n2. 도메인의 계층\r\n    - DNS 서버는 정보를 분산시켜서 다수의 DNS 서버에 등록하고, 다수의 DNS 서버가 연대하여 어디에 정보가 등록되어 있는지를 찾아내는 구조.\r\n    - DNS 서버에 등록한 정보에는 모두 도메인명이라는 계층적 구조를 가진 이름이 붙여져 있다.\r\n        - 계층적 구조는 간단하게 회사 부서와 같이 생각하면 됨. 하나의 부서에 해당하는 것을 도메인이라고 함.\r\n        - 한 대의 DNS 서버에 도메인 한 대를 등록한다고 생각하자. (실제로 한 대의 DNS 서버에 복수의 도메인 등록 가능)\r\n        - 도메인 아래에 하위 도메인을 만들 수 있다. (서브 도메인)\r\n\r\n<br/>\r\n\r\n3. 담당 DNS 서버를 찾아 IP 주소를 가져온다.\r\n    - 하위의 도메인을 담당하는 DNS 서버의 IP 주소를 그 상위의 DNS 서버에 등록하는 방식으로 차례대로 등록함.\r\n        - 상위가 하위 DNS 서버 IP 주소를 알 수 있고, 거기에서 조회 메시지를 보낼 수 있다.\r\n        - com이나 kr 같은 최상위 도메인 상위에 루트 도메인이 존재.\r\n        - 루트 도메인의 DNS 서버를 인터넷에 존재하는 DNS 서버에 전부 등록함. 전부 루트 도메인에 액세스 가능.\r\n            - DNS 서버 소프트웨어를 설치하면 자동으로 등록이 완료됨.\r\n    - 원하는 DNS 서버를 찾는 순서\r\n        1. 클라이언트의 가장 가까이에 있는 서버 (TCP/IP 설정 항목에 등록이 되어 있는 서버) 에 [www.lab.glasscom.com](http://www.lab.glasscom.com) 이라는 웹 서버에 관한 정보를 조회하기로 함.\r\n        2. 가장 가까운 DNS 서버에 없다면 루트 도메인으로 조회 메시지를 전송.\r\n        3. 루트 도메인에 없지만 com 도메인이 등록되어 있으므로 이 DNS 서버 IP를 가장 가까운 DNS 서버로 반송.\r\n        4. 가장 가까운 DNS 서버는 com 도메인의 DNS 서버에 조회 메시지를 전송.\r\n        5. 여기에도 등록되어 있지 않으므로 [glasscom.com](http://glasscom.com) 도메인의 DNS 서버 IP 주소를 반송.\r\n        6. 2~4 반복\r\n        7. www.lab.glasscom.com의 IP 주소를 조사해 이를 클라이언트에 회답.\r\n        8. 클라이언트는 이 IP 주소를 알고 거기에 액세스할 수 있게 됨.\r\n\r\n<br/>\r\n\r\n4. DNS 서버는 캐시 기능으로 빠르게 회답할 수 있다.\r\n    - 현실의 인터넷에서는 한 대의 DNS 서버에 복수의 도메인의 정보를 등록할 수 있음.\r\n        - 최상위 루트 도메인에서 차례대로 따라간다는 원칙대로 움직이지 않을 수도 있다.\r\n    - DNS 서버는 한 번 조사한 이름을 캐시에 기록할 수 있다.\r\n        - 조회한 이름에 해당하는 정보가 있으면 그 정보를 회답함.\r\n        - 조회한 이름이 도메인에 등록되어 있지 않은 경우조차 캐시에 보존할 수 있다.\r\n        - 단, 저장된 정보가 올바르다고 단언할 수는 없다.\r\n            - DNS 서버에 등록하는 정보에는 유효 기간을 설정하고 기간이 지나면 삭제한다. 또한 조회에 회답할 때 정보가 캐시에 저장된 것인지 아닌지를 알려준다.\r\n\r\n<br/>\r\n\r\n## 04. 프로토콜 스택에 메시지 송신을 의뢰한다.\r\n\r\n1. 데이터 송, 수신 동작의 개요\r\n    - 액세스 대상 웹 서버에 메시지를 송신하도록 OS의 내부에 있는 프로토콜 스택에 의뢰한다.\r\n        - Socket 라이브러리 프로그램 부품을 결정된 순번대로 호출함.\r\n            - 데이터를 송, 수신하는 컴퓨터 사이에 데이터의 통로 같은 것이 있고, 이것을 통해 데이터가 흐르면서 상대측에 도착. 통로는 파이프와 같은 것이라고 생각.\r\n        - 데이터 송, 수신 동작 4단계\r\n            1. 소켓을 만든다 (소켓 작성 단계)\r\n            2. 서버측의 소켓에 파이프를 연결한다 (접속 단계)\r\n            3. 데이터를 송, 수신한다 (송, 수신 단계)\r\n            4. 파이프를 분리하고 소켓을 말소한다 (연결 끊기 단계)\r\n            - 이 네 가지 동작을 실행하는 것이 OS 내부의 프로토콜 스택.\r\n\r\n<br/>\r\n\r\n2. 소켓의 작성 단계\r\n    - Socket 라이브러리의 socket이라는 프로그램 부품 호출.\r\n    - 소켓이 생기면 디스크립터라는 것이 돌아오는데 이것을 메모리에 기록함.\r\n        - 디스크립터는 소켓을 식별하기 위해 사용함.\r\n        - 복수의 소켓이 한 대의 컴퓨터에 존재할 때 (브라우저 2개의 창을 열어 웹 서버에 액세스할 때) 소켓을 하나하나 식별해야 하는데 이때 사용되는 것이 디스크립터.\r\n        - 호텔에서 가방 맡길 때 받는 번호표를 연상하자.\r\n\r\n<br/>\r\n\r\n3. 파이프를 연결하는 접속 단계\r\n    - 만든 소켓을 서버측의 소켓에 접속하도록 프로토콜 스택에 의뢰하기 위해 Socket 라이브러리의 connect라는 프로그램 부품 호출.\r\n        - 디스크립터, 서버 IP 주소, 포트 번호를 지정함\r\n        - 디스크립터 - 프로토콜이 통지받은 디스크립터를 보고 어느 소켓을 서버 측의 소켓에 접속할지 판단하여 접속 동작을 실행함.\r\n        - 서버 IP 주소 - IP 주소는 각 컴퓨터를 식별하기 위해 각각에 서로 다른 값을 할당한 것. 즉, IP 주소로 지정할 수 있는 것은 네트워크의 어느 컴퓨터인가 하는 것 까지다.\r\n        - 포트 번호 - 소켓까지 지정하기 위해 필요한 것이 포트 번호. 접속 상대측에 소켓을 식별하기 위해 사용됨.\r\n            - 서버 측의 포트 번호는 애플리케이션의 종류에 따라 미리 결정된 값을 사용한다는 규칙이 있음.\r\n\r\n              웹은 80번, 메일은 25번\r\n\r\n            - 클라이언트 측의 포트 번호는 소켓을 만들 때 프로토콜 스택이 적당한 값을 골라서 할당하고 이 값을 프로토콜 스택이 접속 동작을 실행할 때 서버 측에 통지함.\r\n\r\n<br/>\r\n\r\n4. 메시지를 주고받는 송, 수신 단계\r\n    - 소켓에 데이터를 쏟아부으면 상대 측의 소켓에 데이터가 도착함.\r\n    - 송신을 위해서는 write라는 프로그램 부품을 사용함.\r\n        1. URL을 바탕으로 만든 HTTP 리퀘스트 메시지 (송신 데이터) 와 디스크립터를 지정해 write를 호출함.\r\n        2. 프로토콜 스택이 송신 데이터를 서버에게 송신함.\r\n            - 소켓에는 연결된 상대가 기록되어 있으므로 디스크립터로 소켓을 지정하면 연결된 상대가 판명되어 그곳을 향해 데이터를 송신함.\r\n            - 송신 데이터는 네트워크를 통해 전부 그대로 액세스 대상의 서버에 도착함.\r\n        3. 서버는 수신 동작을 실행하여 받은 데이터의 내용을 조사하고 적절한 처리를 실행하여 응답 메시지를 반송함.\r\n    - 수신을 위해서는 read라는 프로그램 부품을 사용함.\r\n        - 수신 버퍼 - 수신한 응답 메시지를 저장하기 위해 지정한 메모리 영역.\r\n            - 응답 메시지가 돌아올 때 read가 받아서 수신 버퍼에 저장함.\r\n            - 수신 버퍼에 메시지를 저장한 시점에서 메시지를 애플리케이션(브라우저)에 건네준다.\r\n\r\n<br/>\r\n\r\n5. 연결 끊기 단계에서 송, 수신이 종료된다.\r\n    - 브라우저가 데이터 수신을 완료하면 송, 수신 동작은 끝난다.\r\n    - Socket 라이브러리의 close라는 프로그램 부품을 호출한다.\r\n        - 소켓 사이를 연결한 파이프와 같은 것이 분리되고 소켓도 말소됨.\r\n    - 동작은 다음과 같다.\r\n        1. 웹 서버측에서 close를 호출하여 연결을 끊는다.\r\n        2. 클라이언트 측에 전달되어 클라이언트의 소켓은 연결 끊기 단계로 들어간다.\r\n            - 브라우저가 read로 수신 동작을 의뢰했을 때 read는 수신한 데이터를 건네주는 대신 송, 수신 동작이 완료되어 연결이 끊겼다는 사실을 브라우저에 통지한다.\r\n            - 브라우저도 close를 호출하여 연결 끊기 단계로 들어간다.\r\n    - 같은 서버에서 복수의 데이터를 읽을 때 접속과 연결 끊기 동작이 계속 반복되면 비효율적이다.\r\n        - 이를 위해 HTTP 1.1 버전부터 한 번 접속 후 연결을 끊지 않고도 복수의 리퀘스트와 응답 주고받기를 실행하는 방법이 마련되었다.","excerpt":"'성공과 실패를 결정하는 1%의 네트워크 원리' 스터디를 진행하며 정리한 내용이다. 01 HTTP 리퀘스트 메시지를 작성한다. 탐험의 여행은 URL 입력부터 시작한다. URL은 http: 뿐만 아니라 ftp:, file:, mailto: 로 시작하는…","fields":{"slug":"/1per-network-ch1/"},"frontmatter":{"date":"Sep 25, 2021","title":"[성공과 실패를 결정하는 1%의 네트워크 원리] 1장","tags":["network","book","1per-network"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n## ANSI SQL\r\n\r\nDBMS(Oracle, MySQL 등등)들에서 각기 다른 SQL을 사용하므로 미국 표준 협회(American National Standards Institute)에서 이를 표준화하여 표준 SQL문을 정립시켜 놓은 것.\r\n\r\nANSI SQL 문법의 Join을 익혀두는 것이 좋을듯 싶다.\r\n\r\n### 특징\r\n\r\n1. 표준 SQL문이기 때문에 DBMS의 종류에 제약을 받지 않는다. 즉, 특정 벤더에 종속적이지 않아 다른 벤더의 DBMS올 교체하더라도 빠르게 다른 벤더사를 이용할 수 있다.\r\n   특정 DBMS의 이탈이 가속되는 것도 ANSI SQL의 영향이 크다고 할 수 있다\r\n2. 테이블 간의 Join 관계가 FROM에서 명시되기 때문에 WHERE 문에서 조건만 확인하면 된다. 즉, 가독성이 일반 Query문보다 좋다\r\n\r\n<br/>\r\n\r\n## Join\r\n\r\n테이블별로 분리되어 있는 데이터를 연결하여 하나의 결과 데이터 셋으로 출력해야 할 때가 반드시 존재한다. 이럴 때 사용하는 것이 Join이다.\r\n\r\n두 개의 테이블이 있다고 가정.\r\n\r\n컬럼은 1개이고 데이터는 아래와 같다.\r\n\r\n```\r\nA    B\r\n-    -\r\n1    3\r\n2    4\r\n3    5\r\n4    6\r\n```\r\n\r\n<br/>\r\n\r\n### Inner Join\r\n\r\nInner Join을 수행하면 두 집합에 모두 있는 열만 남게 된다.\r\n\r\n```sql\r\nANSI SQL\r\nSELECT * FROM A INNER JOIN B ON A.A = B.B;\r\n\r\nORACLE\r\nSELECT A.*,B* FROM A,B WHERE A.A = B.B;\r\n\r\nA    B\r\n-    -\r\n3    3\r\n4    4\r\n```\r\n\r\n<br/>\r\n\r\n### Left Outer Join\r\n\r\nLeft Outer Join을 하면 A의 모든 열 더하기 B에 있는 공통부분을 얻게 됩니다.\r\n\r\n```sql\r\nANSI SQL\r\nSELECT * FROM A LEFT OUTER JOIN B ON A.A = B.B;\r\n\r\nORACLE \r\nSELECT A.*,B.* FROM A,B WHERE A.A = B.B(+);\r\n\r\nA       B\r\n-       -\r\n1    null\r\n2    null \r\n3       3\r\n4       4\r\n```\r\n\r\n<br/>\r\n\r\n### Right Outer Join\r\n\r\nRight Outer Join을 하면 B의 모든 열 더하기 A에 있는 공통부분을 얻게 된다.\r\n\r\n```sql\r\nANSI SQL\r\nSELECT * FROM A RIGHT OUTER JOIN B ON A.A = B.B;\r\n\r\nORACLE \r\nSELECT A.*,B.* FROM A,B WHERE A.A(+) = B.B;\r\n\r\nA       B\r\n-       -\r\n3       3\r\n4       4 \r\nnull    5\r\nnull    6\r\n```\r\n\r\n<br/>\r\n\r\n### Full Outer Join\r\n\r\nFull Outer Join을 하면 A와 B의 합집합을 얻게 된다.\r\n\r\nB에 있는데 A에 없는 5, 6은 A에서 해당 부분이 null이 되고, A에 있는데 B에 없는 1, 2는 B에서는 해당 부분이 null이 된다.\r\n\r\n```sql\r\nSELECT * FROM A FULL OUTER JOIN B ON A.A = B.B;\r\n\r\nA       B\r\n-       -\r\n1    null\r\n2    null\r\n3       3\r\n4       4 \r\nnull    5\r\nnull    6\r\n```\r\n\r\n<br/>\r\n\r\n### Cross Join\r\nCross Join은 이 포스트를 참고하자.\r\n\r\n\r\n<br/>\r\n\r\n## 참고\r\n\r\n- [https://stanleykou.tistory.com/entry/SQL-INNER-조인과-OUTER조인이-무엇인가요](https://stanleykou.tistory.com/entry/SQL-INNER-%EC%A1%B0%EC%9D%B8%EA%B3%BC-OUTER%EC%A1%B0%EC%9D%B8%EC%9D%B4-%EB%AC%B4%EC%97%87%EC%9D%B8%EA%B0%80%EC%9A%94)","excerpt":"ANSI SQL DBMS(Oracle, MySQL 등등)들에서 각기 다른 SQL을 사용하므로 미국 표준 협회(American National Standards Institute)에서 이를 표준화하여 표준 SQL문을 정립시켜 놓은 것. ANSI SQL…","fields":{"slug":"/join/"},"frontmatter":{"date":"Sep 12, 2021","title":"DB Join 종류 알아보기","tags":["database"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n## Flyway란?\r\n\r\n- Flyway란 DataBase Migration Tool로 DataBase Migration을 손쉽게 해결해주는 도구 중 하나이다.    \r\n  그렇다면 DataBase Migration은 무엇일까?\r\n  \r\n    ### DataBase Migration\r\n\r\n    - 마이그레이션(migration)이란 한 운영환경으로부터 다른 운영환경으로 옮기는 작업을 뜻하며, 하드웨어, 소프트웨어, 네트워크 등 넓은 범위에서 마이그레이션의 개념이 사용되고 있다.\r\n    - 데이터베이스에서 데이터 마이그레이션이란 데이터베이스 스키마의 버전을 관리하기 위한 하나의 방법이다.  \r\n        예를 들어 dev 환경에서 데이터베이스 스키마가 변경되었지만, prod 환경에서 데이터베이스 스키마가 변경되지 않았을 경우 마이그레이션을 수행한다.\r\n    - 데이터베이스 마이그레이션은 개별 sql 파일을 데이터베이스 콘솔에서 직접 실행하지 않고 프레임워크의 특정 명령어를 통해 실행하고 이 결과를 별도의 테이블에 버전 관리를 하는 기법이다.\r\n\r\n    <br/>\r\n\r\n    ![Untitled](https://user-images.githubusercontent.com/62014888/130363401-1cbf726d-2220-43c5-b211-d2a182780696.png)\r\n\r\n- Flyway를 통해 손쉽게 각각의 dev, prod 환경에 동일한 데이터베이스 스키마를 적용시킬 수 있었고 변경 이력 또한 남아 관리하기 편하다는 장점이 있었다.\r\n\r\n<br/>\r\n\r\n## Flyway를 왜 적용시켰는가?\r\n\r\n- 사실 처음부터 Flyway를 찾아보고 적용시킨 것이 아니다.  \r\n  (초반에 스키마가 변경되고 조앤이 코기 블로그 글을 보내줬을 때나 심지어 코기가 flyway 테코톡을 했을 때도 별 생각 없었다..)\r\n- 그러던 중 스프린트가 진행됨에 따라 데이터베이스 스키마가 변경되고 dev, prod 환경에서 ddl-auto가 update로 설정되어 있다보니 DB가 꼬이는 현상이 발생하였다.   \r\n  게다가 4차 데모데이 요구사항 중 하나가 prod 환경에 DB를 drop 하지말라는 것이 있었기에 이참에 flyway를 적용시켜보자 해서 진행하게 되었다.  \r\n  조금 더 빨리 적용시켰으면 dev 환경에 DB 또한 drop 하지 않았을텐데.. 아쉽다..\r\n\r\n<br/>\r\n\r\n## 간단한 사용법\r\n\r\nflyway를 적용시켜보자.  \r\n당시 상황은 이러하다.\r\n1. User라는 테이블에 github_id라는 컬럼의 이름이 social_id로, 타입이 varchar(255)로 바뀌어야한다.  \r\n   social_type이라는 컬럼이 추가되어야 한다.\r\n2. Heart라는 테이블이 추가되어야 한다.\r\n\r\n지금 방법은 이미 DB에 데이터가 있을 때 적용시킨거라 처음부터 적용시킨 것과 조금은 다를 수도 있다는 것에 주의하자.\r\n\r\n1. dependency를 build.gradle에 추가한다. maven은 maven repository를 찾아보자!\r\n\r\n    ```java\r\n    implementation('org.flywaydb:flyway-core:6.4.2')\r\n    ```  \r\n    <br/>\r\n\r\n2. application.yml 또는 application.properties에 다음과 같은 옵션을 추가한다. (yml 기준)\r\n\r\n    ```java\r\n    spring:\r\n        flyway:\r\n    \t    enabled: true // true면 flyway를 활성화시킨다.\r\n    \t    baseline-on-migrate: true \r\n           // default는 false로 true로 설정하면 히스토리 테이블이 없으면 새로 만든다.\r\n    ```\r\n    <br/>\r\n\r\n3. resources 디렉터리 밑에 db/migration 디렉터리를 만들고 적용할 스크립트를 작성해야 한다.   \r\n   V1__init.sql 안에 테이블 스키마를 작성해두면 스크립트가 적용이 되어 테이블이 생성될 것이다.  \r\n   하지만 이미 우리 프로젝트 DB에는 테이블이 만들어져있다.    \r\n   그렇다면 V1__init.sql이 적용이 되는것인가?   \r\n   이미 테이블이 있는 상태에서 스크립트가 적용이 된다면 에러가 발생하지 않을까라는 생각을 했다.  \r\n   결론부터 말하면 baseline-on-migrate: true 설정에 의해서 이미 DB가 존재하고 V1__init.sql을 작성하였다면 V1__init.sql의 설정은 무시하고 기존의 DB 스키마를 baseline으로 잡게 된다.  \r\n   그래서 사실 V1__init.sql의 내용을 비워놔도 무방하지만 스키마가 변경되기 전의 DDL로 작성해도 괜찮을 것 같다고 생각을 하여 작성해놓았다.\r\n\r\n    <br/>\r\n\r\n   ![Untitled](https://user-images.githubusercontent.com/62014888/130363455-6b482405-32d6-4ef3-a95a-15913e259698.png)\r\n\r\n    <br/>\r\n\r\n    ```sql\r\n    CREATE TABLE user(\r\n                         id BIGINT AUTO_INCREMENT PRIMARY KEY,\r\n                         github_id BIGINT NOT NULL,\r\n                         user_name VARCHAR(255) NOT NULL,\r\n                         profile_url VARCHAR(255) NOT NULL,\r\n                         role VARCHAR(255) NOT NULL,\r\n                         created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,\r\n                         updated_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP\r\n    );\r\n\r\n    CREATE TABLE workbook(\r\n                             id BIGINT AUTO_INCREMENT PRIMARY KEY,\r\n                             name VARCHAR(30) NOT NULL,\r\n                             opened TINYINT(1) NOT NULL,\r\n                             deleted TINYINT(1) NOT NULL,\r\n                             user_id BIGINT not null,\r\n                             created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,\r\n                             updated_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,\r\n                             FOREIGN KEY(user_id) REFERENCES user(id) ON UPDATE CASCADE ON DELETE RESTRICT\r\n    );\r\n\r\n    CREATE TABLE card(\r\n                         id BIGINT AUTO_INCREMENT PRIMARY KEY,\r\n                         question BLOB NOT NULL,\r\n                         answer BLOB NOT NULL,\r\n                         encounter_count INT NOT NULL,\r\n                         bookmark TINYINT(1) not null,\r\n                         next_quiz TINYINT(1) not null,\r\n                         workbook_id BIGINT not null,\r\n                         deleted TINYINT(1) not null,\r\n                         created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,\r\n                         updated_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,\r\n                         FOREIGN KEY(workbook_id) REFERENCES workbook(id) ON UPDATE CASCADE ON DELETE RESTRICT\r\n    );\r\n\r\n    CREATE TABLE tag(\r\n                        id BIGINT AUTO_INCREMENT PRIMARY KEY,\r\n                        name VARCHAR(30) UNIQUE NOT NULL,\r\n                        created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,\r\n                        updated_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP\r\n    );\r\n\r\n    CREATE TABLE workbook_tag(\r\n                                 id BIGINT AUTO_INCREMENT PRIMARY KEY,\r\n                                 workbook_id BIGINT not null,\r\n                                 tag_id BIGINT not null,\r\n                                 deleted TINYINT(1) not null,\r\n                                 created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,\r\n                                 updated_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,\r\n                                 FOREIGN KEY(workbook_id) REFERENCES workbook(id) ON UPDATE CASCADE ON DELETE RESTRICT,\r\n                                 FOREIGN KEY(tag_id) REFERENCES tag(id) ON UPDATE CASCADE ON DELETE RESTRICT\r\n    );\r\n    ```\r\n\r\n   <br/>\r\n\r\n4. User 테이블 변경 내용을 V2__change_user_column.sql, Heart 테이블 추가 내용을 V3__add_heart_table.sql 라는 적당한 이름의 파일로 만들어 작성한다.  \r\n   순서대로 적용시키기 위해 숫자를 1씩 증가시켜야 한다.  \r\n   사실 이미 변경이 되었기에 V2를 작성할 때 한꺼번에 DDL을 작성해도 되지만 분리해서 히스토리로 남기기 위해 이렇게 작성하였다.   \r\n   V2, V3를 한꺼번에 만들어도 V2와 V3가 순서대로 적용이 되었다!\r\n\r\n    <br/>\r\n\r\n   ![Untitled](https://user-images.githubusercontent.com/62014888/130363480-ae8782fc-5fdd-4d6d-9b57-478b176a9d7d.png)\r\n\r\n    <br/>\r\n\r\n    ```sql\r\n    alter table user change github_id social_id varchar(255) not null;\r\n    alter table user add column bio varchar(255) not null default '';\r\n    alter table user add column social_type varchar(255);\r\n    ```\r\n\r\n    ```sql\r\n    CREATE TABLE heart(\r\n                          id BIGINT AUTO_INCREMENT PRIMARY KEY,\r\n                          workbook_id BIGINT not null,\r\n                          user_id BIGINT not null,\r\n                          created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,\r\n                          updated_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,\r\n                          FOREIGN KEY(workbook_id) REFERENCES workbook(id) ON UPDATE CASCADE ON DELETE RESTRICT\r\n    );\r\n    ```\r\n   <br/>\r\n\r\n5. 결과적으로 기존의 prod 환경의 DB 데이터는 유지한 채로 User 테이블의 기존 컬럼명 및 타입을 수정, 새로운 컬럼을 추가할 수 있었다!\r\n6. 이 후에 스키마가 변경이 되면 V4부터 스크립트를 작성해서 추가하면 된다.\r\n\r\n<br/>\r\n\r\n## 주의할 점\r\n\r\n적용하면서 애먹었던 부분을 공유한다.\r\n\r\n1. local 환경에서 H2 DB를 사용하게 되는 경우가 많을텐데 mariadb의 쿼리문을 이용한 스크립트와 같은 스크립트를 적용하다 syntax 에러가 많이 발생하였다. 이를 주의하도록 하자.  \r\n   혹시나 DB마다 다른 스크립트를 적용하려면 flyway에서 벤더사마다 다른 스크립트를 적용하는 방법도 존재하니 그걸 찾아보도록 하자!  \r\n   우리는 팀원들끼리 이야기한 결과 굳이 local에선 flyway를 사용할 필요가 있을까하여 flyway.enabled를 false로 설정하여 사용했다.\r\n\r\n2. 최신 버전의 flyway를 적용하면서 mariadb를 사용한다면 꼭 10.2 버전 이상의 mariadb를 사용하자.   \r\n   10.1 버전의 mariadb를 사용하다 이런 에러를 맞이하게 되어 기존 mariadb를 10.4로 upgrade하는 상황이 발생하게 되었다.   \r\n   조앤이 upgrade 하는 방법을 금방 찾아서 다행이었지만 생각보다 할게 많아 까다로웠다..  \r\n   아니면 에러에 적힌대로 flyway pro edition을 사용하면 괜찮을지도..?\r\n\r\n    <br/>\r\n\r\n   ![Untitled](https://user-images.githubusercontent.com/62014888/130363889-def26e90-88e8-48cd-b7a8-ef2717193fab.png)","excerpt":"Flyway란? Flyway란 DataBase Migration Tool로 DataBase Migration을 손쉽게 해결해주는 도구 중 하나이다. 그렇다면 DataBase Migration은 무엇일까? DataBase Migration 마이그레이션…","fields":{"slug":"/flyway/"},"frontmatter":{"date":"Aug 25, 2021","title":"프로젝트 Flyway 도입기","tags":["flyway","database"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n## 어떤 상황이었나?\r\n\r\n현재 프로젝트 내에서 존재하는 Workbook이라는 엔티티에 card, workbookTag, heart와 같은 엔티티들이 1:N 관계로 구성되어 있고 글로벌 페치 전략은 Lazy로 설정되어있다.  \r\n전부 Lazy로 설정되어있다보니 Workbook List를 조회할 때 Workbook 조회 쿼리가 나가고 해당 List에 존재하는 Workbook의 card, workbookTag, heart의 method를 사용하게 될 때 각각을 조회하는 쿼리가 나가다보니 조회된 데이터 갯수(n) 만큼 연관관계의 조회 쿼리가 추가로 발생하여 데이터를 읽어오게 되는 N+1 문제가 발생하였다.  \r\n\r\n검색 기능에서 이 Workbook List를 조회하기 위해 Pagable과 Specification을 사용하고 있는데 앞서 말한 N+1 문제를 해결하기 위해 fetch join을 사용해보았다.  \r\n하지만 1:N 관계를 2개 이상 fetch join을 하게 되면 MultipleBagFetchException이 발생한다.   \r\n그 이유는 일대다 엔티티 2개 이상과 fetch join을 해서 쿼리를 보내게 되면 중복된 값이 많이 발생하는데 \r\njpa에서 이 데이터들을 이용해 객체로 매핑할 때 어떤 데이터를 선택해야할지 판단할 수가 없어서 MultipleBagException이 발생하게 된다고 한다.\r\n\r\n또한 만약에라도 1개를 fetch join을 성공했다하더라도 이러한 경고문이 뜨고 페이징 쿼리문 또한 제대로 나가고 있지 않았다.\r\n\r\n![Untitled - 2022-01-02T193412 000](https://user-images.githubusercontent.com/62014888/147873117-5163053f-456c-4a7b-a956-93b31b9b8731.png)\r\n\r\n이는 Pagination API와 fetch join을 동시에 사용할 때 발생하는 에러로 fetch join을 하게 되면 불러오는 데이터의 수가 변경되어 단순하게 limit 구문을 사용하는 쿼리로 페이지네이션을 적용하기 어려워 조회한 결과를 모두 메모리로 가져와서 JPA가 페이지네이션 계산을 진행하기 때문에 발생하는 에러다.\r\n\r\n<br/>\r\n\r\n## 어떻게 해결하였나?\r\n\r\n이러한 모든 문제를 해결하기 위한 방법으로 hibernate.default\\_batch\\_fetch\\_size 옵션을 줄 수 있다.  \r\n사실 N+1 문제란 결국 부모 엔티티와 연관 관계가 있는 자식 엔티티들의 조회 쿼리가 문제이다. 부모 엔티티의 Key 하나 하나를 자식 엔티티 조회로 사용하기 때문이다.    \r\n즉, 1개씩 사용되는 조건문을 in 절로 묶어서 조회하면 되는 것이고 hibernate.default\\_batch\\_fetch\\_size를 지정하고 지정된 수만큼 in절에 부모 Key를 사용하게 해준다.   \r\n예를 들어 1000개를 옵션 값으로 지정하면 1000개 단위로 in절에 부모 Key가 넘어가서 자식 엔티티들이 조회되는 것이다.  \r\n전체 옵션을 주기 위해 application.yml 파일에 명시해두었고 실제 쿼리도 줄어든 모습을 볼 수 있었다.  \r\n실제 프로젝트에서는 batch\\_fetch\\_size를 100으로 설정하였다.\r\n\r\n![Untitled - 2022-01-02T193700 908](https://user-images.githubusercontent.com/62014888/147873161-6bf1fc90-8a52-4231-8761-80cf2956d7dc.png)\r\n![Untitled - 2022-01-02T193705 602](https://user-images.githubusercontent.com/62014888/147873162-162f0a95-2794-4cb1-abed-7ee8735ca433.png)\r\n\r\n<br/>\r\n\r\n## 마무리\r\n- 어쩐지 쿼리가 많이 발생하여 콘솔 로그를 꽉 채워 앞에 로그가 짤릴 정도였는데 다 이유가 있었다..\r\n- 항상 쿼리가 너무 많이 발생하지는 않는지 만약 그렇다면 N+1 문제 때문인지를 체크하면서 JPA를 사용해야 할 것 같다.\r\n- batch\\_fetch\\_size를 설정하는 것이 최선인건가? 조금 더 공부를 해봐야겠다.\r\n\r\n\r\n<br/>\r\n\r\n## 참고\r\n\r\n- [https://jojoldu.tistory.com/457](https://jojoldu.tistory.com/457)\r\n- [https://woowacourse.github.io/tecoble/post/2021-07-26-jpa-pageable/](https://woowacourse.github.io/tecoble/post/2021-07-26-jpa-pageable/)\r\n- https://cobbybb.tistory.com/10 ","excerpt":"어떤 상황이었나? 현재 프로젝트 내에서 존재하는 Workbook이라는 엔티티에 card, workbookTag, heart와 같은 엔티티들이 1:N 관계로 구성되어 있고 글로벌 페치 전략은 Lazy로 설정되어있다. 전부 Lazy로 설정되어있다보니 W…","fields":{"slug":"/jpa-problem-n+1/"},"frontmatter":{"date":"Aug 24, 2021","title":"프로젝트에서 발견한 N+1 문제 해결하기","tags":["jpa"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n## @Profile, @ActiveProfiles\r\n\r\n- 이 두 애노테이션을 알아보기 전에 Profile이란 무엇인지에 대해 알아보자.\r\n- 미니 프로젝트가 아닌 대부분의 기업용 서비스는 보통 개발(dev), 테스트(test), 운영(prod) 등으로 구동 환경을 세분화하여 서비스를 관리한다. 이런 식별 키워드를 Profile이라고 부른다. Profile을 지정함으로써 DB 접속 계정 및 옵션, 리소스, 로그 관리 정책 등을 Profile 단위로 구분하여 효과적으로 관리할 수 있다.\r\n- 보통 yml이나 properties 파일로 환경을 구분하여 사용하는데 스프링에서는 @Profile 또는 @ActiveProfiles와 같은 애노테이션도 제공해준다.\r\n\r\n<br/>\r\n\r\n### @Profile\r\n- @Profile을 사용하고 그 안에 환경을 명시해주게 되면 해당 환경에서 이 애노테이션이 붙은 설정이나 빈을 등록하여 사용할 수 있게 된다.\r\n\r\n![Untitled (53)](https://user-images.githubusercontent.com/62014888/145994809-b547deb7-6b30-4e1f-88c6-4d849d5e0502.png)\r\n\r\n- 위와 같이 명시하면 test 환경에서 해당 빈을 등록하여 사용하겠다는 뜻이고 만약 test 환경에서만 사용하기 싫다고 하면 !test를 명시하면 된다.\r\n\r\n<br/>\r\n\r\n\r\n### @ActiveProfiles\r\n- @ActiveProfiles는 테스트할 때 유용힌 애노테이션으로 테스트에서 Profile을 지정할 수 있는데 그 때 사용하는 애노테이션이다.\r\n\r\n![Untitled (54)](https://user-images.githubusercontent.com/62014888/145994816-cb947c00-1658-4c45-ba84-d61c537f7254.png)\r\n\r\n- 이렇게 명시하여 test 환경으로 테스트를 실행시킬 수 있도록 하였다.\r\n\r\n<br/>\r\n\r\n\r\n## 참고\r\n- [http://wonwoo.ml/index.php/post/1933](http://wonwoo.ml/index.php/post/1933)\r\n- [https://jsonobject.tistory.com/220](https://jsonobject.tistory.com/220)","excerpt":"@Profile, @ActiveProfiles 이 두 애노테이션을 알아보기 전에 Profile이란 무엇인지에 대해 알아보자. 미니 프로젝트가 아닌 대부분의 기업용 서비스는 보통 개발(dev), 테스트(test), 운영(prod) 등으로 구동 환경을 …","fields":{"slug":"/profile-activeprofiles/"},"frontmatter":{"date":"Aug 24, 2021","title":"@Profile, @ActiveProfiles 란?","tags":["spring"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n## RestAssured Test\r\n\r\n- RestAssured는 REST 웹 서비스를 검증하기 위한 라이브러리.\r\n- 대부분 End-to-End or 인수 테스트에서 사용된다.\r\n- @SpringBootTest를 통해 애플리케이션에 등록될 빈을 모두 가져와 실제 요청을 보내서 전체적인 로직을 테스트한다. 실제 요청 시 필요한 다양한 메서드도 존재.\r\n\r\n```java\r\ntestImplementation 'io.rest-assured:rest-assured:3.3.0'\r\n```\r\n\r\n- RestAssured의 경우 직접 의존성을 추가해주어야 한다. gradle을 사용한다면 dependencies에 위의 내용을 추가하면 된다.\r\n- 의존성을 추가한다는 것은 프로젝트가 점점 무거워진다는 뜻이므로 RestAssured를 사용하는 순간이 온다면 왜 사용하는지에 대해 고민할 필요가 있다.\r\n\r\n![Untitled (49)](https://user-images.githubusercontent.com/62014888/145994041-5dcde623-477f-490f-bcfc-52484b84e5e6.png)\r\n\r\n- RestAssured의 경우 별도의 구성없이 @WebMvcTest를 사용할 수 없다. 즉, 컨트롤러에 대한 단위테스트를 하기 위해서는 spring-mock-mvc 모듈에 있는 RestAssuredMockMvc를 사용해야한다. (따로 의존성을 추가해야함)\r\n- 그래서 @SpringBootTest로 수행해야한다. 다만 이걸로 수행하면 등록된 Spring Bean을 전부 로드하기 때문에 시간이 오래걸린다.\r\n\r\n![Untitled (50)](https://user-images.githubusercontent.com/62014888/145994045-8bb45ed4-3733-49c0-b2c3-369561823aaa.png)\r\n\r\n- RestAssured는 BDD 스타일로 작성할 수 있어서 가독성이 좋다.\r\n- BDD(Behavior Driven Development)는 TDD를 근간으로 파생된 개발 방법이다.\r\n- 테스트 메서드 이름을 \"이 클래스가 어떤 행위를 해야한다(should do something)\"라는 식의 문장으로 작성하여 행위에 대한 테스트에 집중할 수 있다.\r\n- 즉, 시나리오를 기반으로 테스트 케이스 작성이 가능함. 비개발자가 봐도 이해할 수 있을 정도의 레벨을 권장하며 Given, When, Then 구조를 가지는 것을 기본 패턴으로 권장한다.\r\n- 또한 RestAssured을 사용할 경우 json data를 더 쉽고 편하게 검증할 수 있다.\r\n\r\n<br/>\r\n\r\n## MockMvc Test\r\n\r\n- MockMvc는 웹 애플리케이션을 애플리케이션 서버에 배포하지 않고도 스프링 MVC의 동작을 재현할 수 있는 라이브러리이며 대부분 Controller Layer Unit Test에 사용된다.\r\n- @WebMvcTest를 통해 Presentation Layer Bean들만 불러온다. 그리고 그 외 Bean은 Mock 객체 설정을 해주어 순수한 Controller 로직을 테스트한다.\r\n- MockMvc는 Spring Framework Test 클래스 중 하나다. 즉 Spring test 의존성이 추가되어 있는 경우 별도의 의존성 추가를 하지 않아도 사용할 수 있다.\r\n\r\n![Untitled (51)](https://user-images.githubusercontent.com/62014888/145994048-aef3c277-7b4c-406b-a6bc-d3176bbde926.png)\r\n\r\n- @WebMvcTest는 Presentation Layer의 Bean들만 로드하기 때문에 시간이 상대적으로 빠르다. (@Controller, @ControllerAdvice, @JsonComponent, Converter, GenericConverter, Filter, HandlerInterceptor, WebMvcConfigurer, HandlerMethodArgumentResolver 이거만 스캔하도록 제한)\r\n- controllers로 명시해둔건 MemberController만 가져온다는 뜻이다.\r\n\r\n![Untitled (52)](https://user-images.githubusercontent.com/62014888/145994054-137de9dd-044a-4329-abf8-8c1e10ca5e3a.png)\r\n\r\n- BDD 스타일로 작성한 RestAssured에 비해 쉽게 읽히지는 않는다.\r\n- 또한 RestAssured에 비해 json data 검증도 조금 힘들다.\r\n\r\n<br/>\r\n\r\n## 참고\r\n\r\n- [https://dundung.tistory.com/229](https://dundung.tistory.com/229)\r\n- [https://beomseok95.tistory.com/293](https://beomseok95.tistory.com/293)\r\n- [https://stackoverflow.com/questions/52051570/whats-the-difference-between-mockmvc-restassured-and-testresttemplate](https://stackoverflow.com/questions/52051570/whats-the-difference-between-mockmvc-restassured-and-testresttemplate)\r\n- [https://woowacourse.github.io/javable/post/2020-09-29-compare-mockito-bddmockito/](https://woowacourse.github.io/javable/post/2020-09-29-compare-mockito-bddmockito/)\r\n- [https://cobbybb.tistory.com/16](https://cobbybb.tistory.com/16)\r\n- [https://docs.spring.io/spring-boot/docs/current/api/org/springframework/boot/test/autoconfigure/web/servlet/WebMvcTest.html](https://docs.spring.io/spring-boot/docs/current/api/org/springframework/boot/test/autoconfigure/web/servlet/WebMvcTest.html)","excerpt":"RestAssured Test RestAssured는 REST 웹 서비스를 검증하기 위한 라이브러리. 대부분 End-to-End or 인수 테스트에서 사용된다. @SpringBootTest를 통해 애플리케이션에 등록될 빈을 모두 가져와 실제 요청을 …","fields":{"slug":"/restassured-vs-mockmvc/"},"frontmatter":{"date":"Jun 18, 2021","title":"RestAssured Test vs MockMvc Test","tags":["spring","test"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n## @SpringBootApplication\r\n\r\n- 우테코에서 미션을 하며 스프링 부트를 이용해서 웹 애플리케이션을 만들어보았다.\r\n- 스프링은 간단하게 이야기하면 스프링 빈 컨테이너를 만들어 빈 등록을 하고 필요한 객체에게 의존성 주입을 하는 방식으로 애플리케이션이 실행이 된다.\r\n- 근데 미션을 진행하는 동안 컨트롤러 위에 @Controller, 서비스 위에 @Service, DAO 위에 @Repository와 같은 애노테이션만 명시해주었을 뿐이고 따로 컨테이너를 생성하는 작업을 해 준 적이 없는데 어떻게 main 메서드만 실행하면 모든 작업이 이루어지는 것일까?\r\n- 그럼 차근차근 알아보도록 하자.\r\n\r\n![Untitled (41)](https://user-images.githubusercontent.com/62014888/145945185-711ac646-32f0-4a0b-ad9c-10bc7dc40bcf.png)\r\n\r\n![Untitled (42)](https://user-images.githubusercontent.com/62014888/145945190-c9d881b3-c304-4bb7-a708-504c669fe9ad.png)\r\n\r\n- 일단 결론부터 이야기하자면 스프링 부트를 이용해 처음 프로젝트를 만들때 생기는 main 메서드의 run 메서드에 의해 컨테이너가 생기고 설정을 한다.\r\n- 그렇다면 여기서 궁금한 점이 생겼다.\r\n- 바로 위에 있는 @SpringBootApplication은 어떤 기능을 담당하고 있을까?\r\n\r\n![Untitled (43)](https://user-images.githubusercontent.com/62014888/145945309-9f7f21e2-2391-422b-98f2-e7725ce305a3.png)\r\n\r\n- @SpringBootApplication의 위에 있는 많은 애노테이션이 있다.\r\n- 하나하나 살펴보자면\r\n    - @Target - 애노테이션이 적용할 위치를 결정한다. ElementType.Type는 타입 선언시 적용한다는 뜻이다.\r\n    - @Retention - 애노테이션의 범위라고 할 수 있는데 어떤 시점까지 애노테이션이 영향을 미치는지 결정한다. RetetionPolicy.RUNTIME의 경우 컴파일 이후에도 JVM에 의해서 참조가 가능하다는 뜻이다.\r\n    - @Documented - 문서에도 애노테이션의 정보가 표현된다.\r\n    - @Inherited - 이 애노테이션을 선언하면 자식 클래스가 애노테이션을 상속 받을 수 있다.\r\n    - @SpringBootConfiguration - 스프링 부트의 설정을 나타내는 애노테이션이다. 스프링의 @Configuration을 대체하며 스프링 부트 전용 애노테이션이다. 테스트 애노테이션을 사용할 때 계속 이 애노테이션을 찾기 때문에 스프링 부트에서는 필수 애노테이션이다.\r\n    - @EnableAutoConfiguration - 자동 설정의 핵심 애노테이션이다. 클래스 경로에 지정된 내용을 기반으로 설정 자동화를 수행한다.\r\n    - @ComponentScan - 해당 패키지에서 @Component 애노테이션을 가진 Bean들을 스캔해서 등록한다. (@Configuration, @Repository, @Service, @Controller, @RestController 이 애노테이션들도 다 까보면 @Component가 존재함)\r\n\r\n  이러하다.\r\n\r\n<br/>\r\n\r\n## @ComponentScan, @EnableAutoConfiguration\r\n\r\n- 다른 애노테이션보다 설정 관련 중요한 애노테이션은 @SpringBootConfiguration, @ComponentScan, @EnableAutoConfiguration이다.\r\n- @SpringBootConfiguration은 위에 적힌 대로 스프링의 @Configuration을 대체하는 기능을 하므로 넘어가고 나머지 두 애노테이션을 살펴보도록 하자.\r\n- 빈 등록할 때 순서가 존재한다.\r\n  처음에 @ComponentScan으로 등록하고 그 후 @EnableAutoConfiguration으로 추가적인 Bean을 읽어 등록한다.\r\n\r\n  1단계: @ComponentScan\r\n\r\n  2단계: @EnableAutoConfiguration\r\n\r\n  인 셈이다.\r\n\r\n- 우선 @ComponentScan이 지정된 클래스의 패키지 밑으로 component scan을 진행한다. @Componet 계열 애노테이션 (@Configuration, @Repository, @Service, @Controller, @RestController)과 @Bean 애노테이션이 붙은 method return 객체를 모두 bean으로 등록한다.\r\n- 다음으로 @EnableAutoConfiguration에 의해서 spring.factories 라는 파일 안에 들어있는 많은 설정들을 읽어 bean이 생성되고 스프링 부트 애플리케이션이 실행되는 것이다.\r\n\r\n![Untitled (44)](https://user-images.githubusercontent.com/62014888/145945318-451a5ae7-f2aa-466b-8cf5-5b43c0abdec2.png)\r\n\r\n- @EnableAutoConfiguration의 경우 AutoConfigurationImportSelector를 import하고 있는데 이를 통해 spring.factories에 있는 bean들을 선택하고 등록시킬 수 있다.\r\n\r\n![Untitled (45)](https://user-images.githubusercontent.com/62014888/145945323-3f9664c3-7266-4d06-a873-81d341ac4ce5.png)\r\n\r\n- 그렇다면 spring.factories는 이렇게 되어있는데 여기 있는 모든 bean이 자동 등록될까?\r\n- 그건 아니다.\r\n  ConfigurationClassParser 클래스의 processConfigurationClass() 메서드의 shouldSkip 과정에서 Conditional 애노테이션을 찾아 조건에 부합하는지 확인하고 해당 조건을 충족하는 경우에만 등록을 진행한다고 한다.\r\n- 그리고 우리는 application.properties나 application.yml 파일을 이용해 설정을 하는 경우도 있다. 이때 설정을 하게 되면 spring-configuration-metadata.json 이라는 자동 설정에 사용할 프로퍼티 정의 파일에 작성한 값으로 프로퍼티를 세팅한 후 구현되어 있는 자동 설정에 값을 주입시켜준다.\r\n\r\n```java\r\nCaused by: org.springframework.context.ApplicationContextException: Unable to start ServletWebServerApplicationContext due to missing ServletWebServerFactory bean.\r\n```\r\n\r\n![Untitled (46)](https://user-images.githubusercontent.com/62014888/145945327-39d2fef0-c548-4211-882d-c8e2c0c40b21.png)\r\n\r\n- 참고로 @EnableAutoConfiguration이 있어야 컨테이너에 ServletWebServerFactory bean이 등록이 되어 Web application으로 만들어준다.\r\n- 그래서 @EnableAutoConfiguration이 없다면 위와 같은 오류가 발생하는데 밑과 같이 WebApplicationType.NONE으로 셋팅해주면 정상적으로 실행은 된다.\r\n\r\n<br/>\r\n\r\n## 마무리\r\n\r\n- 스프링 부트의 경우 애노테이션을 통해 자동으로 필요한 빈들을 등록시켜준다는 것을 알게 되었다.\r\n- 이러한 점을 인식하고 사용을 해야 자동 등록 기능을 끄고 수동으로 빈을 등록시켜줘야 할 때 어떤 빈들을 등록을 시켜줘야할지 빠르게 파악할 수 있을 것이다.\r\n    - 대표적인 예로 Repilcation을 하기 위해 직접 Datasource를 설정해줄 때 jpa와 관련해서 어떤 빈을 등록시켜줘야 하는지와 같은 예가 있다.\r\n\r\n<br/>\r\n\r\n## 참고\r\n\r\n- [https://camel-it.tistory.com/26](https://camel-it.tistory.com/26)\r\n- [https://duooo-story.tistory.com/52?category=882088](https://duooo-story.tistory.com/52?category=882088)\r\n- [https://rlawls1991.tistory.com/entry/스프링-부트-원리-자동설정-이해](https://rlawls1991.tistory.com/entry/%EC%8A%A4%ED%94%84%EB%A7%81-%EB%B6%80%ED%8A%B8-%EC%9B%90%EB%A6%AC-%EC%9E%90%EB%8F%99%EC%84%A4%EC%A0%95-%EC%9D%B4%ED%95%B4)\r\n- [https://velog.io/@adam2/SpringBoot-자동-환경-설정AutoConfiguration](https://velog.io/@adam2/SpringBoot-%EC%9E%90%EB%8F%99-%ED%99%98%EA%B2%BD-%EC%84%A4%EC%A0%95AutoConfiguration)\r\n- [https://jdm.kr/blog/216](https://jdm.kr/blog/216)\r\n- [https://www.youtube.com/watch?v=Y11h-NUmNXI](https://www.youtube.com/watch?v=Y11h-NUmNXI)","excerpt":"@SpringBootApplication 우테코에서 미션을 하며 스프링 부트를 이용해서 웹 애플리케이션을 만들어보았다. 스프링은 간단하게 이야기하면 스프링 빈 컨테이너를 만들어 빈 등록을 하고 필요한 객체에게 의존성 주입을 하는 방식으로 애플리케이션…","fields":{"slug":"/springboot-application/"},"frontmatter":{"date":"Jun 15, 2021","title":"@SpringBootApplication 파헤치기","tags":["spring"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n## POJO (Plain Old Java Object)\r\n\r\nPOJO는 Plain Old Java Object의 준말로 말 그대로 오래된 방식의 간단한 자바 오브젝트라는 뜻이다.  \r\nJava EE 등의 중량 프레임워크들을 사용하게 되면서 해당 프레임워크에 종속된 \"무거운\" 객체를 만들게 된 것에 반발해서 사용하게 된 용어로서 2000년 9월 마틴 파울러, 레베카 파슨, 조쉬 맥킨지 등이 처음 사용하기 시작했다.  \r\n과거 EJB, Strust같은 프레임워크는 비즈니스 로직을 구현하기 위한 클래스를 코딩할 때 프레임워크의 특정 인터페이스 등의 상속을 강요하였고, 그 결과 비즈니스 로직을 코딩해야할 시간에 상속을 구현하기 위한 관용적인 코딩 작업을 불필요하게 해야 했었다.  \r\n객체지향의 가장 중요한 개념 중 하나인 느슨한 의존관계를 역행하는 이런 침투적인 프레임워크의 문제점을 강조하기 위해 이 말을 처음 사용하기 시작하였다.  \r\n이 후 POJO는 주로 특정 자바 모델이나 기능, 프레임워크 등을 따르지 않은 자바 오브젝트를 지칭하는 말로 사용되었다. 스프링 프레임워크는 POJO 방식의 프레임워크라고 한다.\r\n\r\n<br/>\r\n\r\n## Java Beans\r\n\r\nJava Beans는 데이터를 표현하기 위한 Java 클래스를 만들 때의 규약이다.  \r\n아래의 규칙을 지킨 Java 클래스는 Java Beans라고 부른다.  \r\n- 모든 클래스의 프로퍼티는 private이며 getter, setter 메서드로 제어한다.\r\n- 인자가 없는 public 생성자가 있어야 한다.\r\n- Serializable 인터페이스를 구현해야 한다.  \r\n\r\nJava Beans 규약은 Java EE 프레임워크에서 데이터를 저장할 Java 클래스를 만들 때 제안하는 일종의 규약이다.\r\n\r\n<br/>\r\n\r\n## POJO == Java Beans?\r\n\r\nNO!  \r\nJava Beans는 POJO이다.  \r\n그러나 POJO는 Java Beans가 아니다.  \r\nPOJO가 Java Beans보다 더 넓은 개념이다.\r\n\r\n<br/>\r\n\r\n## Spring에서 사용하는 Bean은?\r\n\r\n스프링 빈이란 자바 객체를 뜻한다.  \r\n스프링 컨테이너에서 자바 객체가 만들어 지게 되면 이 객체를 스프링 빈이라고 부르는 것이다.  \r\n스프링 빈과 자바 일반 객체와의 차이점은 없다. 다만 스프링 컨테이너에서 만들어지는 객체를 스프링 빈이라고 부를 뿐이다.  \r\n스프링 빈은 설정 메타데이터(xml, 애노테이션)에 의해 생성이 된다.\r\n\r\n<br/>\r\n\r\n## 아무 객체나 Bean 등록을 해도 될까?\r\n\r\nNO!  \r\n스프링 빈은 근본적으로 쓰레드 세이프하지 않다.  \r\n왜?  \r\n일단 그렇게 만들어져있지도 않을 뿐더러 빈 등록을 한다는 것은 싱글톤으로 관리를 한다는 뜻이다.  \r\n객체 인스턴스를 하나만 생성해서 공유하는  싱글톤 방식은 여러 클라이언트가 하나의 같은 객체 인스턴스를 공유하기 때문에 싱글톤 객체는 상태를 유지(stateful)하게 설계하면 안된다.  \r\n즉, 무상태(stateless)로 설계해야 한다.\r\n- 특정 클라이언트에 의존적인 필드가 있으면 안된다.\r\n- 특정 클라이언트가 값은 변경할 수 있는 필드가 있으면 안된다.\r\n- 가급적 읽기만 가능해야 한다.\r\n- 필드 대신에 자바에서 공유되지 않는 지역변수, 파라미터, ThreadLocal 등을 사용해야 한다.\r\n\r\n스프링 필드에 공유 값을 설정하면 정말 큰 장애가 발생할 수 있다.\r\n\r\n<br/>\r\n\r\n## 참고\r\n\r\n- [https://www.hanumoka.net/2019/01/06/java-20190106-java-pojo-vs-bean/](https://www.hanumoka.net/2019/01/06/java-20190106-java-pojo-vs-bean/)\r\n- [https://ko.wikipedia.org/wiki/Plain_Old_Java_Object](https://ko.wikipedia.org/wiki/Plain_Old_Java_Object)\r\n- [https://docs.spring.io/spring-framework/docs/current/reference/html/core.html#beans-introduction](https://docs.spring.io/spring-framework/docs/current/reference/html/core.html#beans-introduction)\r\n- [https://endorphin0710.tistory.com/93](https://endorphin0710.tistory.com/93)\r\n- 김영한님 스프링 core 수업","excerpt":"POJO (Plain Old Java Object) POJO는 Plain Old Java Object의 준말로 말 그대로 오래된 방식의 간단한 자바 오브젝트라는 뜻이다. Java EE 등의 중량 프레임워크들을 사용하게 되면서 해당 프레임워크에 종속된…","fields":{"slug":"/pojo-vs-java-beans/"},"frontmatter":{"date":"Jun 13, 2021","title":"POJO vs Java Beans","tags":["java","spring"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n## Validation이란?\r\n\r\n- Validation이란 유효성 검증을 의미한다.\r\n- 대표적인 예로 String의 값이 null이 되면 안된다던가 Integer의 값이 0보다 커야한다던가 즉, 우테코에서 미션을 진행해오면서 보통 도메인에서 처리했었던 검증을 말한다.\r\n- 그렇다면 왜 Validation이라는 기능이 나오게 되었을까?\r\n- 이 [hibernate validator docs](https://docs.jboss.org/hibernate/validator/5.4/reference/en-US/html_single/#preface) 를 참고하자면\r\n\r\n  > 데이터 검증은 애플리케이션의 여러 계층에 전반에 걸쳐 발생하는 흔한 작업이다. 종종 동일한 데이터 검증 로직이 각 계층에 구현되는데 이는 오류를 일으키기 쉽고 시간을 낭비하는 일이다. 이에 개발자는 이러한 중복을 피하기 위해 유효성 검사를 도메인 모델에 직접 번들로 묶어 실제 클레스 자체에 대한 메타 데이터 (데이터를 위한 데이터) 인 유효성 검사 코드로 복잡하게 만든다.\r\n  >\r\n\r\n  라고 적혀있다. 즉, 도메인 모델에 유효성 검증 코드가 추가되어 복잡해지다 보니 이를 없애주기 위해 Validation이 나오게 되었다고 할 수 있다.\r\n\r\n\r\n![Untitled (29)](https://user-images.githubusercontent.com/62014888/145755472-54f036d2-a3a2-4ebf-a349-61266c6d2cb0.png)\r\n\r\n![Untitled (30)](https://user-images.githubusercontent.com/62014888/145755474-12a7bec5-370c-4c0e-bdbd-453da2ad765f.png)\r\n\r\n<br/>\r\n\r\n## Validation 파헤치기\r\n\r\n- 자, 그럼 Validation을 사용해보자.\r\n- gradle dependencies에 (maven은 검색으로 해결..ㅎㅎ)\r\n\r\n```java\r\nimplementation 'org.springframework.boot:spring-boot-starter-validation'\r\n```\r\n\r\n이거 하나만 추가하면 validation을 사용할 수 있다.\r\n참고로 spring boot 2.3.0 버전부터 spring-boot-starter-web에 validation이 포함되어 있지 않아 의존성을 따로 추가해주는 것이다.\r\n\r\n- 그런데 의문이 들었다.\r\n\r\n    ![Untitled (31)](https://user-images.githubusercontent.com/62014888/145755502-7613d8b7-d8a3-493e-af70-99134d0cf814.png)\r\n\r\n    분명 spring-boot-starter-validation이라고 적혀있는 것을 추가했는데 왜 import 해오는 것은 javax의 validation인 걸까?\r\n\r\n    spring과 관련이 없는 다른 것을 들고 오는걸까?\r\n\r\n    그래서 이를 까보기로 했다.\r\n\r\n    ![Untitled (32)](https://user-images.githubusercontent.com/62014888/145755503-a11e5b0e-403e-4f29-baf5-bdb5dc5b6b7c.png)\r\n\r\n    보니까 hibernate validator가 있는 것이 보인다.\r\n\r\n    이게 아마 validation과 관련이 있는 거라고 생각이 들었다.\r\n\r\n    그리고 다시 hibernate validator를 찾아보았다.\r\n\r\n    > This transitively pulls in the dependency to the Bean Validation API (javax.validation:validation-api:1.1.0.Final).\r\n    >\r\n\r\n    위는 공식문서에 적혀있는 내용인데 hibernate validator를 의존성으로 추가하면 Bean Validation API (javax validation)을 전이적으로 가져오게 된다고 적혀있다.\r\n\r\n    그렇다면 결국 spring-boot-starter-validation이라는 의존성을 추가하게 되면\r\n    hibernate validator와 bean validation이 추가가 된다는 것이다!\r\n\r\n<br/>\r\n\r\n## Bean Validation, Hibernate Validator\r\n\r\n- 여기서 또 의문이 발생할 것이다.\r\n- 그럼 hibernate validator와 bean validation이 도대체 뭘까?\r\n- 우선 bean validation에 대해 먼저 말해보겠다.\r\n\r\n  ![Untitled (33)](https://user-images.githubusercontent.com/62014888/145755544-c3c1be3b-d331-4c01-aeee-99aa46dfed29.png)\r\n\r\n  참고로 추가된 라이브러리를 보게되면 jakarta validation이라고 적혀있지만 안에 패키지를 보면 javax라고 되어 있는 것을 알 수 있는데 jakarta는 자바 플랫폼, 자바 EE 등 확장 사양의 집합이다. 그래서 그냥 java라고 생각하면 될 것 같다.\r\n  즉, java에서 만든 bean validation인 것이다.\r\n\r\n- bean validation은 Java Bean 유효성 검증을 위한 메타데이터 모델과 api에 대한 정의라고 한다.\r\n  무슨 뜻인지 감이 잘 잡히지 않는다. 하나 하나 살펴보도록 하자.\r\n- 메타데이터는 데이터에 대한 데이터, 즉 어떤 목적을 가지고 만들어진 데이터를 뜻한다.\r\n- 우리가 데이터를 각 계층으로 전달할 때 Java Bean 형태로 보내게 되는데 이 때 데이터 유효성 검증을 위해 사용하게 되는 것이 이 메타데이터를 말하는 것이다. 그렇다면 Java에서 메타데이터를 표현할 수 있는 대표적인 방법은? 바로 애노테이션이다.\r\n- 정리하자면 이렇다.\r\n  Bean Validation은 애노테이션을 이용하여 메타데이터를 정의하고 이를 통해 Java Bean의 유효성을 검증하는 것에 대한 명세인 것이다.\r\n  즉, Bean Validation은 명세일 뿐 동작하는 코드가 아니다. 실제로 라이브러리를 열어보면 인터페이스, 애노테이션 등만 포함되면 구현 코드는 없다.\r\n  그렇다면 이를 동작하도록 만드는 구현 코드가 필요하다.\r\n- 그게 바로 hibernate validator인 것이다!\r\n  hibernate validator는 참조 구현이며 현재 JSR-380의 유일한 인증 구현이라고 한다.\r\n  참고로 지금까지 명세서(Specification)은 발전해서 2.0까지 나왔고 Bean Validation 2.0을 JSR 380이라고 부른다.\r\n  여기서 hibernate를 우리가 ORM으로 알고 있는 hibernate와 헷갈려 하지말자 (아 물론 같은 회사다)\r\n\r\n<br/>\r\n\r\n## Validation 예외처리\r\n\r\n- 계속해서 Validation을 보다보니 궁금해졌다.\r\n- 우리가 직접 Validation Annotation과 validator를 만들어 사용하거나 또는 기존에 있던 annotation의 validator를 사용해 검증을 할 것인데 이 때 어디서 validate를 할까?\r\n- validation을 사용하는 법은 다들 알 것이다.\r\n- validation을 원하는 DTO(Java Bean)의 필드 or 클래스에 @NotNull, @Positive 등의 annotation을 명시 해주고 이 DTO를 바인딩 해주는 컨트롤러의 메서드 인자 앞에 @Valid라는 annotation을 걸어주기만 하면 된다.\r\n- 어떨까? 뭔가 DTO를 바인딩 해줄 때 validate를 해줄 것 같지 않은가?\r\n  결론부터 이야기하자면 맞다. DTO를 바인딩할 때 validate를 해준다.\r\n- 그렇다면 DTO를 바인딩해주는 녀석들부터 이야기해보자.\r\n- 이번에 찾아보면서 알게된게 @RequestParam, @PathVariable, @RequestBody, @ModelAttribute 등의 컨트롤러에서 인자를 바인딩해줄 때 사용하는 애들은 전부 HandlerMethodArgumentResolver을 상속받은 클래스에서 처리를 해준다는 것이다.\r\n    - 즉, 리졸버를 사용해서 컨트롤러 메서드의 인자를 바인딩 해주는 것이다!\r\n- 그렇다면 DTO를 바인딩해주는 annotation은?\r\n  @ModelAttribute와 @RequestBody가 있다.\r\n1. @ModelAttribute는 Form data를 바인딩해줄 때 사용하는 것으로 ModelAttributeProcessor에서 이를 바인딩해주고 validate도 해준다.\r\n    - 이 때 예외는 BindException으로 처리를 해준다.\r\n2. 다음으로 @RequestBody인데 주로 json을 바인딩 하다보니 이번에 Rest api를 구현하며 많이 사용을 하였기에 이녀석을 조금 더 자세히 살펴보도록 하자.\r\n    - @RequestBody는 RequestResponseBodyMethodProcessor에서 바인딩을 해주고 validate를 해주는데 이곳에서 WebDataBinder를 만들고 validateIfApplicable 이라는 메서드를 이용해 validate를 해준다.\r\n\r\n  ![Untitled (34)](https://user-images.githubusercontent.com/62014888/145755588-c8dff529-21ab-4474-8df6-ab640c28a76f.png)\r\n\r\n validateIfApplicable을 보면 이런 모습.\r\n 참고로 validateIfApplicable 구현 메서드는 AbstractMessageConverterMethodArgumentResolver에 있다. 이를 상속하는 것이 RequestResponseBodyMethodProcessor다.\r\n\r\n\r\n![Untitled (35)](https://user-images.githubusercontent.com/62014888/145755591-8bb7059e-7bae-4eac-b9e6-d441459dc616.png)\r\n\r\n다음으로 binder.validate(validationHints);를 살펴보면 이렇다.\r\n\r\n\r\n\r\n![Untitled (36)](https://user-images.githubusercontent.com/62014888/145755594-04f1b754-6e0b-48e4-be56-87a742674ba7.png)\r\n\r\nDataBinder 내부를 보면 validator를 가지고 있고 이 validator의 validate를 실행해주는 모습을 볼 수 있다. 그 후 validate를 더 파고 들어가보았는데 실제로는 SmartValidator, javax.validation.Validator를 구현하고 있는 SpringValidatorAdapter라는 곳의 validate 였다.\r\n\r\n이 메서드 안에 있는 processConstraintViolations라는 메서드의 인자를 보면 우리가 만든 validator 또는 기존 validator를 이용해 validate를 해주는 모습이 보인다.\r\n\r\n그리고 그 밑에 processConstraintViolations의 인자를 보니 Set<ConstratintViolation<Object>> violations라고 적혀있다.\r\n\r\n즉, validator를 이용해 validate를 하고 난 결과, violation(위반)이 있을 때 이를 BindingResult에 추가한다.\r\n\r\n![Untitled (37)](https://user-images.githubusercontent.com/62014888/145755660-330102a9-62e1-46c6-b971-4950a3123dfe.png)\r\n\r\n![Untitled (38)](https://user-images.githubusercontent.com/62014888/145755667-74bfd7fd-7a86-4634-88fa-010b2e4b15c1.png)\r\n\r\n그래서 결국 validation이 모두 진행된 BindingResult가 생길 것이고 이를 다시 한번 MethodArgumentNotValidException으로 감싸서 던져주는 것이다.\r\n\r\n참고로 저 this.targetValidator.validate를 끝까지 가본 결과 a single constraint annotation의 경우 ConstraintTree 라는 클래스에서 validator의 isValid라는 메서드를 사용하고 있었다.\r\n\r\n![Untitled (39)](https://user-images.githubusercontent.com/62014888/145755671-99d99b4f-ef51-4081-9f77-8c3626c70ca5.png)\r\n\r\n그리고 이 validateSingleConstraint라는 메서드를 사용하는 곳이 이를 상속하고 있는 SimpleConstraintTree라는 클래스인데 이곳에서 isPresent()를 통해 검증에서 실패했을 경우 위반과 관련된 내용이 담긴 violatedConstraintValidatorContexts에 추가가 되는 것 같다.\r\n\r\n![Untitled (40)](https://user-images.githubusercontent.com/62014888/145755674-c4f0cc60-7a91-4740-99f6-5299169036bc.png)\r\n\r\n정리해보자면 RequestResponseBodyMethodProcessor에서 WebDataBinder를 만들고 validateIfApplicable 메서드를 이용해 @Valid가 있을 경우 validate를 해주는데 이때 유효성 검증 실패 즉, 검증에 위반되는 결과가 있을 경우 WebDataBinder에 error가 추가되고 이 binder의 결과를 MethodArgumentNotValidException로 감싸져서 예외가 던져지는 것이다.\r\n\r\n많이 복잡하다보니 정확하게 이해하지 못하거나 잘못된 내용이 있을 수도 있다..ㅜ.ㅜ\r\n더 궁금하다면 직접 파고 들어가보는 것도 좋을 것 같다..!!\r\n\r\n<br/>\r\n\r\n## 그렇다면 왜 @Valid는 Controller에서만 보일까?\r\n\r\n- 이는 validation에 대해 계속 찾아보다가 느낀 점 + 스택오버플로우의 글을 통해서 정리할 수가 있는데 위에서 적혀있듯이 @Valid라는 annotation은 @RequestBody나 @ModelAttribute와 같은 annotation이 리졸버를 이용해 DTO를 바인딩해줄 때 사용이 된다.\r\n- 그러다보니 단순하게 다른 계층에서 @Valid를 명시하게 되면 이를 보고 작동을 시켜줄 객체가 없는 것이다.\r\n- 그래서 만약 service에서 사용하고 싶다? 그러면 직접 aop를 이용해 동작시키던가(스택오버플로우 답변) 아니면 다른 예제를 보니 validator를 호출하여 직접 validate를 해야한다고 한다.\r\n- 근데 이 작업은 굳이..? 라는 생각이 드니 입력을 했을 때의 유효성 검증은 controller에서 validation을 이용해 처리해주고 중복 체크와 같은 유효성 검증은 service에서 처리해주면 좋지 않을까 싶다.\r\n\r\n\r\n<br/>\r\n\r\n##참고\r\n\r\n- [https://www.popit.kr/javabean-validation과-hibernate-validator-그리고-spring-boot/](https://www.popit.kr/javabean-validation%EA%B3%BC-hibernate-validator-%EA%B7%B8%EB%A6%AC%EA%B3%A0-spring-boot/)\r\n- [https://jcp.org/en/jsr/detail?id=303](https://jcp.org/en/jsr/detail?id=303)\r\n- [https://meetup.toast.com/posts/223](https://meetup.toast.com/posts/223)\r\n- [https://kapentaz.github.io/java/Java-Bean-Validation-제대로-알고-쓰자/#](https://kapentaz.github.io/java/Java-Bean-Validation-%EC%A0%9C%EB%8C%80%EB%A1%9C-%EC%95%8C%EA%B3%A0-%EC%93%B0%EC%9E%90/#)\r\n- [https://docs.jboss.org/hibernate/stable/validator/reference/en-US/html_single/](https://docs.jboss.org/hibernate/stable/validator/reference/en-US/html_single/)\r\n- [https://stackoverflow.com/questions/19425221/spring-validated-in-service-layer](https://stackoverflow.com/questions/19425221/spring-validated-in-service-layer)","excerpt":"Validation이란? Validation이란 유효성 검증을 의미한다. 대표적인 예로 String의 값이 null이 되면 안된다던가 Integer의 값이 0보다 커야한다던가 즉, 우테코에서 미션을 진행해오면서 보통 도메인에서 처리했었던 검증을 말한…","fields":{"slug":"/java-validation/"},"frontmatter":{"date":"Jun 10, 2021","title":"Java Validation 파헤치기","tags":["java","spring"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"## Servlet\r\n\r\n- 컨테이너는 서블릿을 실행하고 관리한다.\r\n- 컨테이너가 주는 혜택\r\n    - 통신(커뮤니케이션) 지원\r\n        - 컨테이너는 서블릿과 웹 서버가 서로 통신할 수 있는 손쉬운 방법을 제공.\r\n        - 서버와 대화하기 위해 개발자가 직접 ServcerSocket을 만들고, 특정 포트에 리스닝하고, 연결요청이 들어오면 스트림을 생성하는 등 이런 복잡한 일련의 일을 할 필요가 없다.\r\n        - 컨테이너는 어떻게 웹 서버와 통신해야 하는지 잘 알고 있으며, 이런 통신 기능을 API로 제공.\r\n        - 고로 개발자가 신경 쓸 부분은 서블릿이 구현해야할 비즈니스 로직에만 집중하면 됨.\r\n    - 생명주기(라이프사이클) 관리\r\n        - 컨테이너는 서블릿의 탄생과 죽음을 관리함.\r\n        - 서블릿 클래스를 로딩하여 인스턴스화하고, 초기화 메서드를 호출하고, 요청이 들어오면 적절한 서블릿 메서드를 호출하는 작업을 컨테이너가 함.\r\n        - 서블릿이 생명을 다한 순간에는 적절하게 가비지 컬렉션을 진행함.\r\n    - 멀티스레딩 지원\r\n        - 컨테이너는 요청이 들어올 때마다 새로운 자바 스레드를 하나 만듦.\r\n        - 클라이언트의 요청에 따라 적절한 HTTP 서비스 메서드를 실행하면 그걸로 스레딩 작업은 끝이 남.\r\n    - 선언적인 보안 관리\r\n        - 컨테이너를 사용하면, 보안에 관련된 내용을 서블릿 또는 자바 클래스 코드 안에 하드코딩할 필요가 없다.\r\n- 컨테이너는 서블릿 하나에 대한 다수의 요청을 처리하기 위하여 다수의 스레드를 실행하지 다수의 인스턴스를 만들지는 않는다.\r\n\r\n<br/>\r\n\r\n## Dispatcher Servlet\r\n\r\n- 기존의 Servlet 방식은 요청 url 당 Servlet을 생성하고 그에 맞는 Controller에게 요청을 보내주는 코드를 각각 다 따로 작성해야 했다.\r\n- 그러다보니 수많은 Servlet과 Controller를 만들어야하는 일이 발생했다.\r\n- Spring에서는 Front Controller 패턴을 취하는 Servlet을 미리 만들어 두었다. 그것이 바로 Dispatcher Servlet!\r\n    - 즉, 모든 요청을 한 곳에서 받아서 필요한 처리를 한 뒤, 요청에 맞는 handler로 요청을 dispatch하고, 해당 handler의 실행 결과를 http response 형태로 만드는 역할을 한다.\r\n- 참고로 Front Controller 패턴을 적용하면 하나의 Servlet에서 모든 요청을 받아들여 적절한 Controller로 요청을 위임해준다.\r\n\r\n![Untitled (47)](https://user-images.githubusercontent.com/62014888/145956098-0dcf31f3-3a70-435f-bfdd-90753e0de378.png)\r\n\r\n- 그림과 같이 dispatcher servlet은 servlet context와 root context가 존재하는데 여기서 말하는 WebApplicationContext는 ApplicationContext를 확장한 WebApplicationContext 인터페이스의 구현체를 말하며 ApplicationContext를 상속받아 사용한다.\r\n- Root WebApplicationContext\r\n    - ContextLoaderListner에 의해 생성되며, 자식 Context에서 Root Context를 참조할 수 있다.\r\n    - 여러 Servlet Context를 서로 공유해야 하는 빈들을 등록하고 설정할 때 사용한다.\r\n    - 주로 Service와 Repository 빈들이 등록됨.\r\n- Servlet WebApplicationContext\r\n    - DispatcherServlet에 의해 생성되며 Root Context에서는 상속 개념이기에 참조가 불가능하다.\r\n    - 해당 Servlet Context에서만 사용이 가능하며, 스프링 Dispatcher Servlet에서 관리하는 독립적인 웹 애플리케이션 형태로 사용한다.\r\n    - 주로 Controller, HandlerMapping 등이 등록됨.\r\n\r\n```xml\r\n<listener>\r\n  \t<listener-class>org.springframework.web.context.ContextLoaderListener</listener-class>\r\n  </listener>\r\n  <context-param>\r\n  \t <param-name>contextConfigLocation</param-name>\r\n  \t <param-value>\r\n  \t \t/WEB-INF/spring/root-context.xml\r\n  \t </param-value>\r\n  </context-param>\r\n  \r\n  <servlet>\r\n  \t<servlet-name>dispatcher</servlet-name>\r\n  \t<servlet-class>org.springframework.web.servlet.DispatcherServlet</servlet-class>\r\n  \t<init-param>\r\n  \t\t<param-name>contextConfigLocation</param-name>\r\n  \t\t<param-value>/WEB-INF/spring/appServlet/servlet-context.xml</param-value>\r\n  \t</init-param>\r\n  </servlet>\r\n  <servlet-mapping>\r\n  \t<servlet-name>dispatcher</servlet-name>\r\n  \t<url-pattern>*.htm</url-pattern>\r\n  </servlet-mapping>\r\n```\r\n\r\n- 예전 스프링 레거시를 보면 web.xml (Deployment Descriptor)에 context를 등록시켜둔다.\r\n- was 구동 시 /WEB-INF 디렉토리에 존재하는 web.xml을 읽어 웹 애플리케이션의 설정을 구성한다.\r\n- 그런데 우테코 미션을 진행하면서 이런 web.xml을 한 번도 본 적이 없다.\r\n- 그 이유는 뭘까?\r\n- 정답은 스프링 부트와 Servlet 3.0에 있다.\r\n- 우선, 스프링 부트는 servlet이 내장되어 있다. 또한 Servlet 3.0부터 자바 소스 설정으로도 context 설정이 가능하다.\r\n- 스프링 부트에서는 spring-boot-starter 모듈에 이미 모든 내장 컨테이너들의 설정을 지원한다. 부트는 서블릿 컨테이너의 라이프 사이클에 연결하는 대신 스프링 설정을 사용하여 부트 자체와 내장된 서블릿 컨테이너를 구동시킨다. 필터 및 서블릿 선언은 스프링 구성으로 서블릿 컨테이너에 등록한다.\r\n    - 즉, 간단하게 말하면 부트로 프로젝트를 만들때 생기는 application 클래스를 보면 @SpringBootApplication이 존재하는데 이 친구에 의해 빈 자동 등록이 된다고 생각하면 된다.\r\n- 그리고 요즘은 굳이 context를 2개로 나누어서 사용하지 않고 root context 하나를 만들어 모든 빈을 등록하여 사용한다고 한다.\r\n\r\n![Untitled (48)](https://user-images.githubusercontent.com/62014888/145955885-4fbe43ab-2859-4595-8f04-1d9c86af3041.png)\r\n\r\n### Dispatcher Servlet 동작 순서\r\n1. 클라이언트가 was에 접근하면 front controller 역할을 하는 dispatcher servlet이 요청을 가로챔.\r\n2. handler mapping 설정에서 해당 요청을 처리할 controller를 탐색\r\n3. form data 요청이다 그럼 ModelAttributeProcessor가 파라미터를 바인딩함.\r\n   그게 아닌 json 요청이다? RequestResponseBodyMethodProcessor가 MessageConverter을 이용하여 파라미터를 바인딩함. (즉 jackson 라이브러리 사용)\r\n4. 데이터 저장 및 응답 가공\r\n5. 요청을 처리한 뒤, html로 응답할 경우 결과를 출력할 view의 이름, data로 응답할 경우 MessageConverter을 이용하여 json 데이터로 반환,\r\n6. html로 응답한 경우 ViewResolver에서 받은 view 이름(string)으로부터 해당 view를 탐색\r\n7. 탐색한 view 객체를 반환\r\n8. 처리 결과가 포함된 view를 dispatcher servlet에 전달\r\n9. 클라이언트에게 최종 결과 출력\r\n\r\n## 궁금한 점\r\n- dispatcher servlet을 여러 개 둔다는게 무슨 말이지?\r\n- dispatcher servlet이 요청을 받아 적절한 처리를 하는 것 아닌가?\r\n- 요즘은 하나의 서블릿에 하나의 컨텍스트로 처리를 하는게 국룰이다라는 글을 보았고 토비 이일민님께서도 하나의 컨텍스트를 사용한다고 했다. 출력해보니 전부 AnnotationConfigServletWebServerApplicationContext 라는 곳에서 모든 빈이 등록되어 있던데 그럼 더이상 계층이 나누어진 컨텍스트는 공부할 필요없이 그냥 넘어가면 되는걸까? 아니면 레거시를 위해 공부하는 것이 좋을까?\r\n\r\n## 출처\r\n\r\n- [https://velog.io/@gokoy/Spring-동작-순서](https://velog.io/@gokoy/Spring-%EB%8F%99%EC%9E%91-%EC%88%9C%EC%84%9C)\r\n- [https://gompangs.tistory.com/entry/Dispatcher-Servlet](https://gompangs.tistory.com/entry/Dispatcher-Servlet)\r\n- [https://docs.spring.io/spring-framework/docs/3.0.0.RC2/spring-framework-reference/html/ch15s02.html](https://docs.spring.io/spring-framework/docs/3.0.0.RC2/spring-framework-reference/html/ch15s02.html)\r\n- [https://sabarada.tistory.com/16](https://sabarada.tistory.com/16)\r\n- [https://linked2ev.github.io/spring/2019/09/15/Spring-5-서블릿과-스프링에서-Context(컨텍스트)란/](https://linked2ev.github.io/spring/2019/09/15/Spring-5-%EC%84%9C%EB%B8%94%EB%A6%BF%EA%B3%BC-%EC%8A%A4%ED%94%84%EB%A7%81%EC%97%90%EC%84%9C-Context(%EC%BB%A8%ED%85%8D%EC%8A%A4%ED%8A%B8)%EB%9E%80/)\r\n- [https://jeong-pro.tistory.com/222](https://jeong-pro.tistory.com/222)\r\n- [https://github.com/binghe819/TIL/blob/master/Spring/MVC/DispatcherServlet.md](https://github.com/binghe819/TIL/blob/master/Spring/MVC/DispatcherServlet.md)\r\n- [https://docs.spring.io/spring-framework/docs/3.2.x/spring-framework-reference/html/mvc.html](https://docs.spring.io/spring-framework/docs/3.2.x/spring-framework-reference/html/mvc.html)","excerpt":"Servlet 컨테이너는 서블릿을 실행하고 관리한다. 컨테이너가 주는 혜택 통신(커뮤니케이션) 지원 컨테이너는 서블릿과 웹 서버가 서로 통신할 수 있는 손쉬운 방법을 제공. 서버와 대화하기 위해 개발자가 직접 ServcerSocket을 만들고, 특정…","fields":{"slug":"/servlet-dispatcherservlet/"},"frontmatter":{"date":"Jun 10, 2021","title":"Servlet, DispatcherServlet 살펴보기","tags":["java","spring"],"update":"Jan 01, 0001"}}}]}},"pageContext":{}},"staticQueryHashes":["2027115977","694178885"]}