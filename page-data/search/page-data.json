{"componentChunkName":"component---src-pages-search-tsx","path":"/search/","result":{"data":{"allMarkdownRemark":{"edges":[{"node":{"rawMarkdownBody":"\r\n- 자바는 두 가지 객체 소멸자를 제공함.\r\n- finalizer는 예측할 수 없고, 상황에 따라 위험할 수 있어 일반적으로 불필요하다.\r\n    - 오동작, 낮은 성능, 이식성 문제의 원인이 되기도 함.\r\n    - 자바 9에서는 deprecated API로 지정하고 cleaner를 대안으로 소개함.\r\n- cleaner는 finalizer보다는 덜 위험하지만, 여전히 예측할 수 없고, 느리고, 일반적으로 불필요하다.\r\n- finalizer와 cleaner는 즉시 수행된다는 보장이 없음.\r\n    - 객체에 접근할 수 없게 된 후 finalizer나 cleaner가 실행되기까지 얼마나 걸릴지 알 수 없음.\r\n    - 즉, finalizer와 cleaner로는 제때 실행되어야 하는 작업은 절대 할 수 없음.\r\n        - 예를 들어 시스템이 동시에 열 수 있는 파일 개수에 한계가 있기에 파일 닫기 작업을 맡기면 중대한 오류를 일으킬 수 있음.\r\n    - 얼마나 신속히 수행할지는 전적으로 가비지 컬렉터 알고리즘에 달렸음.\r\n- 클래스에 finalizer를 달아두면 그 인스턴스의 자원 회수가 제멋대로 지연될 수 있음\r\n    - cleaner는 자신을 수행할 스레드를 제어할 수 있다는 면에서 조금 낫다.\r\n    - 하지만 여전히 백그라운드에서 수행되며 gc의 통제하에 있으니 즉각 수행되리라는 보장이 없음.\r\n- finalizer나 cleaner의 수행 여부조차 보장하지 않음.\r\n    - 상태를 영구적으로 수정하는 작업에서는 절대 finalizer나 cleaner에 의존해서는 안 됨.\r\n    - 예를 들어 DB와 같은 공유 자원의 영구 lock 해제를 finalizer나 cleaner에 맡겨 놓으면 분산 시스템 전체가 서서히 멈출 것이다.\r\n    - System.gc나 System.runFinalization 메서드도 실행될 가능성을 높여줄 수 있으나, 보장해주진 않음.\r\n- finalizer 동작 중 발생한 예외는 무시되며 처리할 작업이 남았더라도 그 순간 종료됨.\r\n    - 경고조차 출력하지 않음.\r\n    - cleaner를 사용하는 라이브러리는 자신의 스레드를 통제하기 때문에 이러한 문제가 발생하지는 않음.\r\n- finalizer와 cleaner는 심각한 성능 문제도 동반함.\r\n    - 객체를 생성하고 가비지 컬렉터가 수거하기까지 걸린 시간\r\n    - AutoCloseable - 12ns\r\n    - finalizer - 550ns, cleaner - 500ns\r\n- finalizer 사용한 클래스는 finalizer 공격에 노출되어 심각한 보안 문제를 일으킬 수도 있음.\r\n    - 생성자나 직렬화 과정에서 예외가 발생하면, 생성되다 만 객체에서 악의적인 하위 클래스의 finalizer가 수행될 수 있게 됨.\r\n    - 이 finalizer는 정적 필드에 자신의 참조를 할당하여 gc가 수집하지 못하게 막을 수 있음.\r\n    - 일그러진 객체가 만들어지고 나면, 이 객체의 메서드를 호출해 애초에는 허용되지 않았을 작업을 수행하는 건 일도 아님.\r\n    - 위 예시가 있는 [블로그](https://yangbongsoo.tistory.com/8?category=919799) 를 참고하자.\r\n    - 객체 생성을 막으려면 생성자에서 예외를 던지는 것만으로 충분하지만, finalizer가 있다면 그렇지도 않음.\r\n    - final 클래스들은 하위 클래스를 만들 수 없으니 이 공격에서 안전하다.\r\n    - final이 아닌 클래스를 finalizer 공격으로부터 방어하려면 아무 일도 하지 않는 finalize 메서드를 만들고 final을 선언하자.\r\n\r\n- 그렇다면 파일이나 스레드 등 종료해야 할 자원을 담고 있는 객체의 클래스에서 finalizer나 cleaner를 대신해줄 묘안은 무엇인가?\r\n    - AutoCloseable을 구현해주고, 클라이언트에서 인스턴스를 다 쓰고 나면 close 메서드를 호출하면 된다. (일반적으로 try-with-resourses를 사용)\r\n\r\n- finalizer와 cleaner의 적절한 쓰임새가 두 가지 정도 있다.\r\n    1. 자원의 소유자가 close 메서드를 호출하지 않는 것에 대비한 안전망 역할.\r\n        - 늦게라도 해주는 것이 아예 안 하는 것보다는 나으니 작성한다.\r\n        - FileInputStream, FileOutputStream, ThreadPoolExecutor가 대표적\r\n    2. 네이티브 피어(native peer)와 연결된 객체\r\n        - 네이티브 피어란 일반 자바 객체가 네이티브 메서드를 통해 기능을 위임한 네이티브 객체를 말함.\r\n        - gc가 네이티브 객체까지 회수하지 못하니 cleaner나 finalizer를 사용하기 적당한 작업임.\r\n        - 단, 성능 저하를 감당할 수 있고 네이티브 피어가 심각한 자원을 가지고 있지 않을 때에만 해당됨.\r\n\r\n- cleaner를 안전망으로 사용하기 조금 까다롭다.\r\n\r\n    ```java\r\n    public class Room implements AutoCloseable {\r\n        private static final Cleaner cleaner = Cleaner.create();\r\n    \r\n        // 청소가 필요한 자원. 절대 Room을 참조해서는 안 된다!\r\n        private static class State implements Runnable {\r\n            int numJunkPiles; // Number of junk piles in this room\r\n    \r\n            State(int numJunkPiles) {\r\n                this.numJunkPiles = numJunkPiles;\r\n            }\r\n    \r\n            // close 메서드나 cleaner가 호출한다.\r\n            @Override public void run() {\r\n                System.out.println(\"Cleaning room\");\r\n                numJunkPiles = 0;\r\n            }\r\n        }\r\n    \r\n        // 방의 상태. cleanable과 공유한다.\r\n        private final State state;\r\n    \r\n        // cleanable 객체. 수거 대상이 되면 방을 청소한다.\r\n        private final Cleaner.Cleanable cleanable;\r\n    \r\n        public Room(int numJunkPiles) {\r\n            state = new State(numJunkPiles);\r\n            cleanable = cleaner.register(this, state);\r\n        }\r\n    \r\n        @Override public void close() {\r\n            cleanable.clean();\r\n        }\r\n    }\r\n    ```\r\n\r\n    - State의 run 메서드는 cleanable에 의해 딱 한 번만 호출될 것임.\r\n    - run 메서드가 호출되는 상황은 둘 중 하나.\r\n        - 보통은 Room의 close 메서드를 호출할 때.\r\n            - close 메서드에서 Cleanable의 clean을 호출하면 이 메서드 안에서 run을 호출한다.\r\n        - gc가 Room을 회수할 때까지 클라이언트가 close를 호출하지 않는다면, cleaner가 State의 run 메서드를 호출해줄 것.\r\n    - State 인스턴스는 '절대로' Room 인스턴스를 참조해서는 안 된다.\r\n        - 참조하면 순환참조가 생겨 gc가 Room 인스턴스를 회수해갈 기회가 오지 않음.\r\n        - 정적 중첩 클래스로 구성한 이유도 여기에 있음.\r\n        - 정적이 아닌 중첩 클래스는 자동으로 바깥 객체의 참조를 갖게 됨.\r\n            - 람다 역시 바깥 객체의 참조를 갖기 쉬우니 사용하지 말자.\r\n\r\n- Room 생성을 try-with-resources 블록으로 감쌌다면 자동 청소는 전혀 필요하지 않음.\r\n\r\n    ```java\r\n    public class Adult {\r\n        public static void main(String[] args) {\r\n            try (Room myRoom = new Room(7)) {\r\n                System.out.println(\"안녕~\");\r\n            }\r\n        }\r\n    }\r\n    ```\r\n\r\n    - \"안녕~\"을 출력한 후, 이어서 \"방 청소\"를 출력한다.\r\n\r\n- 아래의 경우는 \"방 청소\"가 출력되는 것을 예측할 수 없음.\r\n\r\n    ```java\r\n    public class Teenager {\r\n        public static void main(String[] args) {\r\n            new Room(99);\r\n            System.out.println(\"Peace out\");\r\n    \r\n            // 다음 줄의 주석을 해제한 후 동작을 다시 확인해보자.\r\n            // 단, 가비지 컬렉러를 강제로 호출하는 이런 방식에 의존해서는 절대 안 된다!\r\n    //      System.gc();\r\n        }\r\n    }\r\n    ```\r\n\r\n    - cleaner 명세는 이렇게 적혀 있음.\r\n\r\n      > System.exit을 호출할 때의 cleaner 동작은 구현하기 나름이다. 청소가 이뤄질지는 보장하지 않는다.\r\n    >\r\n    - System.gc()를 추가하는 것으로 종료 전에 \"방 청소\"를 출력할 수 있었지만, 보장할 수 없다.\r\n\r\n\r\n## 핵심 정리\r\n\r\n- cleaner(자바 8까지는 finalizer)는 안전망 역할이나 중요하지 않은 네이티브 자원 회수용으로만 사용하자.\r\n- 이런 경우라도 불확실성과 성능 저하에 주의해야 한다.","excerpt":"자바는 두 가지 객체 소멸자를 제공함. finalizer는 예측할 수 없고, 상황에 따라 위험할 수 있어 일반적으로 불필요하다. 오동작, 낮은 성능, 이식성 문제의 원인이 되기도 함. 자바 9에서는 deprecated API로 지정하고 cleaner…","fields":{"slug":"/effective-java-item8/"},"frontmatter":{"date":"Dec 16, 2021","title":"[이펙티브 자바] 8. finalizer와 cleaner 사용을 피하라","tags":["java","book"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n- 자바와 같이 가비지 컬렉터를 갖춘 언어를 사용하기에 자칫 메모리 관리에 더 이상 신경 쓰지 않아도 된다고 오해할 수 있는데, 절대 사실이 아니다.\r\n\r\n```java\r\npublic class Stack {\r\n    private Object[] elements;\r\n    private int size = 0;\r\n    private static final int DEFAULT_INITIAL_CAPACITY = 16;\r\n\r\n    public Stack() {\r\n        elements = new Object[DEFAULT_INITIAL_CAPACITY];\r\n    }\r\n\r\n    public void push(Object e) {\r\n        ensureCapacity();\r\n        elements[size++] = e;\r\n    }\r\n\r\n    public Object pop() {\r\n        if (size == 0)\r\n            throw new EmptyStackException();\r\n        return elements[--size];\r\n    }\r\n\r\n    /**\r\n     * 원소를 위한 공간을 적어도 하나 이상 확보한다.\r\n     * 배열 크기를 늘려야 할 때마다 대략 두 배씩 늘린다.\r\n     */\r\n    private void ensureCapacity() {\r\n        if (elements.length == size)\r\n            elements = Arrays.copyOf(elements, 2 * size + 1);\r\n    }\r\n}\r\n```\r\n\r\n- 이 스택을 사용하는 프로그램을 오래 실행하다 보면 '메모리 누수'로 점차 가비지 컬렉션 활동과 메모리 사용량이 늘어나 결국 성능이 저하될 것이다.\r\n- 상대적으로 드문 경우긴 하지만 심할 때는 디스크 페이징이나 OutOfMemoryError를 일으켜 프로그램이 예기치 않게 종료되기도 한다.\r\n- 그렇다면 어디서 메모리 누수가 일어날까?\r\n    - 이 코드에서는 스택이 커졌다가 줄어들었을 때 스택에서 꺼내진 객체들을 가비지 컬렉터로 회수하지 않는다. (프로그램에서 그 객체들을 더 이상 사용하지 않더라도)\r\n    - 다 쓴 참조(obsolete reference)를 여전히 가지고 있기 때문이다.\r\n        - 다 쓴 참조란 문자 그대로 앞으로 다시 쓰지 않을 참조를 뜻한다.\r\n        - elements 배열의 '활성 영역' 밖의 참조들이 모두 여기에 해당됨.\r\n        - 활성 영역은 인덱스가 size보다 작은 원소들로 구성.\r\n- 객체 참조 하나를 살려두면 가비지 컬렉터는 그 객체뿐 아니라 그 객체가 참조하는 모든 객체를 회수해가지 못함.\r\n    - 단 몇 개의 객체가 매우 많은 객체를 회수되지 못하게 할 수 있고 잠재적으로 성능에 악영향을 줄 수 있음.\r\n- 해당 참조를 다 썼을 때 null 처리(참조 해제)하면 해결될 수 있다.\r\n\r\n    ```java\r\n    public Object pop() {\r\n          if (size == 0)\r\n              throw new EmptyStackException();\r\n          Object result = elements[--size];\r\n          elements[size] = null; // 다 쓴 참조 해제\r\n          return result;\r\n    }\r\n    ```\r\n\r\n    - null 처리를 통해 실수로 사용할 때 NullPointerException을 던지며 종료되는 이점을 가질 수 있음.\r\n    - 단, 객체 참조를 null 처리하는 일은 예외적인 경우여야 함.\r\n        - 다 쓴 참조를 해제하는 가장 좋은 방법은 그 참조를 담은 변수를 유효 범위(scope) 밖으로 밀어내는 것임.\r\n            - 메서드, for문에서만 사용하는 지역변수 등 변수의 범위를 최소가 되게 정의하면 됨.\r\n        - 참고로 ArrayList의 remove도 null 처리를 해준다.\r\n\r\n            ![Untitled (91)](https://user-images.githubusercontent.com/62014888/146503206-2dabd7a6-4e1e-41a5-9e95-639de4dbd096.png)\r\n\r\n- 그렇다면 null 처리는 언제?\r\n    - 자기 메모리를 직접 관리할 때!\r\n    - 이 스택의 경우 객체 참조를 담는 elements 배열로 저장소 풀을 만들어 원소들을 관리함.\r\n    - 가비지 컬렉터가 보기에는 비활성 영역에서 참조하는 객체도 똑같이 유효한 객체이므로 프로그래머는 비활성 영역이 되는 순간 null 처리해서 해당 객체를 더는 쓰지 않을 것임을 가비지 컬렉터에 알려야 함.\r\n    - 자기 메모리를 직접 관리하는 클래스라면 프로그래머는 항시 메모리 누수에 주의해야 함.\r\n\r\n- 캐시 역시 메모리 누수를 일으키는 주범임.\r\n    - 캐시 외부에서 key를 참조하는 동안만 엔트리가 살아 있는 캐시가 필요한 상황이라면 WeakHashMap을 사용해 캐시를 만들자.\r\n    - 다 쓴 엔트리는 그 즉시 자동으로 제거될 것임.\r\n    - 단, WeakHashMap은 이러한 상황에서만 유용하다는 사실을 기억하자.\r\n    - WeakHashMap의 간단한 캐시 예시는 [블로그](http://blog.breakingthat.com/2018/08/26/java-collection-map-weakhashmap/) 참고.\r\n    - 캐시 엔트리의 유효 기간을 정확히 정의하기 어려울 때는 쓰지 않는 엔트리를 이따금 청소해줘야 함.\r\n        - (ScheduledThreadPoolExecutor 같은) 백그라운드 스레드를 활용\r\n        - 캐시에 새 엔트리를 추가할 때 부수 작업으로 수행하는 방법이 있음.\r\n            - LinkedHashMap은 removeEldestEntry 메서드를 써서 후자의 방식으로 처리\r\n            - 간단하게 얘기하면 removeEldestEntry를 오버라이딩하고 직접 구현하여 엔트리 개수에 따라 추가할 때 오래된 엔트리를 삭제하는 방식으로 만들 수도 있다. 예시는 [블로그](https://javafactory.tistory.com/735) 참고\r\n        - 더 복잡한 캐시를 만들고 싶다면 java.lang.ref 패키지를 직접 활용해야 할 것이다.\r\n            - Reference 클래스 관련 내용으로 필요한 경우 더 공부해야 할 듯하다.\r\n            - [GC, Reference 클래스 관련된 글](https://d2.naver.com/helloworld/329631) 참고\r\n\r\n- 메모리 누수의 세 번째 주범은 바로 리스너(listener) 혹은 콜백(callback)이라 부르는 것이다.\r\n    - 클라이언트가 콜백을 등록만 하고 명확히 해지하지 않는다면, 뭔가 조치해주지 않는 한 콜백은 계속 쌓여갈 것.\r\n    - 콜백을 약한 참조(weak reference)로 저장하면 가비지 컬렉터가 즉시 수거해간다.\r\n        - 예를 들어 WeakHahMap에 키로 저장.\r\n\r\n\r\n## 핵심 정리\r\n\r\n- 메모리 누수는 겉으로 잘 드러나지 않아 시스템에 수년간 잠복하는 사례도 있다.\r\n- 이런 누수는 철저한 코드 리뷰나 힙 프로파일러 같은 디버깅 도구를 동원해야만 발견되기도 한다.\r\n- 그래서 이런 종류의 문제는 예방법을 익혀두는 것이 중요하다!","excerpt":"자바와 같이 가비지 컬렉터를 갖춘 언어를 사용하기에 자칫 메모리 관리에 더 이상 신경 쓰지 않아도 된다고 오해할 수 있는데, 절대 사실이 아니다. 이 스택을 사용하는 프로그램을 오래 실행하다 보면 '메모리 누수'로 점차 가비지 컬렉션 활동과 메모리 …","fields":{"slug":"/effective-java-item7/"},"frontmatter":{"date":"Dec 16, 2021","title":"[이펙티브 자바] 7. 다 쓴 객체 참조를 해제하라","tags":["java","book"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n- 똑같은 기능의 객체를 매번 생성하기보다는 객체 하나를 재사용하는 편이 나을 때가 많다.\r\n    - 재사용은 빠르고 세련됨.\r\n    - 특히 불변 객체는 언제든 재사용할 수 있다.\r\n\r\n```java\r\nString s = new String(\"bikini\"); // 따라 하지 말 것\r\nString s = \"bikini\";\r\n```\r\n\r\n- 첫번째 코드는 String 인스턴스를 새로 만들게 되어 생성자에 넘겨진 \"bikini\" 자체가 이 생성자로 만들어내려는 String과 기능적으로 완전히 똑같다.\r\n    - 반복문이나 빈번히 호출되는 메서드 안에 있다면 쓸데없는 String 인스턴스가 수백만 개 만들어질 수도 있다.\r\n- 두번째 코드는 새로운 인스턴스를 매번 만드는 대신 하나의 String 인스턴스를 사용한다.\r\n    - 같은 가상 머신 안에서 이와 똑같은 문자열 리터럴을 사용하는 모든 코드가 같은 객체를 재사용함이 보장됨. (상수 풀 사용)\r\n\r\n- 생성자 대신 정적 팩터리 메서드를 제공하는 불변 클래스에서는 정적 팩터리 메서드를 사용해 불필요한 객체 생성을 피할 수 있다.\r\n    - Boolean(String) 생성자 대신 Boolean.valueOf(String) 팩터리 메서드를 사용하는 것이 좋다. (그래서 이 생성자는 자바 9에서 deprecated 되었다)\r\n- 생성 비용이 아주 비싼 객체도 있다.\r\n    - 이런 객체는 반복해서 필요하다면 캐싱하여 재사용하길 권함.\r\n    - 대표적인 예로 String의 matches 메서드가 있다.\r\n\r\n        ```java\r\n        static boolean isRomanNumeralSlow(String s) {\r\n              return s.matches(\"^(?=.)M*(C[MD]|D?C{0,3})\"\r\n                      + \"(X[CL]|L?X{0,3})(I[XV]|V?I{0,3})$\");\r\n        }\r\n        ```\r\n\r\n        - String.matches는 정규표현식으로 문자열 형태를 확인하는 가장 쉬운 방법이지만, 성능이 중요한 상황에서 반복해 사용하기엔 적합하지 않음.\r\n        - 메서드 내부에서 정규표현식용 Pattern 인스턴스를 만드는데 Patten은 입력받은 정규표현식에 해당하는 유한 상태 머신(finite state machine)을 만들기 때문에 인스턴스 생성 비용이 높음.\r\n            - 유한 상태 머신이란 한번에 하나의 상태를 가지며 특정 이벤트에 의해 한 상태에서 다른 상태로 전이할 수 있는 기계라고 하는데 정규표현식은 이러한 유한 상태 머신을 이용해서 구현된다고 한다.\r\n            - 모든 상태와 전이를 찾아놓고 매칭을 하기에 생성 비용이 높다고 한다.\r\n        - 성능 개선을 위해 정규표현식을 표현하는 (불변인) Pattern 인스턴스를 클래스 초기화(정적 초기화) 과정에서 직접 생성해 캐싱해두고, 나중에 isRomanNumeral 메서드가 호출될 때마다 이 인스턴스를 재사용함.\r\n\r\n        ```java\r\n        public class RomanNumerals {\r\n            private static final Pattern ROMAN = Pattern.compile(\r\n                    \"^(?=.)M*(C[MD]|D?C{0,3})\"\r\n                            + \"(X[CL]|L?X{0,3})(I[XV]|V?I{0,3})$\");\r\n        \r\n            static boolean isRomanNumeralFast(String s) {\r\n                return ROMAN.matcher(s).matches();\r\n            }\r\n        }\r\n        ```\r\n\r\n        - ROMAN 필드를 메서드가 처음 호출될 때 필드를 초기화할 수 있게 지연 초기화를 사용할 순 있지만 권하지는 않는다.\r\n            - 코드가 복잡해지고 성능은 크게 개선되지 않을 때가 많기 때문.\r\n\r\n- 객체가 불변이라면 재사용해도 안전함이 명백하다.\r\n    - 하지만 훨씬 덜 명확하거나, 심지어 직관에 반대되는 상황도 있음.\r\n    - 대표적인 예로 어댑터 패턴(Adapter Pattern)이 있음.\r\n        - 어댑터는 실제 작업은 뒷단 객체에 위임하고, 자신은 제2의 인터페이스 역할을 해주는 객체.\r\n        - 어댑터는 뒷단 객체만 관리하면 됨.\r\n        - 즉, 뒷단 객체 외에는 관리할 상태가 없으므로 뒷단 객체 하나당 어댑터 하나씩만 만들어지면 충분함.\r\n    - 예컨대 Map 인터페이스의 keySet 메서드는 Map 객체 안의 키 전부를 담은 Set 뷰를 반환함.\r\n        - keySet을 호출할 때마다 새로운 Set 인스턴스가 만들어지는게 아닌 매번 같은 Set 인스턴스를 반환함.\r\n        - 반환한 객체 중 하나를 수정하면 다른 모든 객체가 따라서 바뀜.\r\n\r\n        ![Untitled (90)](https://user-images.githubusercontent.com/62014888/146502948-b51323f6-a365-4c64-8685-92313f51c1e5.png)\r\n\r\n        - keySet이 뷰 객체를 여러 개 만들어도 상관없지만, 그럴 필요도 없고 이득도 없음.\r\n\r\n- 불필요한 객체를 만들어내는 또 다른 예로 오토박싱(auto boxing)을 들 수 있음.\r\n    - 오토박싱은 프로그래머가 기본 타입과 박싱된 기본 타입을 섞어 쓸 때 자동으로 상호 변환해주는 기술.\r\n    - 오토박싱은 기본 타입과 그에 대응하는 박싱된 기본 타입의 구분을 흐려주지만, 완전히 없애주는 것은 아님.\r\n    - 의미상으로는 별다를 것 없지만 성능에는 그렇지 않음.\r\n\r\n    ```java\r\n    private static long sum() {\r\n        Long sum = 0L;\r\n        for (long i = 0; i <= Integer.MAX_VALUE; i++)\r\n            sum += i;\r\n        return sum;\r\n    }\r\n    ```\r\n\r\n    - sum 변수를 Long으로 선언해서 불필요한 Long 인스턴스가 약 2의 31승개나 만들어진 것.\r\n    - 이 경우에 박싱된 기본 타입보다는 기본 타입을 사용하고, 의도치 않은 오토박싱이 숨어들지 않도록 주의하자.\r\n\r\n\r\n## 정리\r\n\r\n- \"객체 생성은 비싸니 피해야 한다\"로 오해하면 안 됨.\r\n    - 요즘 JVM은 작은 객체 생성하고 회수하는 일이 크게 부담되지 않음.\r\n    - 프로그램의 명확성, 간결성, 기능을 위해서 객체를 추가로 생성하는 것이라면 일반적으로 좋은 일.\r\n- 아주 무거운 객체가 아닌 이상 단순히 객체 생성을 피하고자 객체 풀(pool)을 만들지는 말자.\r\n    - DB Connection과 같이 생성 비용이 비싼 경우가 아니고서야 자체 객체 풀은 코드를 헷갈리게 만들고 메모리 사용량을 늘리고 성능을 떨어뜨림.\r\n    - 요즘 JVM GC는 상당히 잘 최적화되어서 가벼운 객체용을 다룰 때는 직접 만든 객체 풀보다 훨씬 빠르다.\r\n- 방어적 복사가 필요한 상황에서 객체를 재사용했을 때의 피해가 필요 없는 객체를 반복 생성했을 때의 피해보다 훨씬 크다는 사실을 기억하자.\r\n    - 방어적 복사에 실패하면 버그와 보안 구멍으로 이어지지만, 불필요한 객체 생성은 그저 코드 형태와 성능에만 영향을 줌.","excerpt":"똑같은 기능의 객체를 매번 생성하기보다는 객체 하나를 재사용하는 편이 나을 때가 많다. 재사용은 빠르고 세련됨. 특히 불변 객체는 언제든 재사용할 수 있다. 첫번째 코드는 String 인스턴스를 새로 만들게 되어 생성자에 넘겨진 \"bikini\" 자체…","fields":{"slug":"/effective-java-item6/"},"frontmatter":{"date":"Dec 15, 2021","title":"[이펙티브 자바] 6. 불필요한 객체 생성을 피하라","tags":["java","book"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"- 사용하는 자원에 따라 동작이 달라지는 클래스에는 정적 유틸리티 클래스나 싱글턴 방식이 적합하지 않다.\r\n- 대신 클래스가 여러 자원 인스턴스를 지원해야 하며, 클라이언트가 원하는 자원을 사용해야 한다.\r\n    - 이 조건을 만족하는 간단한 패턴이 있으니, 바로 인스턴스를 생성할 때 생성자에 필요한 자원을 넘겨주는 방식이다.\r\n    - 의존 객체 주입의 한 형태로, 맞춤법 검사기를 생성할 때 의존 객체인 사전을 주입해주면 된다.\r\n\r\n    ```java\r\n    public class SpellChecker {\r\n    \tprivate final Lexicon dictionary;\r\n    \r\n    \tpublic SpellChecker(Lexicon dictionary) {\r\n    \t\tthis.dictionary = Objects.requireNonNull(dictionary);\r\n    \t}\r\n    \r\n    \tpublic boolean isValid(String word) {}\r\n    \tpublic List<String> suggestions(String typo) {}\r\n    }\r\n    ```\r\n\r\n    - 불변을 보장하여 여러 클라이언트가 의존 객체들을 안심하고 공유할 수 있다.\r\n    - 의존 객체 주입은 생성자, 정적 팩터리, 빌더 모두에 똑같이 응용할 수 있다.\r\n- 이러한 패턴의 쓸만한 변형으로, 생성자에 자원 팩터리를 넘겨주는 방식이 있다.\r\n    - 팩터리란 호출할 때마다 특정 타입의 인스턴스를 반복해서 만들어주는 객체를 말한다. 즉, 팩터리 메서드 패턴을 구현한 것이다.\r\n    - 자바 8에서 소개한 Supplier<T> 인터페이스가 팩터리를 표현한 완벽한 예.\r\n        - 클라이언트는 자신이 명시한 타입의 하위 타입이라면 무엇이든 생성할 수 있는 팩터리를 넘길 수 있음.\r\n\r\n        ```java\r\n        Mosaic create(Supplier<? extends Tile> tileFactory) {...}\r\n        ```\r\n\r\n        - 클라이언트가 제공한 팩터리가 생성한 Tile들로 구성된 Mosaic을 만드는 메서드\r\n- 의존 객체 주입이 유연성과 테스트 용이성을 개선해주긴 하지만, 의존성이 수 천개나 되는 큰 프로젝트에서는 코드를 어지럽게 만들기도 한다.\r\n    - Dagger, Guice, Spring 같은 의존 객체 주입 프레임워크를 사용하면 이런 어질러짐을 해소할 수 있다.\r\n    - 이들 프레임워크는 의존 객체를 직접 주입하도록 설계된 API를 알맞게 응용해 사용하고 있음.\r\n\r\n## 핵심 정리\r\n\r\n- 클래스가 내부적으로 하나 이상의 자원에 의존하고, 그 자원이 클래스 동작에 영향을 준다면 싱글턴과 정적 유틸리티 클래스는 사용하지 않는 것이 좋다.\r\n- 이 자원들을 클래스가 직접 만들게 해서도 안된다. 대신 필요한 자원을 (혹은 그 자원을 만들어주는 팩터리를) 생성자에 (혹은 정적 팩터리나 빌더에) 넘겨주자.\r\n- 의존 객체 주입이라 하는 이 기법은 클래스의 유연성, 재사용성, 테스트 용이성을 기막히게 개선해준다.","excerpt":"사용하는 자원에 따라 동작이 달라지는 클래스에는 정적 유틸리티 클래스나 싱글턴 방식이 적합하지 않다. 대신 클래스가 여러 자원 인스턴스를 지원해야 하며, 클라이언트가 원하는 자원을 사용해야 한다. 이 조건을 만족하는 간단한 패턴이 있으니, 바로 인스…","fields":{"slug":"/effective-java-item5/"},"frontmatter":{"date":"Dec 15, 2021","title":"[이펙티브 자바] 5. 자원을 직접 명시하지 말고 의존 객체 주입을 사용하라","tags":["java","book"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n- 정적 메서드와 정적 필드만을 담은 클래스를 만들고 싶을 때가 있을 것.\r\n    - 객체 지향적으로 사고하지 않는 이들이 종종 남용하는 방식이기에 그리 곱게 보이지는 않지만, 분명 나름의 쓰임새가 있음.\r\n    - 그렇다면 정적 메서드와 정적 필드를 사용하는 것이 왜 객체 지향적이 아닐까?\r\n        - [https://jgrammer.tistory.com/entry/이펙티브자바-인스턴스화를-막으려거든-private-생성자를-사용해라-java-static-개념](https://jgrammer.tistory.com/entry/%EC%9D%B4%ED%8E%99%ED%8B%B0%EB%B8%8C%EC%9E%90%EB%B0%94-%EC%9D%B8%EC%8A%A4%ED%84%B4%EC%8A%A4%ED%99%94%EB%A5%BC-%EB%A7%89%EC%9C%BC%EB%A0%A4%EA%B1%B0%EB%93%A0-private-%EC%83%9D%EC%84%B1%EC%9E%90%EB%A5%BC-%EC%82%AC%EC%9A%A9%ED%95%B4%EB%9D%BC-java-static-%EA%B0%9C%EB%85%90)\r\n        - 위 블로그 글에 적혀있는 것처럼 정적 필드와 정적 메서드를 사용하면 다형성과 거리가 멀어진다.\r\n        - 객체 지향의 여러 특징 중에 다형성이 있는데 이 다형성을 해치기 때문에 객체 지향적이 아니라고 하는 것 같다.\r\n- 하지만 그럼에도 불구하고 정적 필드와 정적 메서드는 나름의 쓰임새가 있다.\r\n    - 예를 들어 java.lang.Math나 java.util.Arrays 처럼 기본 타입 값이나 배열 관련 메서드들을 모아놓을 수 있다.\r\n    - java.util.Collections처럼 특정 인터페이스를 구현하는 객체를 생성해주는 정적 메서드(혹은 팩터리)를 모아놓을 수도 있음. (자바 8부터는 이런 메서드를 인터페이스에 넣을 수 있다.)\r\n    - final 클래스와 관련한 메서드들을 모아놓을 수도 있음.\r\n        - final 클래스를 상속해서 하위 클래스에서 메서드를 넣는 건 불가능하기 때문이다.\r\n- 정적 멤버만 담은 유틸리티 클래스는 인스턴스로 만들어 쓰려고 설계한게 아니다.\r\n    - 하지만 생성자를 명시하지 않으면 컴파일러가 자동으로 기본 생성자를 만들어 준다.\r\n    - 즉, 매개변수를 받지 않는 public 생성자가 만들어지며, 사용자는 이 생성자가 자동 생성된 것인지 구분할 수 없음.\r\n- **단순하게 추상 클래스로 만드는 것으로는 인스턴스화를 막을 수 없음.**\r\n    - 하위 클래스를 만들어 인스턴스화하면 그만이다.\r\n    - 사용자는 상속해서 쓰라는 뜻으로 오해할 수 있으니 더 큰 문제이다.\r\n- 이를 해결하기 위해 private 생성자를 추가하여 클래스의 인스턴스화를 막을 수 있음.\r\n\r\n    ![Untitled (66)](https://user-images.githubusercontent.com/62014888/146129252-81aa01e2-50a4-42e0-a16e-dcd32b4efc16.png)\r\n\r\n    - 필요에 따라 생성자 코드 내부에 throw new AssertionError()와 같이 예외를 추가할 수 있음.\r\n    - 다만, 이 코드는 직관적이지 않으니 적절한 주석을 달아주는 것을 추천\r\n    - 이 방식은 상속이 불가능하게 하는 효과도 있음!\r\n    \r\n\r\n## 느낀 점\r\n\r\n- 유틸리티 클래스를 만들때 private 생성자를 명시한다는 것 잊지말자","excerpt":"정적 메서드와 정적 필드만을 담은 클래스를 만들고 싶을 때가 있을 것. 객체 지향적으로 사고하지 않는 이들이 종종 남용하는 방식이기에 그리 곱게 보이지는 않지만, 분명 나름의 쓰임새가 있음. 그렇다면 정적 메서드와 정적 필드를 사용하는 것이 왜 객체…","fields":{"slug":"/effective-java-item4/"},"frontmatter":{"date":"Dec 14, 2021","title":"[이펙티브 자바] 4. 인스턴스화를 막으려거든 private 생성자를 사용하라","tags":["java","book"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n- 싱글턴이란 인스턴스를 오직 하나만 생성할 수 있는 클래스를 말한다.\r\n    - 전형적인 예 - 함수와 같은 무상태 객체나 설계상 유일하게 하는 시스템 컴포넌트\r\n- 클래스를 싱글턴으로 만들면 이를 사용하는 클라이언트를 테스트하기가 어려워질 수 있다.\r\n    - 인터페이스를 구현해서 만든 싱글턴이 아니라면 싱글턴 인스턴스를 mocking으로 대체할 수 없기 때문!\r\n- 싱글턴을 만드는 방식은 보통 둘 중 하나.\r\n    - 두 방식 모두 생성자는 private으로 감춰두고, 유일한 인스턴스에 접근할 수 있는 수단으로 public static 멤버를 하나 마련해 둠.\r\n    1. public static 멤버가 final 필드인 방식\r\n\r\n        ```java\r\n        public class Elvis {\r\n            public static final Elvis INSTANCE = new Elvis();\r\n        \r\n            private Elvis() { }\r\n        \r\n            public void leaveTheBuilding() {\r\n            }\r\n        }\r\n        ```\r\n\r\n        - private 생성자는 Elvis.INSTANCE를 초기화할 때 딱 한 번만 호출됨.\r\n        - 단, 리플렉션 API의 AccessibleObject.setAccessible을 사용하면 private 생성자를 호출할 수 있음.\r\n            - 이를 방어하려면 두 번째 객체가 생성되려 할 때 생성자에서 예외를 던지게 하면 됨.\r\n        - 장점\r\n            - 해당 클래스가 싱글턴임이 API에 명백히 드러남.\r\n            - 간결함.\r\n\r\n    2. 정적 팩터리 메서드를 public static 멤버로 제공\r\n\r\n        ```java\r\n        public class Elvis {\r\n            private static final Elvis INSTANCE = new Elvis();\r\n            private Elvis() { }\r\n            public static Elvis getInstance() { return INSTANCE; }\r\n        \r\n            public void leaveTheBuilding() {\r\n            }\r\n        }\r\n        ```\r\n\r\n        - Elvis.getInstance는 항상 같은 객체의 참조를 반환. (리플렉션을 통한 예외는 똑같이 적용됨)\r\n        - 장점\r\n            - (마음이 바뀌면) API를 바꾸지 않고도 싱글턴이 아니게 변경할 수 있음.\r\n            - 원한다면 정적 팩터리를 제너릭 싱글턴 팩터리로 만들 수 있음.\r\n            - 정적 팩터리의 메서드 참조를 공급자(supplier)로 사용할 수 있음.\r\n\r\n    - 둘 중 하나의 방식으로 만든 싱글턴 클래스를 직렬화하려면 단순히 Serializable을 구현한다고 선언하는 것만으로는 부족하다.\r\n        - 모든 인스턴스 필드를 일시적(transient)이라고 선언하고 readResolve 메서드를 제공해야 함.\r\n\r\n            ```java\r\n            // 싱글턴임을 보장해주는 readResolve 메서드\r\n            private Obejct readResolve() {\r\n            \t// '진짜' Elvis를 반환하고, 가짜 Elvis는 가비지 컬렉터에 맡긴다.\r\n            \treturn INSTANCE;\r\n            }\r\n            ```\r\n\r\n            - 이렇게 하지 않으면 직렬화된 인스턴스를 역직렬화할 때마다 새로운 인스턴스가 만들어짐.\r\n\r\n    3. 원소가 하나인 열거 타입을 선언하는 것.\r\n\r\n        ```java\r\n        public enum Elvis {\r\n            INSTANCE;\r\n        \r\n            public void leaveTheBuilding() {\r\n            }\r\n        }\r\n        ```\r\n\r\n        - public 필드 방식과 비슷하지만, 더 간결하고, 추가 노력 없이 직렬화할 수 있고, 심지어 아주 복잡한 직렬화 상황이나 리플렉션 공격에서도 제2의 인스턴스가 생기는 일을 완벽히 막아준다.\r\n        - 대부분 상황에서는 원소가 하나뿐인 열거 타입이 싱글턴을 만드는 가장 좋은 방법임.\r\n            - 단, 만들려는 싱글턴이 Enum 외의 클래스를 상속해야 한다면 이 방법은 사용할 수 없다. (열거 타입이 다른 인터페이스를 구현하도록 선언할 수는 있음)\r\n    \r\n\r\n## 느낀 점\r\n\r\n- 싱글턴으로 클래스를 만들면 직렬화하고 역직렬화할때마다 새로운 인스턴스가 만들어지는 줄은 몰랐는데 흥미로웠다. 제네릭 싱글턴 팩터리나 supplier에 대한 내용 때문에 빨리 뒷부분 아이템을 읽고 싶어졌다.","excerpt":"싱글턴이란 인스턴스를 오직 하나만 생성할 수 있는 클래스를 말한다. 전형적인 예 - 함수와 같은 무상태 객체나 설계상 유일하게 하는 시스템 컴포넌트 클래스를 싱글턴으로 만들면 이를 사용하는 클라이언트를 테스트하기가 어려워질 수 있다. 인터페이스를 구…","fields":{"slug":"/effective-java-item3/"},"frontmatter":{"date":"Dec 14, 2021","title":"[이펙티브 자바] 3. private 생성자나 열거 타입으로 싱글턴임을 보증하라","tags":["java","book"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n- 정적 팩터리와 생성자에는 똑같은 제약이 있다.\r\n    - 선택적 매개변수가 많을때 적절히 대응하기 어렵다는 점!\r\n- 필드에 변수가 많이 있을 때 이런 클래스용 생성자 혹은 정적 팩터리는 어떤 모습일까?\r\n- 3가지 방법을 사용한 모습이 있겠다.\r\n\r\n1. 점층적 생성자 패턴(telescoping constructor pattern)\r\n    - 필수 매개변수 하나만 받는 생성자, 필수 매개변수와 선택 매개변수 1개를 받는 생성자, 2개까지 받는 생성자 .... 이런 식으로 선택 매개변수를 전부 다 받는 생성자까지 늘려가는 방식이다.\r\n\r\n    ```java\r\n    public class NutritionFacts {\r\n        private final int servingSize;  // (mL, 1회 제공량)     필수\r\n        private final int servings;     // (회, 총 n회 제공량)  필수\r\n        private final int calories;     // (1회 제공량당)       선택\r\n        private final int fat;          // (g/1회 제공량)       선택\r\n        private final int sodium;       // (mg/1회 제공량)      선택\r\n        private final int carbohydrate; // (g/1회 제공량)       선택\r\n    \r\n        public NutritionFacts(int servingSize, int servings) {\r\n            this(servingSize, servings, 0);\r\n        }\r\n    \r\n        public NutritionFacts(int servingSize, int servings,\r\n                              int calories) {\r\n            this(servingSize, servings, calories, 0);\r\n        }\r\n    \r\n        public NutritionFacts(int servingSize, int servings,\r\n                              int calories, int fat) {\r\n            this(servingSize, servings, calories, fat, 0);\r\n        }\r\n    \r\n        public NutritionFacts(int servingSize, int servings,\r\n                              int calories, int fat, int sodium) {\r\n            this(servingSize, servings, calories, fat, sodium, 0);\r\n        }\r\n        public NutritionFacts(int servingSize, int servings,\r\n                              int calories, int fat, int sodium, int carbohydrate) {\r\n            this.servingSize  = servingSize;\r\n            this.servings     = servings;\r\n            this.calories     = calories;\r\n            this.fat          = fat;\r\n            this.sodium       = sodium;\r\n            this.carbohydrate = carbohydrate;\r\n        }\r\n    }\r\n    ```\r\n\r\n    - 매개변수가 많아지면 클라이언트 코드를 작성하거나 읽기 어렵다는 단점이 있다.\r\n\r\n1. 자바빈즈 패턴(JavaBeans pattern)\r\n    - JavaBeans란 데이터를 표현하기 위한 Java 클래스를 만들 때의 규약으로 아래의 규약을 지킨 Java 클래스를 JavaBeans라고 부른다.\r\n        - 모든 클래스의 프로퍼티는 private이며 getter, setter 메서드로 제어한다.\r\n        - 인자가 없는 public 생성자가 있어야 한다.\r\n        - Serializable 인터페이스를 구현해야 한다.\r\n    - 즉, 매개변수가 없는 생성자로 객체를 만든 후, 세터(setter) 메서드들을 호출해 원하는 매개변수의 값을 설정하는 방식이다.\r\n    - 점층적 생성자 패턴에 비해 코드가 길어지긴 했지만, 인스턴스를 만들기 쉽고 그 결과 더 읽기 쉬운 코드가 되었다.\r\n\r\n    ```java\r\n    public class NutritionFacts {\r\n        // 매개변수들은 (기본값이 있다면) 기본값으로 초기화된다.\r\n        private int servingSize  = -1; // 필수; 기본값 없음\r\n        private int servings     = -1; // 필수; 기본값 없음\r\n        private int calories     = 0;\r\n        private int fat          = 0;\r\n        private int sodium       = 0;\r\n        private int carbohydrate = 0;\r\n    \r\n        public NutritionFacts() { }\r\n        // Setters\r\n        public void setServingSize(int val)  { servingSize = val; }\r\n        public void setServings(int val)     { servings = val; }\r\n        public void setCalories(int val)     { calories = val; }\r\n        public void setFat(int val)          { fat = val; }\r\n        public void setSodium(int val)       { sodium = val; }\r\n        public void setCarbohydrate(int val) { carbohydrate = val; }\r\n    \r\n        public static void main(String[] args) {\r\n            NutritionFacts cocaCola = new NutritionFacts();\r\n            cocaCola.setServingSize(240);\r\n            cocaCola.setServings(8);\r\n            cocaCola.setCalories(100);\r\n            cocaCola.setSodium(35);\r\n            cocaCola.setCarbohydrate(27);\r\n        }\r\n    }\r\n    ```\r\n\r\n    - 하지만 심각한 단점이 있다.\r\n      자바빈즈 패턴에서는 객체 하나를 만들려면 메서드를 여러 개 호출해야 하고, 객체가 완전히 생성되기 전까지 일관성(consistency)이 무너진 상태에 놓이게 된다.\r\n      따라서 클래스를 불변으로 만들수 없으며 스레드 안전성을 얻으려면 프로그래머가 추가 작업을 해줘야만 한다.\r\n\r\n1. 빌더 패턴(Builder pattern)\r\n    - 점층적 생성자 패턴의 안전성과 자바빈드 패턴의 가독성을 겸비했다.\r\n    - 클라이언트는 필요한 객체를 직접 만드는 대신, 필수 매개변수만으로 생성자(혹은 정적 팩터리)를 호출해 빌더 객체를 얻는다.\r\n      그런 다음 빌더 객체가 제공하는 일종의 세터 메서드들로 원하는 선택 매개변수들을 설정한다.\r\n      마지막으로 매개변수가 없는 build 메서드를 호출해 드디어 우리에게 필요한 (보통은 불변인) 객체를 얻는다.\r\n\r\n    ```java\r\n    public class NutritionFacts {\r\n        private final int servingSize;\r\n        private final int servings;\r\n        private final int calories;\r\n        private final int fat;\r\n        private final int sodium;\r\n        private final int carbohydrate;\r\n    \r\n        public static class Builder {\r\n            // 필수 매개변수\r\n            private final int servingSize;\r\n            private final int servings;\r\n    \r\n            // 선택 매개변수 - 기본값으로 초기화한다.\r\n            private int calories      = 0;\r\n            private int fat           = 0;\r\n            private int sodium        = 0;\r\n            private int carbohydrate  = 0;\r\n    \r\n            public Builder(int servingSize, int servings) {\r\n                this.servingSize = servingSize;\r\n                this.servings    = servings;\r\n            }\r\n    \r\n            public Builder calories(int val)\r\n            { calories = val;      return this; }\r\n            public Builder fat(int val)\r\n            { fat = val;           return this; }\r\n            public Builder sodium(int val)\r\n            { sodium = val;        return this; }\r\n            public Builder carbohydrate(int val)\r\n            { carbohydrate = val;  return this; }\r\n    \r\n            public NutritionFacts build() {\r\n                return new NutritionFacts(this);\r\n            }\r\n        }\r\n    \r\n        private NutritionFacts(Builder builder) {\r\n            servingSize  = builder.servingSize;\r\n            servings     = builder.servings;\r\n            calories     = builder.calories;\r\n            fat          = builder.fat;\r\n            sodium       = builder.sodium;\r\n            carbohydrate = builder.carbohydrate;\r\n        }\r\n    \r\n        public static void main(String[] args) {\r\n            NutritionFacts cocaCola = new NutritionFacts.Builder(240, 8)\r\n                    .calories(100).sodium(35).carbohydrate(27).build();\r\n        }\r\n    }\r\n    ```\r\n\r\n\r\n- 빌더 패턴은 (파이썬과 스칼라에 있는) 명명된 선택적 매개변수를 흉내 낸 것이다.\r\n- 잘못된 매개변수를 일찍 발견하려면 빌더의 생성자와 메서드에서 입력 매개변수를 검사하고, build 메서드가 호출하는 생성자에서 여러 매개변수에 걸친 불변식을 검사하자.\r\n    - 불변(immutable 혹은 immutability) - 어떠한 변경도 허용하지 않는다는 뜻. 주로 변경을 허용하는 가변 객체와 구분하는 용도로 쓰임.\r\n    - 불변식(invariant) - 프로그램이 실행되는 동안, 혹은 정해진 기간 동안 반드시 만족해야 하는 조건을 말함. 즉, 변경을 허용할 수 있으나 주어진 조건 내에서만 허용한다는 뜻.\r\n    - 가변 객체에도 불변식은 존재할 수 있으며, 넓게 보면 불변은 불변식의 극단적인 예라 할 수 있음.\r\n- 그리고 빌더 패턴은 계층적으로 설계된 클래스와 함께 쓰기 좋다.\r\n\r\n    ```java\r\n    // 참고: 여기서 사용한 '시뮬레이트한 셀프 타입(simulated self-type)' 관용구는\r\n    // 빌더뿐 아니라 임의의 유동적인 계층구조를 허용한다.\r\n    \r\n    public abstract class Pizza {\r\n        public enum Topping { HAM, MUSHROOM, ONION, PEPPER, SAUSAGE }\r\n        final Set<Topping> toppings;\r\n    \r\n        abstract static class Builder<T extends Builder<T>> {\r\n            EnumSet<Topping> toppings = EnumSet.noneOf(Topping.class);\r\n            public T addTopping(Topping topping) {\r\n                toppings.add(Objects.requireNonNull(topping));\r\n                return self();\r\n            }\r\n    \r\n            abstract Pizza build();\r\n    \r\n            // 하위 클래스는 이 메서드를 재정의(overriding)하여\r\n            // \"this\"를 반환하도록 해야 한다.\r\n    \t\t\t\t// 하위 클래스에서는 형변환하지 않고도 메서드 연쇄를 지원할 수 있음.\r\n            protected abstract T self();\r\n        }\r\n        \r\n        Pizza(Builder<?> builder) {\r\n            toppings = builder.toppings.clone(); // 아이템 50 참조\r\n        }\r\n    }\r\n    \r\n    public class NyPizza extends Pizza {\r\n        public enum Size { SMALL, MEDIUM, LARGE }\r\n        private final Size size;\r\n    \r\n        public static class Builder extends Pizza.Builder<Builder> {\r\n            private final Size size;\r\n    \r\n            public Builder(Size size) {\r\n                this.size = Objects.requireNonNull(size);\r\n            }\r\n    \r\n            @Override public NyPizza build() {\r\n                return new NyPizza(this);\r\n            }\r\n    \r\n            @Override protected Builder self() { return this; }\r\n        }\r\n    \r\n        private NyPizza(Builder builder) {\r\n            super(builder);\r\n            size = builder.size;\r\n        }\r\n    }\r\n    \r\n    public class Calzone extends Pizza {\r\n        private final boolean sauceInside;\r\n    \r\n        public static class Builder extends Pizza.Builder<Builder> {\r\n            private boolean sauceInside = false; // 기본값\r\n    \r\n            public Builder sauceInside() {\r\n                sauceInside = true;\r\n                return this;\r\n            }\r\n    \r\n            @Override public Calzone build() {\r\n                return new Calzone(this);\r\n            }\r\n    \r\n            @Override protected Builder self() { return this; }\r\n        }\r\n    \r\n        private Calzone(Builder builder) {\r\n            super(builder);\r\n            sauceInside = builder.sauceInside;\r\n        }\r\n    }\r\n    ```\r\n\r\n\r\n- 빌더 패턴은 상당히 유연하다.\r\n    - 빌더 하나로 여러 객체를 순회하면서 만들 수 있고, 빌더에 넘기는 매개변수에 따라 다른 객체를 만들 수도 있다.\r\n    - 객체에게 부여되는 일련번호와 같은 특정 필드는 빌더가 알아서 채우도록 할 수도 있다.\r\n- 단, 장점만 있는 것은 아니다.\r\n    - 객체를 만들려면, 그에 앞서 빌더부터 만들어야한다.\r\n    - 빌더 생성 비용이 크지는 않지만 성능에 민감한 상황에서는 문제가 될 수 있다.\r\n    - 매개변수가 4개 이상은 되어야 값어치를 한다.\r\n    - 하지만 api는 시간이 지날수록 매개변수가 많아지는 경향이 있음을 명시하자!\r\n\r\n## 핵심정리\r\n\r\n- 생성자나 정적 팩터리가 처리해야 할 매개변수가 많다면 빌더 패턴을 선택하는게 더 낫다!\r\n\r\n## 느낀 점\r\n\r\n- 짱 긴 생성자나 setter 범벅인 코드에 비해서 빌더는 깔끔하고 편하다.\r\n  특히 롬복을 더한다면..ㅋㅋ;;\r\n  그렇다면 무조건적인 빌더 사용이 좋을까? 책에서는 매개변수가 많아지는 경향이 있기에\r\n  애초에 빌더 사용하는 거도 좋은 방법이라곤 하지만 직접 빌더를 만들어서 사용하려면\r\n  그거도 비용이기 때문에 고민해봐야 할 것 같다.","excerpt":"정적 팩터리와 생성자에는 똑같은 제약이 있다. 선택적 매개변수가 많을때 적절히 대응하기 어렵다는 점! 필드에 변수가 많이 있을 때 이런 클래스용 생성자 혹은 정적 팩터리는 어떤 모습일까? 3가지 방법을 사용한 모습이 있겠다. 점층적 생성자 패턴(te…","fields":{"slug":"/effective-java-item2/"},"frontmatter":{"date":"Dec 13, 2021","title":"[이펙티브 자바] 2. 생성자에 매개변수가 많다면 빌더를 고려하라","tags":["java","book"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n- 클라이언트가 클래스의 인스턴스를 얻는 전통적인 수단은 public 생성자다.\r\n- 클래스는 생성자와 별도로 정적 팩터리 메서드를 제공할 수 있다.\r\n    - 정적 팩터리 메서드는 클래스의 인스턴스를 반환하는 단순한 정적 메서드를 뜻한다.\r\n    - 정적 팩터리 메서드는 디자인 패턴에서의 팩터리 메서드와 다르다.\r\n\r\n## 정적 메서드의 장점 5가지\r\n\r\n1. 이름을 가질 수 있다.\r\n    - 생성자에 넘기는 매개변수, 생성자 자체 만으로는 반환될 객체의 특성을 제대로 설명하지 못한다.\r\n      반면, 정적 팩터리는 이름만 잘 지으면 반환될 객체의 특성을 쉽게 묘사할 수 있다.\r\n        - BigInteger(int, int ,Random)과 BigInteger.probablaPrime 중 어느 쪽이\r\n          '값이 소수인 BigInteger를 반환한다'는 의미를 더 잘 설명할 것 같은지 생각해보라.\r\n    - 한 클래스에 시그니처가 같은 생성자가 여러 개 필요할 것 같으면, 생성자를 정적 팩터리 메서드로 바꾸고 각각의 차이를 잘 드러내는 이름을 지어주자.\r\n2. 호출될 때마다 인스턴스를 새로 생성하지는 않아도 된다.\r\n    - 불변 클래스는 인스턴스를 미리 만들어 놓거나 새로 생성한 인스턴스를 캐싱하여 재활용하는 식으로 불필요한 객체 생성을 피할 수 있다.\r\n        - 대표적인 예로 Boolean.valueOf(boolean), 플라이웨이트 패턴\r\n        - 플라이웨이트 패턴은 동일하거나 유사한 객체들 사이에 가능한 많은 데이터를 공유하여 메모리 사용을 최소화하는 디자인 패턴\r\n\r\n            ![Untitled (64)](https://user-images.githubusercontent.com/62014888/146127817-4b75b2b3-9e47-4a6f-87ee-38629537abd7.png)\r\n    \r\n    - 정적 팩터리 방식의 클래스는 언제 어느 인스턴스를 살아 있게 할지를 철저히 통제할 수 있다.\r\n        - 클래스를 통제하는 이유는?\r\n          클래스를 싱글턴으로 만들 수도, 인스턴스화 불가로 만들 수도 있음.\r\n          불변 값 클래스에서 동치인 인스턴스가 단 하나뿐임을 보장할 수 있음.\r\n3. 반환 타입의 하위 타입 객체를 반환할 수 있는 능력이 있다.\r\n    - 반환할 객체의 클래스를 자유롭게 선택할 수 있게 하는 '엄청난 유연성'을 선물한다!\r\n    - 자바 8 전에는 인터페이스 정적 메서드를 선언할 수 없었다.\r\n        - 그래서 자바 컬렉션 프레임워크는 Collections라는 인스턴스화 불가 클래스에서 정적 팩터리 메서드를 통해 구현체를 얻도록 했음.\r\n    - 자바 8 후에는 인터페이스가 정적 메서드를 가질 수 있어졌기에 인스턴스화 불가 동반 클래스를 둘 이유가 별로 없어짐.\r\n        - 그래서 이러한 List 인터페이스에 List.of()와 같은 정적 팩터리 메서드가 생김.\r\n\r\n        ![Untitled (65)](https://user-images.githubusercontent.com/62014888/146127819-698c8dac-3c7a-4ea7-9fab-126a262cf05a.png)\r\n\r\n\r\n1. 입력 매개변수에 따라 매번 다른 클래스의 객체를 반환할 수 있다.\r\n    - EnumSet 클래스는 원소가 64개 이하면 RegularEnumSet 인스턴스를, 65개 이상이면 JumboEnumSet 인스턴스를 반환한다.\r\n        - 클라이언트는 이 두 클래스의 존재를 모른다. 더 나아가 알 필요도 없다. EnumSet의 하위 클래스이기만 하면 되는 것이다.\r\n\r\n2. 정적 팩터리 메서드를 작성하는 시점에는 반환할 객체의 클래스가 존재하지 않아도 된다.\r\n    - 나중에 만들 클래스가 기존의 인터페이스나 클래스를 상속 받는 상황이라면 언제든지 의존성 주입 받아서 사용이 가능하다.\r\n      반환값이 인터페이스여도 되며, 정적 팩터리 메서드의 변경 없이 구현체를 바꿔 끼울 수 있다.\r\n    - 이러한 유연함은 서비스 제공자 프레임워크를 만드는 근간이 된다.\r\n        - 서비스 제공자 프레임워크에서의 제공자는 서비스의 구현체로 3개의 핵심 컴포넌트로 이뤄짐.\r\n            - 구현체의 동작을 정의하는 서비스 인터페이스\r\n            - 제공자가 구현체를 등록할 때 사용하는 제공자 등록 API\r\n            - 클라이언트가 서비스의 인스턴스를 얻을 때 사용하는 서비스 접근 API\r\n        - 대표적인 예로 JDBC가 있다.\r\n            - Connection이 서비스 인터페이스 역할\r\n            - DriverManager.registerDriver가 제공자 등록 API 역할\r\n            - DriverManager.getConnection이 서비스 접근 API 역할\r\n            - Driver가 서비스 제공자 인터페이스 역할\r\n        - 자바 6부터는 ServiceLoader라는 범용 서비스 제공자 프레임워크가 제공됨.\r\n\r\n## 정적 메서드의 단점 2가지\r\n\r\n1. 상속을 하려면 public이나 protected 생성자가 필요하니 정적 팩터리 메서드만 제공하면 하위 클래스를 만들 수 없다.\r\n    - 우테코 레벨 1 로또 미션에서 사용했던 코드를 예로 들 수 있다.\r\n\r\n        ```java\r\n        public class LottoTicket {\r\n            private static final int VALID_LOTTO_NUMBER_COUNTS = 6;\r\n            private static final String INVALID_LOTTO_NUMBER_COUNTS = \"로또 티켓은 중복되지 않은 6자리의 숫자로 구성되어야 합니다.\";\r\n            \r\n            private final Set<LottoNumber> lottoNumbers;\r\n        \r\n            private LottoTicket(Set<LottoNumber> lottoNumbers) {\r\n                validateNumberCounts(lottoNumbers.size());\r\n                this.lottoNumbers = lottoNumbers;\r\n            }\r\n        \r\n            public static LottoTicket generateTicket(List<LottoNumber> numbers) {\r\n                return numbers.stream()\r\n                        .collect(Collectors.collectingAndThen(Collectors.toSet(), LottoTicket::new));\r\n            }\r\n        }\r\n        \r\n        public class WinningLottoTicket {\r\n            private static final String DUPLICATION_NUMBER = \"보너스 볼 번호는 당첨 번호와 중복될 수 없습니다.\";\r\n        \r\n            private final LottoTicket lottoTicket;\r\n            private final LottoNumber bonusBallNumber;\r\n        \r\n            private WinningLottoTicket(LottoTicket lottoTicket, LottoNumber bonusBallNumber) {\r\n                validateDuplicateNumbers(lottoTicket, bonusBallNumber);\r\n                this.lottoTicket = lottoTicket;\r\n                this.bonusBallNumber = bonusBallNumber;\r\n            }\r\n        }\r\n        ```\r\n\r\n        - LottoTicket 클래스 내부에는 private 생성자와 LottoTicket 클래스를 반환하는 정적 팩터리 메서드가 있었다.\r\n        - WinningLottoTicket 이라는 클래스를 만들기 위해 LottoTicket 클래스를 상속받았는데 그러다보니 상위 클래스의 생성자를 public이나 protected로 바꾸지 않는 이상 상속받을 수가 없었다.\r\n        - 그래서 상속보다는 컴포지션(조합)을 사용하라는 조언을 통해 문제를 해결했다.\r\n        - 이는 어떻게 보면 상속보다는 컴포지션을 사용하도록 유도하고 불변 타입으로 만들려면 이 제약을 지켜야 한다는 점에서 오히려 장점으로 받아들일 수도 있다!\r\n2. 정적 팩터리 메서드는 프로그래머가 찾기 어렵다.\r\n    - 생성자처럼 API 설명에 명확히 드러나지 않으니 사용자는 정적 팩터리 메서드 방식 클래스를 인스턴스화할 방법을 알아내야 한다.\r\n      이러한 어려움을 해결하기 위해 API 문서를 잘 써놓고 메서드 이름도 널리 알려진 규약을 따라 짓는 식으로 문제를 완화해줘야 한다.\r\n    - 흔히 사용하는 정적 팩터리 메서드 명명 방식들\r\n        - from: 매개변수를 하나 받아서 해당 타입의 인스턴스를 반환하는 형변환 메서드\r\n        - of: 여러 매개변수를 받아 적합한 타입의 인스턴스를 반환하는 집계 메서드\r\n        - valueOf: from과 of의 더 자세한 버전\r\n        - instance or getInstance: (매개변수를 받는다면) 매개변수로 명시한 인스턴스를 반환하지만, 같은인스턴스임을 보장하지는 않는다.\r\n        - create or newInstance: instance 혹은 getInstance와 같지만, 매번 새로운 인스턴스를 생성해 반환함을 보장한다.\r\n        - getType: getInstance와 같으나, 생성할 클래스가 아닌 다른 클래스에 팩터리 메서드를 정의할 때 쓴다. \"Type\"은 팩터리 메서드가 반환할 객체의 타입이다.\r\n        - newType: newInstance와 같으나, 생성할 클래스가 아닌 다른 클래스에 팩터리 메서드를 정의할 때 쓴다. \"Type\"은 팩터리 메서드가 반환할 객체의 타입이다.\r\n        - type: getType과 newType의 간결한 버전\r\n\r\n## 핵심정리\r\n\r\n- 정적 팩터리 메서드와 public 생성자는 각자의 쓰임새가 있으니 상대적인 장단점을 이해하고 사용하는 것이 좋다.\r\n  그렇다 하더라도 정적 팩터리를 사용하는 게 유리한 경우가 더 많으므로 무작정 public 생성자를 제공하던 습관이 있으면 고치자!\r\n  \r\n\r\n## 느낀 점\r\n\r\n- Collections가 인터페이스에 정적 메서드를 선언하지 못해서 만든 클래스고\r\n  List.of()와 같은 메서드가 선언할 수 있게 되어서 생긴 메서드라니 흥미로웠다.\r\n  그리고 솔직히 흔히 사용되는 명명 방식의 기준은 잘 모르겠다.. 중요한건 그것보다\r\n  정적 팩터리 메서드를 사용할 때 메서드 명에 대한 팀 컨벤션을 만들어 혼용해서 쓰지 않도록 하는 것이 좋을 것 같다.","excerpt":"클라이언트가 클래스의 인스턴스를 얻는 전통적인 수단은 public 생성자다. 클래스는 생성자와 별도로 정적 팩터리 메서드를 제공할 수 있다. 정적 팩터리 메서드는 클래스의 인스턴스를 반환하는 단순한 정적 메서드를 뜻한다. 정적 팩터리 메서드는 디자인…","fields":{"slug":"/effective-java-item1/"},"frontmatter":{"date":"Dec 13, 2021","title":"[이펙티브 자바] 1. 생성자 대신 정적 팩터리 메서드를 고려하라","tags":["java","book"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\nSpring Framework는 자바 기반의 엔터프라이즈 애플리케이션을 위해서 여러가지 기능을 제공한다. 그 중 웹 애플리케이션 구현을 위한 모듈로 Spring Web MVC가 제공되는데 클라이언트가 요청을 하고 Spring Web MVC에 의해 응답을 반환하기 까지 어떠한 흐름으로 진행되는지 구조를 파악해보도록 하자.\r\n\r\n기본적으로 DispatcherServlet에 대한 설명은 생략하고 @Controller, @RestController 애노테이션에 따라 흐름이 진행되는 순서를 설명할 것이니 DistpatcherServlet에 대해 알아보려면 이 [포스트](https://www.notion.so/Servlet-Dispatcher-Servlet-2f0ad465b2484bd0ae5f55b83b1a2e65) 를 참고하자.\r\n\r\n<br/>\r\n\r\n## @Controller\r\n\r\n![Untitled (13)](https://user-images.githubusercontent.com/62014888/145709182-5d95c1d7-83bf-419f-ba77-d7f6d13db00b.png)\r\n\r\n- 조금 많이 간략화했지만 @Controller 애노테이션을 사용하면서 @RequestMapping을 사용한다면 이런 흐름으로 진행된다.\r\n- HandlerMapping의 경우 기본적으로 5개 정도 있는데 @RequestMapping을 사용할 경우 RequestMappingHandlerMapping을 사용해서 handler를 가져온다.\r\n\r\n  ![Untitled (14)](https://user-images.githubusercontent.com/62014888/145709191-9ecac958-3f71-4387-9849-7d602efb8386.png)\r\n  \r\n    - 보는바와 같이 Spring에서 기본적으로 List에 5개의 HandlerMapping을 우선순위에 따라 저장시켜두는데 RequestMappingHandlerMapping이 우선순위가 제일 높은 것을 볼 수 있다.\r\n    - Handler를 가져오면서 Interceptor가 설정되어 있으면 해당하는 url일 경우 Interceptor를 타게 된다.\r\n- HandlerReturnValueHandlerComposite에서 selectHandler 메소드를 통해 적절한  HandlerMethodReturnValueHandler를 반환해주게 된다.\r\n  만약 Controller에 해당하는 메소드가 ModelAndView를 반환해주게 된다면 ModelAndViewReturnValueHandler를 String이라면 ViewNameMethodReturnValueHandler를 반환해주게 된다.\r\n\r\n  ![Untitled (15)](https://user-images.githubusercontent.com/62014888/145709203-91a724e8-e95d-4bc1-a1d6-c1c238839ded.png)\r\n\r\n    - supportsReturnType이라는 메소드를 사용해 HandlerMethodReturnValueHandler에게 적절한 리턴 타입인지를 물어보게 되는 것이다.\r\n    - ViewNameMethodReturnValueHandler일 경우 View Name을 저장해 DispathcerServlet의 render 메소드에서 ViewResolver를 통해 View 객체로 resolve 시켜준다.\r\n\r\n<br/>\r\n\r\n## @RestController\r\n\r\n![Untitled (16)](https://user-images.githubusercontent.com/62014888/145709213-61394e37-af89-4d24-993c-6d5966d56523.png)\r\n\r\n- @RestController도 마찬가지로 같은 흐름으로 진행되나 Return Value를 처리해주는 HandlerMethodReturnValueHandler가 다르다.\r\n- @RestController를 열어보면 @ResponseBody가 포함되어 있는데 이 애노테이션에 의해 RequestResponseBodyMethodProcessor가 선택된다.\r\n\r\n  ![Untitled (17)](https://user-images.githubusercontent.com/62014888/145709220-8bfb6125-3838-43a1-96e6-fe635e07ca7c.png)\r\n\r\n\r\n- RequestResponseBodyMethodProcessor 내부에는 메시지 컨버터를 가지고 있는데 MappingJackson2HttpMessageConverter에 의해 Json으로 변환하여 클라이언트에게 반환하게 된다.\r\n- 코드를 보다보면 HandlerAdapter의 handle 메소드는 ModelAndView를 반환해주게 되던데 RequestResponseBodyMethodProcessor의 경우 메시지 컨버터를 사용하며 ModelAndViewContatiner의 requestHandled 필드를 true로 바꿔주고 이 필드가 true일 경우 ModelAndView를 null로 리턴하게 된다.\r\n  DispatcherServlet에서는 ModelAndView가 null일 경우 이미 렌더링 되어있다고 판단하고 넘어가게 된다.\r\n\r\n![Untitled (18)](https://user-images.githubusercontent.com/62014888/145709229-8d7c6353-5731-43a0-b39d-57e8d7cce50c.png)\r\n\r\n<br/>\r\n\r\n## 마무리\r\n\r\n- 예전에도 DispatcherServlet을 파보았지만 이번에 @Controller와 @RestController 애노테이션에 따라 어떻게 진행되는지 조금 더 깊게 파보았다.\r\n- 한번 더 Spring을 정리하게 되는 계기가 되었다.\r\n- 더 자세히 공부하실 분은 Spring 코드를 직접 열어보면서 공부하는 걸 추천드린다.\r\n\r\n<br/>\r\n\r\n## 참고\r\n\r\n- [https://yoon0120.tistory.com/60](https://yoon0120.tistory.com/60)","excerpt":"Spring Framework는 자바 기반의 엔터프라이즈 애플리케이션을 위해서 여러가지 기능을 제공한다. 그 중 웹 애플리케이션 구현을 위한 모듈로 Spring Web MVC가 제공되는데 클라이언트가 요청을 하고 Spring Web MVC에 의해 응…","fields":{"slug":"/spring-mvc/"},"frontmatter":{"date":"Dec 07, 2021","title":"Spring MVC 구조 파악하기","tags":["spring","mvc"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n캐싱이라는 용어는 프로그래밍에서 자주 등장하게 된다.\r\n캐싱이란 '성능 향상을 위해 사용이 많은 데이터를 별도 공간에 일시적으로 저장하여 필요할 때마다 데이터를 가져오는 기술'이다.\r\n메모리, 네트워크 등 다양한 곳에서 사용하게 되는데 Spring에서도 편리하게 캐싱을 사용하기 위해 캐싱 추상화 형식으로 제공해준다.\r\n공식 문서를 바탕으로 간단하게 이를 알아보도록 하자.\r\n\r\n---\r\n\r\n## Spring Cache?\r\n\r\nSpring Framework는 버전 3.1 부터 기존 Spring 애플리케이션에 투명하게 캐싱을 추가하는 지원을 제공한다. Spring에서 제공하는 트랜잭션 지원과 유사하게 캐싱 추상화를 통해 코드에 미치는 영향을 최소화하면서 다양한 캐싱 솔루션을 일관되게 사용할 수 있다.\r\n\r\n간단하게 이야기하자면 Java 메소드에 애노테이션과 같은 추상화된 캐싱을 적용하여 캐시에서 사용 가능한 정보를 기반으로 실행 횟수를 줄이는 것이다. 즉, 해당 메소드가 호출될 때 주어진 인자에 대해 메소드가 이미 실행되었는지 여부를 확인하고 실행되었다면 실제 메소드를 실행할 필요 없이 캐시된 결과가 반환된다.\r\n\r\n이를 통해 값비싼 메소드(CPU or I/O 바인딩 여부)를 주어진 매개변수 집합에 대해 한 번만 실행할 수 있으며 실제로 메소드를 다시 실행할 필요 없이 결과를 재사용할 수 있다.\r\n\r\n캐시 추상화를 사용하려면 개발자는 두 가지 측면을 처리해야 한다.\r\n\r\n- caching declaration(캐싱 선언) - 캐싱해야 하는 메소드와 해당 정책 식별\r\n- cache configuration(캐시 구성) - 데이터가 저장되고 읽히는 백업 캐시\r\n\r\nSpring Framework의 다른 서비스와 마찬가지로 캐싱 서비스는 추상화(캐시 구현이 아님)이며 캐시 데이터를 저장하기 위해 실제 저장소를 사용해야 한다. 기본적으로 Spring에서는 EhCache, Caffeine, Redis 등 여러 캐시들을 지원해주며 애플리케이션에 저장하는 ConcurrentMap 또한 저장소로 사용할 수 있다.\r\n\r\n<br/>\r\n\r\n## Configuration\r\n\r\nSpring Boot, Gradle을사용하고 있다면 간단하게 아래 dependencies를 추가하여 사용 가능하다.\r\n\r\n```groovy\r\ndependencies {\r\n    implementation 'org.springframework.boot:spring-boot-starter-cache'\r\n}\r\n```\r\n\r\n```java\r\n@EnableCaching\r\n@Configuration\r\npublic class CacheConfig {\r\n\r\n    @Bean\r\n    public CacheManager cacheManager() {\r\n        return new ConcurrentMapCacheManager(\"workbooks\");\r\n    }\r\n\r\n}\r\n```\r\n\r\n- Spring에서는 설정과 상관없이 동일한 코드로 캐시에 접근하기 위해서 CacheManager를 제공헤준다.\r\n- 예시를 위해 ConcurrentMap을 사용했는데 상황에 따라 무엇을 사용할지 결정될 것 같다.\r\n    - ConcurrerntMap의 경우 TTL을 설정할 수 없고 애플리케이션 내에서 사용되는 캐시이기에 WAS가 늘어나면 WAS 별로 따로 관리를 해줘야한다.\r\n        - TTL을 설정할 수 없기에 Scheduling 등을 이용해 삭제해줘야 한다.\r\n    - 외부에 같은 캐시 저장소를 사용하려면 Redis나 Memcached를 사용하는게 좋다.\r\n- @EnableCaching은 내부적으로 Spring AOP를 이용하여 애노테이션 기반 캐싱 설정을 사용하게 해준다.\r\n    - 원래는 proxyTargetClass가 false인 경우 JDK Dynamic Proxy 사용, true인 경우 CGLIB Proxy를 사용하나 Spring Boot가 버전이 업데이트 되면서 CGLIB 사용을 강제했기 때문에 현재 2.5.1 기준 false 여도 CGLIB를 사용한다.\r\n\r\n<br/>\r\n\r\n## @Cacheable\r\n\r\n@Cacheable은 캐싱할 수 있는 메소드를 지정하는데 사용한다.\r\n\r\n```java\r\n\r\n@Cacheable(cacheNames = \"workbooks\", key = \"#keyword\")\r\npublic Workbook findWorkbookByKeyword(String keyword) {\r\n    return workbookRepository.findByName(keyword);\r\n}\r\n```\r\n\r\n```java\r\n\r\n@Test\r\nvoid findWorkbookByKeyword() {\r\n    // given\r\n    String keyword = \"java\";\r\n    given(workbookRepository.findByName(anyString()))\r\n            .willReturn(new Workbook());\r\n\r\n    // when\r\n    workbookService.findWorkbookByKeyword(keyword);\r\n    workbookService.findWorkbookByKeyword(keyword);\r\n    workbookService.findWorkbookByKeyword(keyword);\r\n\r\n    // then\r\n    then(workbookRepository)\r\n            .should(times(1))\r\n            .findByName(anyString());\r\n}\r\n```\r\n\r\n- cacheNames는 설정에서 ConcurrentMapCacheManager의 저장소 명과 일치한 값이 들어가며 value도 같은 역할을 한다. (일치하지 않으면 캐싱이 안됨)\r\n- key의 경우 캐시 데이터가 들어있는 key (여기서는 ConcurrentMap의 key) 이며 해당 key의 value가 존재하면 findWorkbookByKeyword 메소드가 수행되지 않고, 존재하지 않으면 수행된다.\r\n    - key는 SpEL (Spring Expression Language) 문법을 사용할 수 있는데 위와 같이 파라미터로 넘어온 값을 지정할 수 있고 파라미터가 객체일 경우 객체의 멤버 변수에도 접근할 수 있다.\r\n    - SpEL에 대한 자세한 사항은 [공식 문서](https://docs.spring.io/spring-framework/docs/3.2.x/spring-framework-reference/html/cache.html) 를 참고하자.\r\n\r\n    ```java\r\n    @Cacheable(cacheNames = \"workbooks\", key = \"#workbook.name\")\r\n    public Workbook findWorkbookByKeyword(Workbook workbook) {\r\n        return workbookRepository.findByName(workbook.getName());\r\n    }\r\n    ```\r\n\r\n    ```java\r\n    @Test\r\n    void findWorkbookByKeyword() {\r\n        // given\r\n        Cache cache = Objects.requireNonNull(concurrentMapCacheManager.getCache(\"workbooks\"));\r\n        Workbook workbook = new Workbook(\"java\");\r\n        given(workbookRepository.findByName(anyString()))\r\n                .willReturn(workbook);\r\n    \r\n        // when\r\n        workbookService.findWorkbookByKeyword(workbook);\r\n    \r\n        // then\r\n        assertThat(cache.get(workbook.getName())).isNotNull();\r\n    }\r\n    ```\r\n\r\n\r\n- condition 속성을 이용하면 조건도 부여할 수 있다.\r\n\r\n    ```java\r\n    @Cacheable(cacheNames = \"workbooks\", key = \"#workbook.name\", condition = \"#workbook.name.length() > 4\")\r\n    public Workbook findWorkbookByKeyword(Workbook workbook) {\r\n        return workbookRepository.findByName(workbook.getName());\r\n    }\r\n    ```\r\n\r\n    ```java\r\n    @Test\r\n    void findWorkbookByKeywordWhenConditionExists() {\r\n        // given\r\n        Workbook workbook = new Workbook(\"java\");\r\n        given(workbookRepository.findByName(anyString()))\r\n                .willReturn(workbook);\r\n    \r\n        // when\r\n        workbookService.findWorkbookByKeyword(workbook);\r\n        workbookService.findWorkbookByKeyword(workbook);\r\n        workbookService.findWorkbookByKeyword(workbook);\r\n    \r\n        // then\r\n        then(workbookRepository)\r\n                .should(times(3))\r\n                .findByName(anyString());\r\n    }\r\n    ```\r\n\r\n    - workbook의 name length가 4보다 큰 경우에 캐싱하도록 조건을 부여했기에 캐싱이 되지 않은 모습을 볼 수 있다.\r\n\r\n- 특정 로직에 의해 key를 만들고자 하는 경우 KeyGenerator 인터페이스를 별도로 구현하여 Custom KeyGenerator를 만들어 사용할 수 있다고 한다.\r\n    - default는 SimpleKeyGeneretor를 사용한다고 하며 파라미터를 보고 key를 생성해주게 된다.\r\n\r\n        ![Untitled (11)](https://user-images.githubusercontent.com/62014888/145708088-61abe80d-72c8-4dda-b679-053c455ada65.png)\r\n\r\n    - 파라미터가 없는 경우는 빈 값,\r\n      1개일 경우 해당 파라미터,\r\n      여러 개일 경우 모든 파라미터의 해시에서 계산된 키를 반환한다.\r\n    - 만약 key를 따로 지정하지 않는다면 side effect가 생길 수 있으니 지정해주는 것이 좋다.\r\n\r\n- cacheManager가 여러 개라면 cacheManager 속성을 사용해 원하는 cacheManager 설정도 가능하다.\r\n\r\n<br/>\r\n\r\n## @CachePut\r\n\r\n@CachePut은 메소드 실행에 영향을 주지 않고 캐시를 갱신해야 할 경우 사용한다. 즉, 메소드를 항상 실행하고 그 결과를 캐시에 보관한다.\r\n\r\n```java\r\n@CachePut(cacheNames = \"workbooks\", key = \"#workbook.name\")\r\npublic Workbook findWorkbookByKeyword(Workbook workbook) {\r\n    return workbookRepository.findByName(workbook.getName());\r\n}\r\n```\r\n\r\n```java\r\n@Test\r\nvoid findWorkbookByKeywordWhenCachePut() {\r\n\t  // given\r\n\t  Workbook workbook = new Workbook(\"java\");\r\n\t  given(workbookRepository.findByName(anyString()))\r\n\t          .willReturn(workbook);\r\n\t\r\n\t  // when\r\n\t  workbookService.findWorkbookByKeyword(workbook);\r\n\t  workbookService.findWorkbookByKeyword(workbook);\r\n\t  workbookService.findWorkbookByKeyword(workbook);\r\n\t\r\n\t  // then\r\n\t  then(workbookRepository)\r\n\t          .should(times(3))\r\n\t          .findByName(anyString());\r\n}\r\n```\r\n\r\n- Spring에서는 같은 메소드에 @CachePut과 @Cacheable을 사용하는 것을 권장하지 않는다. @Cacheable은 캐시를 사용해서 메소드를 건너뛰려하고 @CachePut은 메소드 실행을 강제하기 때문에 의도치 않은 동작이 발생할 수 있기 때문이다.\r\n\r\n    ![Untitled (12)](https://user-images.githubusercontent.com/62014888/145708123-70dd5b48-4324-4088-894d-8b70c3e3c841.png)\r\n\r\n\r\n<br/>\r\n\r\n## @CacheEvict\r\n\r\n@CacheEvict는 저장된 캐시를 제거할 때 사용한다. 메소드 실행 시,  해당 캐시를 삭제한다.\r\n\r\n```java\r\n@CacheEvict(cacheNames = \"workbooks\", key = \"#keyword\")\r\npublic void removeWorkbookCache(String keyword) {\r\n    // ...\r\n}\r\n```\r\n\r\n```java\r\n@Test\r\nvoid removeWorkbookCacheByKeyword() {\r\n    // given\r\n    String keyword = \"java\";\r\n    String anotherKeyword = \"spring\";\r\n    Cache cache = Objects.requireNonNull(concurrentMapCacheManager.getCache(\"workbooks\"));\r\n    given(workbookRepository.findByName(anyString()))\r\n            .willReturn(new Workbook());\r\n\r\n    // when\r\n    workbookService.findWorkbookByKeyword(keyword);\r\n    workbookService.findWorkbookByKeyword(anotherKeyword);\r\n    workbookService.removeWorkbookCache(keyword);\r\n\r\n    // then\r\n    assertThat(cache.get(keyword)).isNull();\r\n    assertThat(cache.get(anotherKeyword)).isNotNull();\r\n}\r\n```\r\n\r\n- allEntries 속성을 true로 설정하여 하나의 캐시가 아닌 전체 캐시를 제거할 수 있다. default가 false다.\r\n\r\n    ```java\r\n    @CacheEvict(cacheNames = \"workbooks\", allEntries = true)\r\n    public void removeWorkbookCache() {\r\n        // ...\r\n    }\r\n    ```\r\n\r\n    ```java\r\n    @Test\r\n    void removeWorkbookAllCacheByKeyword() {\r\n        // given\r\n        String keyword = \"java\";\r\n        String anotherKeyword = \"spring\";\r\n        Cache cache = Objects.requireNonNull(concurrentMapCacheManager.getCache(\"workbooks\"));\r\n        given(workbookRepository.findByName(anyString()))\r\n                .willReturn(new Workbook());\r\n    \r\n        // when\r\n        workbookService.findWorkbookByKeyword(keyword);\r\n        workbookService.findWorkbookByKeyword(anotherKeyword);\r\n        workbookService.removeWorkbookCache();\r\n    \r\n        // then\r\n        assertThat(cache.get(keyword)).isNull();\r\n        assertThat(cache.get(anotherKeyword)).isNull();\r\n    }\r\n    ```\r\n\r\n\r\n- beforeInvocation 속성을 이용해 true면 메소드 실행 이전에 캐시를 삭제하고, false면 메소드 실행 이후 삭제를 할 수 있다. default가 false다.\r\n- 위 예제처럼 void 메소드와 함께 사용할 수 있다. 메소드가 트리거로 동작하므로 반환값은 무시한다.\r\n\r\n<br/>\r\n\r\n## @Caching\r\n\r\n@Caching은 @CacheEvict나 @CachePut을 여러 개 지정해야 하는 경우에 사용한다.\r\n\r\n- 예를 들어 조건이나 키 표현식이 캐시에 따라 다른 경우다.\r\n- 여러가지의 key에 대한 캐시를 중첩적으로 삭제해야할 때 사용할 수 있다.\r\n\r\n```java\r\n@Caching(evict = {@CacheEvict(value = \"workbooks\", key = \"#keyword\"), @CacheEvict(\"tags\")})\r\npublic void removeWorkbookCache(String keyword) {\r\n    // ...\r\n}\r\n```\r\n\r\n- @Cacheable, @CachePut, @CacheEvict를 같은 메소드에 다수 사용할 수 있다.\r\n\r\n<br/>\r\n\r\n## @CacheConfig\r\n\r\n@CacheConfig는 클래스 단위로 캐시 설정을 동일하게 하는데 사용한다.\r\n\r\n- CacheManager가 여러 개인 경우 사용할 수 있다.\r\n- 프로젝트를 진행하면서 Redis용 CacheManager와 ConcurrentMapCacheManager를 같이 사용했는데 이때 ConcurrentMapCacheManager를 사용하는 클래스에서 다음과 같이 @CacheConfig를 사용할 수 있다.\r\n\r\n    ```java\r\n    @Slf4j\r\n    @Service\r\n    @CacheConfig(cacheManager = \"concurrentMapCacheManager\")\r\n    public class SearchRankService {\r\n    \r\n        private static final String SEARCH_RANKS_CACHE_VALUE = \"SearchRanks\";\r\n        private static final int SEARCH_RANK_COUNT = 3;\r\n    \r\n        private final SearchRankRepository searchRankRepository;\r\n        private final SearchScoreRepository searchScoreRepository;\r\n    \r\n        public SearchRankService(SearchRankRepository searchRankRepository, SearchScoreRepository searchScoreRepository) {\r\n            this.searchRankRepository = searchRankRepository;\r\n            this.searchScoreRepository = searchScoreRepository;\r\n        }\r\n    \r\n        @Cacheable(value = SEARCH_RANKS_CACHE_VALUE, key = \"'SearchRanksKey'\")\r\n        public List<SearchRankResponse> bringSearchRanks() {\r\n            List<SearchRank> searchRanks = findSearchRanks();\r\n            return SearchRankResponse.listOf(searchRanks);\r\n        }\r\n    \r\n        @CacheEvict(value = SEARCH_RANKS_CACHE_VALUE, key = \"'SearchRanksKey'\")\r\n        public void removeSearchRanksCache() {\r\n            log.info(\"cleared cache for search rankings request\");\r\n        }\r\n    \t\r\n    \t\t// ...\r\n    }\r\n    ```\r\n\r\n<br/>\r\n\r\n## 마무리\r\n\r\n- Spring Cache에 대해 대략적으로 알아보았다. Spring에서 제공하는 이러한 추상화 기술(PSA)을 통해 트랜잭션을 사용하는 것과 마찬가지로 간단하게 캐싱을 적용할 수가 있었다.\r\n- 위에서 설명한 것보다 더 많은 애노테이션 속성이 존재하기 때문에 필요한 경우 공식 문서를 참고하는 것이 좋을 듯 하다.\r\n- 프로젝트에서 사용한 캐싱 전략 및 설정, 코드에 대한 설명은 다음 포스트에 적도록 하겠다.\r\n\r\n<br/>\r\n\r\n## 참고\r\n\r\n- [https://docs.spring.io/spring-framework/docs/4.3.x/spring-framework-reference/html/cache.html](https://docs.spring.io/spring-framework/docs/4.3.x/spring-framework-reference/html/cache.html)\r\n- [https://12bme.tistory.com/550](https://12bme.tistory.com/550)\r\n- [https://sunghs.tistory.com/132](https://sunghs.tistory.com/132)\r\n- [https://jaehun2841.github.io/2018/11/07/2018-10-03-spring-ehcache/#spring-cache-annotation](https://jaehun2841.github.io/2018/11/07/2018-10-03-spring-ehcache/#spring-cache-annotation)","excerpt":"캐싱이라는 용어는 프로그래밍에서 자주 등장하게 된다.\n캐싱이란 '성능 향상을 위해 사용이 많은 데이터를 별도 공간에 일시적으로 저장하여 필요할 때마다 데이터를 가져오는 기술'이다.\n메모리, 네트워크 등 다양한 곳에서 사용하게 되는데 Spring에서도…","fields":{"slug":"/spring-cache/"},"frontmatter":{"date":"Dec 04, 2021","title":"Spring Cache 살펴보기","tags":["spring","cache"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n보통 로깅을 위해서 System.out.println() 보다는 logback 이나 log4j 같은 로깅 프레임워크를 사용하는 것이 좋다고 한다.\r\n\r\n로깅 프레임워크를 사용하면 로깅 레벨을 설정할 수 있다는 점이 좋다고는 알고 있지만 성능상으로도 더 좋다고 하는데 그게 진짜일까?\r\n\r\n둘 다 입출력을 위해 i/o 작업이 발생하는데 왜 System.out.println()이 성능상 떨어진다고 할까? 한번 알아보도록 하자.\r\n\r\n---\r\n\r\n## System.out.println()\r\n\r\n- System.out.println 은 정확히 코드를 열어보게 되면\r\n  System이라는 final 클래스에 있는 out이라는 변수명을 가진 PrintStream 객체의 println 이라는 메소드를 뜻한다.\r\n\r\n- println이라는 메소드는 오버로딩이 많이 되어있는 메소드인데 보는바와 같이 동기화를 위해 synchronized 키워드를 많이 사용을 하고 라인 단위로 flush를 한다.\r\n\r\n![Untitled (25)](https://user-images.githubusercontent.com/62014888/145754156-4426b0ec-dbb9-4acf-a5f5-8d28afa567ef.png)\r\n\r\n![Untitled (26)](https://user-images.githubusercontent.com/62014888/145754160-44600f2a-2b96-4a21-ada3-90c3fa2843c6.png)\r\n\r\n- 이는 곧 동기화를 위해 오버헤드가 많이 발생한다는 뜻이다.\r\n  즉 작업이 순차적으로 진행되어야 하기에 콘솔에 출력을 완료할 때까지 다음 작업은 block된 상태로 대기하고 있어야한다.\r\n\r\n<br/>\r\n\r\n## Logger\r\n\r\n- logger로 사용되는 다양한 로깅 프레임워크가 존재한다. 기본적으로 SLF4J라는 다양한 로깅 프레임워크들에 대한 공용 인터페이스(Facade)가 존재하고 이들의 구현체인 log4j, logback, log4j2 등의 로깅 프레임워크가 존재한다.\r\n- 예시로 들 것은 logback이며 logger를 사용하여 콘솔에 로그를 출력하기로 했다.\r\n- logback에서는 콘솔에 출력하기 위해 ConsoleAppender를 사용하게 되는데 해당 클래스의 모습이다.\r\n\r\n![Untitled (27)](https://user-images.githubusercontent.com/62014888/145754208-5d07a394-f1a4-4aa7-bea1-7dc71fd8aa14.png)\r\n\r\n- 근데 뭔가 이상하지 않은가? 해당 클래스의 주석에도 그렇고 공식 문서에도 그렇고 콘솔에 출력하기 위해 기본적으로 System.out을 사용한다고 적혀있다.\r\n\r\n![Untitled (28)](https://user-images.githubusercontent.com/62014888/145754215-83bd9002-a633-4b34-bab1-0ccffccb7f1e.png)\r\n\r\n- 실제로 ConsoleTarget이라는 enum도 살펴보면 System.out.write를 사용하는 모습을 볼 수 있다.\r\n- 이걸 보고 \"System.out.println()을 사용하는 것은 logger를 사용해 로깅하는 것에 비해 성능상 좋지 않아!\" 라고 무조건적으로 생각하는 것은 조금 잘못되었다라는 것을 알게 되었다.\r\n- 결국은 둘 다 System.out을 사용하여 i/o 작업이 발생하는 것이며 println의 경우 synchronized 키워드가 더 붙여져 있는 것일뿐 성능상으로 크게 차이가 없다고 추측이 된다.\r\n- 실제로 for문으로 출력 테스트를 해보았을 때 logger를 사용한 출력 시간이 더 오래걸렸다.\r\n- 그렇다면 왜 성능에 관해서 이야기가 나오는 걸까?\r\n    - 결론적으로 비동기 로깅을 사용하면 성능이 향상된다.\r\n    - 특히 파일로 로그를 남길 때 비동기 로깅을 적용시킬 수가 있는데 적용하게 되면 로그 발생과 로그 쓰기를 분리시키기에 로깅 메소드를 호출하는 시점에 i/o 작업이 바로 수행되지 않아 성능이 향상된다.\r\n- Baeldung 블로그나 스택오버플로우를 검색해봐도 System.out.println() vs logger에서 성능 이야기는 전혀 나오지 않았다. 나오더라도 비동기와 같이 나오는 경우만 볼 수 있었다.\r\n\r\n<br/>\r\n\r\n\r\n## 그렇다면 언제 무엇을 쓸까?\r\n\r\n- 당연히 프로젝트를 진행하는 상황이라면 디버깅을 위해서 또는 로그를 남기기 위해서 logger를 사용해야한다.\r\n- System.out.println()은 사용하긴 편하나 콘솔에만 출력이 가능하고 날짜, 시간을 출력하지 않아 기록을 위한 로그용으로 불편하다.\r\n  또한 출력되는 메시지를 제어할 수 없다.\r\n- logger는 로깅 레벨을 설정하여 필요한 로그만 출력할 수 있다.\r\n  또한 로그 내역을 별도의 파일에 저장할 수 있다. 파일로 저장할 경우 프레임워크에 의해 파일 유지 기간, 용량 등도 설정이 가능하여 자동화된 관리가 가능하다.\r\n  원하는 패턴으로 출력이 되도록 설정할 수도 있다.\r\n- System.out.println()을 사용하여 디버깅하는 습관을 들이게 되면 프로젝트를 진행하다 깜빡하고 코드를 삭제하지 못한 채로 운영 서버 코드로 반영되는 경우도 있고하니 logger를 사용하여 디버깅하는 습관을 들이도록 하자!\r\n\r\n<br/>\r\n\r\n\r\n## 참고\r\n\r\n- [https://lob-dev.tistory.com/entry/Logging-slf4j-Logback-Framework](https://lob-dev.tistory.com/entry/Logging-slf4j-Logback-Framework)\r\n- [https://ckddn9496.tistory.com/81?category=428336](https://ckddn9496.tistory.com/81?category=428336)\r\n- [https://stackoverflow.com/questions/31869391/what-is-the-difference-between-java-logger-and-system-out-println](https://stackoverflow.com/questions/31869391/what-is-the-difference-between-java-logger-and-system-out-println)\r\n- [https://www.baeldung.com/java-system-out-println-vs-loggers](https://www.baeldung.com/java-system-out-println-vs-loggers)\r\n- [https://xlffm3.github.io/spring & spring boot/async-logger-performance/](https://xlffm3.github.io/spring%20&%20spring%20boot/async-logger-performance/)","excerpt":"보통 로깅을 위해서 System.out.println() 보다는 logback 이나 log4j 같은 로깅 프레임워크를 사용하는 것이 좋다고 한다. 로깅 프레임워크를 사용하면 로깅 레벨을 설정할 수 있다는 점이 좋다고는 알고 있지만 성능상으로도 더 좋…","fields":{"slug":"/sout-vs-logger/"},"frontmatter":{"date":"Dec 01, 2021","title":"System.out.println() vs Logger","tags":["java","logger"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n## 혼잡 제어(Congestion Control)\r\n\r\n- 혼잡 상황이 발생하면 네트워크 자원이 낭비되므로 혼잡 상황을 최소화 하기 위한 기법\r\n    - 데이터의 양이 라우터가 처리할 수 있는 양을 초과하면 초과된 데이터는 라우터가 처리하지 못한다.\r\n      송신측에서 라우터가 처리하지 못한 데이터를 손실 데이터로 간주하고 계속 재전송하게 되므로 네트워크는 더욱 더 혼잡하게 된다.\r\n- 흐름 제어\r\n    - 송신측과 수신측의 데이터 처리 속도 차이를 해결하기 위한 기법\r\n    - 송신측의 데이터 전송량 제어\r\n- 혼잡 제어\r\n    - 송신측의 데이터 전달과 네트워크 상의 데이터 처리 속도 차이를 해결하기 위한 기법\r\n    - 송신측의 데이터 전송 속도 제어\r\n\r\n<br/>\r\n\r\n## 혼잡 제어 방법\r\n\r\n![Untitled - 2021-12-18T133859 551](https://user-images.githubusercontent.com/62014888/146629187-ddf0d5ae-c589-469a-99ca-f9a688282738.png)\r\n\r\n### AIMD (Additive Increase / Multiplicative Decrease)\r\n\r\n- 합 증가 / 곱 감소 방식.\r\n- 처음에 패킷을 하나씩 보내고 문제없이 도착하면 윈도우의 크기(단위 시간 내에 보내는 패킷의 수)를 1씩 증가시켜가며 전송한다.\r\n- 만약 전송에 실패하면 윈도우 크기를 반으로 줄임.\r\n- 공평한 방식으로, 여러 호스트가 한 네트워크를 공유하고 있으면 나중에 집입하는 쪽이 처음에는 불리하지만, 시간이 흐르면 평형 상태로 수렴한다.\r\n- 윈도우 크기를 너무 조금씩 늘리기 때문에 모든 대역을 활용하여 제대로 된 속도로 통신하기까지 시간이 오래 걸린다.\r\n\r\n### Slow Start\r\n\r\n- 윈도우의 크기를 1, 2, 4, 8... 과 같이 2배씩 증가시킨다.\r\n- 혼잡이 감지되면 윈도우의 크기를 1로 줄여버림.\r\n- 시간이 지날수록 AIMD보다 빠르게 윈도우 크기를 증가시킨다.\r\n- 처음에는 네트워크 수용량을 예상할 수 있는 정보가 없지만, 한번 혼잡 현상이 발생하고 나면 네트워크 수용량을 어느 정도 예상할 수 있다.\r\n- 그러므로 혼잡 현상이 발생하였던 윈도우 크기의 절반까지는 이전처럼 지수 함수 꼴로 증가시키고 이후부터는 1씩 증가시킨다.\r\n    - 이를 임계점(sshthresh, Slow Start Threshold)이라고 함. 이 임계점은 윈도우 사이즈가 기하급수적으로 증가하는 것을 방지하기 위해 설정하는 것으로 임계점부터 윈도우 크기는 1씩 증가한다.\r\n\r\n### Fast Retransmit(빠른 재전송)\r\n\r\n![Untitled - 2021-12-18T133902 669](https://user-images.githubusercontent.com/62014888/146629188-08a5576b-b2f8-4a27-a8bc-37d048e52ab9.png)\r\n\r\n- Fast Restransmit은 TCP 혼잡 제어에 추가된 정책.\r\n- 먼저 도착해야 할 패킷이 도착하지 않고 다음 패킷이 도착한 경우에도 ACK 패킷을 보냄.\r\n- 순서대로 잘 도착한 마지막 패킷의 다음 순번을 ACK 패킷에 실어보내게 되므로 송신측에서는 순번이 중복된 것을 알게 됨.\r\n- 이것을 감지하여 중복된 순번의 패킷을 3개 받으면 타임아웃 전에 문제가 되는 순번의 패킷을 즉시 재전송해줌.\r\n- 이런 현상이 일어나면 혼잡 현상이 발생한 것이므로 윈도우 크기를 줄임.\r\n\r\n### Fast Recovery (빠른 회복)\r\n\r\n- 혼잡 상태가 되면 윈도우 크기를 1로 줄이지 않고 반으로 줄인 후 선형 증가\r\n- 혼잡 상태를 한 번 겪고 나서부터는 AIMD 방식으로 동작.\r\n\r\n<br/>\r\n\r\n## 혼잡 제어 정책\r\n\r\nTCP는 혼잡 제어를 위하여 다양한 기법을 혼합하여 사용하고 있으며 가장 오래되고 기본이 되는 2가지 방식이 있음.\r\n\r\n### TCP Tahoe\r\n\r\n![Untitled - 2021-12-18T133906 384](https://user-images.githubusercontent.com/62014888/146629189-4cbf9558-8a18-4155-a804-8c28ad72e937.png)\r\n\r\n- 처음에는 Slow Start 방식으로 사용하다가 임계점에 도달하면 AIMD 방식 사용\r\n- 그러다 3 ACK 순번 중복 (중간 패킷 유실) 이나 타임아웃이 발생하면 혼잡이라고 판단하여 임계점은 혼잡 발생한 윈도우 크기 절반으로, 윈도우 크기는 1로 줄임.\r\n- 혼잡 이후 Slow Start 구간에서 윈도우 크기를 키울 때 너무 오래걸림.\r\n\r\n### TCP Reno\r\n- Tahoe와 마찬가지로 Slow Start로 시작해서 임계점 이후에는 AIMD 방식으로 변경\r\n- 단, 3 ACK 중복과 타임아웃을 구분함.\r\n- 3 ACK 중복이 발생하면 Fast Recovery 방식을 사용\r\n    - 윈도우 크기를 1로 줄이는 것이 아니라 반으로 줄인 후 윈도우 크기를 선형적으로 증가시킴\r\n    - 임계점은 줄어든 윈도우 값으로 설정\r\n- 타임아웃이 발생하면 Tahoe와 마찬가지로 윈도우 1로 줄이고 Slow Start 진행\r\n    - 임계점은 반으로 줄인다.","excerpt":"혼잡 제어(Congestion Control) 혼잡 상황이 발생하면 네트워크 자원이 낭비되므로 혼잡 상황을 최소화 하기 위한 기법 데이터의 양이 라우터가 처리할 수 있는 양을 초과하면 초과된 데이터는 라우터가 처리하지 못한다.\n송신측에서 라우터가 처…","fields":{"slug":"/congestion-control/"},"frontmatter":{"date":"Oct 23, 2021","title":"혼잡 제어(Congestion Control)란?","tags":["network"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n## 1. 교착상태 특징\r\n\r\n- 멀티 프로그래밍 환경에서는 여러 프로세스들이 한정된 자원을 사용하기 위해 경쟁하고 있으며, 한 프로세스가 자원을 요청했을 때 해당 자원이 사용 불가능한 상태라면 교착상태(Deadlock)가 발생하게 된다.\r\n  즉, 요청한 자원을 다른 프로세스가 점유하고 있고, 점유하고 있는 프로세스도 다른 자원에 대해 대기 상태에 있기 때문에 두 프로세스가 대기 상태에서 벗어날 수 없는 상황을 교착상태라고 한다.\r\n\r\n![Untitled (95)](https://user-images.githubusercontent.com/62014888/146518312-d72c8294-b6eb-4d37-8714-e99488ca800c.png)\r\n\r\n### 교착상태 발생 조건\r\n\r\n- 교착상태는 다음과 같은 네 가지 조건을 모두 성립해야 발생한다.\r\n  (하나라도 성립하지 않으면 교착상태 문제 해결 가능)\r\n1. 상호 배제(Mutual Exclusion)\r\n    - 한 번에 프로세스 하나만 해당 자원을 사용할 수 있다. 사용 중인 자원을 다른 프로세스가 사용하려면 요청한 자원이 해제될 때까지 기다려야 한다.\r\n2. 점유 대기(Hold-and-wait)\r\n    - 자원을 최소한 하나 보유하고, 다른 프로세스에 할당된 자원을 점유하기 위해 대기하는 프로세스가 존재해야 한다.\r\n3. 비선점(No preemption)\r\n    - 이미 할당된 자원을 강제로 빼앗을 수 없다.\r\n4. 순환 대기(Circular wait)\r\n    - 대기 프로세스의 집합이 순환 형태로 자원을 대기하고 있어야 한다.\r\n\r\n\r\n### 자원 할당 그래프\r\n\r\n![Untitled (96)](https://user-images.githubusercontent.com/62014888/146518397-28c949b5-7080-43af-9357-3440ab419c44.png)\r\n\r\n- Vertex\r\n    - 동그라미로 그려진 P1, P2, P3는 프로세스를 의미함.\r\n    - 사각형으로 그려진 R1, R2, R3, R4는 자원을 의미함.\r\n    - 각 사각형 안의 점들은 할당 가능한 자원 개수를 의미함.\r\n- Edge\r\n    - 자원 → 프로세스 (이 프로세스가 해당 자원에게 할당되었다.)\r\n    - 프로세스 → 자원 (프로세스가 자원을 요청하고 있으며 아직  획득하진 못하였다)\r\n\r\n- 그래프에서 사이클이 없으면 교착상태가 아니다.\r\n- 그래프에서 사이클이 있으면\r\n    - 자원당 개수가 하나라면 교착상태\r\n    - 자원당 개수가 여러 개라면 교착상태 가능성이 있음\r\n\r\n- 사이클이 있고 교착상태인 경우\r\n\r\n    ![Untitled (97)](https://user-images.githubusercontent.com/62014888/146518402-4a2d487d-9f10-4db3-a93b-e94073c40d83.png)\r\n\r\n- 사이클이 있지만 교착상태가 아닌 경우\r\n\r\n    ![Untitled (98)](https://user-images.githubusercontent.com/62014888/146518405-a64eed6a-a336-476b-81aa-fb22ab1d6b2c.png)\r\n\r\n<br/>\r\n\r\n## 2. 교착상태 처리 방법\r\n\r\n### 교착상태 예방\r\n\r\n- 교착상태 예방은 교착상태가 되지 않도록 교착상태 발생 조건 네 가지 중 하나라도 발생하지 않게 방지하는 방법이다.\r\n1. 상호 배제(Mutual Exclusion) 조건 방지\r\n    1. 상호 배제가 일어나는 경우는 공유가 불가능한 자원에 의해서임.\r\n    2. 여러 프로세스가 자원에 대한 동시 접근을 보장받으면 상호 배제가 깨어지게 되어 교착상태를 예방할 수 있음.\r\n    3. 어떤 자원들은 근본적으로 공유가 불가능하기 때문에 교착상태를 예방하기 어렵다고 할 수 있음.\r\n2. 점유 대기(Hold-and-wait) 조건 방지\r\n    1. 점유 대기 조건을 부정하기 위해서는 프로세스가 작업을 수행하기 전에 필요한 자원들을 모두 요청하고 획득해야함.\r\n    2. 프로세스 하나를 실행하는데 필요한 모든 자원을 먼저 다 할당하고 끝나면 다른 프로세스에 자원을 할당하는 것.\r\n    3. 프로세스가 자원을 전혀 갖고 있지 않을 때만 자원 요청을 허용해주는 방법도 있다.\r\n    4. 자원의 이용률이 낮아지고 기아 상태가 발생할 수 있다.\r\n3. 비선점(No preemption) 조건 방지\r\n    1. 모든 자원에 대한 선점을 허용한다.\r\n    2. 프로세스가 할당받을 수 없는 자원을 요청하는 경우, 기존에 가지고 있던 자원을 모두 반납하고 새 자원과 이전 자원을 얻기 위해 대기하도록 한다.\r\n4. 순환 대기(Circular wait) 조건 방지\r\n    1. 자원에 고유한 번호를 할당하고 번호 순서대로 자원을 요구하도록 한다.\r\n\r\n\r\n### 교착상태 회피\r\n\r\n- 교착상태 회피는 자원이 어떻게 요청될지에 대한 정보를 미리 파악하고 회피 알고리즘을 통해 교착상태가 일어나지 않도록 자원을 할당하는 방식.\r\n    - 조건을 차단하는 것이 아니라, 정보를 미리 파악하고 일어나지 않는 방향으로 자원을 할당하는 것.\r\n- 프로세스 수, 자원 종류 수가 고정되어 있어야 하고 프로세스가 요구하는 자원 및 최대 자원의 수를 알아야 하며 반드시 자원을 사용 후 반납해야 한다는 가정들이 필요하기 때문에 현실성이 부족함.\r\n- 자원 요청이 있을 때마다 교착상태 회피 알고리즘을 사용한다는 것은 상당한 오버헤드임.\r\n\r\n1. 안정 상태(Safe State)\r\n\r\n    ![Untitled (99)](https://user-images.githubusercontent.com/62014888/146518410-e6a24d09-bae2-4c5d-a429-96cb9054517a.png)\r\n    \r\n    1. 안정 순서(Safe Sequence)를 찾을 수 있는 경우.\r\n        - 안정 순서란 프로세스들이 요청한 모든 자원들을 교착상태 발생 없이 할당할 수 있는 순서를 의미함.\r\n    2. 즉 프로세스가 순서만 잘 조정해주면 교착상태가 일어나지 않는 상태를 의미함.\r\n    3. 불안정 상태(Unsafe State)\r\n        - 안정 순서를 찾을 수 없는 경우이며 불안정 상태라고 무조건 교착 상태가 발생하는 것은 아니다.\r\n\r\n        ![Untitled (100)](https://user-images.githubusercontent.com/62014888/146518416-238d2d2c-a380-4cc5-aa95-e624250f5191.png)\r\n    \r\n        - 할당 가능한 자원 수가 12개일 때 안정 순서는 P0 → P1 → P2 → P1 → P2 → P0가 된다.\r\n\r\n        ![Untitled - 2021-12-17T180447 364](https://user-images.githubusercontent.com/62014888/146518422-902435e2-12c1-4a53-b133-c592d1fb3591.png)\r\n    \r\n        - P1이 작업을 끝마친 후 4개의 자원을 P0, P2 어느쪽으로도 할당하든 작업을 마칠 수 없다.\r\n        - 어느 한 쪽이 자원을 선점하지 않는 한 무한히 대기하게 되므로 교착상태가 발생하게 된다.\r\n        - 즉, 처음 세 개의 프로세스에게 5, 2, 3개의 자원을 할당하는 순간 불안정 상태가 됨.\r\n\r\n2. 자원 할당 그래프 알고리즘(Resource-Allocation Graph Algorithm)\r\n\r\n    ![Untitled - 2021-12-17T180517 190](https://user-images.githubusercontent.com/62014888/146518475-e2474de6-ffaf-4e7a-85c6-fbdf04860910.png)\r\n\r\n    ![Untitled - 2021-12-17T180519 016](https://user-images.githubusercontent.com/62014888/146518486-4359524f-d294-4098-84e0-4eeccae31d2a.png)\r\n\r\n    1. 자원이 하나일 때 사용하는 방법으로 자원 할당 그래프를 이용해 교착상태를 회피하는 것.\r\n    2. 자원 할당 그래프에 예약 간선(claim edge)를 추가한다.\r\n        - 예약 간선이란 향후 요청할 수 있는 자원을 가리키는 점선으로 표시된 간선을 뜻함.\r\n    3. 프로세스 시작 전에 모든 예약 간선들을 자원 할당 그래프에 표시한다.\r\n    4. 예약 간선으로 설정한 자원에 대해서만 요청할 수 있고 사이클이 형성되지 않을 때만 자원을 할당 받는다.\r\n    5. 사이클 생성 여부를 조사할 때 O(n^2) 시간이 걸린다.\r\n\r\n3. 은행원 알고리즘(Banker's Algorithm)\r\n    1. 자원이 여러 개일 때 은행원 알고리즘으로 교착상태를 회피할 수 있음.\r\n    2. 프로세스 시작 시 자신이 필요한 각 자원의 최대(Max) 개수를 미리 선언한다.\r\n    3. 각 프로세스에서 자원 요청이 있을 때 요청을 승인하면 시스템이 안정 상태로 유지되는 경우에만 자원을 할당함.\r\n    4. 불안정 상태가 예상되면 다른 프로세스가 끝날 때까지 대기를 한다.\r\n\r\n<br/>\r\n\r\n## 3. 교착상태 탐지 & 회복\r\n\r\n- 교착상태 예방이나 회피 알고리즘을 사용하지 않는 시스템, 교착상태가 발생할 수 있는 환경이라면 두 알고리즘을 지원해야 한다.\r\n    - 교착상태가 발생했는지 결정하기 위해 시스템 상태를 검사하는 알고리즘\r\n    - 교착상태로부터 회복하는 알고리즘\r\n- 탐지와 회복 알고리즘 방법은 필요한 정보를 유지하고 탐지 알고리즘을 실행시키기 위한 실행 시간, 비용, 교착상태로부터 회복할 때 내재하는 가능한 손실을 포함하는 오버헤드가 필요함.\r\n\r\n### 교착상태 탐지\r\n\r\n- 자원이 하나일 때는 자원 할당 그래프를 변형하여 대기 그래프를 그린다.\r\n    - 대기 그래프에서 사이클을 감지하면, 시스템의 교착상태 가능성을 보고하게 된다.\r\n- 자원이 여러 개라면 은행원 알고리즘처럼 시시각각 내용이 달라지는 자료구조를 사용한다.\r\n- 탐지 알고리즘은 다음과 같을 때 사용한다.\r\n    - 자원을 요청했는데 즉시 할당되지 못하고 있는 경우\r\n    - 일반적으로 CPU 사용률이 40% 이하로 떨어지는 경우\r\n\r\n\r\n### 교착상태 회복\r\n\r\n- 교착상태 일으킨 프로세스를 종료하거나 할당된 자원을 해제시켜 회복시키는 방법이 있다.\r\n- 프로세스 종료 방법\r\n    - 교착상태의 프로세스를 모두 중지한다.\r\n    - 교착상태가 제거될 때까지 하나씩 프로세스를 중지한다.\r\n- 자원 선점 방법\r\n    - 교착상태의 프로세스가 점유하고 있는 자원을 선점해 다른 프로세스에게 할당한다(해당 프로세스를 일시정지 시킨다)\r\n    - 우선 순위가 낮은 프로세스나 수행 횟수가 적은 프로세스 위주로 프로세스 자원을 선점한다.\r\n\r\n<br/>\r\n\r\n## 4. 교착상태 무시\r\n\r\n- Unix와 Windows를 포함한 대부분의 운영체제가 이 방법을 사용한다.\r\n- 교착상태 무시란 말 그대로 교착상태에 대해 아무런 대응도 하지 않는 것.\r\n- 교착상태는 자주 일어나지 않는데다가 예방 및 처리 비용이 많이 들기 때문에 이 방법은 꽤나 경제적일 수 있다.\r\n    - 발생하면 재부팅하면 된다.","excerpt":"1. 교착상태 특징 멀티 프로그래밍 환경에서는 여러 프로세스들이 한정된 자원을 사용하기 위해 경쟁하고 있으며, 한 프로세스가 자원을 요청했을 때 해당 자원이 사용 불가능한 상태라면 교착상태(Deadlock)가 발생하게 된다.\n즉, 요청한 자원을 다른…","fields":{"slug":"/deadlock/"},"frontmatter":{"date":"Oct 23, 2021","title":"교착상태(Deadlock)란?","tags":["os"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n공유된 자원에 여러 프로세스들이 동시에 접근했을 경우 데이터 무결성에 문제가 발생할 수 있다.\r\n\r\n이러한 문제를 해결하기 위해 동기화(Synchronization) 개념이 도입되었다. 즉 공유 데이터에 대하여 동시에 접근하려 할 때, 처리 순서에 상관없이 원하는 결과를 얻기 위함이다. 이를 데이터 일관성(Data Consistency)라고 한다.\r\n\r\n## 1. 경쟁 상태(Race Condition)\r\n\r\n- 공유된 자원에 대해 여러 프로세스가 동시에 접근을 시도할 때, 타이밍이나 순서 등이 결과값에 영향을 줄 수 있는 상태를 의미한다.\r\n    - 동시에 접근할 때 데이터의 일관성을 해치는 결과가 나타날 수 있음.\r\n- OS에서 Race Condition이 발생하는 경우 세 가지\r\n    1. 커널 안의 코드를 수행하는 중 인터럽트가 발생하는 경우\r\n\r\n        ![Untitled (92)](https://user-images.githubusercontent.com/62014888/146517086-3c1f061d-0b03-4e9c-af62-2ffadab5aa6c.png)\r\n\r\n        - 커널 안에 있는 변수를 증가시키는 중 인터럽트가 발생하고 인터럽트 처리 함수에서 해당 변수를 감소시킬 때 변수의 결과값에 문제가 생김.\r\n        - 사용자 프로세스는 해당 프로세스의 할당받은 메모리에만 존재할 수 있지만 커널은 서로 다른 프로세스가 공유하기 때문에 발생한다.\r\n        - 해결법: 작업을 할 때 인터럽트가 발생하더라도 작업이 완료된 후 인터럽트가 발생하도록 처리 순서를 부여한다.\r\n    2. 프로세스가 시스템 콜을 호출하여 커널 모드로 수행 중일 때 문맥교환이 발생하는 경우\r\n\r\n        ![Untitled (93)](https://user-images.githubusercontent.com/62014888/146517090-fb8e5d52-b95e-4cd6-af76-9bc1c6354cd9.png)\r\n\r\n        - 사용자 프로세스가 시스템 콜을 호출하면 커널 모드로 커널 안에 존재하는 변수를 수정할 수 있다. 할당된 CPU 사용기간이 만료되면 문맥교환이 발생하는데 새롭게 CPU를 할당받은 사용자 프로세스가 이전 프로세스와 동일한 시스템 콜을 호출하여 수정하고 있던 변수에 대한 작업을 수행할 때 결과적으로 변수 값에 문제가 발생하는 경우\r\n        - 해결법: 사용자 프로세스가 시스템 콜을 호출하여 커널 모드의 작업을 완료한 후 종료될 때 문맥교환이 발생할 수 있게 한다. 즉, 커널 모드에 있다면 CPU 제어권을 빼앗지 않는다.\r\n    3. 여러 프로세스의 공유 메모리 내의 커널 데이터에 접근하는 경우\r\n\r\n        ![Untitled (94)](https://user-images.githubusercontent.com/62014888/146517093-f43885e7-c251-4401-8e71-22bcc02f5013.png)\r\n\r\n        - CPU가 여러 개인 시스템에서 공유 메모리 속 데이터를 여러 프로세스가 접근할 때 발생하는 경우\r\n        - 해결법: 커널 안 데이터에 접근할 때 lock/unlock을 걸어 매 순간 데이터에 접근하는 프로세스는 1개로 한정한다.\r\n\r\n\r\n<br/>\r\n\r\n## 2. 임계영역 문제(The Critical-Section Problem)\r\n\r\n- 임계영역이란 OS에서 여러 프로세스가 데이터를 공유하면서 수행될 때, 각 프로세스에서 공유 데이터를 액세스하는 프로그램 코드 부분을 의미한다.\r\n    - 공유 자원의 독점을 보장해주는 역할을 수행함.\r\n- 임계영역 문제를 해결하기 위한 기본 조건 세 가지\r\n    1. 상호 배제(Mutual exclusion)\r\n        - 어떤 프로세스가 임계영역에서 실행 중이라면, 다른 프로세스는 임계영역에 접근할 수 없다.\r\n    2. 진행(Progress)\r\n        - 임계영역에서 실행 중인 프로세스가 없다면, 다른 프로세스가 접근할 수 있도록 한다.\r\n    3. 한정된 대기(Bounded Waiting)\r\n        - 다른 프로세스의 기아(Starvation)를 방지하기 위해, 한번 임계영역에 들어간 프로세스는 다음 번 임계영역에 들어갈 때 제한을 두어야 한다.\r\n\r\n<br/>\r\n\r\n## 3. 피터슨의 해결안(Peterson's Solution)\r\n\r\n- 임계영역 문제를 해결하는 기본 조건 세 가지를 충족하는 고전적 SW 기반 해결책으로 피터슨의 해결안이 있다.\r\n    - 이 해결방안은 임계영역과 나머지 영역을 오가며 실행하는 두 개의 프로세스로 한정한다.\r\n    - 두 프로세스는 아래의 두 데이터 항목을 공유한다.\r\n\r\n        ```java\r\n        int turn; //임계영역으로 진입할 순번\r\n        boolean flag[2]; //프로세스가 임계영역으로 진입할 준비 되었음을 의미\r\n        ```\r\n\r\n    - turn == i 이면 프로세스 Pi가 임계영역으로 실행될 수 있고 flag[i]가 true이면 Pi가 임계영역으로 진입할 준비 됨을 의미한다.\r\n    - 프로세스 Pi의 실행 구조\r\n\r\n        ```java\r\n        do {\r\n        \tflag[i] = true;\r\n        \tturn = j;\r\n        \twhile (flag[j] && turn == j);\r\n        \t//critical section\r\n        \tflag[i] = false;\r\n        \t//remainder section \r\n        } while(true);\r\n        ```\r\n\r\n        1. flag[i] = true에 의해 프로세스 Pi는 임계영역에 들어갈 준비가 됐다는 것을 알려주고 turn = j에 의해 프로세스 Pj가 실행될 차례라는 것을 알려줌.\r\n        2. flag[j] = true이고 turn == j 이면 프로세스 Pj가 임계영역에 들어갈 차례이므로, Pi는 무한 루프에 들어가 기다리게 됨.\r\n        3. 프로세스 Pj가 임계영역 작업을 마치고 flag[j] = false가 되면, 프로세스 Pi는 무한루프를 빠져나와 임계영역에 들어가게 됨.\r\n        4. 프로세스 Pi가 작업 완료 후 flag[i] = false로 설정하면, 다른 프로세스가 임계영역을 사용할 수 있게 됨.\r\n- 피터슨의 해결안이 세 가지 조건을 만족하는지 확인해보자.\r\n    1. 상호 배제\r\n        - flag와 turn을 이용해 한 개의 프로세스만 임계영역에 접근할 수 있도록 하였다.\r\n    2. 진행\r\n        - 하나의 프로세스가 임계영역에서 빠져나오면서 flag를 false로 만들어 버리고 다른 프로세스가 접근이 가능하도록 한다.\r\n    3. 한정된 대기\r\n        - 마찬가지로 하나의 프로세스가 임계영역을 빠져나오며 flag를 false로 만드니 다른 프로세스가 실행될 기회가 적어도 한번은 주어지게 된다.\r\n- 피터슨의 알고리즘의 문제점은 while (flag[j] && turn == j); 부분이다.\r\n    - 이 무한루프에 CPU 자원을 쓰고 있다보니 운영체제가 CPU를 효율적으로 활용하지 못하여 문제가 발생하는데 이를 Busy waiting이라고 한다.\r\n\r\n<br/>\r\n\r\n## 4. 세마포어(Semaphore) & 뮤텍스(Mutex)\r\n\r\n세마포어와 뮤텍스는 공유 자원 관리를 위해 상호 배제를 달성하는 기법들이다.\r\n\r\n### 1. 세마포어(Semaphore)\r\n\r\n- 세마포어는 멀티 프로그래밍 환경에서 공유 자원에 대한 접근을 제한하는 방법으로 현재 공유 자원에 접근할 수 있는 쓰레드, 프로세스의 수를 나타내는 값을 두어 상호 배제를 달성하는 기법이다.\r\n- 세마포어 P, V 연산\r\n    - P: 임계영역 들어가기 전에 수행 (프로세스 진입 여부를 자원의 개수(S)를 통해 결정)\r\n    - V: 임계영역에서 나올 때 수행 (자원 반납 알림, 대기 중인 프로세스를 깨우는 신호)\r\n    - 구현 방법\r\n\r\n        ```java\r\n        P(S);\r\n        //critical section\r\n        V(S); \r\n        ```\r\n\r\n        ```java\r\n        procedure P(S)\r\n        \twhile S=0 do wait\r\n        \tS := S-1\r\n        end P\r\n        \r\n        procedure V(S)\r\n        \tS := S+1\r\n        end V\r\n        ```\r\n\r\n    - 흐름\r\n\r\n      최초 S값은 1이고, 현재 해당 구역을 수행할 프로세스가 A, B 있다고 가정한다. (2개 이상도 가능)\r\n\r\n        1. 먼저 도착한 A가 P(S)를 실행하여 S를 0으로 만들고 임계영역에 들어감\r\n        2. 그 뒤에 도착한 B가 P(S)를 실행하지만 S가 0이므로 대기 상태\r\n        3. A가 임계영역 수행을 마치고 V(S)를 실행하면 S는 다시 1이 됨\r\n        4. B는 P(S)에서 while문을 빠져나올 수 있고, 임계영역으로 들어가 수행함.\r\n\r\n\r\n### 2. 뮤텍스(**Mu**tual Exclusion)\r\n\r\n- 임계영역을 가진 쓰레드들의 실행시간이 서로 겹치지 않고 단독으로 실행되게 하는 기술로 해당 접근을 조율하기 위해 lock과 unlock을 사용한다.\r\n    - lock: 현재 임계영역에 들어갈 권한을 얻어옴 (만약 다른 프로세스/쓰레드가 임계영역 수행 중이면 종료할 때까지 대기)\r\n    - unlock: 현재 임계영역을 모두 사용했음을 알림 (대기 중인 다른 프로세스/쓰레드가 임계영역에 진입할 수 있음)\r\n- 구현 방법\r\n\r\n    ```java\r\n    lock();\r\n    // critical section\r\n    unlock();\r\n    ```\r\n\r\n    ```java\r\n    mutex = 1;\r\n    \r\n    void lock() {\r\n    \twhile (mutex != 1) {\r\n    \t}\r\n    \tmutex = 0;\r\n    }\r\n    \r\n    void unlock() {\r\n    \tmutex = 1;\r\n    }\r\n    ```\r\n\r\n<br/>\r\n\r\n### 세마포어와 뮤텍스의 차이\r\n\r\n- 세마포어는 공유 자원에 세마포어의 변수만큼의 프로세스, 쓰레드가 접근할 수 있다.\r\n  반면, 뮤텍스는 오직 1개만의 프로세스, 쓰레드만 접근할 수 있다.\r\n- 현재 수행 중인 프로세스가 아닌 다른 프로세스(wait 하지 않는 프로세스)가 세마포어를 해제할 수 있다.\r\n  반면, 뮤텍스는 lock을 획득한 프로세스가 반드시 unlock 해야 한다.\r\n- 세마포어는 뮤텍스가 될 수 있지만 (S = 1인 경우), 뮤텍스는 세마포어가 될 수 없다.\r\n  뮤텍스를 상태가 0, 1 두 개인 이진 세마포어로 부르기도 한다.\r\n\r\n### 세마포어와 뮤텍스의 단점\r\n\r\n- Busy waiting이 발생한다.\r\n- 세마포어의 경우 큐 or 리스트를 활용하여 Busy waiting을 해결하는 방법이 있다고 한다.\r\n    - 임계영역 진입을 위해 무한루프를 돌며 대기하는 것 대신, 프로세스를 중지시키고 큐에 넣는다.\r\n    1. S ≤ 0 이면 waiting하는 프로세스를 중지시키고 waiting queue에 넣는다.\r\n    2. 어떤 프로세스가 임계영역에서 나오면 signal() 로 대기 큐에 있는 프로세스를 waiting queue에서 빼고 깨워 ready queue에 넣는다.\r\n\r\n<br/>\r\n\r\n## 5. 동기화 문제들\r\n\r\n- 유한 버퍼 문제(bounded-buffer problem)\r\n    - 여러 개의 프로세스를 어떻게 동기화할 것인가에 관한 고전적인 문제\r\n    - 유한한 개수의 데이터를 임시로 보관하는 버퍼에 여러 명의 생산자들과 소비자들이 접근하는 것.\r\n    - 생산자는 데이터가 생기면 버퍼에 저장하는데 저장할 공간이 없는 문제가 발생할 수 있음\r\n    - 소비자는 데이터를 가져가는데 소비할 데이터가 없는 문제가 발생할 수 있다.\r\n    - 세마포어 등으로 해결 가능\r\n- Readers-Writers 문제\r\n    - 여러 명의 Reader와 Writer들이 하나의 저장 공간(버퍼)을 공유하며 이를 접근할 때 발생하는 문제.\r\n    - 세마포어 등으로 해결 가능\r\n- 식사하는 철학자들 문제\r\n    - 여러 프로세스에게 제한된 자원을 할당하는 상황에서 발생할 수 있는 문제.\r\n    - 각각의 철학자들이 동시에 자신의 왼쪽에 있는 젓가락을 드는 경우 Deadlock과 Starvation이 발생할 수 있음.\r\n    - n명이 앉을 수 있는 테이블이면 n-1명만 앉게 하여 자원의 개수를 더 많이 두거나 한 철학자가 젓가락 두 개를 모두 집을 수 있을 때만 젓가락을 집는 것을 허용하도록 하거나 누군가는 왼쪽 젓가락을 먼저 잡지 않고 오른쪽 젓가락을 먼저 잡게 하여 해결하는 방법 등이 있다.\r\n\r\n\r\n<br/>\r\n\r\n## 참고링크\r\n\r\n- [https://hibee.tistory.com/297](https://hibee.tistory.com/297)\r\n- [https://dduddublog.tistory.com/25](https://dduddublog.tistory.com/25)\r\n","excerpt":"공유된 자원에 여러 프로세스들이 동시에 접근했을 경우 데이터 무결성에 문제가 발생할 수 있다. 이러한 문제를 해결하기 위해 동기화(Synchronization) 개념이 도입되었다. 즉 공유 데이터에 대하여 동시에 접근하려 할 때, 처리 순서에 상관없…","fields":{"slug":"/process-synchronization/"},"frontmatter":{"date":"Oct 21, 2021","title":"프로세스 동기화란?","tags":["os"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n## 1. 디스크의 구조\r\n\r\n![Untitled (89)](https://user-images.githubusercontent.com/62014888/146330069-c04dca0f-956e-4bf8-9449-6595b493e114.png)\r\n\r\n- 디스크 외부에서는 디스크를 일정한 크기의 저장공간들로 이루어진 1차원 배열처럼 취급하게 되는데 이 일정한 크기의 저장공간을 논리블록(logical block)이라고 한다.\r\n    - 디스크에 데이터가 저장될 때에는 논리블록 단위로 저장\r\n    - 디스크 외부로 입출력이 일어날 때에도 논리블록 단위로 전송\r\n    - 논리블록에 저장된 데이터를 접근하기 위해서는 배열을 접근하는 것처럼 해당 블록의 인덱스 번호를 전달해야 함.\r\n    - 논리블록이 저장되는 디스크 내의 물리적 위치를 섹터(sector)라고 부르고 논리블록 하나가 섹터 하나와 1 대 1로 매핑되어 저장되는 것.\r\n- 디스크는 마그네틱의 원판으로 구성되어 있는데 각각의 원판은 트랙(track)으로 구성되고 각 트렉은 섹터로 나뉨.\r\n- 여러 개의 원판에서 상대적 위치가 동일한 트랙의 집합을 실린더(cylinder)라 부름.\r\n- 디스크에 데이터를 읽고 쓰기 위해서는 암(arm)이 해당 섹터가 위치한 실린더로 이동.\r\n\r\n## 2. 디스크 스케줄링\r\n\r\n- 디스크에 대한 접근시간(access time)은 몇 가지로 구분된다.\r\n    - 탐색시간(seek time) - 디스크 헤드를 해당 실린더 위치로 이동시키는 데 걸리는 시간.\r\n    - 회전지연시간(rotational latency) - 디스크가 회전해서 읽고 쓰려는 섹터가 헤드 위치에 도달하기까지 걸리는 시간\r\n    - 전송시간(transfer time) - 해당 섹터가 헤드 위치에 도달한 후 데이터를 실제로 섹터에 읽고 쓰는데 소요되는 시간.\r\n- 디스크 입출력의 효율을 높이기 위해서는 디스크 입출력에 소요되는 접근시간을 최소화해야 함.\r\n    - 회전지연시간과 전송시간은 상대적인 수치가 작을 뿐 아니라 운영체제 입장에서 통제하기 힘든 부분.\r\n    - 따라서 탐색시간을 줄이기 위해 헤드의 움직임을 최소화하는 스케줄링 작업을 함.\r\n- 디스크 스케줄링(disk scheduling)이란 효율적인 디스크 입출력을 위해 여러 섹터들에 대한 입출력 요청이 들어왔을 때 이들을 어떠한 순서로 처리할 것인지 결정하는 메커니즘을 뜻함.\r\n    - 가장 중요한 목표는 디스크 헤드의 이동거리를 줄이는 것.\r\n\r\n1. FCFS 스케줄링\r\n    - FCFS(First Come First Served) 스케줄링은 디스크에 먼저 들어온 요청을 먼저 처리하는 방식.\r\n    - FCFS 스케줄링이 적용되는 디스크에서 최악의 경우 입출력 요청이 디스크의 한쪽 끝과 반대쪽 끝에 번갈아 도착한다면 헤드는 디스크를 계속 왕복하며 일을 처리해야 하므로 탐색시간이 매우 비효율적으로 늘어나는 결과를 초래함.\r\n\r\n2. SSTF 스케줄링\r\n    - SSTF(Shortest Seek Time First) 스케줄링은 헤드의 현재 위치로부터 가장 가까운 위치에 있는 요청을 제일 먼저 처리하는 알고리즘.\r\n    - 헤드의 이동거리를 줄여 디스크 입출력의 효율성을 증가시키지만, 자칫 기아 현상(starvation)을 발생시킬 수 있음.\r\n        - 현재 헤드의 위치로부터 가까운 곳에서 지속적인 요청이 들어올 경우 멀리 떨어진 곳의 요청은 무한히 기다려야 하는 문제가 발생.\r\n\r\n3. SCAN 알고리즘\r\n    - SCAN 알고리즘은 헤드가 디스크 원판의 안쪽 끝과 바깥쪽 끝을 오가며, 그 경로에 존재하는 모든 요청을 처리함.\r\n        - 즉 디스크의 어떠한 위치에 요청이 들어오는가와 상관없이 헤드는 정해진 방향으로 이동하며 길목에 있는 요청들을 처리하며 지나가는 것.\r\n    - 엘리베이터에서 사용하는 스케줄링 알고리즘과 유사하여 SCAN 알고리즘을 엘레베이터 스케줄링 알고리즘이라고도 부름.\r\n    - SCAN 알고리즘에서는 FCFS처럼 불필요한 헤드의 이동이 발생하거나 SSTF처럼 일부 지역이 지나치게 오래 기다리는 현상이 발생하지 않는 효율성과 형평성을 모두 만족하는 알고리즘.\r\n    - 다만 모든 실린더 위치의 기다리는 시간이 공평한 것은 아님.\r\n        - 제일 안쪽이나 제일 바깥쪽 위치보다는 가운데 위치가 기다리는 평균시간이 더 짧음.\r\n\r\n4. C-SCAN 알고리즘\r\n    - C-SCAN(Circular-SCAN) 알고리즘은 SCAN처럼 헤드가 한쪽 끝에서 다른 쪽 끝으로 이동하며 가는 길목에 있는 모든 요청을 처리함.\r\n    - SCAN과는 달리 헤드가 다른 쪽 끝에 도달해 방향을 바꾼 후에는 요청을 처리하지 않고 곧바로 출발점으로 다시 이동만 함.\r\n    - 이 방식은 각 실린더 위치에 대해 SCAN보다 좀 더 균일한 탐색시간을 제공함.\r\n\r\n5. LOOK과 C-LOOK 알고리즘\r\n    - LOOK 알고리즘은 헤드가 한쪽 방향으로 이동하다가 그 방향에 더 이상 대기 중인 요청이 없으면 헤드의 이동 방향을 즉시 반대로 바꾸는 스케줄링 방식.\r\n    - C-LOOK 알고리즘은 전방에 요청이 없을 때 방향을 바꾼다는 측면에서는 LOOK과 유사하며, 한쪽 방향으로 이동할 때에만 요청을 처리한다는 점에서 C-SCAN과 유사함.\r\n\r\n\r\n## 3. 다중 디스크 환경에서의 스케줄링\r\n\r\n- 다중 디스크를 사용하면 시스템의 성능과 신뢰성을 동시에 향상시킬 수 있음.\r\n- 같은 데이터가 저장되어 있는 여러 개의 디스크 중 어느 디스크에서 요청을 처리할지 결정하는 스케줄링 문제가 발생함.\r\n- 다중 디스크에서의 스케줄링은 작업을 수행할 디스크를 결정하는 문제까지 포함함.\r\n- 이러한 시스템에서는 스케줄링의 목표에 따라 요청을 처리할 디스크를 결정하는 기준이 달라짐.\r\n    - 탐색시간을 줄이는 것이 목표라면 여러 디스크 중에서 헤드의 현재 위치가 요청한 데이터와 가장 가까운 디스크를 선택하는 방법을 사용\r\n    - 좀 더 거시적인 관점에서는 각 디스크 간의 부하균형(load balancing)을 이루도록 스케줄링하는 것이 중요\r\n- 최근에는 전력 소모를 줄이는 것이 또 다른 중요한 목표로 인식되고 있음\r\n    - 일부 디스크에 요청을 집중시키고 나머지 디스크는 회전을 정지시키는 것이 효과적.\r\n\r\n\r\n## 4. 디스크의 저전력 관리\r\n\r\n1. 비활성화 기법\r\n    - 디스크의 상태는 전력 소모를 기준으로 크게 네 가지로 나눌 수 있음\r\n        - 활동(active) 상태 - 현재 헤드가 데이터를 읽거나 쓰고 있는 상태\r\n        - 공회전(idle) 상태 - 디스크가 회전 중이지만 데이터를 읽거나 쓰지는 않는 상태\r\n        - 준비(standby) 상태 - 디스크가 회전하지 않지만 인터페이스가 활성화된 상태\r\n        - 휴면(sleep) 상태 - 디스크가 회전하지 않고 인터페이스도 비활성화된 상태\r\n    - 디스크가 회전 중인 상태를 활성 상태라고 부르고, 디스크가 정지한 상태를 비활성 상태라고 부르면 활성 상태보다 비활성 상태에서 전력 소모가 적으며 요청이 없을 경우 디스크를 정지시키는 것이 전력 절감 측면에서 효과적.\r\n    - 다만 각 상태로 전환할 때는 부가적인 전력 및 시간이 소모됨.\r\n        - 따라서 후속 요청까지의 시간 간격이 일정 시간(break-even time) 이상일 경우에만 디스크의 회전을 정지시키는 것이 전력 소모를 절감하는 데 효과적.\r\n        - 비활성화할 지점을 결정하기 위해 미래의 요청이 도착하는 시점과 간격을 정확히 예측하는 것이 중요함.\r\n    - 디스크를 비활성화하는 시점을 결정하는 방법으로는 세 가지가 있음\r\n        - 시간기반(timeout based) 기법 - 일정 시간 동안 디스크가 공회전 상태이면 장치를 정지시켰다가, 다시 요청이 왔을 때 디스크를 활성화함.\r\n        - 예측기반(prediction based) 기법 - 과거 요청을 관찰하여 다음 공회전 구간의 길이를 예측한 후 디스크를 비활성화할 시점을 결정함.\r\n        - 확률기반(stochastic based) 기법 - 디바이스의 상태변경 시간 간격을 구하기 위해 확률분포를 통해 요청을 모델링하고 마르코프 체인 등과 같은 통계적 모델을 이용함.\r\n\r\n2. 회전속도 조절 기법\r\n    - 디스크의 전력 소모를 줄이기 위한 방법으로 최근에는 디스크의 회전속도(Rotations Per Minute: RPM)를 가변적으로 조절하는 기법이 제안되었음.\r\n    - 디바이스 스준에서 이와 같은 기능이 지원됨에 따라 운영체제에서는 전력 소모를 최소화하기 위해 디스크의 회전속도를 관리하는 지능형 전력 관리 기법에 대한 연구가 이루어지고 있음.\r\n\r\n3. 디스크의 데이터 배치 기법\r\n    - 디스크의 용량은 매년 빠른 속도로 증가하고 있으나 디스크의 접근 속도는 기계적 메커니즘으로 인해 그다지 큰 발전이 없는 실정임.\r\n    - 대부분의 컴퓨터 시스템에서 디스크의 53% 이상이 빈 공간 상태로 남아 있다는 점에 착안해, 디스크 내에 데이터의 복제본을 많이 만들어 헤드 위치에서 가까운 복제본을 접근하도록 함으로써 빠른 응답시간과 전력 소모량 절감을 얻는 FS2 파일 시스템을 제안한 팀도 있음.\r\n\r\n4. 버퍼캐싱 및 사전인출 기법\r\n    - 미래에 요청될 데이터를 미리 알거나 어느 정도 예측할 수 있다면 디스크가 활성 상태일 때 헤드 위치로부터 가까운 데이터를 사전인출(prefetching) 함으로써 향후 디스크의 비활성화 가능성을 높여 전력 소모를 줄일 수 있음.\r\n    - 데드라인을 꼭 지켜야 하는 요청이 아닌 경우, 디스크의 활성 상태 여부에 따라 요청을 최대한 지연시키는 방식으로 전력 소모를 줄일 수 있음.\r\n\r\n5. 쓰기전략을 통한 저전력 디스크 기법\r\n    - 저장장치의 데이터에 대한 쓰기전략을 통해 전력 소모를 줄이는 기법도 제안되고 있음.\r\n    - 디스크가 활성 상태로 돌아왔을 때 쓰는 방식 또는 대상 디스크가 활성 상태가 아니면 일단 블록들을 로그 디스크에 썼다가 디스크가 활성 상태로 돌아왔을 때 디스크에 쓰기연산을 수행하는 방식 등이 있음.","excerpt":"1. 디스크의 구조 Untitled (89) 디스크 외부에서는 디스크를 일정한 크기의 저장공간들로 이루어진 1차원 배열처럼 취급하게 되는데 이 일정한 크기의 저장공간을 논리블록(logical block)이라고 한다. 디스크에 데이터가 저장될 때에는 …","fields":{"slug":"/os-it-principle-ch9/"},"frontmatter":{"date":"Oct 18, 2021","title":"[운영체제와 정보기술의 원리] 9. 디스크 관리","tags":["os","book"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n- 시분할 환경에서는 한정된 메모리 공간을 여러 프로그램이 조금씩 나누어서 사용하다보니 운영체제는 어떤 프로그램에게 어느 정도의 메모리를 할당할 것인가 하는 문제에 당면하게 됨.\r\n- 운영체제는 모든 프로그램들에게 공평하게 메모리를 할당하기보다는 몇몇 프로그램에게 집중적으로 할당한 후, 시간이 지나면 메모리를 회수해서 다른 프로그램들에게 다시 할당하는 방식을 채택.\r\n    - 프로세스의 빠른 수행을 위해 프로그램마다 최소한 확보해야 하는 메모리의 크기가 존재하기 때문\r\n- 메모리의 연장 공간으로 디스크의 스왑 영역이 사용될 수 있기 때문에 프로그램 입장에서는 물리적 메모리 크기에 대한 제약을 생각할 필요가 없어지고 나아가 운영체제는 자기 자신만이 메모리를 사용하는 것처럼 가정해 프로그램하는 것을 지원.\r\n    - 프로그램은 0번지부터 시작하는 자기 자신만의 메모리 주소 공간을 가정할 수 있는데, 이를 가상메모리(virtual memory)라고 부름.\r\n    - 이 공간 중 일부는 물리적 메모리에 적재되고 일부는 디스크 스왑 영역에 존재하게 됨.\r\n- 프로세스 주소 공간을 메모리로 적재하는 단위에 따라 가상메모리 기법은 요구 페이징(demand paging) 방식과 요구 세그먼테이션(demanding segmentation) 방식으로 구현될 수 있음.\r\n    - 대부분의 경우 요구 페이징 방식을 사용, 요구 세그먼테이션의 경우 대개 페이지드 세그먼테이션 기법을 사용하다보니 세부적인 구현은 요구 페이징 기법만이 사용됨.\r\n\r\n## 1. 요구 페이징\r\n\r\n- 요구 페이징이란 프로그램 실행 시 프로세스를 구성하는 모든 페이지를 한꺼번에 메모리에 올리는 것이 아니라 당장 사용될 페이지만을 올리는 방식.\r\n    - 특정 페이지에 대해 CPU의 요청이 들어온 후에야 해당 페이지를 메모리에 적재함.\r\n    - 메모리 사용량이 감소하고, 프로세스 전체를 메모리에 올리는데 소요되는 입출력 오버헤드도 줄어든다.\r\n    - 응답시간을 단축시킬 수 있으며, 시스템이 더 많은 프로세스를 수용할 수 있게 해준다.\r\n    - 프로그램이 물리적 메모리의 용량 제약을 벗어날 수 있도록 한다.\r\n- 요구 페이징에서는 유효-무효 비트(valid-invalid bit)를 두어 각 페이지가 메모리에 존재하는지 표시하게 된다.\r\n    - 이 비트는 각 프로세스를 구성하는 모든 페이지에 대해 존재해야 하므로 페이지 테이블의 각 항목별로 저장됨.\r\n    - CPU가 참조하려는 페이지가 현재 메모리에 올라와 있지 않아 유효-무효 비트가 무효로 세팅되어 있는 경우를 '페이지 부재(page fault)'가 일어났다고 함.\r\n\r\n    1. 요구 페이징의 페이지 부재 처리\r\n\r\n        ![Untitled (82)](https://user-images.githubusercontent.com/62014888/146327963-09bb65dc-c7be-4c3c-8846-0f1bdba13039.png)\r\n\r\n        - CPU가 무효 페이지에 접근하면 주소 변환을 담당하는 하드웨어인 MMU가 페이지 부재 트랩(page fault trap)을 발생시키게 됨.\r\n            - CPU 제어권이 커널모드로 전환되고, 운영체제의 페이지 부재 처리루틴(page fault handler)이 호출되어 페이지 부재를 처리하게 됨.\r\n        - 운영체제는 해당 페이지에 대한 접근이 적법한지를 먼저 체크하여 주소 영역에 속한 페이지 접근이 아니거나 접근 권한을 위반했을 경우 프로세스를 종료시킴.\r\n        - 적법한 것으로 판명된 경우 비어 있는 프레임을 할당받아 그 공간에 해당 페이지를 읽어온다.\r\n            - 비어 있는 프레임이 없다면 기존에 메모리에 있던 페이지 중 하나를 디스크로 쫓아내는데 이를 스왑 아웃이라고 한다.\r\n        - 요청된 페이지를 디스크로부터 메모리로 적재하기까지는 오랜 시간이 소요되므로 페이지 부재를 발생시킨 프로세스는 CPU를 빼앗기고 봉쇄 상태가 됨.\r\n            - CPU 레지스터 상태 및 프로그램 카운터값은 프로세스 제어블록에 저장해둠.\r\n        - 디스크 입출력이 끝나 인터럽트가 발생하면 페이지 테이블에서 해당 페이지를 유효 비트로 설정하고, 봉쇄되었던 프로세스를 준비 큐로 이동시킨다.\r\n        - 다시 CPU를 할당받으면 PCB에 저장한 값을 복원시켜 중단되었던 명령부터 실행을 재개함.\r\n\r\n    2. 요구 페이지의 성능\r\n        - 요구 페이징 기법의 성능에 가장 큰 영향을 미치는 요소는 페이지 부재의 발생 빈도임.\r\n            - 페이지 부재가 일어나면 디스크로부터 메모리로 읽어오는 막대한 오버헤드가 발생하기 때문.\r\n            - 페이지 부재가 적게 발생할수록 요구 페이징의 성능이 향상될 수 있음.\r\n        - 유효 접근시간(effective access time)\r\n          = (1-P) * 메모리 접근시간 + P * (페이지 부재 발생 처리 오버헤드 + 메모리에 빈 프레임이 없는 경우 스왑 아웃 오버헤드 + 요청된 페이지의 스왑 인 오버헤드 + 프로세스의 재시작 오버헤드)           \r\n            - 페이지 부재 발생비율 (page fault rate) 0 ≤ P ≤ 1  \r\n              P = 0: 페이지 부재가 한 번도 일어나지 않은 경우  \r\n              P = 1: 모든 참조 요청에서 페이지 부재가 발생한 경우\r\n\r\n\r\n## 2. 페이지 교체\r\n\r\n- 물리적 메모리에 빈 프레임이 존재하지 않아 메모리에 올라와 있는 페이지 중 하나를 디스크로 쫓아내 메모리에 빈 공간을 확보하는 작업이 필요한데 이것을 페이지 교체(page replacement)라고 함.\r\n- 페이지 교체를 할 때에 어떤 프레임에 있는 페이지를 쫓아낼 것인지 결정하는 알고리즘을 교체 알고리즘(replacement algorithm)이라고 하는데, 이 알고리즘의 목표는 페이지 부재율을 최소화하는 것이다.\r\n    - 그러므로 가까운 미래에 참조될 가능성이 가장 적은 페이지를 선택해서 내쫓는 것이 성능을 향상시킬 수 있는 방안임.\r\n- 페이지 교체 알고리즘의 성능은 주어진 페이지 참조열(page reference string)에 대해 페이지 부재율을 계산함으로써 평가할 수 있음.\r\n    - 페이지 참조열은 참조되는 페이지들의 번호를 시간 순서에 따라 나열한 것.\r\n\r\n1. 최적 페이지 교체\r\n    - 페이지 부재율을 최소화하기 위해서는 페이지 교체 시 물리적 메모리에 존재하는 페이지 중 가장 먼 미래에 참조될 페이지를 쫓아내면 됨.\r\n        - 이러한 최적의 알고리즘을 빌레디의 최적 알고리즘(Belady's optimal algorithm) 또는 MIN, OPT 등의 이름으로 부름.\r\n\r\n        ![Untitled (83)](https://user-images.githubusercontent.com/62014888/146327971-6d37c6f3-5348-453d-83b0-228ce144b60d.png)\r\n\r\n    - 페이지 5를 참조하려고 할 때에 페이지 부재가 발생하는데 이때 빌레디의 최적 알고리즘은 가장 먼 미래에 참조될 페이지를 선정하게 됨.\r\n    - 페이지 1, 2, 3, 4 중 가장 먼 미래에 참조되는 페이지가 4번 페이지이므로 이 알고리즘은 4를 내쫓고 그 자리에 페이지 5를 적재함.\r\n    - 이 알고리즘은 미래에 어떤 페이지가 어떠한 순서로 참조될지 미리 알고 있다는 전제하에 알고리즘을 운영하므로 실제 시스템에서 온라인으로 사용할 수 있는 알고리즘이 아님.\r\n        - 오프라인 알고리즘이라고 부른다.\r\n        - 이 알고리즘은 어떠한 알고리즘보다도 가장 적은 페이지 부재율을 보장하므로 다른 알고리즘의 성능에 대한 상한선을 제공함.\r\n        - 빌레디의 최적 알고리즘과 유사했다고 한다면, 이는 더 이상 그 시스템을 위한 교체 알고리즘의 연구가 필요하지 않음을 시사함.\r\n\r\n2. 선입선출 알고리즘\r\n    - 선입선출 알고리즘은 페이지 교체 시 물리적 메모리에 가장 먼저 올라온 페이지를 우선적으로 내쫓음.\r\n\r\n        ![Untitled (84)](https://user-images.githubusercontent.com/62014888/146327979-098e8811-525e-45d8-a102-b19cd008344b.png)\r\n\r\n    - 페이지의 향후 참조 가능성을 고려하지 않고, 물리적 메모리에 들어온 순서대로 내쫓을 대상을 선정하기 때문에 비효율적인 상황이 발생할 수 있음.\r\n        - 가장 먼저 물리적 메모리에 들어온 페이지가 계속해서 많은 참조가 이루어진다 하더라도 FIFO 알고리즘은 이 페이지를 내쫓게 되는 것.\r\n    - 메모리를 증가시켰음에도 불구하고 페이지 부재가 오히려 늘어나는 상황을 FIFO의 이상 현상(FIFO anomaly)이라고 부름.\r\n\r\n3. LRU 알고리즘\r\n    - 메모리 페이지의 참조 성향 중 중요한 한 가지 성질로 시간지역성(temporal locality)이라는 것이 있는데 이 성질은 최근에 참조된 페이지가 가까운 미래에 다시 참조될 가능성이 높은 성질을 뜻함.\r\n    - LRU(Least Recently Used) 알고리즘은 페이지 교체 시 가장 오래전에 참조가 이루어진 페이지를 쫓아낸다.\r\n      즉, 마지막 참조 시점이 가장 오래된 페이지를 교체하게 되는 것.\r\n\r\n        ![Untitled (85)](https://user-images.githubusercontent.com/62014888/146327981-eaf3732a-da52-4c6e-876b-852993629974.png)\r\n\r\n    - 페이지 5가 참조될 때 페이지 부재가 발생하고 페이지 3과 교체되는데, 이는 페이지 3이 가장 오래전에 참조된 페이지이기 때문.\r\n\r\n4. LFU 알고리즘\r\n    - LFU(Least Frequently Used) 알고리즘은 페이지의 참조 횟수로 교체시킬 페이지를 결정함.\r\n        - 즉 물리적 메모리 내에 존재하는 페이지 중에서 과거에 참조 횟수가 가장 적었던 페이지를 쫓아내고 그 자리에 새로 참조될 페이지를 적재한다.\r\n        - 최저 참조 횟수를 가진 페이지가 여러 개 존재하는 경우네는 임의로 하나를 선정해 그 페이지를 쫓아냄.\r\n        - 성능 향상을 위해서는 최저 참조 횟수를 가진 페이지들 중에서 상대적으로 더 오래전에 참조된 페이지를 쫓아내도록 구현하는 것이 효율적.\r\n    - LFU는 페이지의 참조 횟수를 계산하는 방식에 따라 Incache-LFU와 Perfect-LFU로 나뉨.\r\n        - Incache-LFU\r\n            - 페이지가 물리적 메모리에 올라온 후부터의 참조 횟수를 카운트하는 방식.\r\n            - 페이지가 메모리에서 쫓겨났다가 다시 들어온 경우 참조 횟수는 1부터 새롭게 시작.\r\n        - Perfect-LFU\r\n            - 메모리에 올라와있는지의 여부와 상관없이 그 페이지의 과거 총 참조 횟수를 카운트함.\r\n            - 페이지의 참조 횟수를 정확히 반영할 수 있다는 장점이 있지만, 메모리에 쫓겨난 페이지의 참조 기록까지 모두 보관하고 있어야 하므로 그 오버헤드가 상대적으로 더 크다고 할 수 있음.\r\n    - LFU 알고리즘은 LRU 알고리즘보다 오랜 시간 동안의 참조 기록을 반영할 수 있다는 장점이 있음.\r\n        - LRU는 직전에 참조된 시점만을 반영, LFU는 장기적인 시간 규모에서의 참조 성향을 고려하기 때문.\r\n    - LFU는 시간에 따른 페이지 참조 변화를 반영하지 못하고, LRU보다 구현이 복잡하다는 단점이 있음.\r\n\r\n    ![Untitled (86)](https://user-images.githubusercontent.com/62014888/146327986-0195ad12-cf48-4eba-bb40-816de47ad954.png)\r\n\r\n    - LRU 알고리즘은 1번 페이지가 참조 횟수가 가장 많았지만 그걸 인지하지 못한다.\r\n    - LFU 알고리즘은 4번 페이지가 지금부터 인기를 얻기 시작하는 페이지일 수도 있는데 그걸 인지하지 못한다.\r\n\r\n5. 클럭 알고리즘\r\n    - LRU, LFU 알고리즘은 페이지의 참조 시각 및 참조 횟수를 소프트웨어적으로 유지하고 비교해야 하므로 알고리즘의 운영에 시간적인 오버헤드가 발생함.\r\n    - 클럭 알고리즘(clock algorithm)은 하드웨어적인 지원을 통해 이와 같은 알고리즘의 운영 오버헤드를 줄인 방식.\r\n        - LRU를 근사시킨 알고리즘으로 NUR(Not Used Recently) 또는 NRU(Not Recently Used) 알고리즘으로도 불린다.\r\n    - 클럭 알고리즘은 오랫동안 참조되지 않은 페이지 중 하나를 교체함.\r\n        - 즉, 최근에 참조되지 않은 페이지를 교체 대상으로 선정한다는 측면에서 LRU와 유사하지만 교체되는 페이지의 참조 시점이 가장 오래되었다는 것을 보장하지는 못한다는 점에서 LRU를 근사시킨 알고리즘으로 볼 수 있다.\r\n    - 하드웨어적인 지원으로 동작하기 때문에 LRU에 비해 페이지 관리가 훨씬 빠르고 효율적이기에 대부분의 시스템에서 클럭 알고리즘을 채택함.\r\n\r\n    ![Untitled (87)](https://user-images.githubusercontent.com/62014888/146327990-e537f022-67d6-4a46-8252-cdec48519c13.png)\r\n\r\n    - 클럭 알고리즘은 교체할 페이지를 선정하기 위해 페이지 프레임들의 참조비트를 순차적으로 조사함.\r\n    - 프레임 내의 페이지가 참조될 때 하드웨어에 의해 1로 자동 세팅됨.\r\n    - 참조비트가 1인 페이지는 0으로 바꾼 후 그냥 지나가고 참조비트가 0인 페이지는 교체함.\r\n    - 모든 페이지 프레임을 다 조사한 경우 첫 번째 페이지 프레임부터 조사 작업을 반복한다.\r\n        - 즉 시곗바늘이 한 바퀴 도는 동안 다시 참조되지 않은 페이지를 교체하는 것임.\r\n    - 적어도 시곗바늘이 한 바퀴 도는데 소요되는 시간만큼 페이지를 메모리에 유지시켜둠으로써 페이지 부재율을 줄이도록 설계되었기 때문에 이 알고리즘을 2차 기회 알고리즘(second chance algorithm)이라고도 부름\r\n\r\n## 3. 페이지 프레임의 할당\r\n\r\n- 프로세스가 여러 개가 동시에 수행되는 상황에서는 각 프로세스에 얼마만큼의 메모리 공간을 할당할 것인지 결정해야 함.\r\n- 기본적인 할당 알고리즘(allocation algorithm)은 세 가지로 나누어볼 수 있음.\r\n    1. 균등할당(equal allocation) 방식\r\n        - 모든 프로세스에게 페이지 프레임을 균일하게 할당하는 방식\r\n    2. 비례할당(proportional allocation) 방식\r\n        - 프로세스의 크기에 비례해 페이지 프레임을 할당하는 방식\r\n        - 프로세스의 크기를 고려한 균등할당 방식으로 볼 수 있다\r\n    3. 우선순위 할당(priority allocation) 방식\r\n        - 프로세스의 우선순위에 따라 페이지 프레임을 다르게 할당하는 방식\r\n        - 프로세스 중 당장 CPU에서 실행될 프로세스와 그렇지 않은 프로세스를 구분하여 전자 쪽에 더 많은 페이지 프레임을 할당하는 방식.\r\n- 이와 같은 할당 알고리즘만으로는 프로세스 페이지 참조 특성을 제대로 반영하지 못할 우려가 있음\r\n    - 수행 중인 프로세스 수가 지나치게 많아 프로세스당 할당되는 메모리 양이 과도하게 적어질 수 있음.\r\n- 프로세스를 정상적으로 수행하기 위해서는 적어도 일정 수준 이상의 페이지 프레임을 각 프로세스에 할당해야 함.\r\n- 반복문을 실행 중인 프로세스의 경우 반복문을 구성하는 페이지들을 한꺼번에 메모리에 올려놓는 것이 유리함.\r\n    - 적게 할당하면 매 반복마다 적어도 한 번 이상의 페이지 부재가 발생하기 때문\r\n- 또한 프로세스에게 최소한으로 필요한 메모리 양은 시간에 따라 달라질 수 있음.\r\n- 종합적인 상황을 고려해 할당 페이지 프레임 수를 결정할 필요가 있으며, 경우에 따라 일부 프로세스에게 메모리를 할당하지 않는 방식으로 나머지 프로세스들에게 최소한의 메모리 요구량을 충족시킬 수 있어야 함.\r\n\r\n## 4. 전역교체와 지역교체\r\n\r\n- 교체할 페이지를 선정할 때, 교체 대상이 될 프레임의 범위를 어떻게 할지에 따라 교체 방법을 전역교체(global replacement)와 지역교체(local replacement)로 구분할 수 있음.\r\n- 전역교체 방법은 모든 페이지 프레임이 교체 대상이 될 수 있는 방법.\r\n    - 프로세스마다 메모리를 할당하는 것이 아니라 전체 메모리를 각 프로세스가 공유해서 사용하고 교체 알고리즘에 근거해서 할당되는 메모리 양이 가변적으로 변하는 방법.\r\n    - 페이지 교체 시 다른 프로세스에 할당된 프레임을 빼앗아올 수 있는 방식.\r\n    - 프로세스별 프레임 할당량을 조절하는 또 다른 방법이 될 수 있음.\r\n    - LRU, LFU, 클럭 등의 알고리즘을 물리적 메모리 내에 존재하는 전체 페이지 프레임들을 대상으로 적용하는 경우가 이러한 전역교체 방법이 됨.\r\n    - 워킹셋 알고리즘, PFF 알고리즘도 전역교체 방법으로 사용될 수 있음.\r\n- 지역교체 방법은 현재 수행 중인 프로세스에게 할당된 프레임 내에서만 교체 대상을 선정할 수 있는 방법\r\n    - 프로세스마다 페이지 프레임을 미리 할당하는 것을 전제로 한다.\r\n    - 프로세스별로 페이지 프레임을 할당하고, 교체할 페이지도 그 프로세스에게 할당된 프레임 내에서 선정하게 되는 것.\r\n    - LRU, LFU 등의 알고리즘을 프로세스별로 독자적으로 운영할 때에는 지역교체 방법이 됨.\r\n\r\n## 5. 스레싱\r\n\r\n- 프로세스가 최소한의 페이지 프레임을 할당받지 못할 경우 성능상의 심각한 문제가 발생할 수 있음.\r\n- 집중적으로 참조되는 페이지들의 집합을 메모리에 한꺼번에 적재하지 못하면 페이지 부재율이 크게 상승해 CPU 이용률이 급격히 떨어질 수 있기 때문이다.\r\n  이와 같은 현상을 스레싱(thrashing)이라고 부른다.\r\n- CPU 이용률이 낮다는 것은 준비 큐가 비는 경우가 발생한다는 뜻이여서 운영체제는 메모리에 올라가는 프로세스의 수를 늘리게 된다.\r\n- 메모리에 동시에 올라가 있는 프로세스의 수를 다중 프로그래밍의 정도(Multi-Programming Degree: MPD)라고 부르는데 CPU 이용률이 낮을 경우 운영체제는 MPD를 높이게 된다.\r\n- MPD가 과도하게 높아지면 각 프로세스에게 할당하는 메모리의 양이 지나치게 감소하게 된다.\r\n- 프로세스는 최소한의 페이지 프레임도 할당받지 못하는 상태가 되어 페이지 부재가 빈번히 발생하게 된다. 페이지 부재는 디스크 I/O 작업을 수반하므로 문맥교환을 통해 다른 프로세스에게 CPU가 이양된다.\r\n- 다른 프로세스 역시 페이지 부재가 발생할 수밖에 없고 또 다른 프로세스에게 CPU가 할당된다.\r\n- 모든 프로세스에게 다 페이지 부재를 발생시켜 시스템은 페이지 부재를 처리하느라 매우 분주해지고 CPU 이용률은 급격히 떨어지게 된다.\r\n- 이 상황에서 운영체제는 프로세스 수가 적다고 판단해 MPD를 높이기 위해 또 다른 프로세스를 메모리에 추가하게 된다.\r\n- 결과적으로 프로세스당 할당된 프레임 수는 더욱 감소하여 페이지 부재는 더욱 빈번히 발생하게 되고 CPU는 대부분의 시간에 일을 하지 않게되는데 이를 스레싱이라고 한다.\r\n- MPD를 적절히 조절해 CPU 이용률을 높이는 동시에 스레싱 발생을 방지하는 방법에는 워킹셋 알고리즘과 페이지 부재 빈도 알고리즘이 있음.\r\n1. 워킹셋 알고리즘(working-set algorithm)\r\n\r\n    ![Untitled (88)](https://user-images.githubusercontent.com/62014888/146328019-dc0c4b94-2d64-40c5-b1c2-75247c248eb4.png)\r\n    1. 프로세스는 일정 시간 동안 특정 주소 영역을 집중적으로 참조하는 경향이 있는데 이렇게 집중적으로 참조되는 페이지들의 집합을 지역성 집합(locality set)이라고 한다.\r\n    2. 워킹셋 알고리즘은 이러한 지역성 집합이 메모리에 동시에 올라갈 수 있도록 보장하는 메모리 관리 알고리즘을 뜻함.\r\n        - 프로세스가 원활히 수행되기 위해 한꺼번에 올라와 있어야 하는 페이지들의 집합을 워킹셋이라고 정의하고, 워킹셋 페이지들이 한꺼번에 메모리에 올라갈 수 있는 경우에만 할당한다.\r\n        - 그렇지 않을 경우 페이지 프레임들을 모두 반납시키고 디스크로 스왑 아웃시킨다.\r\n        - 이를 통해 MPD를 조절하고 스레싱을 방지하게 됨.\r\n    3. 한꺼번에 메모리에 올라가야 할 페이지들의 집합을 결정하기 위해 워킹셋 알고리즘은 워킹셋 윈도우를 사용한다.\r\n        - 페이지가 참조된 시점부터 워킹셋 윈도우 시간 동안은 메모리에 유지하고, 그 시점이 지나면 메모리에서 지워버리게 되는 것.\r\n    4. 워킹셋 알고리즘은 메모리에 올라와 있는 프로세스들의 워킹셋 크기의 합이 프레임 수보다 클 경우 일부 프로세스를 스왑 아웃시켜서 남은 프로세스의 워킹셋이 메모리에 모두 올라가는 것을 보장함.\r\n        - MPD를 줄이는 효과를 발생\r\n    5. 워킹셋을 모두 할당한 후에도 프레임이 남을 경우, 스왑 아웃되었던 프로세스를 다시 메모리에 올려서 워킹셋을 할당함으로써 MPD를 증가시킴.\r\n    6. 윈도우의 크기가 너무 낮으면 지역성 집합을 모두 수용하지 못할 우려가 있고, 반대로 윈도우의 크기가 너무 크면 여러 규모의 지역성 집합을 수용할 수 있는 반면 MPD가 감소해 CPU 이용률이 낮아질 우려가 있다.\r\n    7. 워킹셋의 크기는 시간이 흐름에 따라 변하기도 하므로 일종의 동적인 프레임 할당 기능까지 수행한다고 할 수 있다.\r\n2. 페이지 부재 빈도 알고리즘(Page Fault Frequency: PFF)\r\n    1. 프로세스의 페이지 부재율을 주기적으로 조사하고 이 값에 근거해서 각 프로세스에 할당할 메모리 양을 동적으로 조절한다.\r\n    2. 페이지 부재율이 상한값을 넘게 되면 프로세스에게 프레임을 추가로 더 할당한다.\r\n        - 빈 프레임이 없다면 일부 프로세스를 스왑 아웃시켜 프로세스 수를 조절함.\r\n    3. 페이지 부재율이 하한값 이하로 떨어지면 필요 이상으로 많은 프레임이 할당된 것으로 간주해 할당된 프레임의 수를 줄인다.\r\n        - 메모리 내에 존재하는 모든 프로세스에 필요한 프레임을 다 할당한 후에도 프레임이 남는 경우 스왑 아웃되었던 프로세스에게 프레임을 할당함으로써 MPD를 높인다.","excerpt":"시분할 환경에서는 한정된 메모리 공간을 여러 프로그램이 조금씩 나누어서 사용하다보니 운영체제는 어떤 프로그램에게 어느 정도의 메모리를 할당할 것인가 하는 문제에 당면하게 됨. 운영체제는 모든 프로그램들에게 공평하게 메모리를 할당하기보다는 몇몇 프로그…","fields":{"slug":"/os-it-principle-ch8/"},"frontmatter":{"date":"Oct 17, 2021","title":"[운영체제와 정보기술의 원리] 8. 가상메모리","tags":["os","book"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"- 컴퓨터에서는 byte 단위로 메모리 주소를 부여하기 때문에 32비트 주소 체계를 사용하면 2의 32제곱 바이트만큼의 메모리 공간에 서로 다른 주소를 할당할 수 있다.\r\n- 효율적인 운영을 위해 보통 4KB(= 2의 12제곱 byte) 단위로 묶어서 페이지(page)라는 하나의 행정구역을 만들어서 관리한다.\r\n\r\n## 1. 주소 바인딩\r\n\r\n- 프로그램이 실행을 위해 메모리에 적재되면 그 프로세스를 위한 독자적인 주소 공간이 생성되는데 이 주소를 논리적 주소(logical address) 혹은 가상 주소(virtual address)라고 부른다.\r\n    - CPU는 프로세스마다 독립적으로 갖는 논리적 주소에 근거해 명령을 실행함.\r\n    - 각 프로세스마다 독립적으로 할당되며 0번지부터 시작됨.\r\n- 물리적 주소(physical address)는 물리적 메모리에 실제로 올라가는 위치를 말한다.\r\n    - 물리적 메모리의 낮은 주소 영역에는 운영체제가 올라가고, 높은 주소 영역에는 사용자 프로세스들이 올라간다.\r\n- 프로세스가 실행되기 위해서는 해당 프로그램이 물리적 메모리에 올라가 있어야한다.\r\n  또한 CPU가 기계어 명령을 수행하기 위해 논리적 주소를 통해 메모리 참조를 하게 되면 해당 논리적 주소가 물리적 메모리의 어느 위치에 매핑되는지 확인해야 한다.\r\n    - 프로세스의 주소를 물리적 메모리 주소로 연결시켜주는 작업을 주소 바인딩(address binding)이라고 한다.\r\n- 주소 바인딩의 방식은 프로그램이 적재되는 물리적 메모리의 주소가 결정되는 시기에 따라 세 가지로 분류할 수 있음.\r\n    1. 물리적 메모리 주소가 프로그램을 컴파일할 때 결정되는 주소 바인딩 방식을 컴파일 타임 바인딩(compile time binding)이라고 부름.\r\n        - 컴파일 하는 시점에 해당 프로그램이 물리적 메모리의 몇 번지에 위치할 것인지 결정한다.\r\n        - 절대주소로 적재된다는 뜻에서 절대코드(absolute code)를 생성하는 바인딩 방식이라고도 말함.\r\n        - 물리적 메모리 위치를 변경하고 싶다면 다시 컴파일을 해야하기에 비현실적이고 현대의 시분할 컴퓨팅 환경에서는 잘 사용하지 않음.\r\n    2. 프로그램 실행이 시작될 때 물리적 메모리 주소가 결정되는 주소 바인딩 방식을 로드 타임 바인딩(load time binding)이라고 한다.\r\n        - 로더(loader)의 책임하에 물리적 메모리 주소가 부여되며 프로그램이 종료될 때까지 물리적 메모리상의 위치가 고정된다.\r\n            - 로더란 사용자 프로그램을 메모리에 적재시키는 프로그램\r\n        - 컴파일러가 재배치 가능 코드(relocatable code)를 생성한 경우에 가능한 주소 바인딩 방식\r\n    3. 실행시간 바인딩(execution time binding 또는 run time binding)은 프로그램이 실행을 시작한 후에도 그 프로그램이 위치한 물리적 메모리상의 주소가 변경될 수 있는 바인딩 방식.\r\n        - CPU가 주소를 참조할 때마다 해당 데이터가 물리적 메모리의 어느 위치에 존재하는지, 주소 매핑 테이블(address mapping table)을 이용해 바인딩을 점검해야 함.\r\n        - 기준 레지스터와 한계 레지스터를 포함해 MMU(Memory Management Unit: 메모리 관리 유닛)라는 하드웨어적인 지원이 뒷받침되어야 함.\r\n            - MMU는 논리적 주소를 물리적 주소로 매핑해주는 하드웨어 장치.\r\n- CPU가 특정 프로세스의 논리적 주소를 참조하려고 할 때 MMU 기법은 그 주소값에 기준 레지스터의 값을 더해 물리적 주소값을 얻어냄.\r\n    - 기준 레지스터는 재배치 레지스터(relocation register)라고도 부르며 그 프로세스의 물리적 메모리 시작 주소를 가지고 있음.\r\n    - MMU 기법에서 사용자 프로그램이나 CPU는 논리적 주소만 다룰 뿐, 물리적 주소는 알지 못하며 알 필요도 없음.\r\n- 동일한 주소값이라 하더라도 각 프로세스마다 서로 다른 내용을 담고 있게 되므로 CPU가 논리적 주소 100번지를 참조한다고 했을 때 현재 CPU에서 수행되고 있는 프로세스가 무엇인지에 따라 100번지가 가리키는 내용은 상이해진다.\r\n    - MMU 기법에서는 문맥교환으로 프로세스가 바뀔 때마다 재배치 레지스터 값을 그 프로세스에 해당되는 값으로 재설정함.\r\n- 다중 프로그래밍 환경에서 MMU 방식을 사용하여 주소 변환을 했을 때 해당 프로세스의 주소 공간을 벗어나는 경우가 발생할 수 있다.\r\n  이렇게 되면 메모리 보안(memory protection)이 이루어지지 않아 다른 프로그램 영역을 침범하거나 심지어 운영체제 메모리 영역을 변경해 시스템에 치명적인 결과를 초래할 수도 있음.\r\n    - 이를 방지하기 위해 한계 레지스터를 사용한다.\r\n- 한계 레지스터는 프로세스가 자신의 주소 공간을 넘어서는 메모리 참조를 하려고 하는지 체크하는 용도로 사용되며, 현재 CPU에서 수행 중인 프로세스의 논리적 주소의 최댓값, 즉 그 프로세스의 크기를 담고 있음.\r\n    - CPU가 메모리 참조 요청을 했을 때 그 주소가 한계 레지스터값보다 큰지를 먼저 체크해 물리적 메모리 영역에 대한 보안을 유지하게 됨.\r\n- 먼저 CPU가 요청한 프로세스의 논리적 주소값이 한계 레지스터 내에 저장된 그 프로세스의 크기보다 작은지 확인함\r\n    - 작다면 재배치 레지스터값을 더해 물리적 주소를 구한 다음 해당 물리적 메모리 위치에 접근하도록 허락함.\r\n    - 크다면 다른 프로세스 주소 영역에 접근하려는 시도이므로 트랩을 발생시켜 프로세스를 강제종료시킴.\r\n\r\n\r\n## 2. 메모리 관리와 관련된 용어\r\n\r\n1. 동적로딩(dynamic loading)\r\n    1. 다중 프로그래밍 환경에서 메모리 사용의 효율성을 높이기 위해 사용하는 기법 중 하나.\r\n    2. 프로세스가 시작될 때 주소 공간 전체를 메모리에 다 올려놓는 것이 아니라 해당 부분이 불릴 때 그 부분만을 메모리에 적재하는 방식을 사용함.\r\n       즉, 프로세스 내에서 실행에 필요한 부분이 실제로 불릴 때마다 메모리에 적재하는 것을 의미함.\r\n    3. 프로그램 자체에서 구현이 가능하며 운영체제가 라이브러리를 통해 지원할 수도 있음.\r\n2. 동적연결(dynamic linking)\r\n    1. 연결(linking)이란 프로그래머가 작성한 소스 코드를 컴파일하여 생성된 목적 파일(object file)과, 이미 컴파일된 라이브러리 파일(library file)들을 묶어 하나의 실행파일을 생성하는 과정을 말함.\r\n    2. 동적연결은 컴파일을 통해 생성된 목적 파일과 라이브러리 파일 사이의 연결을 프로그램 실행 시점까지 지연시키는 기법.\r\n        - 반대 개념인 정적연결(static linking)에서는 프로그래머가 작성한 코드와 라이브러리 코드가 모두 합쳐져서 실행파일이 생성됨.\r\n        - 실행파일 크기가 상대적으로 크며, 동일한 라이브러리를 각 프로세스가 개별적으로 메모리에 적재해야 하므로 물리적 메모리가 낭비되는 단점이 존재.\r\n    3. 동적연결은 프로그램이 실행되면서 라이브러리 함수를 호출할 때가 되어서야 라이브러리에 대한 연결이 이루어짐.\r\n    4. 실행파일의 라이브러리 호출 부분에 해당 라이브러리의 위치를 찾기 위한 스텁(stub)이라는 작은 코드를 둠.\r\n        - 라이브러리가 메모리에 이미 존재하면 그 주소의 메모리 위치에 직접 참조하며, 그렇지 않으면 디스크에서 동적 라이브러리 파일을 찾아 메모리에 적재한 후 수행함.\r\n    5. 메모리 사용의 효율성을 높일 수 있고 동적연결 기법은 운영체제의 지원을 필요로 함.\r\n3. 중첩(overlays)\r\n    1. 프로세스의 주소 공간을 분할해 실제 필요한 부분만을 메모리에 적재하는 기법.\r\n    2. 초창기 컴퓨터 시스템에서 물리적 메모리의 크기 제약으로 인해 하나의 프로세스조차도 메모리에 한꺼번에 올릴 수 없을 때, 프로세스의 주소 공간을 분할해서 당장 필요한 일부분을 메모리에 올려 실행하고 실행이 끝난 후 나머지 부분을 올려 실행하는 기법을 뜻함.\r\n    3. 동적로딩은 메모리에 더 많은 프로세스를 동시에 올려놓고 실행하기 위한 용도인 반면, 중첩은 단일 프로세스만을 메모리에 올려놓는 환경에서 메모리 용량보다 큰 프로세스를 실행하기 위한 어쩔 수 없는 선택이었다.\r\n    4. 운영체제 지원 없이 프로그래머에 의해 구현되어야 했으며 손수 구현했다고 해서 수작업 중첩(manual overlays)이라고도 부름.\r\n4. 스와핑(swapping)\r\n    1. 스와핑이란 메모리에 올라온 프로세스의 주소 공간 전체를 디스크의 스왑 영역에 일시적으로 내려놓는 것을 말한다.\r\n        - 스왑 역역은 백킹스토어(backing store)라고도 부르며, 디스크 내에 파일 시스템과는 별도로 존재하는 일정 영역을 말함.\r\n        - 파일 시스템은 비휘발성 저장공간임에 비해 스왑 영역은 프로세스가 수행 중인 동안에만 디스크에 일시적으로 저장하는 공간이므로 저장 기간이 상대적으로 짧은 저장공간임\r\n    2. 스왑 영역은 충분히 큰 저장공간이어야 하고 어느 정도의 접근 속도가 보장되어야 한다.\r\n    3. 스와핑은 프로세스가 종료되어 그 주소 공간을 디스크로 내쫓는 것이 아니라, 특정 이유로 수행 중인 프로세스의 주소 공간을 일시적으로 메모리에서 디스크로 내려놓는 것을 의미함.\r\n        - 디스크에서 메모리로 올리는 작업을 스왑 인(swap in), 메모리에서 디스크로 내리는 작업을 스왑 아웃(swap out)이라고 부름.\r\n    4. 스와핑은 스와퍼(swapper)라고 불리는 중기 스케줄러에 의해 스왑 아웃시킬 프로세스를 선정함.\r\n    5. 스와핑의 가장 중요한 역할은 메모리에 존재하는 프로세스의 수를 조절하는 것. 즉, 스와핑을 통해 다중 프로그래밍의 정도를 조절할 수 있다.\r\n    6. 컴파일 타임 바인딩 방식이나 로드 타임 바인딩 방식에서는 스왑 인될 때에 원래 존재하던 메모리 위치로 다시 올라가야 하지만 실행시간 바인딩 기법에서는 추후 빈 메모리 영역 아무 곳에나 올릴 수 있음.\r\n    7. 스와핑에 소요되는 시간은 디스크의 탐색시간(seek time)이나 회전지연시간(rotational latency)보다는 디스크 섹터에서 실제 데이터를 읽고 쓰는 전송시간(transfer time)이 대부분을 차지함.\r\n\r\n\r\n## 3. 물리적 메모리의 할당 방식\r\n\r\n- 물리적 메모리는 운영체제 상주 영역과 사용자 프로세스 영역으로 나뉘어 사용됨.\r\n    - 운영체제 상주 영역은 인터럽트 벡터와 함께 물리적 메모리의 낮은 주소 영역을 사용하며, 운영체제 커널이 이곳에 위치하게 됨.\r\n    - 사용자 프로세스 영역은 물리적 메모리의 높은 주소 영역을 사용하며 여러 사용자 프로세스들이 이곳에 적재되어 실행됨.\r\n- 사용자 프로세스 영역에서는 프로세스를 메모리에 올리는 방식에 따라 두 가지로 나누어 볼 수 있음.\r\n- 연속할당(contiguous allocation) 방식\r\n    - 각각의 프로세스를 물리적 메모리의 연속적인 공간에 올리는 방식.\r\n    - 물리적 메모리를 다수의 분할로 나누어 하나의 분할에 하나의 프로세스가 적재되도록 함.\r\n    - 고정분할(fixed partition allocation) 방식\r\n        - 물리적 메모리를 고정된 크기의 분할로 미리 나누어두는 방식\r\n    - 가변분할(variable partition allocation) 방식\r\n        - 미리 나누어놓지 않은 채 프로그램이 실행되고 종료되는 순서에 따라 분할을 관리하는 방식.\r\n- 불연속할당(noncontiguous allocation) 방식\r\n    - 하나의 프로세스를 물리적 메모리의 여러 영역에 분산해 적재하는 방식.\r\n    - 페이징 기법과 세그먼테이션 기법, 페이즈드 세그먼테이션 기법 등이 있음.\r\n\r\n1. 연속할당 방식\r\n    - 프로세스를 메모리에 올릴 때 그 주소 공간을 여러 개로 분할하지 않고 물리적 메모리의 한 곳에 연속적으로 적재하는 방식.\r\n    1. 고정분할 방식\r\n        - 물리적 메모리를 주어진 개수만큼의 영구적인 분할(partition)로 미리 나누어두고 각 분할에 하나의 프로세스를 적재해 실행시킬 수 있게 함.\r\n        - 분할의 크기는 모두 동일하게 할 수도 있고 서로 다르게 할 수도 있음.\r\n        - 하나의 분할에는 하나의 프로그램만을 적재할 수 있어 고정분할 방식은 동시에 메모리에 올릴 수 있는 프로그램의 수가 고정되어 있으며 수행 가능한 프로그램의 최대 크기 또한 제한된다는 점에서 가변분할 방식에 비해 융통성이 떨어짐.\r\n        - 외부조각과 내부조각이 발생할 수 있음.\r\n        - 외부조각\r\n            - 프로그램의 크기보다 분할의 크기가 작은 경우 해당 분할이 비어 있는데도 불구하고 프로그램을 적재하지 못하기 때문에 발생하는 메모리 공간.\r\n        - 내부조각\r\n            - 프로그램의 크기보다 분할의 크기가 큰 경우 해당 분할에 프로그램을 적재하고 남는 메모리 공간을 의미.\r\n    2. 가변분할 방식\r\n        - 메모리에 적재되는 프로그램의 크기에 따라 분할의 크기, 개수가 동적으로 변하는 방식.\r\n        - 내부조각은 발생하지 않으나 외부조각이 발생할 가능성이 있음.\r\n        - 가변분할 방식에서는 주소 공간의 크기가 n인 프로세스를 메모리에 올릴 때 물리적 메모리 내 가용 공간 중 어떤 위치에 올릴 것인지 결정하는 것이 문제이고 이를 동적 메모리 할당 문제(dynamic storage-allocation problem)이라고 부름.\r\n        - 가용 공간들을 좀 더 효율적으로 관리하기 위해 운영체제는 이미 사용 중인 메모리 공간과 사용하고 있지 않은 가용 공간에 대한 정보를 각각 유지하고 있음.\r\n        - 동적 메모리 할당 문제를 해결하는 대표적인 방법으로는 세 가지가 있음.\r\n            - 최초적합(first-fit) 방법\r\n                - 크기가 n 이상인 가용 공간 중 가장 먼저 찾아지는 곳에 프로세스를 할당하는 방법.\r\n                - 가용 공간을 모두 탐색하는 방법이 아니므로 시간적인 측면에서 효율적.\r\n            - 최적적합(best-fit) 방법\r\n                - 크기가 n 이상인 가장 작은 가용 공간을 찾아 그곳에 새로운 프로그램을 할당하는 방법.\r\n                - 가용 공간 리스트가 크기순으로 정렬되어 있지 않은 경우 모든 가용 공간 리스트를 탐색해야 하므로 시간적 오버헤드가 발생하고 다수의 매우 작은 가용 공간들이 생성될 수 있다는 단점이 있지만 공간적인 측면에서 효율적.\r\n            - 최악적합(worst-fit) 방법\r\n                - 가장 크기가 큰 곳에 새로운 프로그램을 할당하는 방법.\r\n                - 모든 가용 공간 리스트를 탐색해야 하는 오버헤드가 발생하고 상대적으로 더 큰 프로그램을 담을 수 있는 가용 공간을 빨리 소진한다는 문제점이 있음.\r\n        - 외부조각 문제를 해결하기 위해 컴팩션(compaction)이라는 방법이 있음.\r\n            - 물리적 메모리 중에서 프로세스에 의해 사용 중인 메모리 영역을 한쪽으로 몰고 가용 공간들을 다른 한쪽으로 모아서 하나의 큰 가용 공간을 만드는 방법.\r\n            - 현재 수행 중인 프로세스의 메모리상 위치를 상당 부분 이동시켜야 하므로 비용이 매우 많이 드는 작업.\r\n            - 수행 중인 프로세스 물리적 메모리 위치를 옮겨야 하므로 실행시간 바인딩 방식이 지원되는 환경에서만 수행될 수 있음.\r\n\r\n2. 불연속할당 기법\r\n    - 하나의 프로세스가 물리적 메모리의 여러 위치에 분산되어 올라갈 수 있는 메모리 할당 기법을 의미함.\r\n    - 페이징 기법, 세그먼테이션 기법, 페이지드 세그먼테이션 기법 등이 있음.\r\n\r\n\r\n## 4. 페이징 기법\r\n\r\n- 페이징(paging) 기법이란 프로세스의 주소 공간을 동일한 크기의 페이지 단위로 나누어 물리적 메모리의 서로 다른 위치에 페이지들을 저장하는 방식.\r\n- 페이징 기법에서는 물리적 메모리를 페이지와 동일한 크기의 프레임(frame)으로 미리 나누어둔다.\r\n    - 메모리에 올리는 단위가 동일한 크기의 페이지 단위이므로, 빈 프레임이 있으면 어떤 위치이든 사용될 수 있다.\r\n      따라서 동적 메모리 할당 문제가 발생하지 않는다.\r\n- 주소 변환 절차가 연속할당 방식에 비해 다소 복잡하다.\r\n    - 하나의 프로세스라 하더라도 페이지 단위로 물리적 메모리에 올리는 위치가 상이하므로, 논리적 주소를 물리적 주소로 변환하는 작업이 페이지 단위로 이루어져야 하기 때문이다.\r\n    - 페이지별 주소 변환 정보를 유지하고 있어야 하므로 모든 프로세스가 각각의 주소 변환을 위한 페이지 테이블을 가지며, 이 테이블은 프로세스가 가질 수 있는 페이지의 개수만큼 주소 변환 엔트리를 가지고 있게 된다.\r\n\r\n    ![Untitled (74)](https://user-images.githubusercontent.com/62014888/146325391-f9c3e38e-0fd4-4ace-9eec-f820553da91d.png)\r\n\r\n- 페이징 기법에서는 빈 공간은 어느 곳이든 활용할 수 있어서 외부조각 문제가 발생하지 않는다.\r\n  그러나 프로그램의 크기가 항상 페이지 크기의 배수가 된다는 보장이 없기 때문에 프로세스 주소 공간 중 제일 마지막에 위치한 페이지에서는 내부조각이 발생할 가능성이 있다.\r\n\r\n1. 주소 변환 기법\r\n    1. 페이징 기법에서는 CPU가 사용하는 논리적 주소를 페이지 번호(p)와 페이지 오프셋(d)으로 나누어 주소 변환(address translation)에 사용한다.\r\n    2. 페이지 번호는 각 페이지별 주소 변환 정보를 담고 있는 페이지 테이블 접근 시 인덱스(index)로 사용되고, 해당 인덱스의 항목(entry)에는 그 페이지의 물리적 메모리상의 기준 주소(base address), 즉 시작 위치가 저장된다.\r\n       따라서 p번째 페이지가 위치한 물리적 메모리의 시작 위치를 알고 싶다면 해당 프로세스 페이지 테이블에서 p번째 항목을 찾아보면 된다.\r\n    3. 페이지 오프셋은 하나의 페이지 내에서의 변위를 알려주므로 기준 주소값에 변위를 더함으로써 요청된 논리적 주소에 대응하는 물리적 주소를 알 수 있다.\r\n\r\n2. 페이지 테이블의 구현\r\n    1. 페이지 테이블은 페이징 기법에서 주소 변환을 하기 위한 자료구조로, 물리적 메모리에 위치하게 된다.\r\n    2. CPU에서 프로세스의 페이지 테이블에 접근하기 위해 운영체제는 2개의 레지스터를 사용하는데, 각각 페이지 테이블 기준 레지스터(page-table base register)와 페이지 테이블 길이 레지스터(page-table length register)로 불린다.\r\n        - 페이지 테이블 기준 레지스터는 메모리 내에서의 페이지 테이블의 시작 위치를 가리킴.\r\n        - 페이지 테이블 길이 레지스터는 페이지 테이블의 크기를 보관함.\r\n    3. 페이징 기법에서의 메모리 접근 연산은 주소 변환을 위해 페이지 테이블에 접근하는 것, 변환된 주소에서 실제 데이터에 접근하는 것, 이렇게 두 번의 메모리 접근을 필요로 함.\r\n        - 이러한 오버헤드를 줄이고 메모리 접근 속도를 향상시키기 위해 TLB(Translation Look-aside Buffer)라고 불리는 고속의 주소 변환용 하드웨어 캐시가 사용된다.\r\n    4. TLB는 비싸기 때문에 페이지 테이블의 모든 정보를 담을 수는 없으며, 빈번히 참조되는 페이지에 대한 주소 변환 정보만을 담게 됨.\r\n        - 요청된 페이지 번호가 TLB에 존재한다면 곧바로 대응하는 물리적 메모리의 프레임 번호를 얻을 수 있다.\r\n        - 존재하지 않는 경우에는 메인 메모리에 있는 페이지 테이블로부터 프레임 번호를 알아내야 한다.\r\n        - 주소 변환 정보는 프로세스별로 다 다르기 때문에 문맥교환 시 이전 프로세스의 주소 변환 정보를 담고 있던 TLB 내용은 모두 지워버려야 함.\r\n    5. 페이지 테이블과 TLB에 저장되어 있는 정보는 그 구조가 조금 다르다.\r\n        - 페이지 테이블에는 모든 페이지에 대한 주소 변환 정보가 페이지 번호에 따라 순차적으로 들어 있다.\r\n        - TLB는 모든 페이지에 대한 주소 변환 정보를 가지고 있지 않기 때문에 페이지 번호와 이에 대응하는 프레임 번호가 쌍으로 저장되어야 한다.\r\n    6. TLB를 통한 주소 변환을 위해서 TLB의 모든 항목(entry)을 다 찾아봐야 하는 오버헤드가 발생하는데 이를 줄이기 위해 병렬탐색(parallel search)이 가능한 연관 레지스터(associative register)를 사용함.\r\n        - 병렬탐색 기능이란 TLB 내의 모든 항목을 동시에 탐색할 수 있는 기능을 뜻함.\r\n\r\n3. 계층적 페이징\r\n    1. 페이지 테이블에 사용되는 메모리 공간의 낭비를 줄이기 위해 2단계 페이징(two-level paging) 기법을 사용함.\r\n    2. 2단계 페이징 기법에서는 주소 변환을 위해 외부 페이지 테이블과 내부 페이지 테이블의 두 단계에 걸친 페이지 테이블을 사용함.\r\n        - 사용 메모리 공간을 줄여 공간적인 이득을 볼 수 있지만, 접근 테이블 수가 증가하므로 시간적인 손해가 뒤따르게 됨.\r\n    3. 프로세스의 주소 공간이 커질수록 페이지 테이블의 크기도 커지므로 주소 변환을 위한 메모리 공간 낭비 역시 더 심각해지게 됨.\r\n        - 2단계를 넘어 3단계, 4단계에 이르는 다단계 페이지 테이블이 필요하게 됨.\r\n        - 다단계 페이지 테이블을 사용하면 페이지 테이블을 위해 사용되는 메모리 공간의 소모는 줄일 수 있지만 그만큼 메모리에 대한 접근 횟수가 많아지기 때문에 메모리 접근시간이 크게 늘어나는 문제가 발생할 수 있음\r\n        - 이에 시간적인 오버헤드를 줄이기 위해 TLB를 사용하는 것이 효과적.\r\n        - TLB를 사용하면 4단계로 구성해도 시간 오버헤드가 그다지 크지 않으면서 메모리 공간의 효율적인 사용 효과는 매우 클 것으로 기대할 수 있음.\r\n\r\n1. 역페이지 테이블\r\n    1. 역페이지 테이블(inverted page table) 기법은 물리적 메모리의 페이지 프레임 하나당 페이지 테이블에 하나씩의 항목을 두는 방식.\r\n        - 즉, 논리적 주소에 대해 페이지 테이블을 만드는 것이 아니라 물리적 주소에 대해 테이블을 만드는 것.\r\n        - 각 프로세스마다 페이지 테이블을 두지 않고, 시스템 전체에 페이지 테이블을 하나만 두는 방법.\r\n        - 페이지 테이블의 각 항목은 프로세스 번호(pid)와 그 프로세스 내의 논리적 페이지 번호(p)를 담고 있게 됨.\r\n    2. 역페이지 테이블에 주소 변환 요청이 들어오면, 그 주소를 담은 페이지가 물리적 메모리에 존재하는지 여부를 판단하기 위해 페이지 전체를 다 탐색해야 하는 어려움이 있음.\r\n        - 역페이지 테이블은 연관 레지스터에 보관해 테이블 전체 항목에 대한 병렬탐색을 가능하게 함으로써 시간적 효율성을 꾀하게 됨.\r\n\r\n2. 공유 페이지\r\n    1. 공유 코드(shared code)는 메모리 공간의 효율적인 사용을 위해 여러 프로세스에 의해 공통으로 사용될 수 있도록 작성된 코드를 말함.\r\n        - 재진입 가능 코드(re-entrant code), 순수 코드(pure code)라고도 불리며 읽기전용(read-only)의 특성을 가지고 있음.\r\n    2. 공유 페이지(shared page)란 공유 코드를 담고 있는 페이지를 말한다.\r\n        - 공유 페이지는 여러 프로세스에 의해 공유되는 페이지이므로 물리적 메모리에 하나만 적재되어 메모리를 좀 더 효율적으로 사용할 수 있게 한다.\r\n    3. 공유 코드는 읽기전용의 성질을 가져야 할 뿐 아니라 모든 프로세스의 논리적 주소 공간에서 동일한 위치에 존재해야 하는 제약점이 있다.\r\n       즉, 공유 페이지는 그 페이지를 공유하는 모든 프로세스의 주소 공간에서 동일한 페이지 번호를 가져야 한다.\r\n    4. 공유 페이지와 대비되는 개념으로 사유 페이지(private page)가 있는데, 이것은 프로세스들이 공유하지 않고 프로세스별로 독자적으로 사용하는 페이지를 말한다.\r\n        - 해당 프로세스의 논리적 주소 공간 중 어떠한 위치에 있어도 무방함.\r\n\r\n3. 메모리 보호\r\n    1. 페이지 테이블의 각 항목에는 주소 변환 정보뿐 아니라 메모리 보호를 위한 보호비트(protection bit)와 유효-무효 비트(valid-invalid bit)를 두고 있다.\r\n    2. 보호비트는 각 페이지에 대한 접근 권한의 내용을 담고 있다.\r\n        - 각 페이지에 대해 읽기-쓰기/읽기전용 등의 접근 권한을 설정하는 데에 사용됨.\r\n    3. 유효-무효 비트는 해당 페이지의 내용이 유효한지에 대한 내용을 담고 있다.\r\n        - '유효'로 세팅되어 있으면 해당 메모리 프레임에 그 페이지가 존재함을 뜻하며, 따라서 접근이 허용된다.\r\n        - '무효'로 세팅되어 있으면 프로세스가 그 주소 부분을 사용하지 않거나, 해당 페이지가 물맂걱 메모리에 올라와 있지 않고 백킹스토어에 존재해 해당 메모리 프레임에 유효한 접근 권한이 없다는 의미를 지닌다.\r\n\r\n\r\n## 5. 세그먼테이션\r\n\r\n- 세그먼테이션(segmentation) 기법은 프로세스의 주소 공간을 의미 단위의 세그먼트(segment)로 나누어 물리적 메모리에 올리는 기법이다.\r\n- 하나의 프로세스를 구성하는 주소 공간은 코드, 데이터, 스택 등의 의미 있는 단위들로 구성되는데 세그먼트는 이와 같이 주소 공간을 기능 단위 또는 의미 단위로 나눈 것을 뜻함.\r\n    - 프로세스 주소 공간 전체를 하나의 세그먼트로 볼 수도 있으며, 일반적으로는 코드, 데이터, 스택 등의 기능 단위로 세그먼트를 정의한다.\r\n    - 논리적인 단위로 나눈 것이기 때문에 그 크기가 균일하지 않다.\r\n- 페이징과 유사하나 의미 단위의 세그먼트로 나누어 관리하므로, 크기가 균일하지 않은 세그먼트들을 메모리에 적재하는 부가적인 관리 오버헤드가 뒤따르게 됨.\r\n- 논리적 주소가 <세그먼트 번호, 오프셋>으로 나뉘어 사용됨.\r\n    - 세그먼트 번호는 해당 주소가 프로세스 주소 공간 내에서 몇 번째 세그먼트에 속하는지를 나타냄.\r\n    - 오프셋은 그 세그먼트 내에서 얼마만큼 떨어져 있는지에 대한 정보를 나타냄.\r\n- 세그먼트 테이블의 각 항목은 기준점(base)과 한계점(limit)을 가지고 있음.\r\n    - 기준점은 물리적 메모리에서 그 세그먼트의 시작 위치를 나타냄\r\n    - 한계점은 그 세그먼트의 길이를 나타냄.\r\n    - 세그먼트의 길이가 균일하지 않으므로 길이 정보를 함께 보관하고 있는 것.\r\n- 세그먼테이션 기법에서도 세그먼트 테이블 기준 레지스터(Segment-Table Base Register: STBR)와 세그먼트 테이블 길이 레지스터(Segment-Table Length Register: STLR)로 사용하게 됨.\r\n    - 세그먼트 테이블 기준 레지스터는 현재 CPU에서 실행 중인 프로세스의 세그먼트 테이블이 메모리 어느 위치에 있는지 그 시작 주소를 담고 있음.\r\n    - 세그먼트 테이블 길이 레지스터는 그 프로세스의 주소 공간이 총 몇 개의 세그먼트로 구성되는지, 즉 세그먼트의 개수를 나타낸다.\r\n- 세그먼테이션 기법에서는 논리적 주소를 물리적 주소로 변환하기 전에 두 가지 사항을 먼저 확임함.\r\n    - 요청된 세그먼트 번호가 STLR에 저장된 값보다 작은 값인가 하는 점\r\n        - 만약 그렇지 않다면 존재하지 않는 세그먼트에 대한 접근 시도이므로 예외상황을 발생시켜 메모리 접근을 봉쇄해야 할 것.\r\n    - 논리적 주소의 오프셋값이 그 세그먼트의 길이보다 작은 값인가 하는 점.\r\n        - 세그먼트 테이블의 한계점과 요청된 논리적 주소의 오프셋값을 비교해 확인하게 됨.\r\n        - 만약 세그먼트 길이를 넘어서는 오프셋 위치에 대한 접근 시도라면 예외상황을 발생시킨다.\r\n- 페이징 기법과 마찬가지로 보호비트, 유효비트를 두고 공유 세그먼트(shared segment) 개념을 지원함.\r\n- 세그먼트는 의미 단위로 나누어져 있기 때문에 공유와 보안의 측면에서 페이징 기법에 비해 훨씬 효과적임.\r\n    - 주소 공간의 일부를 공유하거나 특정 주소 공간에 읽기전용 등의 접근 권한 제어를 하고자 할 경우, 이는 어떤 의미 단위로 이루어지지 단순히 크기 단위로 수행되지 않기 때문\r\n- 의미 단위로 나누기에 세그먼트의 길이가 균일하지 않아서 외부조각이 발생하게 되며, 어느 가용 공간에 할당할 것인지 결정하는 문제가 발생함.\r\n    - 가변분할 방식의 문제와 동일한 범주의 문제라 할 수 있다.\r\n    - 최초적합 방식과 최적적합 방식을 사용해 할당한다.\r\n\r\n\r\n## 6. 페이지드 세그먼테이션\r\n\r\n- 페이징과 세그먼테이션 두 기법의 장점만을 취하는 주소 변환 기법으로 페이지드 세그먼테이션(paged segmentation) 기법이 있다.\r\n- 세그먼테이션 기법과 마찬가지로 프로그램을 의미 단위의 세그먼트로 나눈다.\r\n    - 단, 반드시 동일한 크기 페이지들의 집합으로 구성되어야 하고 물리적 메모리에 적재하는 단위는 페이지 단위로 한다.\r\n    - 즉, 페이지드 세그먼테이션 기법에서는 하나의 세그먼트 크기를 페이지 크기의 배수가 되도록 함으로써 외부조각 문제를 해결하며, 동시에 세그먼트 단위로 공유나 보호가 이루어지도록 함으로써 페이징 기법의 약점을 해소한다.\r\n- 주소 변환을 위해 외부의 세그먼트 테이블과 내부의 페이지 테이블, 이렇게 두 단계의 테이블을 이용함.\r\n- 논리적 주소의 상위 비트인 세그먼트 번호를 통해 세그먼트 테이블의 해당 항목에 접근함.\r\n    - 세그먼트 항목에는 세그먼트 길이와 그 세그먼트의 페이지 테이블 시작 주소가 들어 있음.\r\n- 세그먼트 길이값과 오프셋값을 비교해서 오프셋이 크다면 트랩을 발생시킨다.\r\n- 그렇지 않을 경우 오프셋값을 다시 상위, 하위 비트로 나누어 상위 비트는 그 세그먼트 내에서의 페이지 번호로 사용하고 하위 비트는 페이지 내에서의 변위로 사용함.\r\n- 세그먼트 테이블의 항목을 통해 세그먼트를 위한 페이지 테이블의 시작 위치를 얻었으므로, 그 위치에서 페이지 번호만큼 떨어진 페이지 테이블 항목으로부터 물리적 메모리의 페이지 프레임 위치를 얻게 됨.\r\n- 이 위치에서 오프셋의 하위 비트값인 페이지 내 변위만큼 떨어진 곳이 바로 원하는 물리적 메모리 주소가 됨.","excerpt":"컴퓨터에서는 byte 단위로 메모리 주소를 부여하기 때문에 32비트 주소 체계를 사용하면 2의 32제곱 바이트만큼의 메모리 공간에 서로 다른 주소를 할당할 수 있다. 효율적인 운영을 위해 보통 4KB(= 2의 12제곱 byte) 단위로 묶어서 페이지…","fields":{"slug":"/os-it-principle-ch7/"},"frontmatter":{"date":"Oct 16, 2021","title":"[운영체제와 정보기술의 원리] 7. 메모리 관리","tags":["os","book"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n- CPU는 프로그램의 기계어 명령을 실제로 수행하는 컴퓨터 내의 중앙처리장치.\r\n- 일반적으로 한 시스템 내에 하나씩밖에 없으므로 시분할 환경에서 매우 효율적으로 관리되어야 하는 자원.\r\n- 기계어 명령은 크게 CPU 내에서 수행되는 명령, 메모리 접근을 필요로 하는 명령, 입출력을 동반하는 명령으로 나누어볼 수 있음.\r\n    - CPU 내에서 수행되는 명령\r\n        1. Add 명령 - CPU 내의 레지스터에 있는 두 값을 더해 레지스터에 저장하는 명령. CPU 내에서 수행되므로 명령의 수행 속도가 빠르다.\r\n    - 메모리 접근을 수행하는 명령\r\n        1. Load 명령 - 메모리에 있는 데이터를 CPU로 읽어들이는 명령\r\n        2. Store 명령 - CPU에서 계산된 결괏값을 메모리에 저장하는 명령     \r\n       CPU 내에서 수행되는 명령보다는 오래 소요되지만 비교적 짧은 시간에 수행할 수 있음.   \r\n       CPU 내에서 수행되는 명령과 메모리 접근을 수행하는 명령은 일반명령에 해당함.\r\n    - 입출력을 동반하는 명령\r\n        - CPU나 메모리 접근 명령에 비해 대단히 오랜 시간이 소요됨.\r\n        - 특권명령으로 규정해 운영체제를 통해 서비스를 대행하도록 하고 있음.\r\n- 프로그램의 수행은 서로 다른 두 단계의 조합으로 이루어짐.\r\n    1. 사용자 프로그램이 CPU를 직접 가지고 빠른 명령을 수행하는 일련의 단계\r\n        - CPU 버스트라고 함.\r\n        - 프로그램이 I/O를 한 번 수행한 후 다음 번 I/O를 수행하기까지 직접 CPU를 가지고 명령을 수행하는 일련의 작업\r\n    2. I/O 요청이 발생해 커널에 의해 입출력 작업을 진행하는 비교적 느린 단계\r\n        - I/O 버스트라고 함.\r\n        - I/O 작업이 요청된 후 완료되어 다시 CPU 버스트로 돌아가기까지 일어나는 일련의 작업.\r\n- I/O 바운드 프로세스\r\n    - I/O 요청이 빈번해 CPU 버스트가 짧게 나타나는 프로세스\r\n    - 사용자로부터 인터랙션을 계속 받아가며 프로그램을 수행시키는 대화형 프로그램(interactive program)\r\n    - 짧은 CPU 버스트를 많이 가짐.\r\n- CPU 바운드 프로세스\r\n    - I/O 작업을 거의 수행하지 않아 CPU 버스트가 길게 나타나는 프로세스를 말함.\r\n    - 프로세스 수행의 상당 시간을 입출력 작업 없이 CPU 작업에 소모하는 계산 위주의 프로그램.\r\n    - 소수의 긴 CPU 버스트로 구성됨.\r\n- CPU 스케줄링은 CPU를 사용하는 패턴이 상이한 여러 프로그램이 동일한 시스템 내부에서 함께 실행되기 때문에 필요한 것.\r\n    - 시분할 시스템에서 CPU 버스트가 균일하지 않은 다양한 프로그램이 공존하므로 효율적인 CPU 스케줄링 기법이 반드시 필요함.\r\n- 프로세스들을 살펴보면 CPU를 한 번에 오래 사용하기보다는 잠깐 사용하고 I/O 작업을 수행하는 프로세스들이 많음.\r\n    - 이러한 CPU 버스트가 짧은 프로세스는 대화형 작업으로 사용자와 인터랙션을 해가며 프로그램을 수행시킴.\r\n    - CPU의 빠른 서비스를 필요로 하기에 (대화형 작업은 빠른 응답이 중요함) CPU 스케줄링을 할 때 CPU 버스트가 짧은 프로세스에게 우선적으로 CPU를 사용할 수 있도록 하는 스케줄링이 필요함.\r\n- 따라서 I/O 바운드 프로세스의 우선순위를 높여주는 것이 바람직하다.\r\n    - I/O 바운드 프로세스에게 먼저 CPU를 할당할 경우 CPU를 잠깐만 사용한 후 곧바로 I/O 장치의 이용률이 높아짐.\r\n    - CPU 바운드 프로세스에게 먼저 CPU를 할당하면 그 프로세스가 CPU를 다 사용할 때까지 I/O 바운드 프로세스는 응답시간이 길어질 뿐 아니라 해당 I/O 장치도 그 시간 동안 작업을 수행하지 않는 휴면 상태가 되기 때문에 비효율적.\r\n\r\n\r\n## 1. CPU 스케줄러\r\n\r\n- CPU 스케줄러는 준비 상태에 있는 프로세스들 중 어떠한 프로세스에게 CPU를 할당할지 결정하는 운영체제의 코드.\r\n- 타이머 인터럽트가 발생하면 CPU 스케줄러가 호출되고 준비 큐에서 CPU를 기다리는 프로세스 중 하나를 선택해 CPU를 할당하게 됨.\r\n- CPU 스케줄링이 필요한 경우\r\n    1. 실행 상태에 있던 프로세스가 I/O 요청 등에 의해 봉쇄 상태로 바뀌는 경우\r\n    2. 실행 상태에 있던 프로세스가 타이머 인터럽트 발생에 의해 준비 상태로 바뀌는 경우\r\n    3. I/O 요청으로 봉쇄 상태에 있던 프로세스의 I/O 작업이 완료되어 인터럽트가 발생하고 그 결과 이 프로세스의 상태가 준비 상태로 바뀌는 경우\r\n    4. CPU에서 실행 상태에 있는 프로세스가 종료되는 경우\r\n- CPU 스케줄링 방식에는 두 가지가 있음.\r\n    - 비선점형(nonpreemptive) 방식\r\n        - CPU를 획득한 프로세스가 스스로 CPU를 반납하기 전까지는 CPU를 빼앗기지 않는 방법을 말함.\r\n    - 선점형(preemptive) 방식\r\n        - 프로세스가 CPU를 계속 사용하기를 원하더라도 강제로 빼앗을 수 있는 스케줄링 방법을 말함.\r\n    - 위 네 가지 경우에서 1, 4는 비선점형 스케줄링, 2, 3은 선점형 스케줄링에 해당함.\r\n    - 3의 경우 I/O 작업이 완료된 프로세스가 인터럽트 당한 프로세스보다 우선순위가 높아 인터럽트 처리 후 수행되던 프로세스에게 CPU를 다시 할당하는 것이 아닌 문맥교환을 통해 I/O가 완료된 프로세스에게 CPU를 할당하는 경우가 해당됨.\r\n- CPU를 빼앗는 방법으로는 할당시간(time quantum)을 부여한 후 타이머 인터럽트를 발생시키는 방법이 대표적.\r\n\r\n## 2. 디스패처\r\n\r\n- 새롭게 선택된 프로세스가 CPU를 할당받고 작업을 수행할 수 있도록 환경설정을 하는 운영체제의 코드를 디스패처(dispatcher)라고 부름.\r\n- 디스패처는 현재 수행 중이던 프로세스의 문맥을 그 프로세스의 PCB에 저장하고, 새롭게 선택된 프로세스의 문맥을 PCB로부터 복원한 후 그 프로세스에게 CPU를 넘기는 과정을 수행함.\r\n- 새로운 프로세스의 문맥을 복원시킨 후엔 시스템의 상태를 사용자모드로 전환해 사용자 프로그램에게 CPU의 제어권을 넘기게 됨.\r\n    - 사용자 프로그램은 복원된 문맥 중 프로그램 카운터로부터 현재 수행할 주소를 찾을 수 있게 됨.\r\n- 디스패처가 하나의 프로세스를 정지시키고 다른 프로세스에게 CPU를 전달하기까지 걸리는 시간을 디스패치 지연시간(dispatch latency)이라고 하며, 디스패치 지연시간의 대부분은 문맥교환 오버헤드에 해당됨.\r\n\r\n## 3. 스케줄링의 성능 평가\r\n\r\n- 스케줄링 기법의 성능을 평가하기 위해 여러 지표들이 사용되는데, 이 지표들은 크게 시스템 관점의 지표와 사용자 관점의 지표로 나누어볼 수 있음.\r\n    - 시스템 관점의 지표로는 CPU 이용률과 처리량이 있음.\r\n    - 사용자 관점의 지표로는 소요시간, 대기시간, 응답시간 등 기다린 시간과 관련된 지표들이 있음.\r\n- CPU 이용률(CPU utilization)\r\n    - 전체 시간 중에서 CPU가 일을 한 시간의 비율을 나타냄.\r\n    - CPU는 고비용 자원이므로 CPU 이용률은 시스템 전체의 성능과 밀접하게 관련되어 있어 CPU가 일을 하지 않고 휴면(idle) 상태에 머무르는 시간을 최대한 줄이는 것이 스케줄링의 중요한 목표가 됨.\r\n- 처리량(throughput)\r\n    - 주어진 시간 동안 준비 큐에서 기다리고 있는 프로세스 중 몇 개를 끝마쳤는지(CPU 버스트를 완료한 프로세스의 개수)를 나타냄.\r\n    - CPU의 서비스를 원하는 프로세스 중 몇 개가 원하는 만큼의 CPU를 사용하고 이번 CPU 버스트를 끝내어 준비 큐를 떠났는지 측정하는 것이 처리량의 개념\r\n    - 더 많은 프로세스들이 CPU 작업을 완료하기 위해서는 CPU 버스트가 짧은 프로세스에게 우선적으로 CPU를 할당하는 것이 유리함.\r\n- 소요시간(turnaround time)\r\n    - 프로세스가 CPU를 요청한 시점부터 자신이 원하는 만큼의 CPU를 다 쓰고 CPU 버스트가 끝날 때까지 걸린 시간, 즉 준비 큐에서 기다린 시간과 실제로 CPU를 사용한 시간의 합을 뜻함.\r\n    - 프로그램이 시작해 종료하는 데까지 걸리는 시간이 아님을 주의.\r\n- 대기시간(waiting time)\r\n    - CPU 버스트 기간 중 프로세스가 준비 큐에서 CPU를 얻기 위해 기다린 시간의 합을 뜻함.\r\n    - 한 번의 CPU 버스트 중에도 준비 큐에서 기다린 시간이 여러 번 발생할 수 있음.\r\n- 응답시간(response time)\r\n    - 프로세스가 준비 큐에 들어온 후 첫 번째 CPU를 획득하기까지 기다린 시간을 뜻함.\r\n    - 타이머 인터럽트가 빈번히 발생할수록 각 프로세스가 CPU를 연속적으로 사용할 수 있는 시간이 짧아지므로 처음 CPU를 얻기까지 걸리는 시간을 줄어들게 되어 응답시간이 향상된다.\r\n    - 대화형 시스템에 적합한 성능 척도로서 사용자 입장에서 가장 중요한 성능 척도\r\n\r\n## 4. 스케줄링 알고리즘\r\n\r\n1. 선입선출 스케줄링(First-Come First-Served: FCFS)\r\n    - 프로세스가 준비 큐에 도착한 시간 순서대로 CPU를 할당하는 방식을 말함.\r\n    - CPU를 먼저 요청한 프로세스에게 CPU를 먼저 할당하고, 그 프로세스가 자발적으로 CPU를 반납할 때까지 빼앗지 않음.\r\n    - 합리적인 스케줄링 방식인 것 같지만 경우에 따라 비효율적인 결과를 초래하기도 함.\r\n        - CPU 버스트가 긴 프로세스가 먼저 도착할 경우 평균 대기시간이 길어지고 I/O 장치 이용률도 동반 하락하게 됨.\r\n    - CPU 버스트가 긴 프로세스가 먼저 도착할 경우 평균 대기시간이 길어지는 반면, CPU 버스트가 짧은 프로세스가 먼저 도착하게 되면 평균 대기시간이 짧아지게 됨.\r\n    - CPU 버스트가 짧은 프로세스가 CPU 버스트가 긴 프로세스보다 나중에 도착해 오랜 시간을 기다려야 하는 현상을 콘보이 현상(Convoy effect)라고 한다.\r\n\r\n2. 최단작업 우선 스케줄링(Shortest-Job First: SJF)\r\n    - CPU 버스트가 가장 짧은 프로세스에게 제일 먼저 CPU를 할당하는 방식.\r\n    - 프로세스들이 준비 큐에서 기다리는 전체적인 시간이 줄어들게 됨.\r\n    - 평균 대기시간을 가장 짧게 하는 최적 알고리즘(optimal algorithm)으로 알려져 있음.\r\n    - 비선점형 방식\r\n        - CPU를 획득하면 그 프로세스가 CPU를 자진 반납하기 전까지는 CPU를 빼앗지 않는 방식\r\n    - 선점형 방식\r\n        - 준비 큐에서 CPU 버스트가 가장 짧은 프로세스에게 CPU를 할당했다 하더라도, CPU 버스트가 더 짧은 프로세스가 도착할 경우 CPU를 빼앗아 더 짧은 프로세스에게 부여하는 방식을 말함.\r\n        - SRTF(Shortest Remaining Time First)라고도 부름.\r\n    - 프로세스들이 준비 큐에 도착하는 시간이 불규칙한 환경에서는 선점형 방식이 프로세스들의 평균 대기시간을 최소화하는 최적 알고리즘이 됨.\r\n    - 준비 큐에 한꺼번에 도착하고 그 후에 따로 도착하지 않는 환경에서는 비선점형 방식과 선점형 방식이 서로 같은 결과를 나타내기도 함.\r\n    - 일반적인 시분할 환경에서는 중간중간에 새로운 프로세스가 도착하는 경우가 발생하므로 선점형 방식이 평균 대기시간을 가장 많이 줄일 수 있는 방식이 됨.\r\n    - SJF 스케줄링 기법의 구현에서 현실적으로 어려운 부분은 프로세스의 CPU 버스트 시간을 미리 알 수 없다는 점.\r\n        - 예측을 통해 CPU 버스트 시간을 구한 후 예측치가 가장 짧은 프로세스에게 CPU를 할당하게 됨.\r\n        - CPU 버스트 시간의 예측은 과거의 CPU 버스트 시간을 통해 이루어짐.\r\n    - 계속 CPU 버스트가 짧은 프로세스에게만 CPU를 할당할 경우 CPU 버스트가 긴 프로세스는 준비 큐에 줄 서서 무한정 기다려야 하는 문제가 발생할 수 있기 때문에 항상 좋은 방식이라고는 말할 수 없다.\r\n    - CPU 버스트가 짧은 프로세스가 계속 도착할 경우 CPU 버스트가 긴 프로세스는 영원히 CPU를 할당받지 못할 수도 있는데 이 현상을 기아 현상(starvation)이라고 한다.\r\n\r\n3. 우선순위 스케줄링(priority scheduling)\r\n    - 준비 큐에서 기다리는 프로세스들 중 우선순위가 가장 높은 프로세스에게 제일 먼저 CPU를 할당하는 방식을 말함.\r\n    - 우선순위값이 작을수록 높은 우선순위를 가지는 것으로 가정.\r\n    - 우선순위를 결정하는 방식에는 여러 가지가 있는데 CPU 버스트 시간을 기준으로 하거나 시스템과 관련된 중요한 작업을 수행하는 프로세스 우선순위를 높게 부여할 수도 있다.\r\n    - 비선점형 방식\r\n        - CPU를 얻었으면 우선순위가 더 높은 프로세스가 도착하더라도 CPU를 자진 반납하기 전까지 선점하지 않는다.\r\n    - 선점형 방식\r\n        - 현재 CPU에서 수행 중인 프로세스보다 우선순위가 높은 프로세스가 도착하여 CPU를 선점해서 새롭게 도착한 프로세스에게 할당하는 경우\r\n    - 우선순위가 높은 프로세스가 계속 도착하는 상황에서 우선순위가 낮은 프로세스는 CPU를 얻지 못한 채 계속 기다려야 하는 기아 현상이 발생할 수 있음.\r\n        - 기다리는 시간이 길어지면 우선순위를 조금씩 높여, 언젠가는 가장 높은 우선순위가 되어 CPU를 할당받을 수 있게 해주는 노화(aging) 기법을 통해 해결할 수 있다.\r\n\r\n4. 라운드 로빈 스케줄링(Round Robin Scheduling)\r\n    - 각 프로세스가 CPU를 연속적으로 사용할 수 있는 시간이 특정 시간으로 제한되며, 이 시간이 경과하면 해당 프로세스로부터 CPU를 회수해 준비 큐에 줄 서 있는 다른 프로세스에게 CPU를 할당한다.\r\n    - 각 프로세스마다 한 번에 CPU를 연속적으로 사용할 수 있는 최대시간을 할당시간(time quantum)이라고 부름.\r\n    - 할당시간이 너무 길면 라운드 로빈 스케줄링은 FCFS와 같은 결과를 나타내게 됨.\r\n    - 할당시간이 너무 짧으면 CPU를 사용하는 프로세스가 빈번하게 교체되어 문맥교환의 오버헤드가 커짐.\r\n    - 따라서 일반적으로 할당시간을 수십 밀리초 정도의 규모로 설정하게 됨.\r\n        - 여러 프로세스가 동시에 수행되는 환경에서 대화형 프로세스가 CPU를 한 번 할당받기까지 지나치게 오래 기다리지 않을 정도의 시간 규모에 해당됨.\r\n    - 라운드 로빈 스케줄링은 여러 종류의 이질적인 프로세스가 같이 실행되는 환경에서 효과적.\r\n    - 할당시간이 만료되어 CPU를 회수하는 방법으로는 타이머 인터럽트를 사용하게 됨.\r\n    - 라운드 로빈 스케줄링의 기본적인 목적은 CPU 버스트 시간이 짧은 프로세스가 빨리 CPU를 얻을 수 있도록 하는 동시에, CPU 버스트 시간이 긴 프로세스가 불이익을 당하지 않도록 하는 것.\r\n    - 자신이 CPU를 쓰고자 하는 양이 적으면 소요시간이 짧아지고, 많으면 소요시간도 거기에 비례해서 길어진다.\r\n      대기시간 역시 비례해서 증가하므로 공정하다고 할 수 있음.\r\n    - 동일한 CPU 버스트 시간을 가지는 프로세스들이 도착했을 경우 FCFS에서는 CPU를 먼저 쓰고 나가는 프로세스의 소요시간 및 대기시간이 짧아지는 반면, 라운드 로빈 스케줄링에서는 CPU를 조금씩 같이 쓰고 거의 동시에 끝나게 되어 소요시간 및 대기시간이 가장 오래 기다린 프로세스에 맞춰지게 된다.\r\n      따라서 라운드 로빈 스케줄링의 평균 대기시간 및 평균 소요시간은 FCFS의 거의 두 배가 된다.\r\n    - 일반적인 시스템에서는 CPU 버스트 시간이 균일하지 않고 각자 다른 CPU 버스트 및 I/O 버스트를 가지는 경우가 대부분이다.\r\n        - 이 경우 라운드 로빈 스케줄링을 적용하면 CPU 버스트 시간이 짧은 프로세스는 빨리 끝마치고, 반대로 CPU 버스트 시간이 긴 프로세스는 상대적으로 오래 기다린다.\r\n        - FCFS는 CPU 버스트가 긴 프로세스가 먼저 도착하는 경우 소요시간의 편차가 크고 평균값드 극단적으로 상승하게 된다.\r\n\r\n5. 멀티레벨 큐(multi-level queue)\r\n    - 준비 큐를 여러 개로 분할해 관리하는 스케줄링 기법.\r\n      즉, 프로세스들이 CPU를 기다리기 위해 한 줄로 서는 것이 아니라 여러 줄로 서는 것.\r\n    - 멀티레벨 큐는 성격이 다른 프로세스들을 별도로 관리하고, 프로세스의 성격에 맞는 스케줄링을 적용하기 위해 준비 큐를 별도로 두게 됨.\r\n    - 일반적으로 멀티레벨 큐에서 준비 큐는 대화형 작업을 담기 위한 전위 큐(foreground queue)와 계산 위주의 작업을 담기 위한 후위 큐(background queue)로 분할하여 운영됨.\r\n        - 전위 큐에서는 응답시간을 짧게 하기 위해 라운드 로빈 스케줄링을 사용하는 반면, 계산 위주의 작업을 위한 후위 큐에서는 응답시간이 큰 의미를 가지지 않기 때문에 FCFS 스케줄링 기법을 사용해 문맥교환 오버헤드를 줄이도록 함.\r\n    - 여러 개의 준비 큐에 대해서 어느 큐에 먼저 CPU를 할당할 것인지 결정하는 스케줄링이 필요함.\r\n        - 고정 우선순위 방식(fixed priority scheduling)\r\n            - 큐에 고정적인 우선순위를 부여해 우선순위가 높은 큐를 먼저 서비스하고 우선순위가 낮은 큐는 우선순위가 높은 큐가 비어 있을 때에만 서비스하게 됨.\r\n            - 전위 큐에 있는 프로세스에게 우선적으로 CPU가 할당되고, 전위 큐가 비어 있는 경우에만 후위 큐 프로세스에 CPU 할당.\r\n        - 타임 슬라이스(time slice) 방식\r\n            - 큐에 대한 기아 현상을 해소할 수 있는 방식으로, 각 큐에 CPU 시간을 적절한 비율로 할당함.\r\n\r\n6. 멀티레벨 피드백 큐(Multilevel Feedback Queue)\r\n    - 멀티레벨 큐와 동일하나, 프로세스가 하나의 큐에서 다른 큐로 이동가능하다는 점이 다르다.\r\n    - 멀티레벨 피드백 큐를 정의하는 요소들로는 큐의 수, 각 큐의 스케줄링 알고리즘, 프로세스를 상위 큐로 승격시키는 기준, 프로세스를 하위 큐로 강등시키는 기준, 프로세스가 도착했을 때 들어갈 큐를 결정하는 기준 등이 있음.\r\n    - 프로세스의 CPU 작업시간을 다단계로 분류함으로써 작업시간이 짧은 프로세스일수록 더욱 빠른 서비스가 가능하도록 하고, 작업시간이 긴 프로세스에 대해서는 문맥교환 없이 CPU 작업에만 열중할 수 있는 FCFS 방식을 채택할 수 있게 함.\r\n\r\n7. 다중처리기 스케줄링\r\n    - CPU가 여러 개인 시스템을 다중처리기 시스템(multi-processor system)이라고 부른다.\r\n    - 다중처리기 스케줄링에서는 일부 CPU에 작업이 편중되는 현상을 방지하기 위해 각 CPU별 부하가 적절히 분산되도록 하는 부하균형(load balancing) 메커니즘을 필요로 한다.\r\n    - 대칭형 다중처리(symmetric multi-processing)\r\n        - 각 CPU가 각자 알아서 스케줄링을 결정하는 방식\r\n    - 비대칭형 다중처리(asymmetric multi-processing)\r\n        - 하나의 CPU가 다른 모든 CPU의 스케줄링 및 데이터 접근을 책임지고 나머지 CPU는 거기에 따라 움직이는 방식\r\n\r\n8. 실시간 스케줄링\r\n    - 실시간 시스템에서는 각 작업마다 주어진 데드라인이 있어 정해진 데드라인 안에 반드시 작업을 처리해야 함.\r\n    - 경성 실시간 시스템(hard real-time system)\r\n        - 미사일 발사, 원자로 제어 등 시간을 정확히 지켜야 하는 시스템.\r\n        - 정해진 시간 안에 반드시 작업이 완료되도록 스케줄링해야 함.\r\n    - 연성 실시간 시스템(soft real-time system)\r\n        - 데드라인이 존재하기는 하지만 데드라인을 지키지 못했다고 해서 위험한 상황이 발생하지는 않음. ex) 멀티미디어 스트리밍 시스템\r\n    - 데드라인이 얼마 남지 않은 요청을 먼저 처리하는 EDF(Earlist Deadline First) 스케줄링을 사용함.\r\n    - 연성 실시간 시스템처럼 일반 작업과 VOD 작업 등이 혼합된 환경에서는 데드라인이 존재하는 프로세스에게 일반 프로세스보다 높은 우선순위를 할당하는 방식도 사용함.\r\n\r\n\r\n## 5. 스케줄링 알고리즘의 평가\r\n\r\n- 큐잉모델(queueing model)\r\n    - 주로 이론가들이 수행하는 방식\r\n    - 확률분포를 통해 프로세스들의 도착률과 CPU 처리율을 입력값으로 주면 복잡한 수학적 계산을 통해 각종 성능지표인 CPU의 처리량, 프로세스 평균 대기시간 등을 구하게 됨.\r\n- 구현 및 실측(implementation & measurement)\r\n    - 구현가들이 수행할 수 있는 방식\r\n    - 커널의 CPU 스케줄링 수행 코드를 수정해서 커널을 컴파일한 후 시스템에 설치하는 과정을 필요로 함.\r\n      그 후 원래 커널과 스중한 커널에서 프로그램을 실행시켜보고 실행시간을 측정.\r\n- 시뮬레이션(simulation)\r\n    - 가상으로 CPU 스케줄링 프로그램을 작성한 후 프로그램의 CPU 요청을 입력값으로 넣어 어떤 결과가 나오는지를 확인하는 방법.","excerpt":"CPU는 프로그램의 기계어 명령을 실제로 수행하는 컴퓨터 내의 중앙처리장치. 일반적으로 한 시스템 내에 하나씩밖에 없으므로 시분할 환경에서 매우 효율적으로 관리되어야 하는 자원. 기계어 명령은 크게 CPU 내에서 수행되는 명령, 메모리 접근을 필요로…","fields":{"slug":"/os-it-principle-ch6/"},"frontmatter":{"date":"Oct 15, 2021","title":"[운영체제와 정보기술의 원리] 6. CPU 스케줄링","tags":["os","book"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n## 1. 프로세스의 개념\r\n\r\n- 프로세스(process)란 실행 중인 프로그램(program in execution)을 뜻한다.\r\n- 디스크에 실행파일 형태로 존재하던 프로그램이 메모리에 올라가서 실행되기 시작하면 프로세스가 되며, 프로세스는 CPU를 획득해 자신의 코드를 수행하기도 하고, 때로는 CPU를 반환하고 입출력 작업을 수행하기도 함.\r\n- 일반적으로 잡(job)이라는 용어와 프로세스를 혼용해 사용하기도 함.\r\n- 프로세스의 문맥(context)이란 프로세스가 현재 어떤 상태에서 수행되고 있는지 정확히 규명하기 위해 필요한 정보를 의미한다.\r\n    - 시분할 시스템과 같은 환경에서는 CPU를 다시 획득해 명령의 수행을 재개하는 시점이 되면 이전의 CPU 보유 시기에 어느 부분까지 명령을 수행했는지 직전 수행 시점의 정확한 상태를 재현할 필요가 있고 이를 위해 필요한 정보가 문맥임.\r\n    - 문맥은 크게 세 가지로 분류가 가능함.\r\n    - 하드웨어 문맥\r\n        - CPU의 수행 상태를 나타내는 것으로 프로그램 카운터값과 각종 레지스터에 저장하고 있는 값들을 의미\r\n    - 프로세스의 주소 공간\r\n        - 코드, 데이터, 스택으로 구성되는 자기 자신만의 독자적인 주소 공간.\r\n    - 커널상의 문맥\r\n        - 프로세스를 관리하기 위한 자료구조인 PCB와 커널스택\r\n\r\n\r\n## 2. 프로세스의 상태\r\n\r\n- 프로세스의 상태는 실행(running), 준비(ready), 봉쇄(blocked, wait, sleep) 세 가지로 구분할 수 있음. + 시작(new), 완료(terminated) 상태\r\n\r\n    ![Untitled (72)](https://user-images.githubusercontent.com/62014888/146319298-3312417b-7b23-43dd-a479-18cba8948d1b.png)\r\n\r\n    - 실행 상태 - 프로세스가 CPU를 보유하고, 기계어 명령을 실행하고 있는 상태\r\n    - 준비 상태 - 프로세스가 CPU만 보유하면 당장 명령을 실행할 수 있지만 CPU를 할당받지 못한 상태\r\n    - 봉쇄 상태 - CPU를 할당받더라도 당장 명령을 실행할 수 없는 상태 ex) 입출력 작업\r\n    - 시작 상태 - 프로세스가 시작되어 그 프로세스를 위한 각종 자료구조는 생성되었지만 아직 메모리 획득을 승인받지 못한 상태\r\n    - 완료 상태 - 프로세스가 종료되었으나 운영체제가 그 프로세스와 관련된 자료구조를 완전히 정리하지 못한 상태\r\n- 실행시킬 프로세스를 변경하기 위해 원래 수행 중이던 프로세스의 문맥을 저장하고 새로운 프로세스의 문맥을 세팅하는 과정을 문맥교환(context switch)이라고 한다.\r\n    - ex) 타이머 인터럽트, 입출력 요청 등\r\n- 준비 상태에 있는 프로세스들 중에서 CPU를 할당받을 프로세스를 선택한 후 실제로 CPU 제어권을 넘겨받는 과정을 CPU 디스패치(dispatch)라고 한다.\r\n- 인터럽트가 발생하면 CPU는 어떤 프로세스를 실행하고 있다가 인터럽트를 확인하고 그에 대응하는 루틴을 실행함.\r\n  루틴이 진행되는 동안 CPU에서 수행되던 프로세스의 상태는 커널모드 실행 상태로 바뀜.\r\n  인터럽트 처리루틴이 직전에 실행 중이던 프로세스와는 무관한 업무를 담고 있기는 하지만 인터럽트 처리를 편의상 직전 프로세스의 문맥에서 실행된 것으로 간주함.\r\n\r\n## 3. 프로세스 제어블록\r\n\r\n- 프로세스 제어블록(PCB)이란 운영체제가 시스템 내의 프로세스들을 관리하기 위해 프로세스마다 유지하는 정보들을 담는 커널 내의 자료구조를 뜻함.\r\n- PCB는 다음과 같은 요소들로 구성되어 있음.\r\n    - 프로세스 상태 - CPU를 할당해도 되는지 여부를 결정하기 위해 필요\r\n    - 프로그램 카운터값 - 다음에 수행할 명령의 위치\r\n    - CPU 레지스터값 - CPU 연산을 위해 현 시점에 레지스터에 어떤 값을 저장하고 있는지를 나타냄.\r\n    - CPU 스케줄링 정보 - 프로세스의 CPU 스케줄링을 위해 필요한 정보\r\n    - 메모리 관리 정보 - 메모리 할당을 위해 필요한 정보\r\n    - 자원 사용 정보 - 자원 사용 요금을 계산해 청구하는 등의 용도로 사용.\r\n    - 입출력 상태 정보 - 프로세스가 오픈한 파일 정보 등 프로세스의 입출력 관련 상태 정보\r\n\r\n## 4. 문맥교환\r\n\r\n- 문맥교환이란 하나의 사용자 프로세스로부터 다른 사용자 프로세스로 CPU 제어권이 이양되는 과정을 뜻함.\r\n    - 문맥교환 중에 원래 CPU를 보유하고 있던 프로세스는 프로그램 카운터값 등 프로세스의 문맥을 자신의 PCB에 저장하고, 새롭게 CPU를 할당받을 프로세스는 예전에 저장했던 자신의 문맥을 PCB로부터 실제 하드웨어로 복원시키는 과정을 거친다.\r\n    - 타이머 인터럽트, 입출력 요청, 다른 조건을 충족하지 못해 CPU를 회수당하고 봉쇄 상태가 되는 경우 등에서 발생.\r\n- 시스템 콜(입출력 요청 시스템 콜이 아님)이나 인터럽트의 경우에도 CPU의 실행 위치 등 프로세스의 문맥 중 일부를 PCB에 저장하게 되지만 이러한 과정을 문맥교환이라고 하지는 않음.\r\n    - 사용자모드에서 커널모드로 바뀌는 것일뿐, CPU를 점유하는 프로세스가 다른 사용자 프로세스로 변경되는 과정이 아니기 때문.\r\n    - 모드 변경에 비해 문맥교환에는 훨씬 많은 오버헤드가 뒤따르게 됨.\r\n- 타이머 인터럽트,  입출력 요청 시스템 콜을 하여 봉쇄 상태에 들어가는 경우에는 문맥교환이 일어나지만, 그 밖의 인터럽트나 시스템 콜 발생 시에는 문맥교환이 일어나지 않고 실행 모드만이 변경될 뿐임.\r\n    - 사용자모드에서 커널모드로 바뀌어 시스템 콜이나 인터럽트를 처리하고, 다시 동일한 프로세스의 사용자모드로 돌아와 이전에 수행하던 작업을 계속 수행할 뿐.\r\n- 타이머에 CPU 할당시간을 아주 작게 세팅해 프로세스 간 문맥교환이 빈번하게 발생하도록 하면 오버헤드가 상당히 커지고 CPU 할당시간을 너무 크게 설정하면 시분할 시스템의 의미가 퇴색하게 되므로 적절한 CPU 할당시간을 정하는 것이 중요함.\r\n\r\n\r\n\r\n## 5. 프로세스를 스케줄링하기 위한 큐\r\n\r\n- 운영체제는 준비 상태에 있는 프로세스들을 줄 세우기 위해 준비 큐(ready queue)를 두고 준비 큐의 제일 앞에 줄 서 있는 프로세스에 제일 먼저 CPU를 할당함.\r\n    - 준비 큐에 프로세스를 줄 세우는 방법은 CPU 스케줄링 방법에 따라 달라짐.\r\n- 특정 자원을 기다리는 프로세스들을 줄 세우기 위해 자원별로 장치 큐(device queue)를 둔다.\r\n    - 디스크에 입출력 서비스를 요청한 프로세스들은 디스크 입출력 큐(disk I/O queue)에 줄 서게 됨.\r\n    - 인터럽트 처리루틴에 의해 디스크 입출력이 완료된 프로세스는 입출력 큐에서 빠져나와 CPU를 기다리는 준비 큐에 줄 서게 됨.\r\n- 하드웨어 자원을 기다리는 프로세스 외에도 소프트웨어 자원을 기다리는 경우에도 큐가 필요함.\r\n    - 공유 데이터에 대한 접근 권한은 소프트웨어 자원으로 분류될 수 있음.\r\n    - 공유 데이터라는 일종의 소프트웨어 자원을 앞서 접근 중인 프로세스가 다 사용하고 반납할 때까지는 다른 프로세스가 CPU를 할당받았다 하더라도 접근하지 말고 기다려야 하는 것.\r\n    - 따라서 여러 프로세스가 공유 데이터에 접근하려고 할 경우 기다리는 큐에 줄 서게 하고, 다른 프로세스가 데이터를 반납할 경우 큐에 줄 서 있는 순서대로 데이터의 접근 권한을 주는 방법을 사용하게 됨.\r\n- 프로세스의 상태 관리는 커널의 주소 영역 중 데이터 영역의 다양한 큐를 두어 수행하게 됨.\r\n- 준비 큐와 장치 큐 외에 작업 큐(job queue)를 추가로 유지함.\r\n    - 작업 큐는 시스템 내의 모든 프로세스를 관리하기 위한 큐로, 프로세스의 상태와 무관하게 현재 시스템 내에 있는 모든 프로세스가 작업 큐에 속하게 됨.\r\n      그러므로 작업 큐에 있다고 해서 반드시 메모리를 가지고 있는 것이 아님.\r\n    - 작업 큐가 가장 넓은 개념이고 준비 큐와 장치 큐에 있는 프로세스들은 모두 작업 큐에 속해있음.\r\n- 큐헤더는 큐의 가장 앞부분을 말하고 큐는 각 프로세스의 PCB를 연결 리스트 형태로 관리하며 포인터를 사용해 순서를 정함.\r\n\r\n## 6. 스케줄러\r\n\r\n- 스케줄러(scheduler)란 어떤 프로세스에게 자원을 할당할지를 결정하는 운영체제 커널의 코드를 지칭함.\r\n- 장기 스케줄러(long term scheduler)\r\n    - 작업 스케줄러(job scheduler)\r\n    - 어떤 프로세스를 준비 큐에 진입시킬지를 결정하는 역할을 함.\r\n    - 프로세스에게 메모리를 할당하는 문제에 관여하게 됨.\r\n    - 즉, 시작 상태의 프로세스들 중 어떠한 프로세를 준비 큐에 삽입할 것인지 결정하는 역할을 하게 되는 것.\r\n- 단기 스케줄러(short term scheduler)\r\n    - CPU 스케줄러\r\n    - 준비 상태의 프로세스 중에서 어떤 프로세스를 다음번에 실행 상태로 만들 것인지 결정함.\r\n    - 즉, 준비 큐에 있는 여러 프로세스들 중 어떠한 프로세스에게 CPU를 할당할 것인가를 단기 스케줄러가 결정함.\r\n    - 시분할 시스템에서는 타이머 인터럽트가 발생하면 단기 스케줄러가 호출됨.\r\n- 단기 스케줄러는 밀리초 정도의 시간 단위로 매우 빈번하게 호출되기 때문에 속도가 충분히 빨라야하는 반면에 장기 스케줄러는 수십 초 내지 수 분 단위로 가끔 호출되기 때문에 상대적으로 속도가 느린 것이 허용됨.\r\n- 장기 스케줄러는 메모리에 동시에 올라가 있는 프로세스의 수를 조절하는 역할을 함.\r\n- 현대 시분할 시스템에서 사용되는 운영체제에는 일반적으로 장기 스케줄러를 두지 않는 경우가 대부분임.\r\n    - 과거에는 자원이 매우 빈약했지만 현대에는 그렇지도 않아 프로세스가 시작 상태가 되면 곧바로 프로세스에 메모리를 할당해 준비 큐에 넣어주게 됨.\r\n- 중기 스케줄러(medium term scheduler)\r\n    - 너무 많은 프로세스에게 메모리를 할당해 시스템의 성능이 저하되는 경우 이를 해결하기 위해 메모리에 적재된 프로세스의 수를 동적으로 조절하기 위해 추가된 스케줄러.\r\n    - 메모리에 올라와 있는 프로세스 중 일부를 선정해 이들로부터 메모리를 통째로 빼앗아 그 내용을 디스크의 스왑 영역에 저장해두는데 이를 스왑 아웃(swap out)이라고 부름.\r\n    - 스왑 아웃시킬 0순위 프로세스는 봉쇄 상태에 있는 프로세스.\r\n        - 봉쇄 상태인 프로세스를 모두 스왑 아웃시킨 후에도 부족한 경우, 타이머 인터럽트가 발생해 준비 큐로 이동한 프로세스를 추가적으로 스왑 아웃시킴.\r\n    - 장기 스케줄러와 마찬가지로 메모리에 올라와 있는 프로세스의 수를 조절하는 역할을 수행\r\n- 중기 스케줄러의 등장으로 인해 프로세스의 상태에는 중지(suspended, stopped) 상태가 추가됨.\r\n\r\n    ![Untitled (73)](https://user-images.githubusercontent.com/62014888/146319301-1f078752-a9be-49ed-881e-3428129e795e.png)\r\n    \r\n    - 중지 상태는 외부적인 이유로 프로세스의 수행이 정지된 상태를 나타내며 외부에서 재개시키지 않는 이상 다시 활성화될 수 없으므로 메모리 자원이 당장 필요하지 않다.\r\n      따라서 메모리를 통째로 빼앗기고 디스크로 스왑 아웃됨.\r\n    - 중지 상태는 중지준비 상태와 중지봉쇄 상태로 세분화할 수 있음.\r\n    - 준비 상태에 있던 프로세스가 스왑 아웃되면 중지준비(suspended ready) 상태가 됨.\r\n    - 봉쇄 상태에 있던 프로세스가 스왑 아웃되면 중지봉쇄(suspended block) 상태가 됨.\r\n    - 중지봉쇄 상태이던 프로세스가 봉쇄되었던 조건을 만족하게 되면 중지준비 상태로 바뀜.\r\n\r\n\r\n## 7. 프로세스의 생성\r\n\r\n- 운영체제가 프로세스를 전부 생성한다고 생각할 수 있지만 사실은 그렇지 않음.\r\n- 최초의 프로세스는 운영체제가 직접 생성하지만 그다음부터는 이미 존재하는 프로세스가 다른 프로세스를 복제 생성하게 됨.\r\n    - 프로세스를 생성한 프로세스를 부모 프로세스라고 하고, 새롭게 생성된 프로세스를 자식 프로세스라고 함.\r\n- 프로세스의 세계는 자식이 먼저 죽고, 이에 대한 처리는 자식을 생성했던 부모 프로세스가 담당하는 방식으로 진행됨.\r\n- 생성된 프로세스가 작업을 수행하기 위해서는 자원이 필요한데 자원을 획득하는 방법은 운영체제 및 자원의 종류에 따라 상이함.\r\n    - 운영체제로부터 직접 자원을 할당\r\n    - 부모 프로세스와 자원을 공유해서 사용\r\n- 프로세스가 수행되는 모델도 부모와 자식이 공존하며 수행되는 모델과 자식이 종료될 때까지 부모가 기다리는 모델이 있음.\r\n    - 부모와 자식이 공존하며 수행되는 모델에서는 자식과 부모가 같이 CPU를 획득하기 위해 경쟁하는 관계가 됨.\r\n    - 부모가 자식의 종료를 기다리는 모델에서는 자식 프로세스가 종료될 때까지 부모 프로세스는 아무 일도 하지 않고 봉쇄 상태에 머물러 있다가, 자식 프로세스가 종료되면 그때 부모 프로세스가 준비 상태가 되어 다시 CPU를 얻을 권한이 생김.\r\n        - ex) 유닉스 명령어 입력창에 커맨드를 입력하는 경우\r\n- 프로세스가 생성되면 자신만의 독자적인 주소 공간을 갖게 됨.\r\n    - 자식 프로세스는 부모 프로세스와는 별도의 주소 공간을 가지게 됨.\r\n- 유닉스로 살펴보는 프로세스의 생성 절차\r\n    - fork() 시스템 콜을 통해 새로운 프로세스를 생성함.\r\n        - 자식 프로세스를 생성할 때 부모 프로세스의 내용을 그대로 복제 생성.\r\n          즉, 프로세스 ID를 제외한 모든 정보(운영체제 커널 내 정보, 주소 공간의 정보)를 그대로 복사함.\r\n        - 주소 공간은 다르지만 주소 공간 내에는 동일한 내용을 가지게 됨.\r\n    - fork()를 통해 생성된 자식 프로세스는 exec() 시스템 콜을 통해 새로운 프로그램으로 주소 공간을 덮어씌울 수 있음.\r\n- 프로세스의 종료는 두 가지로 나뉨.\r\n    1. 프로세스가 마지막 명령을 수행한 후 운영체제에 이를 알려주는 자발적 종료.\r\n        - 프로세스가 명령을 모두 수행한 후, 프로그램이 마쳐지는 코드 부분에 exit()라는 시스템 콜을 넣어주도록 되어 있음.\r\n    2. 부모 프로세스가 자식 프로세스의 수행을 강제로 종료시키는 비자발적 종료.\r\n        - 자식 프로세스가 할당 자원의 한계치를 넘어서는 많은 양의 자원을 요구할 때,\r\n          자식 프로세스에게 할당된 작업이 더 이상 필요하지 않을 때,\r\n          부모 프로세스가 종료되는 경우 등일 때 abort()라는 함수를 통해 이루어지게 됨.\r\n- 종료되는 프로세스의 자식 프로세스를 계속 실행시키기 위해서 종료되지 않을 다른 프로세스의 양자로 자식 프로세스를 보내는 방법도 있음.\r\n- 운영체제는 자식 프로세스의 생성을 위해 fork() 시스템 콜을 제공함.\r\n    - fork() 시스템 콜을 하게 되면 CPU 제어권이 커널로 넘어가게 되고, fork() 함수를 호출한 프로세스와 똑같은 프로세스가 하나 생성됨.\r\n    - fork()를 통해 생성된 프로세스는 부모 프로세스와 모든 문맥을 동일하게 가지고 있음.\r\n    - 단, 프로세스를 관리하기 위해서 사용하는 프로세스 식별자는 다른 식별자를 가지게 됨.\r\n    - fork()로 복제한 프로세스는 자기가 복제본이 아닌 원본이며, 자기를 복제해서 복제본이 생성되었다는 그런 기억을 갖게 됨.\r\n    - 단, fork() 함수의 결괏값으로 원본에게는 양수를 주고 복제본에게는 0을 주어서 조건문을 사용해 다른 작업을 하도록 프로그램을 작성할 수 있음.\r\n- 유닉스에서는 프로세스의 주소 공간에 새로운 프로그램을 덮어씌우는 exec() 시스템 콜을 지원함.\r\n    - exec()는 지금까지 수행했던 상태를 잊어버리고 그 주소 공간을 완전히 새로운 프로그램으로 덮어씌운 후 새로운 프로그램의 첫 부분부터 다시 실행을 시작하도록 하는 시스템 콜.\r\n- fork(), exec()는 특권명령에 해당하므로 시스템 콜을 통해서만 그 수행이 가능함.\r\n- 자식 프로세스가 종료되기를 기다리며 부모 프로세스가 봉쇄 상태에 머무르도록 할 때 사용되는 wait() 시스템 콜도 존재함.\r\n    - fork() 후에 wait()를 호출하면 커널은 자식 프로세스가 종료될 때까지 부모 프로세스를 봉쇄 상태에 머무르게 하고, 자식 프로세스가 종료되면 부모를 준비 상태로 변경시켜 작업을 재개할 수 있도록 함.\r\n    - 이를 통해 두 프로세스 간의 동기화(synchronization)가 가능해짐.\r\n    - 일반적인 봉쇄 상태에서처럼 자원을 기다리며 줄 서 있는 것이 아니라 자식 프로세스가 종료되기를 기다리며 수면 상태에 머무르게 되는 것으로, 자식 프로세스가 종료되는 순간 준비 큐에 재진입한다.\r\n\r\n## 8. 프로세스 간의 협력\r\n\r\n- 프로세스는 각자 자신만의 독립적인 주소 공간을 가지고 수행되며 다른 프로세스의 주소 공간을 참조하는 것은 허용되지 않음.\r\n- 경우에 따라서는 독립적인 프로세스들이 협력할 때 업무의 효율성이 증진될 수 있기 때문에 운영체제는 프로세스 간의 협력 메커니즘을 제공해 하나의 프로세스가 다른 프로세스의 수행에 영향을 미칠 수 있게 함.\r\n- 대표적인 메커니즘으로 IPC(Inter-Process Communication: 인터프로세스 커뮤니케이션)가 있음.\r\n    - IPC란 하나의 컴퓨터 안에서 실행 중인 서로 다른 프로세스 간에 발생하는 통신을 말함.\r\n    - 이러한 통신에는 의사소통 기능과 함께 동기화를 보장해주어야 함.\r\n        - 공유 데이터를 서로 다른 두 프로세스가 사용할 수 있다고 하면 데이터의 불일치 문제가 발생할 수 있기 때문.\r\n        - 하나의 프로세스가 공유 데이터의 값을 변경하는 동안 다른 프로세스는 접근할 수 없게 해야 함.\r\n    - 즉, IPC는 프로세스들 간의 통신과 동기화를 이루기 위한 메커니즘을 뜻함.\r\n    - IPC에는 대표적으로 두 가지 방법이 있는데 공유 데이터를 사용하는가, 그렇지 않는가에 따라 나뉘어진다.\r\n    - 메시지 전달 방식(message passing)\r\n        - 프로세스 간에 공유 데이터를 일체 사용하지 않고 메시지를 주고받으면서 통신하는 방식.\r\n        - 메시지 통신을 하는 시스템은 커널에 의해 send(message)와 receive(message)라는 두 가지 연산을 제공받게 됨.\r\n        - 프로세스끼리 메시지를 직접 주고받는다면 원치 않는 메시지로 인해 악영향을 미칠 수 있으므로 특권명령으로 규정해 커널만 가능하도록 하고 있음.\r\n        - 통신하기를 원하는 두 프로세스는 커뮤니케이션 링크를 생성한 후 send()와 receive()를 이용해서 메시지를 주고받게 됨.\r\n        - 메시지 전달 방식은 메세지 전송 대상이 다른 프로세스인지 아니면 메일박스라는 저장공간인지에 따라 다시 직접통신(direct communication)과 간접통신(indirect communication)으로 나뉨.\r\n          (인터페이스에 대한 차이일 뿐 내부 구현은 동일한 방식으로 이루어짐)\r\n        - 직접통신\r\n            - 통신하려는 프로세스의 이름을 명시적으로 표시함.\r\n            - 커뮤니케이션 링크는 자동적으로 생성되고 하나의 링크가 한 쌍의 프로세스에게 할당됨.\r\n            - 링크는 단방향일수 있으나 대부분은 양방향성임.\r\n        - 간접통신\r\n            - 메시지를 메일박스 또는 포트로부터 전달받음.\r\n            - 각 메일박스에는 고유의 ID가 있으며 메일박스를 공유하는 프로세스들만 서로 통신을 할 수 있음.\r\n            - 커뮤니케이션 링크는 프로세스 간 메일박스를 공유하는 경우에만 생성되고 하나의 링크가 여러 프로세스들에게 할당될 수 있으며 각 프로세스의 쌍은 여러 링크를 공유할 수 있음.\r\n            - 단방향성 또는 양방향성일 수 있음.\r\n            - 새로운 메일박스를 생성하는 연산, 메일박스를 통한 메시지의 send(), receive(), 메일박스를 삭제하는 연상 등이 사용될 수 있음.\r\n            - 만약 P1, P2, P3가 메일박스 A를 공유하는 경우 P1이 메시지를 보냈다면 P2, P3 중 어느 프로세스가 메시지를 받게 될까?\r\n                - 2개의 프로세스에게만 링크를 할당하는 방법이 사용되거나 링크에 대한 receive() 연산을 매 시점 하나의 프로세스만 수행할 수 있도록 하거나 시스템이 메시지 수신자를 임의로 결정해 누가 메시지를 받았는지 송신자에게 통신해주는 방식이 사용될 수 있다.\r\n    - 공유메모리 방식(shared memory)\r\n        - 프로세스들이 주소 공간의 일부를 공유하는 방식.\r\n        - 서로 다른 프로세스들이 그들의 주소 공간 중 일부를 공유할 수 있도록 함.\r\n        - 공유메모리 영역은 여러 프로세스가 읽고 쓰는 것이 가능함.\r\n        - 공유하다보니 데이터 일관성 문제가 유발될 수 있지만 커널이 이를 책임지지 않기에 프로세스들끼리 직접 동기화 문제를 책임져야 한다.","excerpt":"1. 프로세스의 개념 프로세스(process)란 실행 중인 프로그램(program in execution)을 뜻한다. 디스크에 실행파일 형태로 존재하던 프로그램이 메모리에 올라가서 실행되기 시작하면 프로세스가 되며, 프로세스는 CPU를 획득해 자신의…","fields":{"slug":"/os-it-principle-ch5/"},"frontmatter":{"date":"Oct 14, 2021","title":"[운영체제와 정보기술의 원리] 5. 프로세스 관리","tags":["os","book"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n## 1. 프로그램의 구조와 인터럽트\r\n\r\n- 컴퓨터 프로그램은 어떠한 프로그래밍 언어로 작성되었든 그 내부 구조는 함수들로 구성된다.\r\n- 프로그램의 주소 영역은 크게 코드(code), 데이터(data), 스택(stack) 영역으로 구분됨.\r\n    - 코드 영역 - 우리가 작성한 프로그램 함수들의 코드가 CPU에서 수행할 수 있는 기계어 명령 형태로 변환되어 저장되는 부분.\r\n    - 데이터 영역 - 전역 변수 등 프로그램이 사용하는 데이터를 저장하는 부분.\r\n    - 스택 영역 - 함수가 호출될 때 호출된 함수의 수행을 마치고 복귀할 주소 및 데이터를 임시로 저장하는 데에 사용되는 공간.\r\n- 하나의 함수가 수행되는 중에 다른 함수를 호출하고, 호출된 함수가 끝나면 다시 원래 호출했던 함수의 위치로 돌아가 프로그램을 계속 실행하게 됨.\r\n    - 인터럽트 동작 원리와 비슷함.\r\n\r\n\r\n## 2. 컴퓨터 시스템의 작동 개요\r\n\r\n- CPU는 빠른 속도로 처리하는 계산 능력은 가지고 있지만, 어떠한 작업을 수행해야 하는지 스스로 결정하는 능력은 갖추고 있지 못함.\r\n\r\n![Untitled (70)](https://user-images.githubusercontent.com/62014888/146313707-0e86811a-076c-4cd2-af7e-e2aa6ee3ec8b.png)\r\n\r\n- CPU가 수행해야 할 메모리 주소를 담고 있는 레지스터를 프로그램 카운터(Program Counter: PC)라고 부름.\r\n  즉 CPU는 매번 프로그램 카운터가 가리키는 메모리 위치의 명령을 처리하게 됨.\r\n    - 일반적으로 주소 이동이 없는 이상 프로그램 카운터는 항상 바로 다음 명령을 가리키게 되어 코드의 순차적인 수행이 이루어짐.\r\n- 메모리에는 사용자 프로그램들과 운영체제가 같이 올라가 수행됨.\r\n- 프로그램 카운터가 메모리 주소 중 운영체제가 존재하는 부분을 가리키고 있다면 현재 운영체제의 코드를 수행 중이며, 이 경우 CPU가 커널모드에서 수행 중이라는 뜻.\r\n- 프로그램 카운터가 사용자 프로그램이 존재하는 메모리 위치를 가리키고 있다면 그 메모리 위치에 올라가 있는 사용자 프로그램이 수행 중이며, 이 경우 사용자모드에서 CPU가 수행되고 있다는 뜻.\r\n- 일반명령\r\n    - 메모리에서 자료를 읽어와 CPU에서 계산하고 결과를 메모리에 쓰는 일련의 명령들을 말하는데, 이러한 일반명령은 모든 프로그램이 수행할 수 있음.\r\n- 특권명령\r\n    - 특권명령은 보안이 필요한 명령으로 입출력 장치, 타이머 등 각종 장치에 접근하는 명령임.\r\n    - 특권명령은 항상 운영체제만이 수행할 수 있도록 제한하고 있음.\r\n- 두 명령어의 실행가능성을 체크하기 위해 CPU 내에 모드비트를 둠.\r\n- 사용자 프로그램이 스스로 특권 명령을 수행할 수 없으므로 운영체제에게 시스템 콜을 통해 특권명령의 대행을 요청하게 됨.\r\n- 주변장치는 CPU의 도움이 필요한 경우 인터럽트를 사용해 서비스를 요청하는데 이를 위해 주변장치는 인터럽트 라인을 세팅함.\r\n  CPU는 매번 명령을 수행한 직후 인터럽트 라인을 체크해 서비스 요청이 들어왔는지 확인함.\r\n\r\n## 3. 프로그램의 실행\r\n\r\n- '프로그램이 실행되고 있다'는 것은 컴퓨터 시스템 차원에서 볼 때 크게 두 가지 중요한 의미를 가짐.\r\n    1. 디스크에 존재하던 실행파일이 메모리에 적재된다는 의미\r\n    2. 프로그램이 CPU를 할당받고 명령을 수행하고 있는 상태라는 의미\r\n- 실행파일이 메모리에 적재될 때, 프로그램의 주소 공간 중 당장 CPU의 수행에 필요한 부분은 메모리에 올려놓고 그렇지 않은 부분은 디스크 중 메모리 연장 공간으로 사용되는 스왑 영역에 내려놓음.\r\n- 각각의 프로그램마다 주소 공간을 별도로 가지며, 이를 가상메모리(virtual memory) 또는 논리적 메모리(logical memory)라고 부른다.\r\n- 운영체제도 하나의 프로그램이므로 운영체제 커널 역시 코드, 데이터, 스택의 주소 공간 구성을 가지고 있음.\r\n\r\n  ![Untitled (71)](https://user-images.githubusercontent.com/62014888/146313710-cb578ec8-8511-4625-8589-08ef87516473.png)\r\n\r\n    - 커널의 코드는 CPU, 메모리 등의 자원을 관리하기 위한 부분과 사용자에게 편리한 인터페이스를 제공하기 위한 부분이 주를 이룸.\r\n      시스템 콜 및 인터럽트를 처리하기 위한 부분도 포함함.\r\n    - 커널의 데이터 영역에는 각종 자원을 관리하기 위한 자료구조가 저장됨.\r\n        - CPU나 메모리와 같은 하드웨어 자원을 관리하기 위한 자료구조 + 프로세스 상태, CPU 사용 정보, 메모리 사용 정보 등을 유지하기 위한 PCB\r\n    - 커널의 스택 영역은 일반 스택 영역과 마찬가지로 함수호출 시의 복귀 주소를 저장하기 위한 용도로 사용된다.\r\n        - 다만, 현재 수행 중인 프로세스마다 별도의 스택을 두어 관리함.\r\n        - 프로세스가 시스템 콜을 호출하고 시스템 콜 내부에서 다른 함수를 호출하는 경우 그 복귀 주소는 커널 내의 주소가 되어 사용자 프로그램의 스택과는 별도의 저장공간이 필요하기 때문.\r\n        - 또한 커널은 일종의 공유 코드로서 모든 사용자 프로그램이 시스템 콜을 통해 커널의 함수를 접근할 수 있으므로, 일관성을 유지하기 위해서 현재 수행 중인 프로세스마다 별도의 스택을 두어 관리함.\r\n        - 프로그램 내의 함수호출 시 해당 프로그램의 스택에 복귀 주소를 저장하지만, 시스템 콜이나 인터럽트 발생으로 CPU의 수행 주체가 운영체제로 바뀌는 순간에는 직전에 수행되던 프로그램의 복귀 정보를 스택이 아닌 PCB에 저장한다.\r\n\r\n\r\n## 4. 사용자 프로그램이 사용하는 함수\r\n\r\n- 사용자 정의함수\r\n    - 프로그래머 본인이 직접 작성한 함수.\r\n- 라이브러리 함수\r\n    - 프로그래머 본인이 직접 작성하지는 않았지만 이미 누군가 작성해놓은 함수를 호출만 하여 사용하는 경우를 뜻함.\r\n    - 사용자 정의함수와 라이브러리 함수 모두 프로그램의 코드 영역에 기계어 명령 형태로 존재한다.\r\n      따라서 프로그램이 실행될 때에 해당 프로세스의 주소 공간에 포함되며, 또한 함수호출 시에도 자신의 주소 공간에 있는 스택을 사용하게 된다.\r\n- 커널 함수\r\n    - 운영체제 커널의 코드에 정의된 함수.\r\n    - 사용자 프로그램이 운영체제의 서비스를 요청하기 위해 호출하는 시스템 콜 함수와, 각종 하드웨어 및 소프트웨어가 CPU의 서비스를 요청하기 위해 발생시키는 인터럽트 처리함수가 있다.\r\n    - 운영체제 내에 있는 함수를 사용자 프로그램이 호출해서 사용하는 것.\r\n    - 시스템 콜은 운영체제라는 별개의 프로그램에 CPU를 넘겨서 실행하는 것으로 넘기기 위해서 CPU의 인터럽트 라인을 세팅하는 방법을 사용함.\r\n\r\n## 5. 인터럽트\r\n\r\n- 원칙적으로는 인터럽트 처리 중에 또 다른 인터럽트가 발생하는 것을 허용하지 않는다.\r\n    - 그 이유는 인터럽트 처리 중에 다른 인터럽트를 처리하면 데이터의 일관성이 유지되지 않는 문제가 발생할 수 있기 때문.\r\n- 단, 인터럽트마다 중요도가 다르기 때문에 상대적으로 낮은 중요도를 가진 인터럽트를 처리하는 도중에 중요도가 더 높은 인터럽트가 발생하는 것을 허락할 필요는 있음.\r\n    - 현재 처리 중이던 인터럽트 코드의 수행 지점을 저장하고 우선순위가 높은 인터럽트를 처리하게 됨.\r\n    - 처리가 끝나면 저장된 주소로 복귀하고 마저 수행함.\r\n\r\n## 6. 시스템 콜\r\n\r\n- 시스템 콜은 자신의 프로그램이 아닌, 커널이라는 다른 프로그램의 주소 공간에 존재하는 함수를 호출하는 것.\r\n- 주소 공간 자체가 다른 곳으로 이동해야 하므로 일반 함수호출과는 상이한 방법을 사용하는데 그 방법은 프로그램 자신이 인터럽트 라인에 인터럽트를 세팅하는 명령을 통해 이루어짐.\r\n- 디스크 파일 입출력이 이루어지는 과정을 통해 시스템 콜 사용의 예를 살펴보자.\r\n    - 사용자 프로그램이 디스크의 파일을 읽어와야할 경우 시스템 콜로 커널의 함수를 호출하게 됨.\r\n    - CPU의 제어권을 운영체제에 이양하게 되는데, 이는 인터럽트 라인을 세팅하는 명령을 통해 이루어짐.\r\n    - 인터럽트 라인이 세팅되면 CPU는 다음 명령을 수행하기 전에 인터럽트가 발생했는지 점검하고 인터럽트가 발생된 것을 인지하면 현재 수행 중인 프로그램을 잠시 멈추고 CPU 제어권을 운영체제로 이양시킴.\r\n    - 입출력 요청 인터럽트를 인지하게 되면 해당 서비스루틴으로 이동해 입출력 작업을 수행하게 되는데 이때 CPU는 디스크 컨트롤러에게 파일을 읽어오라는 명령을 하게 됨.\r\n    - 입출력 작업은 시간이 많이 소요가 되므로 CPU의 제어권은 다른 프로세스에게 이양함.\r\n    - 입출력 작업이 완료되면 디스크 컨트롤러가 CPU에게 인터럽트를 발생시켜 작업이 완료되었음을 알리게 됨.\r\n    - CPU는 현재 프로세스 수행을 멈추고 인터럽트 처리루틴으로 제어권이 넘어가고 이때 발생한 인터럽트는 하드웨어 인터럽트에 해당함.\r\n    - 디스크로부터 로컬버퍼로 읽어온 내용을 컴퓨터 내의 메모리로 복사한 후 디스크 입출력을 요청했던 프로세스에게 다시 CPU를 획득할 수 있는 권한을 줌(blocked state 해제)\r\n    - 해당 프로세스는 CPU를 기다리는 큐에 삽입되고 CPU 제어권은 인터럽트를 당한 프로세스로넘어감.\r\n- 중간에 CPU를 빼앗기는 경우는 크게 두 가지가 있음.\r\n    1. 타이머에 의해 인터럽트가 발생하는 경우\r\n    2. 입출력 요청을 위해 시스템 콜을 하는 경우\r\n\r\n## 7. 프로세스의 두 가지 실행 상태\r\n\r\n- 하나의 프로세스가 시작되어 수행을 완료하기까지 프로세스 자신의 주소 공간에 있는 코드만 실행되는 것이 아니라 커널의 주소 공간에 있는 코드도 실행됨.\r\n- 자신의 주소 공간에 정의된 코드를 실행하는 것을 사용자모드에서 실행 상태(user mode running)라 하고, 커널의 시스템 콜 함수를 실행하는 것을 커널모드에서의 실행 상태(kernel mode running)라 함.\r\n    - 시스템 콜을 통해 실행되는 것이 프로세스 코드가 아닌 운영체제 커널의 코드라 해도 시스템 콜이 수행되는 동안 커널이 실행 상태(running state)에 있다고 하지 않고 프로세스가 실행 상태에 있다고 말한다.\r\n    - 단, 구분지어서 '프로세스 A가 커널모드에서 실행 중'이라고 이야기함.\r\n- 정리하자면 프로그램은 다양한 함수호출을 하며 실행되는데, 이를 사용자모드, 커널모드의 실행 상태로 구분 지을 수 있음.\r\n  시스템 콜을 하는 경우 커널모드로 진입해 커널의 주소 공간에 정의된 함수를 실행하게 된다.\r\n  시스템 콜이 끝나면 다시 사용자모드로 복귀해 명령들을 계속 실행함.\r\n  프로그램 실행이 끝날 때는 커널모드로 진입해 프로그램을 종료함.","excerpt":"1. 프로그램의 구조와 인터럽트 컴퓨터 프로그램은 어떠한 프로그래밍 언어로 작성되었든 그 내부 구조는 함수들로 구성된다. 프로그램의 주소 영역은 크게 코드(code), 데이터(data), 스택(stack) 영역으로 구분됨. 코드 영역 - 우리가 작성…","fields":{"slug":"/os-it-principle-ch4/"},"frontmatter":{"date":"Oct 13, 2021","title":"[운영체제와 정보기술의 원리] 4. 프로그램의 구조와 실행","tags":["os","book"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n## 1. 컴퓨터 시스템의 구조\r\n\r\n- 컴퓨터 내부장치인 CPU, 메모리와 컴퓨터 외부장치인 디스크, 키보드, 마우스, 모니터, 네트워크 장치 등으로 구성된다.\r\n- 컴퓨터는 외부장치에서 내부장치로 데이터를 읽어와 각종 연산을 수행한 후, 그 결과를 외부장치로 다시 내보내는 방식으로 업무를 처리함.\r\n    - 컴퓨터 내부로 데이터가 들어오는 것을 입력(input), 컴퓨터 외부장치로 데이터가 나가는 것을 출력(output)이라고 함.\r\n    - 컴퓨터 외부장치를 입출력 장치라고 부른다.\r\n- 메모리 및 입출력장치 등의 각 하드웨어 장치에는 컨트롤러라는 것이 붙어 있음.\r\n- 운영체제 중 항상 메모리에 올라가 있는 부분은 전체 운영체제 중 핵심적인 부분에 한정되며, 이 부분을 커널(kernel)이라고 부른다.\r\n\r\n## 2. CPU 연산과 I/O 연산\r\n\r\n- 입출력 장치들의 I/O 연산은 입출력 컨트롤러가 담당하고, 컴퓨터 내에서 수행되는 연산은 메인 CPU가 담당한다. 이때 입출력 장치와 메인 CPU는 동시 수행이 가능하다.\r\n- 각 장치마다 장치 컨트롤러는 장치로부터 들어오고 나가는 데이터를 임시로 저장하기 위한 작은 메모리를 가지고 있다.\r\n  이를 로컬버퍼(local buffer)라고 부른다.\r\n    - 디스크나 키보드 등에서 데이터를 읽어오는 경우, 우선 로컬버퍼에 데이터가 임시로 저장된 후 메모리에 전달됨.\r\n    - 로컬버퍼로 읽어오는 일은 컨트롤러가 담당한다.\r\n- 로컬버퍼로 읽어오는 작업이 끝났는지를 메인 CPU가 지속적으로 체크하는 것이 아니라 장치에 있는 컨트롤러가 인터럽트를 발생시켜 CPU에 보고하게 된다.\r\n    - CPU 옆에는 인터럽트 라인(interrupt line)이 있어서, 자신의 작업을 하던 중간에 인터럽트 라인에 신호가 들어오면 하던 일을 멈추고 인터럽트와 관련된 일을 먼저 처리함.\r\n    - CPU는 명령 하나를 수행할 때마다 인터럽트가 발생했는지 확인한다.\r\n      발생했으면 다음 명령을 수행하기 전에 인터럽트를 처리하게 되고, 그렇지 않으면 다음 명령을 계속 수행하게 되는 것.\r\n- 인터럽트는 키보드 입력 혹은 요청된 디스크 입출력 작업의 완료 등 CPU에 알려줄 필요가 있는 이벤트가 일어난 경우 컨트롤러가 발생시키는 것.\r\n\r\n## 3. 인터럽트의 일반적 기능\r\n\r\n- 운영체제 커널에는 인터럽트가 들어왔을 때 해야 할 일이 미리 다 프로그래밍되어 그 코드가 보관돼 있다.\r\n- 운영체제 커널 내에 있는 인터럽트 처리루틴은 다양한 인터럽트에 대해 각각 처리해야 할 업무들을 정의하고 있음.\r\n- 하드웨어 인터럽트와 소프트웨어 인터럽트가 있음.\r\n  인터럽트 라인에 신호를 보내서 인터럽트가 발생했음을 알려주는 방식은 둘 다 동일.\r\n    - 하드웨어 인터럽트는 컨트롤러 등 하드웨어 장치가 CPU의 인터럽트 라인을 세팅함.\r\n    - 소프트웨어 인터럽트는 소프트웨어가 그 일을 수행함.\r\n- 운영체제는 인터럽트 벡터(interrupt vector)를 가지고 있음.\r\n    - 인터럽트 벡터란 인터럽트 종류마다 번호를 정해서, 번호에 따라 처리해야 할 코드가 위치한 부분을 가리키고 있는 자료구조를 말함.\r\n    - 실제 처리해야 할 코드는 인터럽트 처리루틴(interrupt service routine) 또는 인터럽트 핸들러(interrupt handler)라고 불리는 다른 곳에 정의 됨.\r\n- 인터럽트 처리를 완료하고 나면 원래 수행하던 작업으로 돌아가 일을 계속해서 수행하게 되는데 운영체제는 이 돌아갈 위치에 대한 정보를 저장하기 위한 장소를 별도로 가지고 있다.\r\n- 통상적으로 인터럽트라고 하면 하드웨어 인터럽트를 의미하고, 소프트웨어 인터럽트는 트랩(trap)이라는 용어로 주로 불림.\r\n- 소프트웨어 인터럽트의 예로는 예외상황(exception)과 시스템 콜(system call)이 있음.\r\n    - 예외상황은 사용자 프로그램이 0으로 나누는 연산 등 비정상적인 작업을 시도하거나, 자신의 메모리 영역 바깥에 접근하려는 시도 등 권한이 없는 작업을 시도할 때 이에 대한 처리를 위해 발생시키는 인터럽트를 말함.\r\n    - 시스템 콜은 사용자 프로그램이 운영체제 내부에 정의된 코드를 실행하고 싶을 때 운영체제에 서비스를 요청하는 방법이라고 볼 수 있음.\r\n    - 둘 다 사용자 프로세스로부터 CPU의 제어권이 운영체제에 이양되어 처리된다.\r\n\r\n\r\n## 4. 인터럽트 핸들링\r\n\r\n- 인터럽트 핸들링이란 인터럽트가 발생한 경우에 처리해야 할 일의 절차를 의미한다.\r\n- 프로그램이 실행되고 있을 때 인터럽트가 발생하면 프로그램의 현재 상태를 먼저 저장한다.\r\n    - 현재 상태란 현재 CPU에서 실행 중인 명령의 메모리 주소를 포함해 몇 가지 부가적인 정보들.\r\n    - 원래 CPU에서 명령이 실행될 때 임시기억장치인 레지스터(register)에 데이터를 읽거나 쓰면서 작업하는데, 인터럽트가 발생하면 기존 레지스터값들이 지워지게 되므로 이러한 상태를 저장해두어야 하는 것.\r\n- 운영체제는 현재 시스템 내에서 실행되는 프로그램들을 관리하기 위해 프로세스 제어블록(Process Control Block: PCB)이라는 자료구조를 둔다.\r\n    - PCB는 각각의 프로그램마다 하나씩 존재하며 해당 프로그램의 어느 부분이 실행 중이었는지를 저장하고 있음.\r\n      구체적으로는 실행 중이던 코드의 메모리 주소, 레지스터값, 하드웨어 상태 등이 저장.\r\n    - 인터럽트가 발생하면 프로그램의 실행 상태를 PCB에 저장한 후 CPU의 제어권이 인터럽트 처리루틴으로 넘어가게 되며, 인터럽트 처리가 끝나면 저장된 상태를 PCB로부터 CPU 상에 복원해 인터럽트 당하기 직전의 위치부터 실행이 이어지게 되는 것\r\n- 오늘날의 컴퓨터에서 운영체제는 인터럽트가 발생할 때에만 실행된다.\r\n    - 운영체제가 직접 CPU를 점유하는 경우는 인터럽트에 의하지 않고는 발생하지 않는다.\r\n    - 그럼에도 불구하고 운영체제는 자원을 체계적이고 효율적으로 관리할 수 있다.\r\n\r\n## 5. 입출력 구조\r\n\r\n- 입출력(I/O)이란 컴퓨터 시스템이 컴퓨터 외부의 입출력 장치들과 데이터를 주고받는 것을 말한다.\r\n- 동기식 입출력(synchronous I/O)\r\n    - 어떤 프로그램이 입출력 요청을 했을 때 입출력 작업이 완료된 후에야 그 프로그램이 후속 작업을 수행할 수 있는 방식을 말한다.\r\n    - 동기식 입출력에서 CPU는 입출력 연산이 끝날 때까지 인터럽트를 기다리며 자원을 낭비하게 된다.\r\n    - 따라서 일반적으로 프로그램이 입출력을 수행 중인 경우 CPU를 다른 프로그램에게 이양해 CPU가 계속 쉬지 않고 일할 수 있도록 관리한다.\r\n    - 운영체제는 프로그램을 몇 가지 상태로 나누고 입출력 중인 프로그램의 경우 봉쇄 상태(blocked state)로 전환시킨다.\r\n      봉쇄 상태의 프로그램에게는 CPU를 할당하지 않고, CPU 할당 시 곧바로 명령을 수행할 수 있는 프로그램에만 CPU를 할당한다.\r\n    - 다수의 입출력 연산이 동시에 요청되거나 처리될 수 있다.\r\n        - 입출력 요청의 동기화를 위해 장치별로 큐(queue)를 두어 요청한 순서대로 처리할 수 있도록 한다.\r\n        - 요청들을 모으고 처리 순서를 바꾸어 입출력의 효율성을 높일 수도 있는데, 이러한 경우 동기화를 보장하기 위한 별도의 방안이 마련되어야 한다.\r\n    - 장치마다 큐헤더가 존재하고 컨트롤러는 이 큐 순서에 따라 매 시점 하나씩 자신에게 주어진 입출력 작업을 처리하게 된다.\r\n        - CPU의 수행 속도에 비해 컨트롤러의 수행 속도나 장치 자체의 작업 수행 능력은 매우 떨어진다.\r\n        - 입출력이 완료될 때까지 입출력과 관련 없는 프로그램을 수행하도록 하고, 요청된 입출력 연산이 완료되면 CPU에게 입출력이 완료되었음을 알려주는 방식으로 진행.\r\n- 비동기식 입출력\r\n    - 입출력 연산을 요청한 후에 연산이 끝나기를 기다리는 것이 아니라 CPU의 제어권을 입출력 연산을 호출한 그 프로그램에게 곧바로 다시 부여하는 방식.\r\n    - 비동기식 입출력은 데이터와 관련 없이 수행할 수 있는 작업을 먼저 수행하고, 읽어오는 데이터가 반드시 있어야 수행할 수 있는 일들은 입출력이 완료된 후에 수행함.\r\n    - 쓰기 작업이 완료되기 전에도 다음 명령을 수행할 수 있으므로 비동기식 입출력이 사용될 수 있음\r\n\r\n![Untitled (68)](https://user-images.githubusercontent.com/62014888/146133407-f5ee241d-0839-4e4f-99ee-59ab65031863.png)\r\n\r\n- 사용자가 I/O 요청을 하면 동기식 입출력에서는 먼저 운영체제의 커널로 CPU의 제어권이 넘어와서 입출력 처리와 관련된 커널의 코드가 수행됨.\r\n  이때 입출력을 호출한 프로세스의 상태를 봉쇄 상태로 바꾸어 입출력이 완료될 때까지 CPU를 할당받지 못하도록 함.\r\n  입출력이 완료되면 I/O 컨트롤러가 CPU에게 인터럽트를 발생시켜 입출력이 완료되었음을 알려줌.\r\n  프로세스의 봉쇄 상태를 해제시켜 CPU를 할당받을 수 있는 권한이 다시 생기게 됨\r\n- 비동기식 입출력에서는 CPU의 제어권이 입출력을 요청한 프로세스에게 곧바로 다시 주어지며, 입출력 연산이 완료되는 것과 무관하게 처리 가능한 작업부터 처리함.\r\n  비동기식 입출력에서도 입출력 연산이 완료되면 동기식과 마찬가지로 인터럽트를 통해 CPU에게 알려줌.\r\n  그 시점부터 읽어온 데이터를 필요로 하는 명령을 수행할 수 있게 됨.\r\n\r\n## 6. DMA\r\n\r\n- 원칙적으로 메모리는 CPU에 의해서만 접근할 수 있는 장치.\r\n- 따라서 CPU 외의 장치가 메모리의 데이터에 접근하기 위해서는 CPU에게 인터럽트를 발생시켜 CPU가 이를 대행하는 식으로만 가능함.\r\n- 이 비효율성을 극복하기 위해 CPU 이외에 메모리 접근이 가능한 장치를 하나 더 두는 경우가 많은데, 이와 같은 장치를 DMA(Direct Memory Access)라고 부른다.\r\n- DMA를 사용하면 로컬버퍼에서 메모리로 읽어오는 작업을 CPU가 담당하는 것이 아니라 DMA가 대행함으로써 CPU는 원래 하던 작업을 멈추고 인터럽트를 처리할 필요가 없어지는 것.\r\n- DMA는 바이트(byte) 단위가 아니라 블록(block)이라는 큰 단위로 정보를 메모리로 읽어온 후에 CPU에게 인터럽트를 발생시켜서 해당 작업의 완료를 알려준다.\r\n\r\n## 7. 저장장치의 구조\r\n\r\n- 주기억장치\r\n    - 보통 메모리라고 부르며 전원이 나가면 저장되었던 내용이 모두 사라져버리는 휘발성(volatile)의 RAM을 매체로 사용하는 경우가 대부분\r\n- 보조기억장치\r\n    - 전원이 나가도 저장된 내용을 기억할 수 있는 비휘발성(nonvolatile)의 마그네틱 디스크를 주로 사용함.\r\n    - 플래시 메모리, CD, 마그네틱 테이프 등이 사용됨.\r\n    - 용도는 크게 두 가지로 구분됨.\r\n        1. 파일 시스템용\r\n            - 전원이 나가도 유지해야 할 정보가 있으면 그것을 파일 형태로 보조기억장치에 저장함.\r\n        2. 메모리의 연장 공간인 스왑 영역(swap area)용\r\n            - 운영체제는 프로그램 수행에 당장 필요한 부분만 메모리에 올려놓고 그렇지 않은 부분은 스왑 영역에 내려놓게됨.\r\n            - 디스크에 내려놓는 일을 스왑 아웃(swap out)시킨다고 말하며, 스왑 아웃된 부분이 필요할 때에는 다시 메모리 영역에 올리게 된다.\r\n            - 스왑 영역으로는 하드디스크가 가장 널리 사용\r\n\r\n## 8. 저장장치의 계층 구조\r\n\r\n- 컴퓨터 시스템을 구성하는 저장장치는 빠른 저장장치부터 느린 저장장치까지 단계적인 계층 구조로 이루어진다.\r\n\r\n![Untitled (69)](https://user-images.githubusercontent.com/62014888/146133412-6743e514-8669-4f1d-b3da-7655796eb1c9.png)\r\n\r\n- 빠른 저장장치는 단위 공간당 가격이 높기 때문에 적은 용량을 사용한다.\r\n  따라서 당장 필요한 정보는 빠른 저장장치에 넣어두어 수행 속도를 높인다.\r\n- 느린 저장장치는 가격이 저렴해 대용량을 사용하는 반면 접근 속도가 느리다.\r\n  당장 필요하지 않은 정보는 상대적으로 느린 저장장치에 보관하게 된다.\r\n- 레지스터, 캐시 메모리, 메인 메모리 등은 휘발성 저장장치로 이 부분에 저장되는 정보는 전원이 나가면 그 내용이 사라짐.\r\n  그 밑에 저장장치 계층은 전원이 나가도 지워지지 않는 비휘발성 저장장치.\r\n- 상위 저장장치 계층으로 갈수록 접근 속도가 월등히 빠르지만 용량은 상대적으로 적다.\r\n    - 당장 필요한 정보만을 선별적으로 저장하면 하위에 있는 큰 용량의 저장장치를 가지고 있는 것과 비슷한 성능 효과를 낼 수 있다.\r\n    - 예로 캐시 메모리가 있다.\r\n      상대적으로 용량이 적은 빠른 저장장치를 이용해 느린 저장장치의 성능을 향상시키는 총체적 기법인 캐싱 기법을 사용한다.\r\n      반복되는 코드를 빠른 저장장치에 올려놓으면 적은 저장공간만으로도 전체 시스템의 평균적인 성능을 향상시킬 수 있다.\r\n\r\n\r\n## 9. 하드웨어의 보안\r\n\r\n- 다중 프로그래밍 환경에서는 각 프로그램이 다른 프로그램의 실행을 방해하거나 프로그램 간의 충돌을 일으키는 문제를 막기 위해 하드웨어에 대한 각종 보안 기법이 필요하다.\r\n- 커널모드\r\n    - 중요한 정보에 접근해 위험한 상황을 초래할 수 있는 연산은 커널모드에서 실행되도록 하여 일반 사용자 프로그램이 직접 위험한 명령을 수행할 수 없도록 함.\r\n    - 운영체제가 CPU의 제어권을 가지고 운영체제 코드를 실행하는 모드로서, 이 모드에서는 모든 종류의 명령을 다 실행할 수 있다.\r\n- 사용자모드\r\n    - 일반적인 연산만 사용자모드에서 사용자 프로그램이 수행하도록 통제하여 보안성을 확보함.\r\n    - 일반 사용자 프로그램이 실행되며 제한적인 명령만 수행함.\r\n- 사용자 프로그램이 프로그램 내 중요한 연산을 수행해버리면 제어가 아무런 소용이 없게 되므로 이를 막기 위해 하드웨어적 지원으로 CPU 내부에 모드비트(mode bit)를 두어 사용자 프로그램을 감시하게 됨.\r\n    - 모드비트가 0으로 세팅되어 있으면 커널모드로서 모든 명령을 수행할 수 있고, 모드비트가 1로 세팅되어 있으면 사용자모드로서 제한된 명령만을 수행할 수 있음.\r\n    - 시스템 보안과 관련된 명령들을 특권명령이라 지칭하는데, 특권명령은 모드비트가 0, 즉 커널모드에서 운영체제에 의해서만 수행할 수 있다.\r\n- 모든 입출력 명령은 특권명령으로 규정해서 사용자 프로그램이 직접 입출력을 하는 것을 차단한다.\r\n    - 사용자 프로그램이 입출력을 하고 싶으면 시스템 콜로 운영체제에 요청해야 한다.\r\n    - 그러면 인터럽트 하드웨어에 의해 모드비트가 0으로 세팅되어 운영체제가 입출력을 수행할 수 있게 된다.\r\n\r\n## 10. 메모리 보안\r\n\r\n- 여러 프로그램이 메모리에 동시에 올라가서 실행되기 때문에 하나의 프로그램이 다른 프로그램이나 운영체제가 위치한 메모리 영역을 침범할 수 있기에 메모리 보안도 필요하다.\r\n- 특히, 인터럽트 벡터와 인터럽트 처리루틴이 있는 곳은 각별한 보안이 필요하다.\r\n    - 운영체제만 수행할 수 있는 특권명령을 보안성이 침해되는 이상한 명령어로 변형할 수 있기 때문.\r\n- 2개의 레지스터를 사용해서 프로그램이 접근하려는 메모리 부분이 합법적인지 체크함으로써 메모리를 보호할 수 있다.\r\n    - 기준 레지스터(base register)\r\n        - 어떤 프로그램이 수행되는 동안 그 프로그램이 합법적으로 접근할 수 있는 메모리상의 가장 작은 주소를 보관하고 있다.\r\n    - 한계 레지스터(limit register)\r\n        - 프로그램이 기준 레지스터값부터 접근할 수 있는 메모리의 범위를 보관하고 있음.\r\n    - 어떤 프로그램이 실제 메모리에 올라가 있는 부분의 시작 주소와 그 프로그램의 길이를 각각 기준 레지스터와 한계 레지스터에 보관해 메모리 접근 연산이 있을 때마다 하드웨어적으로 현재 접근하려는 위치가 합법적 범위에 있는지 체크하게 됨.\r\n    - 사용자 프로그램은 기준 레지스터에 있는 주소부터 기준 레지스터 + 한계 레지스터값 사이의 주소 영역에만 접근할 수 있음.\r\n- 메모리 접근 연산은 사용자 프로그램이 CPU를 가지고 있는 동안 수행할 수 있는 연산이므로 특권명령은 아니지만, 사용자 프로그램이 메모리에 접근하기 전에 하드웨어적으로 그 접근이 합법적인지를 체크하여 메모리를 보호하게 됨.\r\n    - 운영체제만이 수행할 수 있는 입출력 연산과 메모리 접근 연산의 차이점.\r\n- 사용자모드인 경우, 기준 레지스터와 한계 레지스터를 사용해서 메모리를 보호하게 되고, 커널모드에서는 메모리에 무제한으로 접근하는 것이 가능함.\r\n\r\n## 11. CPU 보호\r\n\r\n- 특정 프로그램이 CPU를 독점되는 것을 막기 위해 운영체제는 타이머(timer)라는 하드웨어를 사용함.\r\n- 타이머는 정해진 시간이 지나면 인터럽트를 발생시켜 운영체제가 CPU의 제어권을 획득할 수 있도록 하는 역할을 수행함.\r\n- 타이머는 일정한 시간 단위로 세팅될 수 있으며 매 클럭 틱(clock tick) 때마다 1씩 감소하여 0이 되는 순간 인터럽트를 발생하게 됨.\r\n    - 세팅하는 명령을 로드 타이머(load timer)라고 하며 특권명령에 속함.\r\n- 타이머는 시분할 시스템에서 현재 시간을 계산하기 위해서도 사용됨.\r\n\r\n## 12. 시스템 콜을 이용한 입출력 수행\r\n\r\n- 사용자 프로그램이 디스크 파일에 데이터를 쓰거나 읽어오는 행위, 키보드 입력하고 결과 출력하는 행위 등은 모두 특권명령인 입출력 명령에 해당하므로 사용자 프로그램이 직접 수행할 수 없음.\r\n- 사용자 프로그램은 시스템 콜이라는 서비스 대행 요청을 하여 입출력을 수행함.\r\n    - 시스템 콜은 일종의 소프트웨어적인 인터럽트\r\n    - 시스템 콜을 하면 트랩이 발생해 CPU 제어권이 운영체제로 넘어감.\r\n    - 운영체제는 해당 시스템 콜을 처리하기 위한 루틴으로 가서 정의된 명령을 수행함.\r\n    - 예를 들어 디스크 컨트롤러에게 입출력 요청을 수행하도록 명령하고, 추후에 디스트 컨트롤러가 입출력 수행을 마치면 CPU에게 인터럽트를 발생시켜 입출력이 완료되었음을 알려줌으로써 해당 프로그램이 다시 CPU를 할당받을 수 있도록 함.","excerpt":"1. 컴퓨터 시스템의 구조 컴퓨터 내부장치인 CPU, 메모리와 컴퓨터 외부장치인 디스크, 키보드, 마우스, 모니터, 네트워크 장치 등으로 구성된다. 컴퓨터는 외부장치에서 내부장치로 데이터를 읽어와 각종 연산을 수행한 후, 그 결과를 외부장치로 다시 …","fields":{"slug":"/os-it-principle-ch3/"},"frontmatter":{"date":"Oct 12, 2021","title":"[운영체제와 정보기술의 원리] 3. 컴퓨터 시스템의 동작 원리","tags":["os","book"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"## 1. 운영체제의 정의\r\n\r\n- 운영체제란 컴퓨터 하드웨어 바로 윗단에 설치되는 소프트웨어\r\n\r\n    ![Untitled (67)](https://user-images.githubusercontent.com/62014888/146131511-acf8ab22-cc9e-4d2f-a88e-5e3cb9439c46.png)\r\n\r\n    - 운영체제에 시스템이라는 용어가 사용된 것은 하드웨어가 운영체제와 한 몸이 되어야만 사용자에게 쓰일 수 있는 진정한 컴퓨터 시스템이 되기 때문.\r\n    - 사용자 입장에서는 하드웨어 자체를 다룬다는 것이 쉽지 않으므로, 하드웨어 위에 기본적으로 운영체제를 탑재해 전원을 켰을 때 손쉽게 사용할 수 있는 상태가 되도록 하는 것.\r\n- 운영체제도 하나의 소프트웨어로서 전원이 켜짐과 동시에 메모리에 올라감\r\n    - 운영체제 중 항상 필요한 부분만을 전원이 켜짐과 동시에 메모리에 올려놓고 그렇지 않은 부분은 필요할 때 메모리로 올려서 사용하게 됨.\r\n        - 메모리에 상주하는 부분을 커널(kernel)이라고 부름.\r\n          좁은 의미의 운영체제. 핵심적인 부분을 뜻함.\r\n        - 넓은 의미의 운영체제는 커널뿐 아니라 시스템을 위한 유틸리티들을 광범위하게 포함하는 개념. ex) MS 윈도우 환경에서 파일을 복사하는 프로그램 등\r\n\r\n\r\n## 2. 운영체제의 기능\r\n\r\n- 운영체제의 두 가지 주요 기능은 컴퓨터 시스템 내의 자원(resource)을 효율적으로 관리하는 것과 컴퓨터 시스템을 편리하게 사용할 수 있는 환경을 제공하는 것.\r\n    - 두 기능 중 중요한 핵심 기능은 컴퓨터 시스템 내의 자원을 효율적으로 관리하는 것.\r\n      그래서 운영체제를 자원관리자라고 부르기도 한다.\r\n    - 운영체제는 사용자 및 프로그램들 간에 자원이 형평성 있게 분배되도록 하는 균형자 역할도 함께 수행해야함.\r\n    - 효율성 + 형평성\r\n- 이밖에도 사용자와 운영체제 자신을 보호하는 역할을 담당함.\r\n\r\n## 3. 운영체제의 분류\r\n\r\n- 운영체제는 동시 작업을 지원하는지의 여부에 따라 단일작업(single tasking)용 운영체제와 다중작업(multi tasking)용 운영체제로 나누어볼 수 있다.\r\n    - 단일작업용 운영체제는 한 번에 하나의 프로그램만 실행시킬 수 있는 운영체제.\r\n      초창기 운영체제는 대개 단일작업용 운영체제에 해당.\r\n      ex) 도스(Disk Operating System: DOS)\r\n    - 최근에는 대부분의 운영체제가 동시에 2개 이상의 프로그램을 처리할 수 있는 다중작업을 지원함.\r\n      ex) MS 윈도우, 유닉스 환경 등\r\n- 운영체제가 다중작업을 처리할 때에는 여러 프로그램이 CPU와 메모리를 공유하게 됨.\r\n    - 여러 프로그램들이 CPU에 번갈아 실행되면 사용자 입장에서는 여러 프로그램이 동시에 실행되는 것처럼 보임.\r\n    - CPU의 작업시간을 여러 프로그램들이 조금씩 나누어 쓰는 시스템을 시분할 시스템(time sharing system)이라고 부름.\r\n- 메모리 공간을 분할하여 여러 프로그램들을 동시에 메모리에 올려놓고 처리하는 시스템을 다중 프로그래밍 시스템(multi-programming system)이라고 부른다.\r\n- 다중작업용 운영체제의 경우 각 프로그램에 대한 키보드 입력의 결과를 곧바로 화면에 보여주는데 이를 대화형 시스템(interactive system)이라고도 부름.\r\n- 다중처리기 시스템(multi-processor system)은 하나의 컴퓨터 안에 CPU가 여러 개 설치된 경우를 뜻함.\r\n\r\n- 다중 사용자에 대한 동시 지원 여부\r\n    - 한 번에 한명의 사용자만이 사용하도록 허용하는 운영체제를 단일 사용자용 운영체제\r\n        - DOS(단일작업), MS 윈도우(다중작업) 등\r\n    - 여러 사용자가 동시에 접속해 사용할 수 있게 하는 운영체제를 다중 사용자용 운영체제\r\n        - 이메일 서버나 웹서버 등 흔히 서버라고 부르는 컴퓨터.\r\n\r\n- 작업을 처리하는 방식에 따라.\r\n    - 일괄처리(batch processing) 방식\r\n        - 요청된 작업을 일정량씩 모아서 한꺼번에 처리하는 방식\r\n        - 처리해야 할 작업들을 모아 일정량이 쌓이면 일괄적으로 처리하고, 모든 작업이 완전히 종료된 후에 결과를 얻을 수 있음.\r\n        - 사용자 입장에서는 응답시간이 길다는 단점이 있음.\r\n        - ex) 펀치 카드(punch card) 처리 시스템\r\n    - 시분할 방식\r\n        - 여러 작업을 수행할 때 컴퓨터의 처리 능력을 일정한 시간 단위로 분할해 사용하는 방식.\r\n        - 사용자들은 일괄처리 방식에 비해 짧은 응답시간을 갖게 된다.\r\n        - 사용자 요청에 대한 결과를 곧바로 얻을 수 있는 시스템을 대화형 시스템이라고 표현하며, 이는 시분할 방식의 대표적인 특징.\r\n    - 실시간(real time) 운영체제\r\n        - 정해진 시간 안에 어떠한 일이 반드시 처리됨을 보장해야 하는 시스템에서 사용.\r\n        - ex) 원자로, 공장 제어 시스템, 미사일 제어 시스템 등\r\n        - 경성 실시간 시스템(hard realtime system) - 주어진 시간을 지키지 못할 경우 매우 위험한 결과를 초래할 가능성이 있는 로켓, 원자로 제어 시스템 등을 말함.\r\n        - 연성 실시간 시스템(soft realtime system) - 멀티미디어 스트리밍 시스템과 같이 데이터가 정해진 시간 단위로 전달되어야 올바른 기능을 수행할 수 있는 시스템.\r\n\r\n\r\n## 4. 운영체제의 예\r\n\r\n- MS 윈도우\r\n    - 마이크로소프트에서 이전에 개발한 MS-DOS와 윈도우 3.1 등을 한층 발전시킨, 개인용 컴퓨터를 위한 운영체제\r\n    - 윈도우 XP부터 인터페이스 측면에서 그래픽 환경과 아이콘 방식을 기본적으로 채택\r\n    - 시스템에 새로운 하드웨어를 장착하면 운영체제가 자동으로 그 하드웨어를 감지하여 그에 맞게 설정되는 기능인 플러그 앤 플레이(plug and play) 제공.\r\n- 유닉스\r\n    - 프로그램 개발 환경을 위해 설계된 운영체제로서 이식성(portability)이 좋고, 운영체제 커널의 크기가 작으며, 소스 코드(source code)가 공개되었다는 점 등으로 인해 학계를 바탕으로 많은 연구와 함께 그 사용이 확대되어 이제는 가장 널리 사용되는 운영체제 중 하나로 자리 잡음.\r\n    - 리눅스(Linux)의 등장으로 대형 서버뿐 아니라 개인용 컴퓨터에서도 유닉스를 널리 사용할 수 있게 됨.\r\n\r\n\r\n## 5. 운영체제의 자원 관리 기능\r\n\r\n- 운영체제의 가장 핵심적인 기능은 자원을 효율적으로 관리하는 것.\r\n- 자원은 하드웨어 자원과 소프트웨어 자원으로 나뉨\r\n    - 하드웨어 자원 - CPU와 메모리(memory)를 비롯해 주변장치 또는 입출력 장치라 불리는 장치들로 구성됨.\r\n\r\n- CPU 관리하는 방법\r\n- CPU가 하나밖에 없는 가장 기본적인 컴퓨터 구조에서도 여러 개의 프로세스가 동시에 수행될 수 있으므로 매 시점 어떠한 프로세스에 CPU를 할당해 작업을 처리할 것인지 결정하는 일이 필요함.\r\n    - 이를 CPU 스케줄링(CPU scheduling) 이라고 한다.\r\n    - CPU 스케줄링의 목표는 CPU를 가장 효율적으로 사용하면서도, 특정 프로세스가 불이익을 당하지 않도록 하는 것.\r\n    - 선입선출 기법(First Come First Served)\r\n        - CPU를 사용하기 위해 도착한 프로세스들 중 먼저 온 것을 먼저 처리해주는 방식.\r\n        - CPU 자체의 효율적인 사용 측면에서는 문제가 없지만 전체 시스템 입장에서는 비효율적인 결과를 초래할 가능성이 있다.\r\n    - 라운드 로빈 기법(Round Robin)\r\n        - CPU를 한 번 할당받아 사용할 수 있는 시간을 일정하게 고정된 시간으로 제한함.\r\n        - 일반적으로 1회 할당시간은 밀리초 단위를 사용해 다수의 사용자가 동시에 접속할 때에도 각자 1초 이하의 응답시간을 보장받을 수 있게 된다.\r\n    - 우선순위 스케줄링(priority)\r\n        - CPU 사용을 위해 대기 중인 프로세스들에 우선순위를 부여하고 우선순위가 높은 프로세스에 CPU를 먼저 할당한다.\r\n        - 상대적으로 더 중요한 프로세스의 우선순위를 높게 하여 CPU를 먼저 획득할 수 있도록 한다.\r\n        - 지나치게 오래 기다리는 프로세스가 발생하지 않도록, 기다린 시간이 늘어날수록 우선순위를 점차 높여주는 방안도 활용될 수 있음\r\n- 중요 관리 대상으로 메모리도 있다.\r\n- 메모리는 CPU가 직접 접근할 수 있는 컴퓨터 내부의 기억장치로 한정된 메모리 공간에 여러 프로그램을 수용하려면 효율적인 관리 메커니즘이 필요함.\r\n- 메모리의 어떤 부분이 어떤 프로그램에 의해 사용되고 있는지를 파악하여 이를 유지하게 되는데, 이러한 정보는 주소(address)를 통해 관리됨.\r\n- 프로그램에 메모리가 필요할 때 할당하고, 더 이상 필요하지 않을 때 회수하는데 이를 잘 판단해 전체 메모리 공간이 효율적으로 사용될 수 있도록 해야 하며, 각 프로세스가 자신의 메모리 영역에만 접근할 수 있도록 관리해야 함.\r\n    - 고정분할 방식(fixed partition)\r\n        - 물리적 메모리를 몇 개의 분할로 미리 나누어 관리. 나뉜 분할에는 하나의 프로그램이 적재될 수 있음.\r\n        - 융통성이 없다. 최대 프로그램의 수가 분할 개수로 한정되어 있고 분할의 크기보다 큰 프로그램은 적재가 불가능.\r\n        - 효율적인 사용 측면에서 바람직하지 않음.\r\n          분할의 크기보다 작은 프로그램이 적재될 경우 내부조각(internal fragmentation)이라는 비효율적으로 낭비되는 공간이 생김.\r\n    - 가변분할 방식(variable partition)\r\n        - 매 시점 프로그램의 크기에 맞게 메모리를 분할해서 사용하는 방식\r\n        - 물리적 메모리의 크기보다 더 큰 프로그램의 실행은 여전히 불가능.\r\n        - 프로그램에는 할당되지는 않았지만 그 크기가 작아 프로그램을 올리지 못하는 메모리 영역인 외부조각(external fragmentation)이 발생할 수 있다.\r\n    - 가상메모리 기법(virtual memory)\r\n        - 현대의 범용 컴퓨터 환경에서 가장 널리 사용되는 메모리 관리 기법\r\n        - 물리적 메모리보다 더 큰 프로그램이 실행되는 것을 지원함.\r\n        - 가상메모리 기법에서는 물리적 메모리의 크기와 상관없이, 사용할 수 있는 메모리의 크기가 충분히 크다고 가정하고 프로그램을 개발할 수 있음.\r\n            - 현재 사용되고 있는 부분만 메모리에 올리고, 나머지는 하드디스크와 같은 보조기억장치에 저장해두었다가 필요할 때 적재하는 방식을 취함.\r\n        - 동일한 단위로 메모리를 나누는 기법을 페이징(paging) 기법이라고 함.\r\n\r\n- 주변장치 및 입출력 장치\r\n- CPU나 메모리와 달리 인터럽트(interrupt)라는 메커니즘을 통해 관리가 이루어진다.\r\n- 주변장치들은 CPU의 서비스가 필요한 경우에 신호를 발생시켜 서비스를 요청함. 이때 발생시키는 신호를 인터럽트라고 한다.\r\n- CPU는 작업을 수행하다 인터럽트가 발생하면 하던 일을 멈추고 인터럽트에 의한 요청 서비스를 수행한다.\r\n- ex) 키보드 입력\r\n- 인터럽트는 요청하는 장치와 발생 상황에 따라 다양한 종류가 있기 때문에 운영체제는 인터럽트의 종류마다 서로 다른 인터럽트 처리루틴을 가지고 있다.\r\n    - 이는 운영체제 커널 내에 존재하는 코드.\r\n    - 인터럽트가 발생하면 운영체제는 해당하는 인터럽트 처리루틴을 찾아서 정의된 코드에 따라 일을 수행하게 된다.\r\n- 주변장치들은 각 장치마다 그 장치에서 일어나는 업무를 관리하기 위한 일종의 작은 CPU인 컨트롤러(controller)를 가지고 있음.\r\n    - 컨트롤러는 해당 장치에 대한 업무를 처리하고, 이를 메인 CPU에 인터럽트를 발생시켜 보고하는 역할을 한다.","excerpt":"1. 운영체제의 정의 운영체제란 컴퓨터 하드웨어 바로 윗단에 설치되는 소프트웨어 Untitled (67) 운영체제에 시스템이라는 용어가 사용된 것은 하드웨어가 운영체제와 한 몸이 되어야만 사용자에게 쓰일 수 있는 진정한 컴퓨터 시스템이 되기 때문. …","fields":{"slug":"/os-it-principle-ch2/"},"frontmatter":{"date":"Oct 11, 2021","title":"[운영체제와 정보기술의 원리] 2. 운영체제의 개요","tags":["os","book"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n## 프로젝트 로깅 문제\r\n\r\n- 현재 보또보 프로젝트에서는 로깅을 위해 Logback을 사용하고 있다.\r\n- 기본적으로 스프링에서 생기는 로그 + HTTP 요청 응답 로그 + JPA로 생기는 쿼리와 바인딩 데이터 로그를 남기기로 했다.\r\n- Local, Test 환경에서는 콘솔에 로그를 출력시키기만 했고 Dev, Prod 환경에서는 INFO, WARN, ERROR 로그, HTTP 요청 응답 로그, 쿼리 + 바인딩 데이터 로그를 파일로 남기기로 했다.\r\n    - 더 자세한 것은 [보또보 위키](https://github.com/woowacourse-teams/2021-botobo/wiki/로깅-전략) 를 참고하자!  \r\n\r\n- 문제는 쿼리 + 바인딩 데이터 로그에서 시작되었다.\r\n- 다양한 문제집 보기라는 보또보 사이트에서 제공해주는 기능이 있다.\r\n  이 기능은 사이트 내 등록이 되어있는 문제집 중 랜덤으로 100개를 제공해주는 기능이다.\r\n- 100개의 문제집을 조회하기 위해서는 하나의 조회문에서 파생되는 여러 조회문이 있었고 (한방 쿼리를 사용하기에는 연관관계가 너무 많고 N+1 문제를 해결하기 위해 Batch Size를 설정했다) 그러다보니 쿼리문 + 바인딩된 데이터 로그가 정말 많이 발생하게 되었다.\r\n\r\n그 결과 한번 서비스를 접근해서 100개의 문제집을 제공 받기까지 사용자 입장에서 시간이 너무 오래걸렸다.\r\n- 일단 Prod 서버에는 쿼리 + 바인딩 데이터 로그를 남기지 않기기로 했다.\r\n  우리가 이 로그를 남기기로 했는 이유는 최대한 로그를 많이 남기는게 에러를 추적하기 용이하다 + 한번 로그를 다 남겨보자 였다.\r\n  검색해보니 이 로그는 보통 테스트하는 환경에서 남기고 실제 운영 서버에서는 남기지 않는 경우가 많다기에 Prod 서버에서는 남기지 않기로 하였고 그 결과 로딩 시간이 단축되는 현상을 볼 수 있었다.\r\n\r\n하지만 여전히 Dev 서버에는 로그를 남기고 있었기에 어떻게 하면 로그를 남기면서 성능을 향상시킬 수 있을까 고민했다.\r\n\r\n## 비동기 로깅\r\n\r\n- 현재 Logback에서 로그를 동기로 남기고 있었고 비동기로 남기면 성능이 향상될 수 있다는 이야기를 들었고 이에 비동기로 로깅을 변경해보기로 했다.\r\n\r\n```xml\r\n<included>\r\n    <property name=\"QUERY_LOG_PATH\" value=\"logs/query\"/>\r\n    <property name=\"QUERY_LOG_FILE_NAME\" value=\"query\"/>\r\n\r\n    <appender name=\"QUERY_FILE\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\">\r\n        <filter class=\"ch.qos.logback.classic.filter.LevelFilter\">\r\n            <level>TRACE</level>\r\n        </filter>\r\n\r\n        <encoder>\r\n            <pattern>\r\n                %d{yyyy-MM-dd HH:mm:ss} %n    > %msg%n\r\n            </pattern>\r\n        </encoder>\r\n\r\n        <rollingPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy\">\r\n            <fileNamePattern>${QUERY_LOG_PATH}/${QUERY_LOG_FILE_NAME}.%d{yyyy-MM-dd}_%i.log</fileNamePattern>\r\n            <maxFileSize>3MB</maxFileSize>\r\n            <maxHistory>100</maxHistory>\r\n        </rollingPolicy>\r\n    </appender>\r\n\r\n\t\t// AsyncAppender 설정\r\n    <appender name=\"QUERY_FILE_ASYNC\" class=\"ch.qos.logback.classic.AsyncAppender\">\r\n        <appender-ref ref=\"QUERY_FILE\" />\r\n        <queueSize>512</queueSize>\r\n        <discardingThreshold>0</discardingThreshold>\r\n        <includeCallerData>false</includeCallerData>\r\n        <neverBlock>true</neverBlock>\r\n        <maxFlushTime>1000</maxFlushTime>\r\n    </appender>\r\n\r\n    <logger name=\"org.hibernate.SQL\" level=\"DEBUG\" additivity=\"false\">\r\n        <appender-ref ref=\"QUERY_FILE_ASYNC\"/>\r\n    </logger>\r\n    <logger name=\"org.hibernate.type.descriptor.sql.BasicBinder\" level=\"TRACE\" additivity=\"false\">\r\n        <appender-ref ref=\"QUERY_FILE_ASYNC\"/>\r\n    </logger>\r\n    <logger name=\"org.hibernate.type.descriptor.sql.BasicExtractor\" level=\"TRACE\" additivity=\"false\">\r\n        <appender-ref ref=\"QUERY_FILE_ASYNC\"/>\r\n    </logger>\r\n\r\n</included>\r\n```\r\n\r\n- 적용 방법은 생각보다 간단했다.\r\n    - 파일로 남기는 설정인 RollingFileAppender를 AsyncAppender로 감싸기만 하면 되었다.\r\n\r\n- 각각의 AsyncAppender 설정 옵션은 이렇다.\r\n    1. queueSize\r\n        - async로 동작하기 위해서는 log들을 BlockingQueue를 이용해 버퍼에 저장해 둔다. 버퍼에 저장해두는 queue의 사이즈를 의미하며 해당 queue 사이즈의 80%가 초과하게 되면 WARN, ERROR를 제외하고 drop한다. 따라서 적절한 queueSize를 사용해야 하며 default는 256이다.\r\n          밑에 사이트를 바탕으로 512로 설정하였다.\r\n\r\n            ![Untitled - 2021-12-18T135152 434](https://user-images.githubusercontent.com/62014888/146629449-4622b679-2300-4e54-b6e1-59e1633bf6e7.png)\r\n\r\n            - [https://dzone.com/articles/how-instantly-improve-your-0](https://dzone.com/articles/how-instantly-improve-your-0)\r\n    2. discardingThreshold\r\n        - 기본적으로 blocking queue에 20% 용량이 남아 있으면 TRACE, DEBUG 및 INFO 수준의 이벤트를 삭제하고 WARN 및 ERROR 수준의 이벤트만 유지한다. 이 값을 0으로 설정하면 모든 이벤트를 유지한다. default는 20이다.\r\n          INFO 로그를 삭제하고 싶지않아서 0으로 설정했다.\r\n    3. includeCallData\r\n        - 발신자의 정보(class명, 줄번호 등)가 추가되어 수집 서버로 전송여부를 결정한다. true 설정 시 성능 저하를 일으킬 수 있다. default는 false이다. 성능 문제로 인해 false를 권장하지만 false로 설정할 경우에는 class, method, line 수 등을 로그에서 확인할 수 없다. 실제로 false로 설정했을 때 ?.?.? 이런 형식으로 로그가 남는 결과를 볼 수 있었다.\r\n    4. maxFlushTime\r\n        - LoggerContext가 정지하면 AsyncAppender의 stop 메서드는 작업 스레드가 timeout 될 때까지 대기한다. maxFlushTime을 사용하면 timeout 시간을 밀리초로 설정할 수 있다. 해당 시간안에 처리하지 못한 이벤트는 삭제된다. defult는 1000이다.\r\n    5. neverBlock\r\n        - queue에 가득차게 되는 경우 다른 쓰레드의 작업들이 blocking 상태에 빠지게 되는데 해당 옵션을 true하게 되면 blocking 상태에 빠지지 않고 log를 drop하며 계속 진행할 수 있게 해준다. 로그의 버퍼가 꽉 차서 application이 blocking되지 않기 위해 반드시 true를 적용하는 것을 권장한다. default는 false이다.\r\n\r\n\r\n## 비동기 적용 결과\r\n\r\n- 적용하고 성능 테스트를 해보았다.\r\n- 생각보다 결과가 흥미로웠다.\r\n- 성능 테스트 도구로 k6를 사용했다. 설정은 다음과 같다.\r\n    - VUSER는 100명\r\n    - 1분동안 진행\r\n    - 모든 요청의 99% 이상의 소요시간이 1500ms 이내에 들어야 한다.\r\n    - 모든 요청은 다양한 문제집 보기 서비스에 접근하여 100개의 문제집을 조회하도록 하였다.\r\n\r\n- 비동기 로깅 적용 전\r\n\r\n    ![Screen_Shot_2021-09-29_at_5 51 26_PM (1)](https://user-images.githubusercontent.com/62014888/146629455-3582b1e2-4a26-460a-b855-59c80dfdca25.png)\r\n\r\n\r\n주목할 점은 http&#95;req&#95;duration, http&#95;req&#95;failed, \r\nhttp_reqs이다.\r\n\r\nhttp&#95;req&#95;duration은 평균적으로 한번의 요청당 얼마만큼의 시간이 소요되었는지를 알 수 있는데 평균 31초가 걸렸다고 적혀있다.\r\n\r\nhttp&#95;req&#95;failed는 요청 실패율,\r\nhttp_reqs는 총 요청 수를 나타낸다.\r\n73.50%의 실패율과 요청 수가 151개로 측정되었다.\r\n\r\n- 비동기 로깅 적용 후\r\n\r\n    ![Screen_Shot_2021-09-29_at_6 26 02_PM (1)](https://user-images.githubusercontent.com/62014888/146629461-807d2b5d-df69-4bb8-bfc0-55c35f37824a.png)\r\n\r\n\r\n로깅 전과 비교해보면 확실하게 성능이 좋아졌다는 것을 볼 수 있다.\r\n\r\n요청 소요 시간도 평균 4.85초로 줄어들었으며 실패율도 0%, 그에 따라 요청 수도 680개로 이를 모두 처리했다는 결과를 볼 수 있었다.\r\n\r\n## 그렇다면 꼭 비동기로 로깅을 해야할까?\r\n\r\n- 그렇다면 앞으로 모든 로깅을 비동기로 처리해야할까?\r\n- 일단 이렇게 비동기로 로깅을 처리하게 되면 단점들이 몇 가지 있다고 한다.\r\n    - queueSize를 너무 작게 하는 경우 WARN, ERROR를 제외하고 로그의 손실을 가져올 수 있다.\r\n    - 버퍼를 이용하니 메모리의 사용량이 증가하고 CPU 사용량 또한 증가한다.\r\n    - 중간에 서버가 다운되는 경우 버퍼에 로그가 남아 있으면 버퍼가 로그를 다 쓰기 전에 종료되어 손실이 발생한다.\r\n- 개인적인 생각으로 어느 정도 규모가 있고 로그를 많이 남겨야 하는 서비스에서는 비동기로 로깅을 하지 않을 이유는 없다고 생각한다. 비동기로 로그를 남기는게 성능상 이점을 더 챙겨올 수 있고 로그 손실 이슈에 경우는 설정만 잘 해놓으면 어느 정도 방지할 수도 있으니 말이다.\r\n- 그리고 Logback 비동기를 좀 찾아보니 Log4j2 비동기가 훨씬 더 성능상 좋은거 같았다.\r\n  로깅을 남기면서 성능상의 이점을 더 챙기려면 Log4j2를 가지고 가는 것도 좋은것 같으니 필요하면 찾아보도록 하자.\r\n\r\n![Untitled - 2021-12-18T135205 226](https://user-images.githubusercontent.com/62014888/146629463-64520617-fa7d-403c-89de-d421d8f5a663.png)\r\n\r\n[https://logging.apache.org/log4j/2.x/performance.html](https://logging.apache.org/log4j/2.x/performance.html)\r\n\r\n## 마무리\r\n\r\n- 로깅을 비동기로 바꿨을 뿐인데 이렇게 눈에 띄는 성능 차이를 보일 줄은 몰랐다.\r\n- 생각보다 성능 테스트를 하는게 재밌었다.\r\n- 다만 아쉬운점은 테스트용 서버를 따로 구축해서 테스트를 한 것이 아닌 기존 Dev 서버에서 진행했다는 점.\r\n  Redis를 도입하게 될 경우도 생각하면 테스트용 서버를 하나 만들어서 대량의 데이터를 넣어두고 VUSER를 더 높인 테스트를 진행해봐야겠다.","excerpt":"프로젝트 로깅 문제 현재 보또보 프로젝트에서는 로깅을 위해 Logback을 사용하고 있다. 기본적으로 스프링에서 생기는 로그 + HTTP 요청 응답 로그 + JPA로 생기는 쿼리와 바인딩 데이터 로그를 남기기로 했다. Local, Test 환경에서는…","fields":{"slug":"/async-logging/"},"frontmatter":{"date":"Oct 02, 2021","title":"로깅이 성능에 미치는 영향과 비동기 로깅","tags":["spring","logback"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n## Cross Join?\r\n\r\n- JPA 빌더인 QueryDSL을 사용하다보면 Join 쿼리 작성할 때 주의하지 않으면 Cross Join이 발생한다고 한다.\r\n- 예전에 이동욱님 글에서 한번 본 적이 있었는데 당시에는 QueryDSL을 사용하고 있지 않던 터라 그냥 넘어갔던 기억이 있다.\r\n- 이번에 이렇게 Cross Join 문제를 겪고 나서야 해결한 뒤 정신차리고 글을 작성한다.\r\n\r\nCross Join (교차 조인) 은 카디션 곱이라고도 하며 조인되는 두 테이블에서 곱집합을 반환한다.\r\n\r\n이 말은 집합에서 나올 수 있는 모든 경우를 이야기 한다.\r\n\r\n예로 들면 A 집합 {a, b, c}, B 집합 {1, 2, 3, 4} 가 있고 두 집합이 Cross Join이 된다면 A x B로 다음과 같이 총 12개의 집합이 나오게 된다.\r\n{a, 1}, {a, 2}, {a, 3}, {a, 4}, {b, 1} .... {c, 4}\r\n\r\n그러다보니 일반적인 Join 보다 성능상 이슈가 발생하게 된다.\r\n\r\n<br/>\r\n\r\n## 문제 상황\r\n\r\n- 그렇다면 우리 프로젝트에서는 어떤 상황에서 발생했을까?\r\n\r\n- 기존의 검색 기능은 문제집을 검색했을 때 문제집 이름에 포함이 되는 결과를 보여주었다.\r\n- 그런데 태그 이름이 일치하는 문제집도 보여주자는 의견이 나왔고 현재 프로젝트 특성 상 그게 논리적으로도 맞다고 봐 이에 맞춰 기능을 추가하기로 했다.\r\n\r\n- 검색에 쓰이는 동적 쿼리는 QueryDSL을 통해 만들어주고 있었고 기존의 코드는 다음과 같다.\r\n\r\n```java\r\npublic Page<Workbook> searchAll(WorkbookSearchParameter parameter, List<Long> tags,\r\n                                    List<Long> users, Pageable pageable) {\r\n        QueryResults<Workbook> results = jpaQueryFactory.selectFrom(workbook)\r\n                .innerJoin(workbook.user, user).fetchJoin()\r\n                .innerJoin(workbook.cards.cards, card)\r\n                .leftJoin(workbook.workbookTags, workbookTag)\r\n                .leftJoin(workbook.hearts.hearts, heart)\r\n                .where(containKeyword(parameter.getSearchKeyword()),\r\n                        containTags(tags),\r\n                        containUsers(users),\r\n                        openedTrue())\r\n                .groupBy(workbook.id)\r\n                .orderBy(findCriteria(parameter.getSearchCriteria()), workbook.id.asc())\r\n                .offset(pageable.getOffset())\r\n                .limit(pageable.getPageSize())\r\n                .fetchResults();\r\n        return new PageImpl<>(results.getResults(), pageable, results.getTotal());\r\n }\r\n\r\nprivate BooleanExpression containKeyword(SearchKeyword searchKeyword) {\r\n        if (searchKeyword == null) {\r\n            return null;\r\n        }\r\n        String keyword = searchKeyword.getValue();\r\n        return workbook\r\n\t\t\t\t\t\t\t\t\t.name\r\n\t\t\t\t\t\t\t\t\t.lower()\r\n\t\t\t\t\t\t\t\t\t.contains(keyword);\r\n }\r\n```\r\n\r\n- containKeyword 부분이 현재 문제집 이름에 포함이 되는 값만 조회하도록 되어있었고 여기에 태그 이름이 일치하는 경우도 추가하기로 했다.\r\n\r\n```java\r\n private BooleanExpression containKeyword(SearchKeyword searchKeyword) {\r\n        if (searchKeyword == null) {\r\n            return null;\r\n        }\r\n        String keyword = searchKeyword.getValue();\r\n        return containsKeywordInWorkbookName(keyword)\r\n                .or(containsKeywordInWorkbookTag(keyword));\r\n    }\r\n\r\n    private BooleanExpression containsKeywordInWorkbookName(String keyword) {\r\n        return workbook.name.lower().contains(keyword);\r\n    }\r\n\r\n    private BooleanExpression containsKeywordInWorkbookTag(String keyword) {\r\n        StringPath tagName = workbookTag.tag.tagName.value;\r\n        return tagName.eq(keyword);\r\n    }\r\n}\r\n```\r\n\r\n- 지금보니 메서드 이름을 수정하거나 코드 포맷팅을 해줘야 할거같다..\r\n- 아무튼 이런 식으로 or을 사용해서 가져오도록 했고\r\n\r\n![Untitled (19)](https://user-images.githubusercontent.com/62014888/145753361-17a52122-7dd3-452e-86d3-09c1afaf4145.png)\r\n\r\n\r\n\r\n- 실제로도 원하는 위치에 or가 있어서 잘 가져오는 줄 알았는데 테스트 코드에서 실패했다.\r\n\r\n```java\r\n@Test\r\n@DisplayName(\"검색어를 입력하고 좋아요순으로 정렬한다. 좋아요가 같다면 id순으로 정렬한다.\")\r\nvoid searchAllFromKeywordAndHeartDesc() {\r\n    // given\r\n    WorkbookSearchParameter parameter = WorkbookSearchParameter.builder()\r\n            .searchKeyword(\"문제\")\r\n            .searchCriteria(\"heart\")\r\n            .build();\r\n\r\n    // when\r\n    Page<Workbook> workbooks = workbookSearchRepository.searchAll(parameter, null, null, parameter.toPageRequest());\r\n    List<Workbook> workbookList = workbooks.toList();\r\n    \r\n    // then\r\n    assertThat(workbookList).hasSize(7);\r\n    assertThat(workbookList).extracting(Workbook::getName)\r\n            .containsExactly(\"좋아요가 많아 문제다.\",\r\n                    \"Java 문제집0\",\r\n                    \"Javascript 문제집0\",\r\n                    \"Java 문제집1\",\r\n                    \"Javascript 문제집1\",\r\n                    \"Java 문제집2\",\r\n                    \"Javascript 문제집2\");\r\n}\r\n```\r\n\r\n![Untitled (20)](https://user-images.githubusercontent.com/62014888/145753391-420df9f4-5d75-4f91-a11b-2c30e5f86d46.png)\r\n\r\n- 7개를 가져와야 하는데 6개 밖에 가져오지 못했고 이것저것 실험해보니 태그가 포함되지 않은 문제집이 조회가 되지 않는다는 것을 알게 되었다.\r\n\r\n![Untitled (21)](https://user-images.githubusercontent.com/62014888/145753398-c02cc4e8-5111-4618-acb9-70c64e12b5ad.png)\r\n\r\n- 또한 그 위를 보니 이런식으로 tag가 Cross Join이 되어있는 것을 발견했다.\r\n- 현재 Workbook과 Tag 사이의 중간 테이블인 WorkbookTag는 Left Outer Join이 되어있는데 Tag는 아무런 Join이 되어있지 않았다.\r\n- 즉, 연관관계를 맺고 있지만 Join이 되어있지 않은 상태에서 접근하려고 하니 JPA가 자동으로 Cross Join을 해주었고 이런 결과를 보여주게 된 것이다.\r\n\r\n<br/>\r\n\r\n\r\n## 해결\r\n\r\n- 이동욱님의 글에서 적혀있듯이 암묵적으로 Join이 된 것을 명시적으로 해주면 된다.\r\n\r\n```java\r\npublic Page<Workbook> searchAll(WorkbookSearchParameter parameter, List<Long> tags,\r\n                                    List<Long> users, Pageable pageable) {\r\n        QueryResults<Workbook> results = jpaQueryFactory.selectFrom(workbook)\r\n                .innerJoin(workbook.user, user).fetchJoin()\r\n                .innerJoin(workbook.cards.cards, card)\r\n                .leftJoin(workbook.workbookTags, workbookTag)\r\n                .leftJoin(workbookTag.tag, tag) // leftJoin을 추가했다.\r\n                .leftJoin(workbook.hearts.hearts, heart)\r\n                .where(containKeyword(parameter.getSearchKeyword()),\r\n                        containTags(tags),\r\n                        containUsers(users),\r\n                        openedTrue())\r\n                .groupBy(workbook.id)\r\n                .orderBy(findCriteria(parameter.getSearchCriteria()), workbook.id.asc())\r\n                .offset(pageable.getOffset())\r\n                .limit(pageable.getPageSize())\r\n                .fetchResults();\r\n        return new PageImpl<>(results.getResults(), pageable, results.getTotal());\r\n    }\r\n```\r\n\r\n- 참고로 Inner Join으로 하여도 Cross Join과 같은 결과를 받았다.\r\n- 그럼 왜 Inner Join, Cross Join을 사용하면 태그가 없는 문제집을 들고오질 않을까?\r\n- 간단하게 그림으로 보자.\r\n\r\n    ![Untitled (22)](https://user-images.githubusercontent.com/62014888/145753448-87e9b1e8-b999-4ead-9720-498000750d83.png)\r\n\r\n- 발그림이긴 한데 간단하게 요약하면 Workbook과 WorkbookTag가 이미 Left Outer Join이 되어있는 시점에서 WorkbookTag와 Tag를 Inner Join이나 Cross Join을 하려고 하니 태그가 존재하지 않는 문제집은 아예 가져오질 못하는 것이다.\r\n- 나는 Workbook과 WorkbookTag가 이미 Left Outer Join이 되어있는 시점에서 WorkbookTag와 Tag가 Inner Join이 되어도 괜찮지 않을까 생각했는데 잘못되었다는 것을 그림을 통해 알 수 있었다.\r\n\r\n![Untitled (23)](https://user-images.githubusercontent.com/62014888/145753556-587f276a-8f8d-4cca-b584-ef8536420a71.png)\r\n\r\n![Untitled (24)](https://user-images.githubusercontent.com/62014888/145753559-df10dbb0-9abd-449f-aa54-173d4383c1ca.png)\r\n\r\n- 결과적으로 원하는 쿼리문이 나왔고 테스트를 통과하는 모습을 볼 수 있었다.\r\n\r\n<br/>\r\n\r\n\r\n## 마무리\r\n\r\n- JPA를 사용하는데 특히 QueryDSL을 사용한다면 Cross Join을 조심하자.\r\n    - 모든 집합을 가져오다보니 원하지 않는 값까지 들고 올 수도 있다.\r\n- 의도하여 Cross Join을 하지 않는 이상 암묵적 Join은 모두 명시적 Join으로 바꾸도록 하자!\r\n\r\n<br/>\r\n\r\n## 참고\r\n\r\n\r\n- [https://jojoldu.tistory.com/533](https://jojoldu.tistory.com/533)\r\n- [https://clairdelunes.tistory.com/22](https://clairdelunes.tistory.com/22)","excerpt":"Cross Join? JPA 빌더인 QueryDSL을 사용하다보면 Join 쿼리 작성할 때 주의하지 않으면 Cross Join이 발생한다고 한다. 예전에 이동욱님 글에서 한번 본 적이 있었는데 당시에는 QueryDSL을 사용하고 있지 않던 터라 그냥…","fields":{"slug":"/cross-join/"},"frontmatter":{"date":"Sep 30, 2021","title":"Cross Join 살펴보기","tags":["database","join"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n## Master & Slave DB 설치\r\n\r\n```sql\r\nsudo apt update\r\nsudo apt install mariadb-server\r\n```\r\n\r\n<br/>\r\n\r\n\r\n## Master DB 설정\r\n\r\n```sql\r\nCREATE DATABASE db_name DEFAULT CHARACTER SET utf8 COLLATE utf8_general_ci;\r\n```\r\n\r\n```sql\r\n//user 생성\r\n//% 로 설정하면 외부에서도 접근 가능\r\ncreate user 'username'@'%' identified by 'password';\r\n```\r\n\r\n```sql\r\n//해당 계정에 전체 권한이 열림\r\ngrant all privileges on {database}.* to 'username'@'%';\r\nflush privileges;\r\n\r\n//replication에 대한 권한만 설정하려면 이렇게\r\n//위와 같이 {database}.*를 하면 예외가 발생함\r\n//ERROR 1221 (HY000): Incorrect usage of DB GRANT and GLOBAL PRIVILEGES\r\ngrant replication slave on *.* to 'username'@'%';\r\nflush privileges;\r\n\r\n```\r\n\r\n- 아래 파일에서 설정 수정\r\n\r\n![Untitled (55)](https://user-images.githubusercontent.com/62014888/145997271-1f67dad3-851b-44e9-84f0-ee87d8711454.png)\r\n![Untitled (56)](https://user-images.githubusercontent.com/62014888/145997280-91f6c056-bf02-4d98-90a5-5c77fbd28098.png)\r\n- mariadb 재시작\r\n\r\n```sql\r\nsudo service mysqld restart\r\n```\r\n\r\n- master db의 File과 Position 값을 slave db에 설정해야함\r\n\r\n![Untitled (57)](https://user-images.githubusercontent.com/62014888/145997291-21ba5552-5a50-4a44-981a-77d66e50550e.png)\r\n\r\n- File은 replica(slave db)가 master db의 데이터를 읽을 binary 파일이고 Position은 읽기 시작할 위치를 뜻함.\r\n- 즉 slave에서 File과 Position을 설정하면 master의 어떤 파일의 어떤 위치부터 읽겠다는 뜻.\r\n  보통 비동기 방식으로 이 파일을 읽어 slave에서 반영한다.\r\n\r\n<br/>\r\n\r\n\r\n## Slave DB 설정\r\n\r\n- 같은 계정을 만들어주고 권한도 주어야한다.\r\n\r\n```java\r\n//user 생성\r\n//% 로 설정하면 외부에서도 접근 가능\r\ncreate user 'username'@'%' identified by 'password';\r\n```\r\n\r\n- master db와 마찬가지로 해당 파일을 수정\r\n\r\n![Untitled (59)](https://user-images.githubusercontent.com/62014888/145997298-4673eda1-4b80-41d2-9d00-f860447b516c.png)\r\n\r\n- 다만 master에 server-id를 1을 주었던과는 달리 slave에는 2를 주면 된다.\r\n\r\n  만약 slave를 더 추가한다면 3, 4.. 이런식으로 숫자를 증가시켜주면 됨.\r\n\r\n\r\n![Untitled (58)](https://user-images.githubusercontent.com/62014888/145997304-ef075203-3a33-4a24-83b2-69a939caf75b.png)\r\n\r\n- 재시작을 꼭 해주자\r\n\r\n  안해주니 server-id가 설정해달라고 에러가 떴다. 당연한거긴 한데..ㅠㅠ\r\n\r\n\r\n```sql\r\nsudo service mysqld restart\r\n```\r\n\r\n- master db의 정보를 추가해준다.\r\n\r\n  master db ip, 포트, 유저 이름, 비밀번호, File, Position 값을 추가해준다\r\n\r\n\r\n```sql\r\nCHANGE MASTER TO MASTER_HOST='{master_db_ip}', \r\nMASTER_PORT={master_db_port}, \r\nMASTER_USER='{master_db_user_name}', \r\nMASTER_PASSWORD='{master_db_user_password}', \r\nMASTER_LOG_FILE='{master_db_file}', \r\nMASTER_LOG_POS={master_db_position};\r\n```\r\n\r\n```sql\r\nstart slave;\r\n```\r\n\r\n```sql\r\n//\\G 라고 입력하면 이쁘게 출력이 된다\r\nshow slave status\\G;\r\n```\r\n\r\n![Untitled (60)](https://user-images.githubusercontent.com/62014888/145997633-237cebd9-8647-4433-8ccd-ef7d3b34ebe0.png)\r\n\r\n- 각 줄에 대한 의미는 [https://myinfrabox.tistory.com/24](https://myinfrabox.tistory.com/24) 여기를 참고하자.\r\n\r\n<br/>\r\n\r\n\r\n### 주의 사항\r\n\r\n- 처음에 9000으로 포트를 바꿨는데 계속 connection refused가 발생하였다.\r\n\r\n  찾아보니 [https://blog.daum.net/techtip/12415217](https://blog.daum.net/techtip/12415217) 9000 포트가 mariadb 설정에 의해서 127.0.0.1에 대해서만 열려있었다.\r\n\r\n\r\n![Untitled (61)](https://user-images.githubusercontent.com/62014888/145997646-b7962502-c668-4c58-8e3b-cd3ae17a7dc0.png)\r\n\r\n- 그래서 bind-address를 주석 처리해두었다.\r\n\r\n![Untitled (62)](https://user-images.githubusercontent.com/62014888/145997657-db661a67-ef6a-4502-80f9-34a83ad31399.png)\r\n\r\n- 이렇게 master와 slave가 연결이 된 시점에서 master의 db에 데이터가 insert되면 slave에도 insert되는 것을 볼 수 있다.\r\n\r\n<br/>\r\n\r\n\r\n## SpringBoot DB Configuration\r\n\r\n- 방금까지 한 작업은 각각의 DB 서버에 있는 master와 slave db를 서로 연결시켜준 것이다.\r\n  연결을 시켜줌으로써 master db에 insert, update 등의 처리가 발생하면 slave db에도 같이 적용이 되는 것이다.\r\n- 그렇다면 애플리케이션에서는 무슨 작업을 해주어야할까?\r\n  사실 db가 연결이 되었다고 해서 우리가 직접 master db 서버에 가서 쿼리문을 실행시키지 않는다.\r\n  결국 db에 접근을 하는 것은 애플리케이션에서 하는 것이므로 master와 slave에 맞는 datasource를 선택하고 connection을 하여 쿼리를 처리하도록 코드를 구현해야한다.\r\n\r\n1. yml에 datasource 설정\r\n- 그렇다면 우선 datasource 설정부터 해보자.\r\n- 예제 코드이므로 간단하게 application.yml에 datasource 정보를 기입한다.\r\n\r\n  (실제 프로젝트를 진행하면 profile에 따라 설정을 나누기에 더 복잡해질 것이다.)\r\n\r\n\r\n![Inked화면 캡처 2021-09-28 143308_LI](https://user-images.githubusercontent.com/62014888/145997667-a40ab100-3635-46e9-9191-460381aed504.jpg)\r\n\r\n2. DatasourceConfig 설정\r\n\r\n```java\r\n// 1\r\n@EnableAutoConfiguration(exclude = DataSourceAutoConfiguration.class)\r\n@Configuration\r\npublic class DataSourceConfig {\r\n\r\n\t  // 2\r\n    private final JpaProperties jpaProperties;\r\n\r\n    public DataSourceConfig(JpaProperties jpaProperties) {\r\n        this.jpaProperties = jpaProperties;\r\n    }\r\n\r\n    // 3\r\n    @Bean\r\n    public DataSource dataSource() {\r\n        return new LazyConnectionDataSourceProxy(routingDataSource());\r\n    }\r\n\r\n    // 4\r\n    @Bean\r\n    public DataSource routingDataSource() {\r\n        DataSource masterDataSource = masterDatasource();\r\n        RoutingDataSource routingDataSource = new RoutingDataSource();\r\n        routingDataSource.setDefaultTargetDataSource(masterDataSource);\r\n\r\n        Map<Object, Object> dataSources = Map.of(\r\n                \"master\", masterDataSource,\r\n                \"slave\", slaveDatasource()\r\n        );\r\n        routingDataSource.setTargetDataSources(dataSources);\r\n        return routingDataSource;\r\n    }\r\n\r\n    // 4\r\n    @Bean\r\n    @ConfigurationProperties(prefix = \"datasource.master\")\r\n    public DataSource masterDatasource() {\r\n        return DataSourceBuilder.create()\r\n                .type(HikariDataSource.class)\r\n                .build();\r\n    }\r\n\r\n    // 4\r\n    @Bean\r\n    @ConfigurationProperties(prefix = \"datasource.slave\")\r\n    public DataSource slaveDatasource() {\r\n        return DataSourceBuilder.create()\r\n                .type(HikariDataSource.class)\r\n                .build();\r\n    }\r\n\r\n    // 5\r\n    @Bean\r\n    public LocalContainerEntityManagerFactoryBean entityManagerFactory() {\r\n        HibernateProperties hibernateProperties = new HibernateProperties();\r\n        final Map<String, Object> properties = hibernateProperties.determineHibernateProperties(\r\n                jpaProperties.getProperties(), new HibernateSettings()\r\n        );\r\n        HibernateJpaVendorAdapter hibernateJpaVendorAdapter = new HibernateJpaVendorAdapter();\r\n        final EntityManagerFactoryBuilder entityManagerFactoryBuilder = new EntityManagerFactoryBuilder(hibernateJpaVendorAdapter, properties, null);\r\n        return entityManagerFactoryBuilder\r\n                .dataSource(dataSource())\r\n                .packages(\"com.study.playground.replication\")\r\n                .build();\r\n    }\r\n\r\n    // 6\r\n    @Bean\r\n    public PlatformTransactionManager transactionManager(EntityManagerFactory entityManagerFactory) {\r\n        return new JpaTransactionManager(entityManagerFactory);\r\n    }\r\n\r\n}\r\n```\r\n\r\n```java\r\n// 4\r\npublic class RoutingDataSource extends AbstractRoutingDataSource {\r\n\r\n    private static final Logger log = LoggerFactory.getLogger(RoutingDataSource.class);\r\n\r\n    @Override\r\n    protected Object determineCurrentLookupKey() {\r\n        if (TransactionSynchronizationManager.isCurrentTransactionReadOnly()) {\r\n            log.info(\"current db slave\");\r\n            return \"slave\";\r\n        }\r\n        log.info(\"current db master\");\r\n        return \"master\";\r\n    }\r\n}\r\n```\r\n\r\n- 원래는 한 개의 datasource만 사용하므로 spring.datasource~ 라고 yml에 기입을 하면 spring에서 자동으로 datasource를 설정해준다.\r\n- 하지만 두 개를 사용하며 상황에 따라 master 또는 slave db로 연결이 되어야한다. 그러므로 yml에 기입한 datasource 정보를 이용해 직접 설정을 해주어야 한다.\r\n\r\n- 위 코드에서 명시한 번호 순서대로 어떤 역할을 맡고 있는지 명시해보겠다.\r\n    1. 자동으로 datasource를 설정해주는 DataSourceAutoConfiguration을 해제해준다.\r\n    2. yml에 명시해 둔 jpa properties 설정이 자동으로 들어온다.\r\n\r\n  ![Untitled (63)](https://user-images.githubusercontent.com/62014888/145997680-f52bbc10-20d2-4679-a46e-c69d67ef41b9.png)\r\n\r\n    3. Spring은 기본적으로 트랜잭션을 시작할 때 쿼리 실행 전에 datasource를 정해놓는다.\r\n   따라서 트랜잭션이 시작되면 같은 datasource만을 이용한다. 다만 우리는 쿼리 실행할 때 datasource를 결정해줘야하기 때문에 미리 datasource를 정하지 않도록 프록시 datasource인 LazyConnectionDataSourceProxy를 사용하여 실제 쿼리가 실행될 때 connection을 가져오도록 한 것이다.\r\n    4. yml에 명시해둔 datasource를 빈으로 등록시킨다. RoutingDataSource의 경우 AbstractRoutingDataSource을 구현한 클래스인데 AbstractRoutingDataSource는 여러 datasource를 등록해 상황에 맞게 원하는 datasource를 사용할 수 있는 추상 클래스라고 생각하면 된다.\r\n   이 때 determineCurrentLookupKey() 이라는 메서드를 구현하면 되는데 @Transactional(readOnly=?)에 맞춰서 readOnly가 true면 slave를 false면 master를 key로 반환하여 등록된 datasources map에서 value를 반환하게 된다.\r\n    5. EntitiyManagerFactory 설정이다. 원래는 datasource가 자동연결되면서 JPA에 대한 설정도 되지만 우리는 직접 해야한다.\r\n   이 때 Hibernate 설정도 해주게 되는데 앞서 말했듯이 직접 설정을 하다보니 기본적으로 DataSourceAutoConfiguration에서 해주는 네이밍 전략과 같은 설정도 해주어야한다. yml에 같이 명시를 해주어도 되지만 위의 예제와 같이 HibernateProperties를 만들고 determineHibernateProperties() 메서드를 실행하면 기본 설정 + yml에 명시해준 jpa 설정이 같이 합쳐진 properties가 만들어지고 이를 사용해주면 된다.\r\n    6. 마찬가지로 TransactionManager도 직접 설정해준다.\r\n\r\n<br/>\r\n\r\n\r\n## Replication Test\r\n\r\n- 테스트 코드를 통해 insert할 때 master db로 연결하고 select할 때 slave db로 연결되는지 확인해보자.\r\n- @Transactional의 readOnly 설정에 의해 datasource를 고르는 것으로 알고 Controller와 Service를 다 만들어서 인수테스트로 진행할까 했는데 신기하게도 Repository의 save와 findById 만으로도 readOnly 분기를 탈 수 있다.\r\n- 정확히는 잘 모르겠지만 논리적으로 봤을 때 하나의 트랜잭션에서 하나의 find를 사용하면 당연히 readOnly가 true이니 가능한게 아닌가 싶기도 하다.\r\n\r\n```java\r\n@SpringBootTest\r\n@AutoConfigureTestDatabase(replace = AutoConfigureTestDatabase.Replace.NONE) //datasource 자동연결을 막아준다.\r\npublic class ReplicationTest {\r\n\r\n    @Autowired\r\n    private UserRepository userRepository;\r\n\r\n    private User user;\r\n\r\n    @BeforeEach\r\n    void setUp() {\r\n        user = new User(\"oz\", 500);\r\n    }\r\n\r\n    @Test\r\n    @DisplayName(\"save를 하면 master db에 데이터를 insert 한다.\")\r\n    void insert() {\r\n        // given\r\n        Logger logger = (Logger) LoggerFactory.getLogger(RoutingDataSource.class);\r\n        ListAppender<ILoggingEvent> listAppender = new ListAppender<>();\r\n        logger.addAppender(listAppender);\r\n        listAppender.start();\r\n\r\n        // when\r\n        userRepository.save(user);\r\n\r\n        // then\r\n        final List<ILoggingEvent> list = listAppender.list;\r\n        assertThat(list).hasSize(1);\r\n        assertThat(list)\r\n                .extracting(ILoggingEvent::getFormattedMessage)\r\n                .anyMatch(log -> log.equals(\"current db master\"));\r\n    }\r\n\r\n    @Test\r\n    @DisplayName(\"find를 하면 slave db의 데이터를 select 한다.\")\r\n    void find() {\r\n        // given\r\n        userRepository.save(user);\r\n\r\n        Logger logger = (Logger) LoggerFactory.getLogger(RoutingDataSource.class);\r\n        ListAppender<ILoggingEvent> listAppender = new ListAppender<>();\r\n        logger.addAppender(listAppender);\r\n        listAppender.start();\r\n\r\n        // when\r\n        User findUser = userRepository.findById(user.getId())\r\n                .orElseThrow(IllegalStateException::new);\r\n\r\n        // then\r\n        final List<ILoggingEvent> list = listAppender.list;\r\n        assertThat(list).hasSize(1);\r\n        assertThat(list)\r\n                .extracting(ILoggingEvent::getFormattedMessage)\r\n                .anyMatch(log -> log.equals(\"current db slave\"));\r\n        assertThat(findUser).isEqualTo(user);\r\n    }\r\n\r\n}\r\n```\r\n\r\n- RoutingDataSource에서 readOnly 인지에 따라 master, slave db를 사용하기 전에 로그를 남기도록 하였고 이 로그를 이용해 테스트를 진행했다.\r\n\r\n<br/>\r\n\r\n\r\n## 왜 Replication을 적용할까?\r\n\r\n- 프로젝트 규모가 커짐에 따라 DB를 사용할 일은 더 많아질 것이다.\r\n  이 때 DB에서 고민할 것들이 몇 가지가 있을 것이다.\r\n\r\n1. 데이터의 백업\r\n2. 부하 분산\r\n\r\nReplication을 통해 이를 모두 수행할 수 있다.\r\n- master db로 데이터 쓰기 및 업데이트 작업을 하면 연결된 slave db들 모두 쓰기 및 업데이트 작업이 일어나므로 데이터의 백업을 할 수 있다.\r\n- readOnly 속성을 통해 쓰기 및 업데이트 작업은 master db에서 읽기 작업은 slave db 중 하나에서 행함으로써 부하 분산을 할 수 있다.\r\n\r\n<br/>\r\n\r\n## 마무리\r\n\r\n- [보고 또 보고](https://github.com/woowacourse-teams/2021-botobo) 프로젝트에서 Replication을 적용시켰기에 학습하기 위해 한번 따라해보았다.\r\n- Replication을 적용하면 여러 장점이 있지만 서버를 만들거나 적용하는데 쏟는 시간 또한 다 비용이기에 도입할 때는 충분히 고려해야할 것 같다.\r\n- master와 slave 사이의 데이터가 불일치할 수 있는 문제 또한 생각해봐야할 것 같다. \r\n\r\n\r\n## 참고\r\n\r\n- [https://prolog.techcourse.co.kr/posts/1665](https://prolog.techcourse.co.kr/posts/1665)\r\n- [https://velog.io/@max9106/DB-Spring-Replication](https://velog.io/@max9106/DB-Spring-Replication)\r\n- [https://github.com/woowacourse-teams/2021-botobo/wiki/DB-Replication을-위한-데이터베이스-환경-설정-(Master,-Slave)](https://github.com/woowacourse-teams/2021-botobo/wiki/DB-Replication%EC%9D%84-%EC%9C%84%ED%95%9C-%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B2%A0%EC%9D%B4%EC%8A%A4-%ED%99%98%EA%B2%BD-%EC%84%A4%EC%A0%95-(Master,-Slave))","excerpt":"Master & Slave DB 설치 Master DB 설정 아래 파일에서 설정 수정 Untitled (55)\nUntitled (56) mariadb 재시작 master db의 File과 Position 값을 slave db에 설정해야함 Untitl…","fields":{"slug":"/replication/"},"frontmatter":{"date":"Sep 29, 2021","title":"DB Replication 따라해보기","tags":["database","replication"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n## 기존 검색 API\r\n\r\n**/api/search/workbooks?type=name&criteria=date&order=desc&keyword=JAVA&start=0&size=10**\r\n\r\n- type: name, tag, user 중 택 1 (검색할 때 종류)\r\n- criteria: date, name, count, like 중 택 1 (조회할 때 정렬 기준)\r\n- order: asc (오름차순), desc (내림차순)\r\n- keyword: 검색어\r\n- start: 페이징 시작점\r\n- size: 가져올 문제집 개수\r\n\r\n보또보 기존 검색 api이다.\r\n\r\n문제집 이름으로 검색, 태그로 검색, 유저명으로 검색 이렇게 3개로 나누어져있었고 검색을 실시간으로 할 수 있었다.\r\n\r\n태그나 유저로 검색된 결과에서 최신순, 이름순, 카드개수순, 좋아요순으로 정렬이 가능했다.\r\n\r\n![Untitled (8)](https://user-images.githubusercontent.com/62014888/140268421-87b1995d-7311-449b-bffd-f7d504dd5218.png)\r\n\r\n<br/>\r\n\r\n## 새로운 검색 API\r\n\r\n**/api/search/workbooks?keyword=JAVA&tags=1&users=1&criteria=date&start=0&size=10**\r\n\r\n- criteria: date, name, count, like 중 택 1 (조회할 때 정렬 기준)\r\n- keyword: 검색어\r\n- tags: 태그 id (원하는 태그들로 필터링)\r\n- users: 유저 id (원하는 유저들로 필터링)\r\n- start: 페이징 시작점\r\n- size: 가져올 문제집 개수\r\n\r\n보또보 새로운 검색 api이다.\r\n\r\n다른 검색 사이트 + 프롤로그 검색을 참고했다.\r\n\r\n프롤로그의 태그로 필터링 하는 기능을 보고 우리도 태그 또는 유저 검색 기능을 필터링으로 바꾸자는 의견이 나와서 이를 적용시키고 싶었다.\r\n\r\n하지만 실시간으로 검색된 결과에 태그나 유저로 필터링을 하는 것이 뭔가 어색한 것 같았고 실제 다른 검색 사이트에서도 검색된 결과 페이지에서 필터링을 주로 한다는 것을 발견할 수 있었다.\r\n\r\n그래서 검색어에 대한 결과를 실시간으로 보여주는 것이 아닌 검색을 한 결과 페이지에서 보여주기로 했으며 태그, 유저 검색은 삭제하고 문제집 검색만 남기기로 했다. 문제집 이름으로 검색된 결과를 바탕으로 해당 문제집들의 태그, 유저로 필터링을 할 수 있고 최신순, 이름순, 카드개수순, 좋아요순으로 정렬이 가능하도록 했다.\r\n\r\n\r\n\r\n![Untitled (9)](https://user-images.githubusercontent.com/62014888/140268459-3ee4e7b5-416b-44a7-80d2-80d395729c81.png)\r\n\r\n<br/>\r\n\r\n## Criteria? QueryDSL?\r\n\r\n기존의 검색 기능은 동적 쿼리 구현을 위해 JPQL 빌더로 criteria를 사용하고 specification을 이용하여 쿼리 조건을 처리하였다.\r\n\r\n### Criteria\r\n\r\nCriteria는 JPQL을 자바 코드로 작성하도록 도와주는 빌더 클래스 API다.\r\n\r\nCriteria를 사용하면 문자가 아닌 코드로 JPQL을 작성하므로 문법 오류를 컴파일 단계에서 잡을 수 있고 문자 기반의 JPQL보다 동적 쿼리를 안전하게 생성할 수 있다는 장점이 있다. 하지만 코드가 복잡하고 장황해서 직관적으로 이해가 힘들다는 단점도 있다.\r\n\r\n뿐만 아니라 문법 오류를 컴파일 단계에서 잡을 수 있다곤 하지만 사용하다보면 필드명을 문자로 적어야 해서 실수를 한다면 컴파일 단계에서 잡을 수가 없게 된다.\r\n\r\n![화면 캡처 2021-09-27 120432](https://user-images.githubusercontent.com/62014888/140268498-b1127b99-6866-4889-b517-a6298564f637.jpg)\r\n\r\n물론 이를 위해 메타 모델 API를 사용하면 된다고 한다.\r\n\r\n다만, 메타 모델 API를 사용하려면 메타 모텔 클래스를 만들어야 하는데 이는 코드 자동 생성기가 있어 만들어 준다고 한다. 이러한 코드 생성기는 빌드 도구를 사용해서 실행한다.\r\n\r\n<br/>\r\n\r\n### Specification\r\n\r\nSpecification은 검색 조건을 추상화한 객체다.\r\n\r\n즉, 검색 조건에 대해 Specification을 생성하고, 이를 통해 다양한 조건의 검색을 할 수 있다는 뜻이다.\r\n\r\n우리 프로젝트로 예를 들면 어떤 타입의 검색어인지 어떤 순서로 정렬할 것인지를 Criteria를 이용해 만들고 이러한 다양한 검색 조건을 Specification으로 생성한 뒤 Repository 메서드 인자로 넘겨주어서 사용했다.\r\n\r\n<br/>\r\n\r\n## QueryDSL 특징\r\n\r\nCriteria는 위에서 말한 특징들의 장점을 확실하게 가지고 있다.\r\n\r\n하지만 너무 복잡하고 어렵다는 가장 큰 단점이 있다.\r\n\r\n작성된 코드를 보면 그 복잡성으로 인해 어떤 JPQL이 생성될지 파악하기가 쉽지 않다.\r\n\r\n쿼리를 문자가 아닌 코드로 작성해도, 쉽고 간결하며 그 모양도 쿼리와 비슷하게 개발할 수 있는 JPQL 빌더가 바로 QueryDSL이다.\r\n\r\n<br/>\r\n\r\n## Why use QueryDSL?\r\n\r\n일단 어떤 기술을 적용하기 전에 반드시 '왜 적용하는가?' 에 대해 짚고 넘어가야 한다고 생각한다.\r\n\r\n사실 이미 중간곰이랑 피케이가 Criteria, Specification으로 검색 기능을 잘 구현 해놓았기에 처음에는 QueryDSL을 적용할 필요가 있을까 싶었다.\r\n\r\n하지만 곰곰히 생각한 끝에 QueryDSL로 변경하기로 했다.\r\n\r\n그 이유는 두 가지이다.\r\n\r\n1. 기존의 Criteria, Specification를 적용한 코드를 내가 구현한게 아니기에 어차피 처음부터 공부했어야 했다. 둘 다 그렇게 해야하는거면 QueryDSL을 적용해보는 것도 괜찮겠다고 생각했다.\r\n\r\n2. 가독성 및 컴파일 오류다.\r\n\r\n아무래도 Criteria로 작성한 코드는 한번에 의미를 파악하기 어려웠고 따라서 기존 코드에서 새롭게 바뀐 API대로 적용시키는게 생각보다 어려울 것 같았다.\r\n\r\n또한 메타 모델 API를 사용하지 않는 이상 문자열 그대로 코드를 작성해야 하니 컴파일 단계에서 오류를 완전히 잡아주지 못하였다.\r\n\r\n이러한 이유들로 Criteria에서 QueryDSL로 변경하며 새로운 검색 API를 적용시키기로 하였다.\r\n\r\n<br/>\r\n\r\n## QueryDSL 설정\r\n\r\n```groovy\r\nplugins {\r\n\t\t//1\r\n    id \"com.ewerk.gradle.plugins.querydsl\" version \"1.0.10\"\r\n}\r\n\r\ndependencies {\r\n    //2\r\n    implementation 'com.querydsl:querydsl-jpa'\r\n}\r\n\r\n//3\r\ndef querydslDir = \"$buildDir/generated/querydsl\"\r\n\r\n//4\r\nquerydsl {\r\n    jpa = true\r\n    querydslSourcesDir = querydslDir\r\n}\r\n\r\n//5\r\nsourceSets {\r\n    main.java.srcDir querydslDir\r\n}\r\n\r\n//6\r\nconfigurations {\r\n    querydsl.extendsFrom compileClasspath\r\n}\r\n\r\n//7\r\ncompileQuerydsl {\r\n    options.annotationProcessorPath = configurations.querydsl\r\n}\r\n```\r\n\r\n빌드툴로 gradle을 사용했다.\r\n\r\n신기하게도 QueryDSL 공식 문서를 보면 maven이나 ant로 설정하는 방법은 나오지만 gradle에서 설정하는 방법은 나오지 않는다. 그래서 검색을 통해 해결하였다.\r\n\r\n설정들을 위에서부터 하나씩 설명하자면 이렇다.\r\n\r\n1. Q클래스 생성을 위한 QueryDSL 플러그인을 추가한다.\r\n2. QueryDSL 의존성을 추가한다.\r\n3. Q클래스가 저장되는 위치를 뜻한다. Q클래스는 자동으로 생성되는 파일들이라 .gitignore에 추가하여 깃헙에 올리지 않도록 하는것이 좋은데 build 디렉토리에 있는 파일들은 모두 올라가지 않고 있는 중이라 이렇게 설정하였다.\r\n4. jpa true로 하면 빌드할 때 자동으로 Q클래스가 생성된다. querydslSourcesDir는 Q클래스가 어디에 생성할지 결정한다.\r\n5. 빌드할 때 Q클래스가 생성된 위치를 나타낸다.\r\n6. gradle 6.x 버전에서 이 코드를 작성해야 정상작동한다고 한다. compile로 걸린 JPA 의존성에 접근하도록 해준다.\r\n7. annotation processor의 경로를 설정해주어 빌드 시 Q클래스가 생성되도록 해준다.\r\n\r\ncomplieQuerydsl을 실행해주면 이렇게 원하는 위치에 Q클래스가 잘 생성된 모습을 볼 수 있다.\r\n\r\n![Untitled (10)](https://user-images.githubusercontent.com/62014888/140268538-abad940c-0956-4877-b423-b80ed149b34c.png)\r\n\r\n<br/>\r\n\r\n## 기존 코드와 변경된 코드 비교\r\n\r\n```java\r\n@EqualsAndHashCode\r\n@Getter\r\n@NoArgsConstructor\r\n@AllArgsConstructor(access = AccessLevel.PRIVATE)\r\npublic class WorkbookSearchParameter {\r\n\r\n    private static final int MINIMUM_START_PAGE = 0;\r\n    private static final int DEFAULT_START_PAGE = 0;\r\n    private static final int MINIMUM_PAGE_SIZE = 1;\r\n    private static final int MAXIMUM_PAGE_SIZE = 100;\r\n    private static final int DEFAULT_PAGE_SIZE = 20;\r\n\r\n    private SearchKeyword searchKeyword;\r\n    private SearchCriteria searchCriteria;\r\n    private int start;\r\n    private int size;\r\n\r\n    private WorkbookSearchParameter(SearchCriteria searchCriteria, SearchKeyword searchKeyword, int start, int size) {\r\n        this.start = start;\r\n        this.size = size;\r\n        this.searchKeyword = searchKeyword;\r\n        this.searchCriteria = searchCriteria;\r\n    }\r\n\r\n    public static WorkbookSearchParameter ofRequest(String searchCriteria,\r\n                                                    String searchKeyword,\r\n                                                    String start, String size) {\r\n        return of(\r\n                SearchCriteria.of(searchCriteria),\r\n                SearchKeyword.of(searchKeyword),\r\n                initializeStartValue(start),\r\n                initializeSizeValue(size)\r\n        );\r\n    }\r\n\r\n    public static WorkbookSearchParameter of(SearchCriteria searchCriteria,\r\n                                             SearchKeyword searchKeyword,\r\n                                             int start, int size) {\r\n        return new WorkbookSearchParameter(\r\n                searchCriteria,\r\n                searchKeyword,\r\n                start,\r\n                size\r\n        );\r\n    }\r\n\r\n    private static int initializeStartValue(String start) {\r\n        try {\r\n            int value = Integer.parseInt(start);\r\n            if (value < MINIMUM_START_PAGE) {\r\n                throw new InvalidPageStartException();\r\n            }\r\n            return value;\r\n        } catch (NumberFormatException e) {\r\n            return DEFAULT_START_PAGE;\r\n        }\r\n    }\r\n\r\n    private static int initializeSizeValue(String size) {\r\n        try {\r\n            int value = Integer.parseInt(size);\r\n            if (value < MINIMUM_PAGE_SIZE || value > MAXIMUM_PAGE_SIZE) {\r\n                throw new InvalidPageSizeException();\r\n            }\r\n            return value;\r\n        } catch (NumberFormatException e) {\r\n            return DEFAULT_PAGE_SIZE;\r\n        }\r\n    }\r\n\r\n    public PageRequest toPageRequest() {\r\n        return PageRequest.of(start, size);\r\n    }\r\n}\r\n\r\n```\r\n\r\n기존 코드에서는 검색 조건 파라미터 값을 가지고 있으며 Specification을 이용해 검색 조건을 처리하는 클래스인 WorkbookSearchParameter이다.\r\n\r\n여기에 타입, 정렬 기준 등을 처리해주는 SearchCriteria, SearchType, SearchOrder 등이 있다.\r\n\r\n```java\r\n@EqualsAndHashCode\r\n@Getter\r\n@NoArgsConstructor\r\n@AllArgsConstructor(access = AccessLevel.PRIVATE)\r\npublic class WorkbookSearchParameter {\r\n\r\n    private static final int MINIMUM_START_PAGE = 0;\r\n    private static final int DEFAULT_START_PAGE = 0;\r\n    private static final int MINIMUM_PAGE_SIZE = 1;\r\n    private static final int MAXIMUM_PAGE_SIZE = 100;\r\n    private static final int DEFAULT_PAGE_SIZE = 20;\r\n\r\n    private SearchKeyword searchKeyword;\r\n    private SearchCriteria searchCriteria;\r\n    private int start;\r\n    private int size;\r\n\r\n    @Builder\r\n    private WorkbookSearchParameter(String searchCriteria, String searchKeyword, String start, String size) {\r\n        this.start = initializeStartValue(start);\r\n        this.size = initializeSizeValue(size);\r\n        this.searchKeyword = SearchKeyword.of(searchKeyword);\r\n        this.searchCriteria = SearchCriteria.of(searchCriteria);\r\n    }\r\n\r\n    private int initializeStartValue(String start) {\r\n        try {\r\n            int value = Integer.parseInt(start);\r\n            if (value < MINIMUM_START_PAGE) {\r\n                throw new InvalidPageStartException();\r\n            }\r\n            return value;\r\n        } catch (NumberFormatException e) {\r\n            return DEFAULT_START_PAGE;\r\n        }\r\n    }\r\n\r\n    private int initializeSizeValue(String size) {\r\n        try {\r\n            int value = Integer.parseInt(size);\r\n            if (value < MINIMUM_PAGE_SIZE || value > MAXIMUM_PAGE_SIZE) {\r\n                throw new InvalidPageSizeException();\r\n            }\r\n            return value;\r\n        } catch (NumberFormatException e) {\r\n            return DEFAULT_PAGE_SIZE;\r\n        }\r\n    }\r\n\r\n    public PageRequest toPageRequest() {\r\n        return PageRequest.of(start, size);\r\n    }\r\n}\r\n```\r\n\r\n```java\r\n@RequiredArgsConstructor\r\n@Repository\r\npublic class WorkbookSearchRepository {\r\n\r\n    private final JPAQueryFactory jpaQueryFactory;\r\n\r\n    public Page<Workbook> searchAll(WorkbookSearchParameter parameter,\r\n                                    List<Long> tags,\r\n                                    List<Long> users,\r\n                                    Pageable pageable) {\r\n        QueryResults<Workbook> results = queryBy(parameter, tags, users)\r\n                .offset(pageable.getOffset())\r\n                .limit(pageable.getPageSize())\r\n                .fetchResults();\r\n        return new PageImpl<>(results.getResults(), pageable, results.getTotal());\r\n    }\r\n\r\n    public List<Workbook> searchAll(WorkbookSearchParameter parameter) {\r\n        return queryBy(parameter)\r\n                .limit(parameter.getSize())\r\n                .fetch();\r\n    }\r\n\r\n    private JPAQuery<Workbook> queryBy(WorkbookSearchParameter parameter) {\r\n        return queryBy(parameter, Collections.emptyList(), Collections.emptyList());\r\n    }\r\n\r\n    private JPAQuery<Workbook> queryBy(WorkbookSearchParameter parameter, List<Long> tags, List<Long> users) {\r\n        return jpaQueryFactory.selectFrom(workbook)\r\n                .innerJoin(workbook.user, user).fetchJoin()\r\n                .innerJoin(workbook.cards.cards, card)\r\n                .leftJoin(workbook.workbookTags, workbookTag)\r\n                .leftJoin(workbookTag.tag, tag)\r\n                .leftJoin(workbook.hearts.hearts, heart)\r\n                .where(containKeyword(parameter.getSearchKeyword()),\r\n                        containTags(tags),\r\n                        containUsers(users),\r\n                        openedTrue())\r\n                .groupBy(workbook.id)\r\n                .orderBy(findCriteria(parameter.getSearchCriteria()), workbook.id.asc());\r\n    }\r\n\r\n    private BooleanExpression containKeyword(SearchKeyword searchKeyword) {\r\n        if (searchKeyword == null) {\r\n            return null;\r\n        }\r\n        String keyword = searchKeyword.getValue();\r\n        return containsKeywordInWorkbookName(keyword)\r\n                .or(equalsKeywordInWorkbookTag(keyword));\r\n    }\r\n\r\n    private BooleanExpression containsKeywordInWorkbookName(String keyword) {\r\n        return workbook.name.lower().contains(keyword);\r\n    }\r\n\r\n    private BooleanExpression equalsKeywordInWorkbookTag(String keyword) {\r\n        return workbook.workbookTags.any().tag.tagName.value.eq(keyword);\r\n    }\r\n\r\n    private BooleanExpression containTags(List<Long> tags) {\r\n        if (tags == null || tags.isEmpty()) {\r\n            return null;\r\n        }\r\n        return workbookTag\r\n                .tag\r\n                .id\r\n                .in(tags);\r\n    }\r\n\r\n    private BooleanExpression containUsers(List<Long> users) {\r\n        if (users == null || users.isEmpty()) {\r\n            return null;\r\n        }\r\n        return user\r\n                .id\r\n                .in(users);\r\n    }\r\n\r\n    private BooleanExpression openedTrue() {\r\n        return workbook.opened.isTrue();\r\n    }\r\n\r\n    private OrderSpecifier<?> findCriteria(SearchCriteria searchCriteria) {\r\n        if (searchCriteria == SearchCriteria.DATE) {\r\n            return workbook.createdAt.desc();\r\n        }\r\n        if (searchCriteria == SearchCriteria.NAME) {\r\n            return workbook.name.asc();\r\n        }\r\n        if (searchCriteria == SearchCriteria.COUNT) {\r\n            return card.countDistinct().desc();\r\n        }\r\n        return heart.countDistinct().desc();\r\n    }\r\n}\r\n\r\n```\r\n\r\nQueryDSL로 바꾸면서 기존의 WorkbookSearchParameter는 파라미터로 들어온 값만 가지고 있고 이 값을 이용해 QueryDSL 전용 Repository에서 조회를 처리했다.\r\n\r\nconfiguration으로 JPAQueryFactory를 빈으로 등록한 뒤 이를 이용해 동적 쿼리를 작성하는 방식이다.\r\n\r\n디테일한 부분은 설명하기 아직 지식이 부족하지만 대략적으로 JPAQueryFactory를 사용해 동적 쿼리를 만드는데 파라미터로 넘겨온 값을 where 내에 있는 메서드들을 이용해 BooleanExpression을 반환받도록 하여 조건에 맞게 쿼리를 만들 수 있다.\r\n\r\n물론 이와 함께 paging도 가능하다!\r\n\r\nCriteria와 비교하면 상대적으로 가독성이 좋다는 것을 알 수 있다.\r\n\r\n<br/>\r\n\r\n## 주의할 점\r\n\r\n적용하다 생긴 트러블 슈팅을 공유한다.\r\n\r\n1. 소나큐브와 함께 사용하다 보니 테스트 커버리지를 통과하지 못해 빌드할 때 에러가 발생했다.\r\n\r\n   Q클래스도 테스트 커버리지 검증을 하다보니 발생하는 에러였는데 이를 위해 테스트 커버리지 검증에서 Q클래스를 제외시켰다.\r\n\r\n   역시나 검색을 해보니 이런 상황을 맞이한 분들이 있으셔서 이 블로그를 참고하였다.\r\n   [https://velog.io/@lxxjn0/코드-분석-도구-적용기-2편-JaCoCo-적용하기](https://velog.io/@lxxjn0/%EC%BD%94%EB%93%9C-%EB%B6%84%EC%84%9D-%EB%8F%84%EA%B5%AC-%EC%A0%81%EC%9A%A9%EA%B8%B0-2%ED%8E%B8-JaCoCo-%EC%A0%81%EC%9A%A9%ED%95%98%EA%B8%B0)\r\n\r\n    ```groovy\r\n    jacocoTestCoverageVerification {\r\n        def Qdomains = []\r\n    \r\n        for (qPattern in '*.QA'..'*.QZ') {\r\n            Qdomains.add(qPattern + '*')\r\n        }\r\n    \r\n        violationRules {\r\n            rule {\r\n                enabled = true\r\n                element = 'CLASS'\r\n    \r\n                limit {\r\n                    counter = 'BRANCH'\r\n                    value = 'COVEREDRATIO'\r\n                    minimum = 0.80\r\n                }\r\n    \r\n                limit {\r\n                    counter = 'LINE'\r\n                    value = 'COVEREDRATIO'\r\n                    minimum = 0.80\r\n                }\r\n    \r\n                excludes = [\r\n                        //제외될 다른 클래스들\r\n                ] + Qdomains\r\n            }\r\n        }\r\n    }\r\n    ```\r\n\r\n<br/>\r\n\r\n2. distinct와 orderBy가 동시에 적용되지 않는 현상이 발생했다.\r\n\r\n   찾아보니 H2 문법 문제였고 MySQL에서는 같이 사용해도 적용이 되었다.\r\n\r\n   그래서 일단은 workbook의 id로 groupBy를 해서 distinct를 사용하지 않는 방향으로 수정했다. 프로젝트를 진행하며 Flyway를 적용할 때도 그렇고 이번에도 그렇고 local과 test에서는 H2를 사용하고 dev와 prod에서는 Mariadb를 사용하다 보니 H2와 MySQL의 문법 차이 때문에 여러 번 syntax 에러를 경험하는 일이 많았다.\r\n\r\n   그리하여 다음 스프린트 때는 이 차이를 해소시킬 방법을 찾아볼 생각이다.\r\n\r\n<br/>\r\n\r\n3. 이건 우리가 겪은 트러블 슈팅은 아니지만 gradle에서 QueryDSL 설정과 관련해서 많이들 이슈가 있다고 한다. 현재 우리가 적용시킨 설정 방법은 플러그인을 사용해서 Q클래스를 만드는데 이때 gradle 버전이 업그레이드 됨에 따라 여러 가지 설정을 추가해주어야 했다.\r\n   그래서 이 플러그인을 걷어내기 위해 gradle AnnotationProcessor를 사용하여 처리하는 방법이 있다고 한다.\r\n   이게 궁금하다면 [http://honeymon.io/tech/2020/07/09/gradle-annotation-processor-with-querydsl.html](http://honeymon.io/tech/2020/07/09/gradle-annotation-processor-with-querydsl.html) 블로그를 참고하도록 하자.","excerpt":"기존 검색 API /api/search/workbooks?type=name&criteria=date&order=desc&keyword=JAVA&start=0&size=10 type: name, tag, user 중 택 1 (검색할 때 종류) crit…","fields":{"slug":"/criteria-querydsl/"},"frontmatter":{"date":"Sep 27, 2021","title":"Criteria -> QueryDSL 마이그레이션 해보기","tags":["jpql"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n## ANSI SQL\r\n\r\nDBMS(Oracle, MySQL 등등)들에서 각기 다른 SQL을 사용하므로 미국 표준 협회(American National Standards Institute)에서 이를 표준화하여 표준 SQL문을 정립시켜 놓은 것.\r\n\r\nANSI SQL 문법의 Join을 익혀두는 것이 좋을듯 싶다.\r\n\r\n### 특징\r\n\r\n1. 표준 SQL문이기 때문에 DBMS의 종류에 제약을 받지 않는다. 즉, 특정 벤더에 종속적이지 않아 다른 벤더의 DBMS올 교체하더라도 빠르게 다른 벤더사를 이용할 수 있다.\r\n   특정 DBMS의 이탈이 가속되는 것도 ANSI SQL의 영향이 크다고 할 수 있다\r\n2. 테이블 간의 Join 관계가 FROM에서 명시되기 때문에 WHERE 문에서 조건만 확인하면 된다. 즉, 가독성이 일반 Query문보다 좋다\r\n\r\n<br/>\r\n\r\n## Join\r\n\r\n테이블별로 분리되어 있는 데이터를 연결하여 하나의 결과 데이터 셋으로 출력해야 할 때가 반드시 존재한다. 이럴 때 사용하는 것이 Join이다.\r\n\r\n두 개의 테이블이 있다고 가정.\r\n\r\n컬럼은 1개이고 데이터는 아래와 같다.\r\n\r\n```\r\nA    B\r\n-    -\r\n1    3\r\n2    4\r\n3    5\r\n4    6\r\n```\r\n\r\n<br/>\r\n\r\n### Inner Join\r\n\r\nInner Join을 수행하면 두 집합에 모두 있는 열만 남게 된다.\r\n\r\n```sql\r\nANSI SQL\r\nSELECT * FROM A INNER JOIN B ON A.A = B.B;\r\n\r\nORACLE\r\nSELECT A.*,B* FROM A,B WHERE A.A = B.B;\r\n\r\nA    B\r\n-    -\r\n3    3\r\n4    4\r\n```\r\n\r\n<br/>\r\n\r\n### Left Outer Join\r\n\r\nLeft Outer Join을 하면 A의 모든 열 더하기 B에 있는 공통부분을 얻게 됩니다.\r\n\r\n```sql\r\nANSI SQL\r\nSELECT * FROM A LEFT OUTER JOIN B ON A.A = B.B;\r\n\r\nORACLE \r\nSELECT A.*,B.* FROM A,B WHERE A.A = B.B(+);\r\n\r\nA       B\r\n-       -\r\n1    null\r\n2    null \r\n3       3\r\n4       4\r\n```\r\n\r\n<br/>\r\n\r\n### Right Outer Join\r\n\r\nRight Outer Join을 하면 B의 모든 열 더하기 A에 있는 공통부분을 얻게 된다.\r\n\r\n```sql\r\nANSI SQL\r\nSELECT * FROM A RIGHT OUTER JOIN B ON A.A = B.B;\r\n\r\nORACLE \r\nSELECT A.*,B.* FROM A,B WHERE A.A(+) = B.B;\r\n\r\nA       B\r\n-       -\r\n3       3\r\n4       4 \r\nnull    5\r\nnull    6\r\n```\r\n\r\n<br/>\r\n\r\n### Full Outer Join\r\n\r\nFull Outer Join을 하면 A와 B의 합집합을 얻게 된다.\r\n\r\nB에 있는데 A에 없는 5, 6은 A에서 해당 부분이 null이 되고, A에 있는데 B에 없는 1, 2는 B에서는 해당 부분이 null이 된다.\r\n\r\n```sql\r\nSELECT * FROM A FULL OUTER JOIN B ON A.A = B.B;\r\n\r\nA       B\r\n-       -\r\n1    null\r\n2    null\r\n3       3\r\n4       4 \r\nnull    5\r\nnull    6\r\n```\r\n\r\n<br/>\r\n\r\n### Cross Join\r\nCross Join은 이 포스트를 참고하자.\r\n\r\n\r\n<br/>\r\n\r\n## 참고\r\n\r\n- [https://stanleykou.tistory.com/entry/SQL-INNER-조인과-OUTER조인이-무엇인가요](https://stanleykou.tistory.com/entry/SQL-INNER-%EC%A1%B0%EC%9D%B8%EA%B3%BC-OUTER%EC%A1%B0%EC%9D%B8%EC%9D%B4-%EB%AC%B4%EC%97%87%EC%9D%B8%EA%B0%80%EC%9A%94)","excerpt":"ANSI SQL DBMS(Oracle, MySQL 등등)들에서 각기 다른 SQL을 사용하므로 미국 표준 협회(American National Standards Institute)에서 이를 표준화하여 표준 SQL문을 정립시켜 놓은 것. ANSI SQL…","fields":{"slug":"/join/"},"frontmatter":{"date":"Sep 12, 2021","title":"DB Join 종류 알아보기","tags":["database"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n## Flyway란?\r\n\r\n- Flyway란 DataBase Migration Tool로 DataBase Migration을 손쉽게 해결해주는 도구 중 하나이다.    \r\n  그렇다면 DataBase Migration은 무엇일까?\r\n  \r\n    ### DataBase Migration\r\n\r\n    - 마이그레이션(migration)이란 한 운영환경으로부터 다른 운영환경으로 옮기는 작업을 뜻하며, 하드웨어, 소프트웨어, 네트워크 등 넓은 범위에서 마이그레이션의 개념이 사용되고 있다.\r\n    - 데이터베이스에서 데이터 마이그레이션이란 데이터베이스 스키마의 버전을 관리하기 위한 하나의 방법이다.  \r\n        예를 들어 dev 환경에서 데이터베이스 스키마가 변경되었지만, prod 환경에서 데이터베이스 스키마가 변경되지 않았을 경우 마이그레이션을 수행한다.\r\n    - 데이터베이스 마이그레이션은 개별 sql 파일을 데이터베이스 콘솔에서 직접 실행하지 않고 프레임워크의 특정 명령어를 통해 실행하고 이 결과를 별도의 테이블에 버전 관리를 하는 기법이다.\r\n\r\n    <br/>\r\n\r\n    ![Untitled](https://user-images.githubusercontent.com/62014888/130363401-1cbf726d-2220-43c5-b211-d2a182780696.png)\r\n\r\n- Flyway를 통해 손쉽게 각각의 dev, prod 환경에 동일한 데이터베이스 스키마를 적용시킬 수 있었고 변경 이력 또한 남아 관리하기 편하다는 장점이 있었다.\r\n\r\n<br/>\r\n\r\n## Flyway를 왜 적용시켰는가?\r\n\r\n- 사실 처음부터 Flyway를 찾아보고 적용시킨 것이 아니다.  \r\n  (초반에 스키마가 변경되고 조앤이 코기 블로그 글을 보내줬을 때나 심지어 코기가 flyway 테코톡을 했을 때도 별 생각 없었다..)\r\n- 그러던 중 스프린트가 진행됨에 따라 데이터베이스 스키마가 변경되고 dev, prod 환경에서 ddl-auto가 update로 설정되어 있다보니 DB가 꼬이는 현상이 발생하였다.   \r\n  게다가 4차 데모데이 요구사항 중 하나가 prod 환경에 DB를 drop 하지말라는 것이 있었기에 이참에 flyway를 적용시켜보자 해서 진행하게 되었다.  \r\n  조금 더 빨리 적용시켰으면 dev 환경에 DB 또한 drop 하지 않았을텐데.. 아쉽다..\r\n\r\n<br/>\r\n\r\n## 간단한 사용법\r\n\r\nflyway를 적용시켜보자.  \r\n당시 상황은 이러하다.\r\n1. User라는 테이블에 github_id라는 컬럼의 이름이 social_id로, 타입이 varchar(255)로 바뀌어야한다.  \r\n   social_type이라는 컬럼이 추가되어야 한다.\r\n2. Heart라는 테이블이 추가되어야 한다.\r\n\r\n지금 방법은 이미 DB에 데이터가 있을 때 적용시킨거라 처음부터 적용시킨 것과 조금은 다를 수도 있다는 것에 주의하자.\r\n\r\n1. dependency를 build.gradle에 추가한다. maven은 maven repository를 찾아보자!\r\n\r\n    ```java\r\n    implementation('org.flywaydb:flyway-core:6.4.2')\r\n    ```  \r\n    <br/>\r\n\r\n2. application.yml 또는 application.properties에 다음과 같은 옵션을 추가한다. (yml 기준)\r\n\r\n    ```java\r\n    spring:\r\n        flyway:\r\n    \t    enabled: true // true면 flyway를 활성화시킨다.\r\n    \t    baseline-on-migrate: true \r\n           // default는 false로 true로 설정하면 히스토리 테이블이 없으면 새로 만든다.\r\n    ```\r\n    <br/>\r\n\r\n3. resources 디렉터리 밑에 db/migration 디렉터리를 만들고 적용할 스크립트를 작성해야 한다.   \r\n   V1__init.sql 안에 테이블 스키마를 작성해두면 스크립트가 적용이 되어 테이블이 생성될 것이다.  \r\n   하지만 이미 우리 프로젝트 DB에는 테이블이 만들어져있다.    \r\n   그렇다면 V1__init.sql이 적용이 되는것인가?   \r\n   이미 테이블이 있는 상태에서 스크립트가 적용이 된다면 에러가 발생하지 않을까라는 생각을 했다.  \r\n   결론부터 말하면 baseline-on-migrate: true 설정에 의해서 이미 DB가 존재하고 V1__init.sql을 작성하였다면 V1__init.sql의 설정은 무시하고 기존의 DB 스키마를 baseline으로 잡게 된다.  \r\n   그래서 사실 V1__init.sql의 내용을 비워놔도 무방하지만 스키마가 변경되기 전의 DDL로 작성해도 괜찮을 것 같다고 생각을 하여 작성해놓았다.\r\n\r\n    <br/>\r\n\r\n   ![Untitled](https://user-images.githubusercontent.com/62014888/130363455-6b482405-32d6-4ef3-a95a-15913e259698.png)\r\n\r\n    <br/>\r\n\r\n    ```sql\r\n    CREATE TABLE user(\r\n                         id BIGINT AUTO_INCREMENT PRIMARY KEY,\r\n                         github_id BIGINT NOT NULL,\r\n                         user_name VARCHAR(255) NOT NULL,\r\n                         profile_url VARCHAR(255) NOT NULL,\r\n                         role VARCHAR(255) NOT NULL,\r\n                         created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,\r\n                         updated_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP\r\n    );\r\n\r\n    CREATE TABLE workbook(\r\n                             id BIGINT AUTO_INCREMENT PRIMARY KEY,\r\n                             name VARCHAR(30) NOT NULL,\r\n                             opened TINYINT(1) NOT NULL,\r\n                             deleted TINYINT(1) NOT NULL,\r\n                             user_id BIGINT not null,\r\n                             created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,\r\n                             updated_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,\r\n                             FOREIGN KEY(user_id) REFERENCES user(id) ON UPDATE CASCADE ON DELETE RESTRICT\r\n    );\r\n\r\n    CREATE TABLE card(\r\n                         id BIGINT AUTO_INCREMENT PRIMARY KEY,\r\n                         question BLOB NOT NULL,\r\n                         answer BLOB NOT NULL,\r\n                         encounter_count INT NOT NULL,\r\n                         bookmark TINYINT(1) not null,\r\n                         next_quiz TINYINT(1) not null,\r\n                         workbook_id BIGINT not null,\r\n                         deleted TINYINT(1) not null,\r\n                         created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,\r\n                         updated_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,\r\n                         FOREIGN KEY(workbook_id) REFERENCES workbook(id) ON UPDATE CASCADE ON DELETE RESTRICT\r\n    );\r\n\r\n    CREATE TABLE tag(\r\n                        id BIGINT AUTO_INCREMENT PRIMARY KEY,\r\n                        name VARCHAR(30) UNIQUE NOT NULL,\r\n                        created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,\r\n                        updated_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP\r\n    );\r\n\r\n    CREATE TABLE workbook_tag(\r\n                                 id BIGINT AUTO_INCREMENT PRIMARY KEY,\r\n                                 workbook_id BIGINT not null,\r\n                                 tag_id BIGINT not null,\r\n                                 deleted TINYINT(1) not null,\r\n                                 created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,\r\n                                 updated_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,\r\n                                 FOREIGN KEY(workbook_id) REFERENCES workbook(id) ON UPDATE CASCADE ON DELETE RESTRICT,\r\n                                 FOREIGN KEY(tag_id) REFERENCES tag(id) ON UPDATE CASCADE ON DELETE RESTRICT\r\n    );\r\n    ```\r\n\r\n   <br/>\r\n\r\n4. User 테이블 변경 내용을 V2__change_user_column.sql, Heart 테이블 추가 내용을 V3__add_heart_table.sql 라는 적당한 이름의 파일로 만들어 작성한다.  \r\n   순서대로 적용시키기 위해 숫자를 1씩 증가시켜야 한다.  \r\n   사실 이미 변경이 되었기에 V2를 작성할 때 한꺼번에 DDL을 작성해도 되지만 분리해서 히스토리로 남기기 위해 이렇게 작성하였다.   \r\n   V2, V3를 한꺼번에 만들어도 V2와 V3가 순서대로 적용이 되었다!\r\n\r\n    <br/>\r\n\r\n   ![Untitled](https://user-images.githubusercontent.com/62014888/130363480-ae8782fc-5fdd-4d6d-9b57-478b176a9d7d.png)\r\n\r\n    <br/>\r\n\r\n    ```sql\r\n    alter table user change github_id social_id varchar(255) not null;\r\n    alter table user add column bio varchar(255) not null default '';\r\n    alter table user add column social_type varchar(255);\r\n    ```\r\n\r\n    ```sql\r\n    CREATE TABLE heart(\r\n                          id BIGINT AUTO_INCREMENT PRIMARY KEY,\r\n                          workbook_id BIGINT not null,\r\n                          user_id BIGINT not null,\r\n                          created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,\r\n                          updated_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,\r\n                          FOREIGN KEY(workbook_id) REFERENCES workbook(id) ON UPDATE CASCADE ON DELETE RESTRICT\r\n    );\r\n    ```\r\n   <br/>\r\n\r\n5. 결과적으로 기존의 prod 환경의 DB 데이터는 유지한 채로 User 테이블의 기존 컬럼명 및 타입을 수정, 새로운 컬럼을 추가할 수 있었다!\r\n6. 이 후에 스키마가 변경이 되면 V4부터 스크립트를 작성해서 추가하면 된다.\r\n\r\n<br/>\r\n\r\n## 주의할 점\r\n\r\n적용하면서 애먹었던 부분을 공유한다.\r\n\r\n1. local 환경에서 H2 DB를 사용하게 되는 경우가 많을텐데 mariadb의 쿼리문을 이용한 스크립트와 같은 스크립트를 적용하다 syntax 에러가 많이 발생하였다. 이를 주의하도록 하자.  \r\n   혹시나 DB마다 다른 스크립트를 적용하려면 flyway에서 벤더사마다 다른 스크립트를 적용하는 방법도 존재하니 그걸 찾아보도록 하자!  \r\n   우리는 팀원들끼리 이야기한 결과 굳이 local에선 flyway를 사용할 필요가 있을까하여 flyway.enabled를 false로 설정하여 사용했다.\r\n\r\n2. 최신 버전의 flyway를 적용하면서 mariadb를 사용한다면 꼭 10.2 버전 이상의 mariadb를 사용하자.   \r\n   10.1 버전의 mariadb를 사용하다 이런 에러를 맞이하게 되어 기존 mariadb를 10.4로 upgrade하는 상황이 발생하게 되었다.   \r\n   조앤이 upgrade 하는 방법을 금방 찾아서 다행이었지만 생각보다 할게 많아 까다로웠다..  \r\n   아니면 에러에 적힌대로 flyway pro edition을 사용하면 괜찮을지도..?\r\n\r\n    <br/>\r\n\r\n   ![Untitled](https://user-images.githubusercontent.com/62014888/130363889-def26e90-88e8-48cd-b7a8-ef2717193fab.png)","excerpt":"Flyway란? Flyway란 DataBase Migration Tool로 DataBase Migration을 손쉽게 해결해주는 도구 중 하나이다. 그렇다면 DataBase Migration은 무엇일까? DataBase Migration 마이그레이션…","fields":{"slug":"/flyway/"},"frontmatter":{"date":"Aug 25, 2021","title":"프로젝트에 Flyway 도입기","tags":["flyway","database"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n## @Profile, @ActiveProfiles\r\n\r\n- 이 두 애노테이션을 알아보기 전에 Profile이란 무엇인지에 대해 알아보자.\r\n- 미니 프로젝트가 아닌 대부분의 기업용 서비스는 보통 개발(dev), 테스트(test), 운영(prod) 등으로 구동 환경을 세분화하여 서비스를 관리한다. 이런 식별 키워드를 Profile이라고 부른다. Profile을 지정함으로써 DB 접속 계정 및 옵션, 리소스, 로그 관리 정책 등을 Profile 단위로 구분하여 효과적으로 관리할 수 있다.\r\n- 보통 yml이나 properties 파일로 환경을 구분하여 사용하는데 스프링에서는 @Profile 또는 @ActiveProfiles와 같은 애노테이션도 제공해준다.\r\n\r\n<br/>\r\n\r\n### @Profile\r\n- @Profile을 사용하고 그 안에 환경을 명시해주게 되면 해당 환경에서 이 애노테이션이 붙은 설정이나 빈을 등록하여 사용할 수 있게 된다.\r\n\r\n![Untitled (53)](https://user-images.githubusercontent.com/62014888/145994809-b547deb7-6b30-4e1f-88c6-4d849d5e0502.png)\r\n\r\n- 위와 같이 명시하면 test 환경에서 해당 빈을 등록하여 사용하겠다는 뜻이고 만약 test 환경에서만 사용하기 싫다고 하면 !test를 명시하면 된다.\r\n\r\n<br/>\r\n\r\n\r\n### @ActiveProfiles\r\n- @ActiveProfiles는 테스트할 때 유용힌 애노테이션으로 테스트에서 Profile을 지정할 수 있는데 그 때 사용하는 애노테이션이다.\r\n\r\n![Untitled (54)](https://user-images.githubusercontent.com/62014888/145994816-cb947c00-1658-4c45-ba84-d61c537f7254.png)\r\n\r\n- 이렇게 명시하여 test 환경으로 테스트를 실행시킬 수 있도록 하였다.\r\n\r\n<br/>\r\n\r\n\r\n## 참고\r\n- [http://wonwoo.ml/index.php/post/1933](http://wonwoo.ml/index.php/post/1933)\r\n- [https://jsonobject.tistory.com/220](https://jsonobject.tistory.com/220)","excerpt":"@Profile, @ActiveProfiles 이 두 애노테이션을 알아보기 전에 Profile이란 무엇인지에 대해 알아보자. 미니 프로젝트가 아닌 대부분의 기업용 서비스는 보통 개발(dev), 테스트(test), 운영(prod) 등으로 구동 환경을 …","fields":{"slug":"/profile-activeprofiles/"},"frontmatter":{"date":"Aug 24, 2021","title":"@Profile, @ActiveProfiles 란?","tags":["spring"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n## RestAssured Test\r\n\r\n- RestAssured는 REST 웹 서비스를 검증하기 위한 라이브러리.\r\n- 대부분 End-to-End or 인수 테스트에서 사용된다.\r\n- @SpringBootTest를 통해 애플리케이션에 등록될 빈을 모두 가져와 실제 요청을 보내서 전체적인 로직을 테스트한다. 실제 요청 시 필요한 다양한 메서드도 존재.\r\n\r\n```java\r\ntestImplementation 'io.rest-assured:rest-assured:3.3.0'\r\n```\r\n\r\n- RestAssured의 경우 직접 의존성을 추가해주어야 한다. gradle을 사용한다면 dependencies에 위의 내용을 추가하면 된다.\r\n- 의존성을 추가한다는 것은 프로젝트가 점점 무거워진다는 뜻이므로 RestAssured를 사용하는 순간이 온다면 왜 사용하는지에 대해 고민할 필요가 있다.\r\n\r\n![Untitled (49)](https://user-images.githubusercontent.com/62014888/145994041-5dcde623-477f-490f-bcfc-52484b84e5e6.png)\r\n\r\n- RestAssured의 경우 별도의 구성없이 @WebMvcTest를 사용할 수 없다. 즉, 컨트롤러에 대한 단위테스트를 하기 위해서는 spring-mock-mvc 모듈에 있는 RestAssuredMockMvc를 사용해야한다. (따로 의존성을 추가해야함)\r\n- 그래서 @SpringBootTest로 수행해야한다. 다만 이걸로 수행하면 등록된 Spring Bean을 전부 로드하기 때문에 시간이 오래걸린다.\r\n\r\n![Untitled (50)](https://user-images.githubusercontent.com/62014888/145994045-8bb45ed4-3733-49c0-b2c3-369561823aaa.png)\r\n\r\n- RestAssured는 BDD 스타일로 작성할 수 있어서 가독성이 좋다.\r\n- BDD(Behavior Driven Development)는 TDD를 근간으로 파생된 개발 방법이다.\r\n- 테스트 메서드 이름을 \"이 클래스가 어떤 행위를 해야한다(should do something)\"라는 식의 문장으로 작성하여 행위에 대한 테스트에 집중할 수 있다.\r\n- 즉, 시나리오를 기반으로 테스트 케이스 작성이 가능함. 비개발자가 봐도 이해할 수 있을 정도의 레벨을 권장하며 Given, When, Then 구조를 가지는 것을 기본 패턴으로 권장한다.\r\n- 또한 RestAssured을 사용할 경우 json data를 더 쉽고 편하게 검증할 수 있다.\r\n\r\n<br/>\r\n\r\n## MockMvc Test\r\n\r\n- MockMvc는 웹 애플리케이션을 애플리케이션 서버에 배포하지 않고도 스프링 MVC의 동작을 재현할 수 있는 라이브러리이며 대부분 Controller Layer Unit Test에 사용된다.\r\n- @WebMvcTest를 통해 Presentation Layer Bean들만 불러온다. 그리고 그 외 Bean은 Mock 객체 설정을 해주어 순수한 Controller 로직을 테스트한다.\r\n- MockMvc는 Spring Framework Test 클래스 중 하나다. 즉 Spring test 의존성이 추가되어 있는 경우 별도의 의존성 추가를 하지 않아도 사용할 수 있다.\r\n\r\n![Untitled (51)](https://user-images.githubusercontent.com/62014888/145994048-aef3c277-7b4c-406b-a6bc-d3176bbde926.png)\r\n\r\n- @WebMvcTest는 Presentation Layer의 Bean들만 로드하기 때문에 시간이 상대적으로 빠르다. (@Controller, @ControllerAdvice, @JsonComponent, Converter, GenericConverter, Filter, HandlerInterceptor, WebMvcConfigurer, HandlerMethodArgumentResolver 이거만 스캔하도록 제한)\r\n- controllers로 명시해둔건 MemberController만 가져온다는 뜻이다.\r\n\r\n![Untitled (52)](https://user-images.githubusercontent.com/62014888/145994054-137de9dd-044a-4329-abf8-8c1e10ca5e3a.png)\r\n\r\n- BDD 스타일로 작성한 RestAssured에 비해 쉽게 읽히지는 않는다.\r\n- 또한 RestAssured에 비해 json data 검증도 조금 힘들다.\r\n\r\n<br/>\r\n\r\n## 참고\r\n\r\n- [https://dundung.tistory.com/229](https://dundung.tistory.com/229)\r\n- [https://beomseok95.tistory.com/293](https://beomseok95.tistory.com/293)\r\n- [https://stackoverflow.com/questions/52051570/whats-the-difference-between-mockmvc-restassured-and-testresttemplate](https://stackoverflow.com/questions/52051570/whats-the-difference-between-mockmvc-restassured-and-testresttemplate)\r\n- [https://woowacourse.github.io/javable/post/2020-09-29-compare-mockito-bddmockito/](https://woowacourse.github.io/javable/post/2020-09-29-compare-mockito-bddmockito/)\r\n- [https://cobbybb.tistory.com/16](https://cobbybb.tistory.com/16)\r\n- [https://docs.spring.io/spring-boot/docs/current/api/org/springframework/boot/test/autoconfigure/web/servlet/WebMvcTest.html](https://docs.spring.io/spring-boot/docs/current/api/org/springframework/boot/test/autoconfigure/web/servlet/WebMvcTest.html)","excerpt":"RestAssured Test RestAssured는 REST 웹 서비스를 검증하기 위한 라이브러리. 대부분 End-to-End or 인수 테스트에서 사용된다. @SpringBootTest를 통해 애플리케이션에 등록될 빈을 모두 가져와 실제 요청을 …","fields":{"slug":"/restassured-vs-mockmvc/"},"frontmatter":{"date":"Jun 18, 2021","title":"RestAssured Test vs MockMvc Test","tags":["spring","test"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n## @SpringBootApplication\r\n\r\n- 우테코에서 미션을 하며 스프링 부트를 이용해서 웹 애플리케이션을 만들어보았다.\r\n- 스프링은 간단하게 이야기하면 스프링 빈 컨테이너를 만들어 빈 등록을 하고 필요한 객체에게 의존성 주입을 하는 방식으로 애플리케이션이 실행이 된다.\r\n- 근데 미션을 진행하는 동안 컨트롤러 위에 @Controller, 서비스 위에 @Service, DAO 위에 @Repository와 같은 애노테이션만 명시해주었을 뿐이고 따로 컨테이너를 생성하는 작업을 해 준 적이 없는데 어떻게 main 메서드만 실행하면 모든 작업이 이루어지는 것일까?\r\n- 그럼 차근차근 알아보도록 하자.\r\n\r\n![Untitled (41)](https://user-images.githubusercontent.com/62014888/145945185-711ac646-32f0-4a0b-ad9c-10bc7dc40bcf.png)\r\n\r\n![Untitled (42)](https://user-images.githubusercontent.com/62014888/145945190-c9d881b3-c304-4bb7-a708-504c669fe9ad.png)\r\n\r\n- 일단 결론부터 이야기하자면 스프링 부트를 이용해 처음 프로젝트를 만들때 생기는 main 메서드의 run 메서드에 의해 컨테이너가 생기고 설정을 한다.\r\n- 그렇다면 여기서 궁금한 점이 생겼다.\r\n- 바로 위에 있는 @SpringBootApplication은 어떤 기능을 담당하고 있을까?\r\n\r\n![Untitled (43)](https://user-images.githubusercontent.com/62014888/145945309-9f7f21e2-2391-422b-98f2-e7725ce305a3.png)\r\n\r\n- @SpringBootApplication의 위에 있는 많은 애노테이션이 있다.\r\n- 하나하나 살펴보자면\r\n    - @Target - 애노테이션이 적용할 위치를 결정한다. ElementType.Type는 타입 선언시 적용한다는 뜻이다.\r\n    - @Retention - 애노테이션의 범위라고 할 수 있는데 어떤 시점까지 애노테이션이 영향을 미치는지 결정한다. RetetionPolicy.RUNTIME의 경우 컴파일 이후에도 JVM에 의해서 참조가 가능하다는 뜻이다.\r\n    - @Documented - 문서에도 애노테이션의 정보가 표현된다.\r\n    - @Inherited - 이 애노테이션을 선언하면 자식 클래스가 애노테이션을 상속 받을 수 있다.\r\n    - @SpringBootConfiguration - 스프링 부트의 설정을 나타내는 애노테이션이다. 스프링의 @Configuration을 대체하며 스프링 부트 전용 애노테이션이다. 테스트 애노테이션을 사용할 때 계속 이 애노테이션을 찾기 때문에 스프링 부트에서는 필수 애노테이션이다.\r\n    - @EnableAutoConfiguration - 자동 설정의 핵심 애노테이션이다. 클래스 경로에 지정된 내용을 기반으로 설정 자동화를 수행한다.\r\n    - @ComponentScan - 해당 패키지에서 @Component 애노테이션을 가진 Bean들을 스캔해서 등록한다. (@Configuration, @Repository, @Service, @Controller, @RestController 이 애노테이션들도 다 까보면 @Component가 존재함)\r\n\r\n  이러하다.\r\n\r\n<br/>\r\n\r\n## @ComponentScan, @EnableAutoConfiguration\r\n\r\n- 다른 애노테이션보다 설정 관련 중요한 애노테이션은 @SpringBootConfiguration, @ComponentScan, @EnableAutoConfiguration이다.\r\n- @SpringBootConfiguration은 위에 적힌 대로 스프링의 @Configuration을 대체하는 기능을 하므로 넘어가고 나머지 두 애노테이션을 살펴보도록 하자.\r\n- 빈 등록할 때 순서가 존재한다.\r\n  처음에 @ComponentScan으로 등록하고 그 후 @EnableAutoConfiguration으로 추가적인 Bean을 읽어 등록한다.\r\n\r\n  1단계: @ComponentScan\r\n\r\n  2단계: @EnableAutoConfiguration\r\n\r\n  인 셈이다.\r\n\r\n- 우선 @ComponentScan이 지정된 클래스의 패키지 밑으로 component scan을 진행한다. @Componet 계열 애노테이션 (@Configuration, @Repository, @Service, @Controller, @RestController)과 @Bean 애노테이션이 붙은 method return 객체를 모두 bean으로 등록한다.\r\n- 다음으로 @EnableAutoConfiguration에 의해서 spring.factories 라는 파일 안에 들어있는 많은 설정들을 읽어 bean이 생성되고 스프링 부트 애플리케이션이 실행되는 것이다.\r\n\r\n![Untitled (44)](https://user-images.githubusercontent.com/62014888/145945318-451a5ae7-f2aa-466b-8cf5-5b43c0abdec2.png)\r\n\r\n- @EnableAutoConfiguration의 경우 AutoConfigurationImportSelector를 import하고 있는데 이를 통해 spring.factories에 있는 bean들을 선택하고 등록시킬 수 있다.\r\n\r\n![Untitled (45)](https://user-images.githubusercontent.com/62014888/145945323-3f9664c3-7266-4d06-a873-81d341ac4ce5.png)\r\n\r\n- 그렇다면 spring.factories는 이렇게 되어있는데 여기 있는 모든 bean이 자동 등록될까?\r\n- 그건 아니다.\r\n  ConfigurationClassParser 클래스의 processConfigurationClass() 메서드의 shouldSkip 과정에서 Conditional 애노테이션을 찾아 조건에 부합하는지 확인하고 해당 조건을 충족하는 경우에만 등록을 진행한다고 한다.\r\n- 그리고 우리는 application.properties나 application.yml 파일을 이용해 설정을 하는 경우도 있다. 이때 설정을 하게 되면 spring-configuration-metadata.json 이라는 자동 설정에 사용할 프로퍼티 정의 파일에 작성한 값으로 프로퍼티를 세팅한 후 구현되어 있는 자동 설정에 값을 주입시켜준다.\r\n\r\n```java\r\nCaused by: org.springframework.context.ApplicationContextException: Unable to start ServletWebServerApplicationContext due to missing ServletWebServerFactory bean.\r\n```\r\n\r\n![Untitled (46)](https://user-images.githubusercontent.com/62014888/145945327-39d2fef0-c548-4211-882d-c8e2c0c40b21.png)\r\n\r\n- 참고로 @EnableAutoConfiguration이 있어야 컨테이너에 ServletWebServerFactory bean이 등록이 되어 Web application으로 만들어준다.\r\n- 그래서 @EnableAutoConfiguration이 없다면 위와 같은 오류가 발생하는데 밑과 같이 WebApplicationType.NONE으로 셋팅해주면 정상적으로 실행은 된다.\r\n\r\n<br/>\r\n\r\n## 마무리\r\n\r\n- 스프링 부트의 경우 애노테이션을 통해 자동으로 필요한 빈들을 등록시켜준다는 것을 알게 되었다.\r\n- 이러한 점을 인식하고 사용을 해야 자동 등록 기능을 끄고 수동으로 빈을 등록시켜줘야 할 때 어떤 빈들을 등록을 시켜줘야할지 빠르게 파악할 수 있을 것이다.\r\n    - 대표적인 예로 Repilcation을 하기 위해 직접 Datasource를 설정해줄 때 jpa와 관련해서 어떤 빈을 등록시켜줘야 하는지와 같은 예가 있다.\r\n\r\n<br/>\r\n\r\n## 참고\r\n\r\n- [https://camel-it.tistory.com/26](https://camel-it.tistory.com/26)\r\n- [https://duooo-story.tistory.com/52?category=882088](https://duooo-story.tistory.com/52?category=882088)\r\n- [https://rlawls1991.tistory.com/entry/스프링-부트-원리-자동설정-이해](https://rlawls1991.tistory.com/entry/%EC%8A%A4%ED%94%84%EB%A7%81-%EB%B6%80%ED%8A%B8-%EC%9B%90%EB%A6%AC-%EC%9E%90%EB%8F%99%EC%84%A4%EC%A0%95-%EC%9D%B4%ED%95%B4)\r\n- [https://velog.io/@adam2/SpringBoot-자동-환경-설정AutoConfiguration](https://velog.io/@adam2/SpringBoot-%EC%9E%90%EB%8F%99-%ED%99%98%EA%B2%BD-%EC%84%A4%EC%A0%95AutoConfiguration)\r\n- [https://jdm.kr/blog/216](https://jdm.kr/blog/216)\r\n- [https://www.youtube.com/watch?v=Y11h-NUmNXI](https://www.youtube.com/watch?v=Y11h-NUmNXI)","excerpt":"@SpringBootApplication 우테코에서 미션을 하며 스프링 부트를 이용해서 웹 애플리케이션을 만들어보았다. 스프링은 간단하게 이야기하면 스프링 빈 컨테이너를 만들어 빈 등록을 하고 필요한 객체에게 의존성 주입을 하는 방식으로 애플리케이션…","fields":{"slug":"/springboot-application/"},"frontmatter":{"date":"Jun 15, 2021","title":"@SpringBootApplication 파헤치기","tags":["spring"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n## POJO (Plain Old Java Object)\r\n\r\nPOJO는 Plain Old Java Object의 준말로 말 그대로 오래된 방식의 간단한 자바 오브젝트라는 뜻이다.  \r\nJava EE 등의 중량 프레임워크들을 사용하게 되면서 해당 프레임워크에 종속된 \"무거운\" 객체를 만들게 된 것에 반발해서 사용하게 된 용어로서 2000년 9월 마틴 파울러, 레베카 파슨, 조쉬 맥킨지 등이 처음 사용하기 시작했다.  \r\n과거 EJB, Strust같은 프레임워크는 비즈니스 로직을 구현하기 위한 클래스를 코딩할 때 프레임워크의 특정 인터페이스 등의 상속을 강요하였고, 그 결과 비즈니스 로직을 코딩해야할 시간에 상속을 구현하기 위한 관용적인 코딩 작업을 불필요하게 해야 했었다.  \r\n객체지향의 가장 중요한 개념 중 하나인 느슨한 의존관계를 역행하는 이런 침투적인 프레임워크의 문제점을 강조하기 위해 이 말을 처음 사용하기 시작하였다.  \r\n이 후 POJO는 주로 특정 자바 모델이나 기능, 프레임워크 등을 따르지 않은 자바 오브젝트를 지칭하는 말로 사용되었다. 스프링 프레임워크는 POJO 방식의 프레임워크라고 한다.\r\n\r\n<br/>\r\n\r\n## Java Beans\r\n\r\nJava Beans는 데이터를 표현하기 위한 Java 클래스를 만들 때의 규약이다.  \r\n아래의 규칙을 지킨 Java 클래스는 Java Beans라고 부른다.  \r\n- 모든 클래스의 프로퍼티는 private이며 getter, setter 메서드로 제어한다.\r\n- 인자가 없는 public 생성자가 있어야 한다.\r\n- Serializable 인터페이스를 구현해야 한다.  \r\n\r\nJava Beans 규약은 Java EE 프레임워크에서 데이터를 저장할 Java 클래스를 만들 때 제안하는 일종의 규약이다.\r\n\r\n<br/>\r\n\r\n## POJO == Java Beans?\r\n\r\nNO!  \r\nJava Beans는 POJO이다.  \r\n그러나 POJO는 Java Beans가 아니다.  \r\nPOJO가 Java Beans보다 더 넓은 개념이다.\r\n\r\n<br/>\r\n\r\n## Spring에서 사용하는 Bean은?\r\n\r\n스프링 빈이란 자바 객체를 뜻한다.  \r\n스프링 컨테이너에서 자바 객체가 만들어 지게 되면 이 객체를 스프링 빈이라고 부르는 것이다.  \r\n스프링 빈과 자바 일반 객체와의 차이점은 없다. 다만 스프링 컨테이너에서 만들어지는 객체를 스프링 빈이라고 부를 뿐이다.  \r\n스프링 빈은 설정 메타데이터(xml, 애노테이션)에 의해 생성이 된다.\r\n\r\n<br/>\r\n\r\n## 아무 객체나 Bean 등록을 해도 될까?\r\n\r\nNO!  \r\n스프링 빈은 근본적으로 쓰레드 세이프하지 않다.  \r\n왜?  \r\n일단 그렇게 만들어져있지도 않을 뿐더러 빈 등록을 한다는 것은 싱글톤으로 관리를 한다는 뜻이다.  \r\n객체 인스턴스를 하나만 생성해서 공유하는  싱글톤 방식은 여러 클라이언트가 하나의 같은 객체 인스턴스를 공유하기 때문에 싱글톤 객체는 상태를 유지(stateful)하게 설계하면 안된다.  \r\n즉, 무상태(stateless)로 설계해야 한다.\r\n- 특정 클라이언트에 의존적인 필드가 있으면 안된다.\r\n- 특정 클라이언트가 값은 변경할 수 있는 필드가 있으면 안된다.\r\n- 가급적 읽기만 가능해야 한다.\r\n- 필드 대신에 자바에서 공유되지 않는 지역변수, 파라미터, ThreadLocal 등을 사용해야 한다.\r\n\r\n스프링 필드에 공유 값을 설정하면 정말 큰 장애가 발생할 수 있다.\r\n\r\n<br/>\r\n\r\n## 참고\r\n\r\n- [https://www.hanumoka.net/2019/01/06/java-20190106-java-pojo-vs-bean/](https://www.hanumoka.net/2019/01/06/java-20190106-java-pojo-vs-bean/)\r\n- [https://ko.wikipedia.org/wiki/Plain_Old_Java_Object](https://ko.wikipedia.org/wiki/Plain_Old_Java_Object)\r\n- [https://docs.spring.io/spring-framework/docs/current/reference/html/core.html#beans-introduction](https://docs.spring.io/spring-framework/docs/current/reference/html/core.html#beans-introduction)\r\n- [https://endorphin0710.tistory.com/93](https://endorphin0710.tistory.com/93)\r\n- 김영한님 스프링 core 수업","excerpt":"POJO (Plain Old Java Object) POJO는 Plain Old Java Object의 준말로 말 그대로 오래된 방식의 간단한 자바 오브젝트라는 뜻이다. Java EE 등의 중량 프레임워크들을 사용하게 되면서 해당 프레임워크에 종속된…","fields":{"slug":"/pojo-vs-java-beans/"},"frontmatter":{"date":"Jun 13, 2021","title":"POJO vs Java Beans","tags":["java","spring"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\r\n## Validation이란?\r\n\r\n- Validation이란 유효성 검증을 의미한다.\r\n- 대표적인 예로 String의 값이 null이 되면 안된다던가 Integer의 값이 0보다 커야한다던가 즉, 우테코에서 미션을 진행해오면서 보통 도메인에서 처리했었던 검증을 말한다.\r\n- 그렇다면 왜 Validation이라는 기능이 나오게 되었을까?\r\n- 이 [hibernate validator docs](https://docs.jboss.org/hibernate/validator/5.4/reference/en-US/html_single/#preface) 를 참고하자면\r\n\r\n  > 데이터 검증은 애플리케이션의 여러 계층에 전반에 걸쳐 발생하는 흔한 작업이다. 종종 동일한 데이터 검증 로직이 각 계층에 구현되는데 이는 오류를 일으키기 쉽고 시간을 낭비하는 일이다. 이에 개발자는 이러한 중복을 피하기 위해 유효성 검사를 도메인 모델에 직접 번들로 묶어 실제 클레스 자체에 대한 메타 데이터 (데이터를 위한 데이터) 인 유효성 검사 코드로 복잡하게 만든다.\r\n  >\r\n\r\n  라고 적혀있다. 즉, 도메인 모델에 유효성 검증 코드가 추가되어 복잡해지다 보니 이를 없애주기 위해 Validation이 나오게 되었다고 할 수 있다.\r\n\r\n\r\n![Untitled (29)](https://user-images.githubusercontent.com/62014888/145755472-54f036d2-a3a2-4ebf-a349-61266c6d2cb0.png)\r\n\r\n![Untitled (30)](https://user-images.githubusercontent.com/62014888/145755474-12a7bec5-370c-4c0e-bdbd-453da2ad765f.png)\r\n\r\n<br/>\r\n\r\n## Validation 파헤치기\r\n\r\n- 자, 그럼 Validation을 사용해보자.\r\n- gradle dependencies에 (maven은 검색으로 해결..ㅎㅎ)\r\n\r\n```java\r\nimplementation 'org.springframework.boot:spring-boot-starter-validation'\r\n```\r\n\r\n이거 하나만 추가하면 validation을 사용할 수 있다.\r\n참고로 spring boot 2.3.0 버전부터 spring-boot-starter-web에 validation이 포함되어 있지 않아 의존성을 따로 추가해주는 것이다.\r\n\r\n- 그런데 의문이 들었다.\r\n\r\n    ![Untitled (31)](https://user-images.githubusercontent.com/62014888/145755502-7613d8b7-d8a3-493e-af70-99134d0cf814.png)\r\n\r\n    분명 spring-boot-starter-validation이라고 적혀있는 것을 추가했는데 왜 import 해오는 것은 javax의 validation인 걸까?\r\n\r\n    spring과 관련이 없는 다른 것을 들고 오는걸까?\r\n\r\n    그래서 이를 까보기로 했다.\r\n\r\n    ![Untitled (32)](https://user-images.githubusercontent.com/62014888/145755503-a11e5b0e-403e-4f29-baf5-bdb5dc5b6b7c.png)\r\n\r\n    보니까 hibernate validator가 있는 것이 보인다.\r\n\r\n    이게 아마 validation과 관련이 있는 거라고 생각이 들었다.\r\n\r\n    그리고 다시 hibernate validator를 찾아보았다.\r\n\r\n    > This transitively pulls in the dependency to the Bean Validation API (javax.validation:validation-api:1.1.0.Final).\r\n    >\r\n\r\n    위는 공식문서에 적혀있는 내용인데 hibernate validator를 의존성으로 추가하면 Bean Validation API (javax validation)을 전이적으로 가져오게 된다고 적혀있다.\r\n\r\n    그렇다면 결국 spring-boot-starter-validation이라는 의존성을 추가하게 되면\r\n    hibernate validator와 bean validation이 추가가 된다는 것이다!\r\n\r\n<br/>\r\n\r\n## Bean Validation, Hibernate Validator\r\n\r\n- 여기서 또 의문이 발생할 것이다.\r\n- 그럼 hibernate validator와 bean validation이 도대체 뭘까?\r\n- 우선 bean validation에 대해 먼저 말해보겠다.\r\n\r\n  ![Untitled (33)](https://user-images.githubusercontent.com/62014888/145755544-c3c1be3b-d331-4c01-aeee-99aa46dfed29.png)\r\n\r\n  참고로 추가된 라이브러리를 보게되면 jakarta validation이라고 적혀있지만 안에 패키지를 보면 javax라고 되어 있는 것을 알 수 있는데 jakarta는 자바 플랫폼, 자바 EE 등 확장 사양의 집합이다. 그래서 그냥 java라고 생각하면 될 것 같다.\r\n  즉, java에서 만든 bean validation인 것이다.\r\n\r\n- bean validation은 Java Bean 유효성 검증을 위한 메타데이터 모델과 api에 대한 정의라고 한다.\r\n  무슨 뜻인지 감이 잘 잡히지 않는다. 하나 하나 살펴보도록 하자.\r\n- 메타데이터는 데이터에 대한 데이터, 즉 어떤 목적을 가지고 만들어진 데이터를 뜻한다.\r\n- 우리가 데이터를 각 계층으로 전달할 때 Java Bean 형태로 보내게 되는데 이 때 데이터 유효성 검증을 위해 사용하게 되는 것이 이 메타데이터를 말하는 것이다. 그렇다면 Java에서 메타데이터를 표현할 수 있는 대표적인 방법은? 바로 애노테이션이다.\r\n- 정리하자면 이렇다.\r\n  Bean Validation은 애노테이션을 이용하여 메타데이터를 정의하고 이를 통해 Java Bean의 유효성을 검증하는 것에 대한 명세인 것이다.\r\n  즉, Bean Validation은 명세일 뿐 동작하는 코드가 아니다. 실제로 라이브러리를 열어보면 인터페이스, 애노테이션 등만 포함되면 구현 코드는 없다.\r\n  그렇다면 이를 동작하도록 만드는 구현 코드가 필요하다.\r\n- 그게 바로 hibernate validator인 것이다!\r\n  hibernate validator는 참조 구현이며 현재 JSR-380의 유일한 인증 구현이라고 한다.\r\n  참고로 지금까지 명세서(Specification)은 발전해서 2.0까지 나왔고 Bean Validation 2.0을 JSR 380이라고 부른다.\r\n  여기서 hibernate를 우리가 ORM으로 알고 있는 hibernate와 헷갈려 하지말자 (아 물론 같은 회사다)\r\n\r\n<br/>\r\n\r\n## Validation 예외처리\r\n\r\n- 계속해서 Validation을 보다보니 궁금해졌다.\r\n- 우리가 직접 Validation Annotation과 validator를 만들어 사용하거나 또는 기존에 있던 annotation의 validator를 사용해 검증을 할 것인데 이 때 어디서 validate를 할까?\r\n- validation을 사용하는 법은 다들 알 것이다.\r\n- validation을 원하는 DTO(Java Bean)의 필드 or 클래스에 @NotNull, @Positive 등의 annotation을 명시 해주고 이 DTO를 바인딩 해주는 컨트롤러의 메서드 인자 앞에 @Valid라는 annotation을 걸어주기만 하면 된다.\r\n- 어떨까? 뭔가 DTO를 바인딩 해줄 때 validate를 해줄 것 같지 않은가?\r\n  결론부터 이야기하자면 맞다. DTO를 바인딩할 때 validate를 해준다.\r\n- 그렇다면 DTO를 바인딩해주는 녀석들부터 이야기해보자.\r\n- 이번에 찾아보면서 알게된게 @RequestParam, @PathVariable, @RequestBody, @ModelAttribute 등의 컨트롤러에서 인자를 바인딩해줄 때 사용하는 애들은 전부 HandlerMethodArgumentResolver을 상속받은 클래스에서 처리를 해준다는 것이다.\r\n    - 즉, 리졸버를 사용해서 컨트롤러 메서드의 인자를 바인딩 해주는 것이다!\r\n- 그렇다면 DTO를 바인딩해주는 annotation은?\r\n  @ModelAttribute와 @RequestBody가 있다.\r\n1. @ModelAttribute는 Form data를 바인딩해줄 때 사용하는 것으로 ModelAttributeProcessor에서 이를 바인딩해주고 validate도 해준다.\r\n    - 이 때 예외는 BindException으로 처리를 해준다.\r\n2. 다음으로 @RequestBody인데 주로 json을 바인딩 하다보니 이번에 Rest api를 구현하며 많이 사용을 하였기에 이녀석을 조금 더 자세히 살펴보도록 하자.\r\n    - @RequestBody는 RequestResponseBodyMethodProcessor에서 바인딩을 해주고 validate를 해주는데 이곳에서 WebDataBinder를 만들고 validateIfApplicable 이라는 메서드를 이용해 validate를 해준다.\r\n\r\n  ![Untitled (34)](https://user-images.githubusercontent.com/62014888/145755588-c8dff529-21ab-4474-8df6-ab640c28a76f.png)\r\n\r\n validateIfApplicable을 보면 이런 모습.\r\n 참고로 validateIfApplicable 구현 메서드는 AbstractMessageConverterMethodArgumentResolver에 있다. 이를 상속하는 것이 RequestResponseBodyMethodProcessor다.\r\n\r\n\r\n![Untitled (35)](https://user-images.githubusercontent.com/62014888/145755591-8bb7059e-7bae-4eac-b9e6-d441459dc616.png)\r\n\r\n다음으로 binder.validate(validationHints);를 살펴보면 이렇다.\r\n\r\n\r\n\r\n![Untitled (36)](https://user-images.githubusercontent.com/62014888/145755594-04f1b754-6e0b-48e4-be56-87a742674ba7.png)\r\n\r\nDataBinder 내부를 보면 validator를 가지고 있고 이 validator의 validate를 실행해주는 모습을 볼 수 있다. 그 후 validate를 더 파고 들어가보았는데 실제로는 SmartValidator, javax.validation.Validator를 구현하고 있는 SpringValidatorAdapter라는 곳의 validate 였다.\r\n\r\n이 메서드 안에 있는 processConstraintViolations라는 메서드의 인자를 보면 우리가 만든 validator 또는 기존 validator를 이용해 validate를 해주는 모습이 보인다.\r\n\r\n그리고 그 밑에 processConstraintViolations의 인자를 보니 Set<ConstratintViolation<Object>> violations라고 적혀있다.\r\n\r\n즉, validator를 이용해 validate를 하고 난 결과, violation(위반)이 있을 때 이를 BindingResult에 추가한다.\r\n\r\n![Untitled (37)](https://user-images.githubusercontent.com/62014888/145755660-330102a9-62e1-46c6-b971-4950a3123dfe.png)\r\n\r\n![Untitled (38)](https://user-images.githubusercontent.com/62014888/145755667-74bfd7fd-7a86-4634-88fa-010b2e4b15c1.png)\r\n\r\n그래서 결국 validation이 모두 진행된 BindingResult가 생길 것이고 이를 다시 한번 MethodArgumentNotValidException으로 감싸서 던져주는 것이다.\r\n\r\n참고로 저 this.targetValidator.validate를 끝까지 가본 결과 a single constraint annotation의 경우 ConstraintTree 라는 클래스에서 validator의 isValid라는 메서드를 사용하고 있었다.\r\n\r\n![Untitled (39)](https://user-images.githubusercontent.com/62014888/145755671-99d99b4f-ef51-4081-9f77-8c3626c70ca5.png)\r\n\r\n그리고 이 validateSingleConstraint라는 메서드를 사용하는 곳이 이를 상속하고 있는 SimpleConstraintTree라는 클래스인데 이곳에서 isPresent()를 통해 검증에서 실패했을 경우 위반과 관련된 내용이 담긴 violatedConstraintValidatorContexts에 추가가 되는 것 같다.\r\n\r\n![Untitled (40)](https://user-images.githubusercontent.com/62014888/145755674-c4f0cc60-7a91-4740-99f6-5299169036bc.png)\r\n\r\n정리해보자면 RequestResponseBodyMethodProcessor에서 WebDataBinder를 만들고 validateIfApplicable 메서드를 이용해 @Valid가 있을 경우 validate를 해주는데 이때 유효성 검증 실패 즉, 검증에 위반되는 결과가 있을 경우 WebDataBinder에 error가 추가되고 이 binder의 결과를 MethodArgumentNotValidException로 감싸져서 예외가 던져지는 것이다.\r\n\r\n많이 복잡하다보니 정확하게 이해하지 못하거나 잘못된 내용이 있을 수도 있다..ㅜ.ㅜ\r\n더 궁금하다면 직접 파고 들어가보는 것도 좋을 것 같다..!!\r\n\r\n<br/>\r\n\r\n## 그렇다면 왜 @Valid는 Controller에서만 보일까?\r\n\r\n- 이는 validation에 대해 계속 찾아보다가 느낀 점 + 스택오버플로우의 글을 통해서 정리할 수가 있는데 위에서 적혀있듯이 @Valid라는 annotation은 @RequestBody나 @ModelAttribute와 같은 annotation이 리졸버를 이용해 DTO를 바인딩해줄 때 사용이 된다.\r\n- 그러다보니 단순하게 다른 계층에서 @Valid를 명시하게 되면 이를 보고 작동을 시켜줄 객체가 없는 것이다.\r\n- 그래서 만약 service에서 사용하고 싶다? 그러면 직접 aop를 이용해 동작시키던가(스택오버플로우 답변) 아니면 다른 예제를 보니 validator를 호출하여 직접 validate를 해야한다고 한다.\r\n- 근데 이 작업은 굳이..? 라는 생각이 드니 입력을 했을 때의 유효성 검증은 controller에서 validation을 이용해 처리해주고 중복 체크와 같은 유효성 검증은 service에서 처리해주면 좋지 않을까 싶다.\r\n\r\n\r\n<br/>\r\n\r\n##참고\r\n\r\n- [https://www.popit.kr/javabean-validation과-hibernate-validator-그리고-spring-boot/](https://www.popit.kr/javabean-validation%EA%B3%BC-hibernate-validator-%EA%B7%B8%EB%A6%AC%EA%B3%A0-spring-boot/)\r\n- [https://jcp.org/en/jsr/detail?id=303](https://jcp.org/en/jsr/detail?id=303)\r\n- [https://meetup.toast.com/posts/223](https://meetup.toast.com/posts/223)\r\n- [https://kapentaz.github.io/java/Java-Bean-Validation-제대로-알고-쓰자/#](https://kapentaz.github.io/java/Java-Bean-Validation-%EC%A0%9C%EB%8C%80%EB%A1%9C-%EC%95%8C%EA%B3%A0-%EC%93%B0%EC%9E%90/#)\r\n- [https://docs.jboss.org/hibernate/stable/validator/reference/en-US/html_single/](https://docs.jboss.org/hibernate/stable/validator/reference/en-US/html_single/)\r\n- [https://stackoverflow.com/questions/19425221/spring-validated-in-service-layer](https://stackoverflow.com/questions/19425221/spring-validated-in-service-layer)","excerpt":"Validation이란? Validation이란 유효성 검증을 의미한다. 대표적인 예로 String의 값이 null이 되면 안된다던가 Integer의 값이 0보다 커야한다던가 즉, 우테코에서 미션을 진행해오면서 보통 도메인에서 처리했었던 검증을 말한…","fields":{"slug":"/java-validation/"},"frontmatter":{"date":"Jun 10, 2021","title":"Java Validation 파헤치기","tags":["java","spring"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"## Servlet\r\n\r\n- 컨테이너는 서블릿을 실행하고 관리한다.\r\n- 컨테이너가 주는 혜택\r\n    - 통신(커뮤니케이션) 지원\r\n        - 컨테이너는 서블릿과 웹 서버가 서로 통신할 수 있는 손쉬운 방법을 제공.\r\n        - 서버와 대화하기 위해 개발자가 직접 ServcerSocket을 만들고, 특정 포트에 리스닝하고, 연결요청이 들어오면 스트림을 생성하는 등 이런 복잡한 일련의 일을 할 필요가 없다.\r\n        - 컨테이너는 어떻게 웹 서버와 통신해야 하는지 잘 알고 있으며, 이런 통신 기능을 API로 제공.\r\n        - 고로 개발자가 신경 쓸 부분은 서블릿이 구현해야할 비즈니스 로직에만 집중하면 됨.\r\n    - 생명주기(라이프사이클) 관리\r\n        - 컨테이너는 서블릿의 탄생과 죽음을 관리함.\r\n        - 서블릿 클래스를 로딩하여 인스턴스화하고, 초기화 메서드를 호출하고, 요청이 들어오면 적절한 서블릿 메서드를 호출하는 작업을 컨테이너가 함.\r\n        - 서블릿이 생명을 다한 순간에는 적절하게 가비지 컬렉션을 진행함.\r\n    - 멀티스레딩 지원\r\n        - 컨테이너는 요청이 들어올 때마다 새로운 자바 스레드를 하나 만듦.\r\n        - 클라이언트의 요청에 따라 적절한 HTTP 서비스 메서드를 실행하면 그걸로 스레딩 작업은 끝이 남.\r\n    - 선언적인 보안 관리\r\n        - 컨테이너를 사용하면, 보안에 관련된 내용을 서블릿 또는 자바 클래스 코드 안에 하드코딩할 필요가 없다.\r\n- 컨테이너는 서블릿 하나에 대한 다수의 요청을 처리하기 위하여 다수의 스레드를 실행하지 다수의 인스턴스를 만들지는 않는다.\r\n\r\n<br/>\r\n\r\n## Dispatcher Servlet\r\n\r\n- 기존의 Servlet 방식은 요청 url 당 Servlet을 생성하고 그에 맞는 Controller에게 요청을 보내주는 코드를 각각 다 따로 작성해야 했다.\r\n- 그러다보니 수많은 Servlet과 Controller를 만들어야하는 일이 발생했다.\r\n- Spring에서는 Front Controller 패턴을 취하는 Servlet을 미리 만들어 두었다. 그것이 바로 Dispatcher Servlet!\r\n    - 즉, 모든 요청을 한 곳에서 받아서 필요한 처리를 한 뒤, 요청에 맞는 handler로 요청을 dispatch하고, 해당 handler의 실행 결과를 http response 형태로 만드는 역할을 한다.\r\n- 참고로 Front Controller 패턴을 적용하면 하나의 Servlet에서 모든 요청을 받아들여 적절한 Controller로 요청을 위임해준다.\r\n\r\n![Untitled (47)](https://user-images.githubusercontent.com/62014888/145956098-0dcf31f3-3a70-435f-bfdd-90753e0de378.png)\r\n\r\n- 그림과 같이 dispatcher servlet은 servlet context와 root context가 존재하는데 여기서 말하는 WebApplicationContext는 ApplicationContext를 확장한 WebApplicationContext 인터페이스의 구현체를 말하며 ApplicationContext를 상속받아 사용한다.\r\n- Root WebApplicationContext\r\n    - ContextLoaderListner에 의해 생성되며, 자식 Context에서 Root Context를 참조할 수 있다.\r\n    - 여러 Servlet Context를 서로 공유해야 하는 빈들을 등록하고 설정할 때 사용한다.\r\n    - 주로 Service와 Repository 빈들이 등록됨.\r\n- Servlet WebApplicationContext\r\n    - DispatcherServlet에 의해 생성되며 Root Context에서는 상속 개념이기에 참조가 불가능하다.\r\n    - 해당 Servlet Context에서만 사용이 가능하며, 스프링 Dispatcher Servlet에서 관리하는 독립적인 웹 애플리케이션 형태로 사용한다.\r\n    - 주로 Controller, HandlerMapping 등이 등록됨.\r\n\r\n```xml\r\n<listener>\r\n  \t<listener-class>org.springframework.web.context.ContextLoaderListener</listener-class>\r\n  </listener>\r\n  <context-param>\r\n  \t <param-name>contextConfigLocation</param-name>\r\n  \t <param-value>\r\n  \t \t/WEB-INF/spring/root-context.xml\r\n  \t </param-value>\r\n  </context-param>\r\n  \r\n  <servlet>\r\n  \t<servlet-name>dispatcher</servlet-name>\r\n  \t<servlet-class>org.springframework.web.servlet.DispatcherServlet</servlet-class>\r\n  \t<init-param>\r\n  \t\t<param-name>contextConfigLocation</param-name>\r\n  \t\t<param-value>/WEB-INF/spring/appServlet/servlet-context.xml</param-value>\r\n  \t</init-param>\r\n  </servlet>\r\n  <servlet-mapping>\r\n  \t<servlet-name>dispatcher</servlet-name>\r\n  \t<url-pattern>*.htm</url-pattern>\r\n  </servlet-mapping>\r\n```\r\n\r\n- 예전 스프링 레거시를 보면 web.xml (Deployment Descriptor)에 context를 등록시켜둔다.\r\n- was 구동 시 /WEB-INF 디렉토리에 존재하는 web.xml을 읽어 웹 애플리케이션의 설정을 구성한다.\r\n- 그런데 우테코 미션을 진행하면서 이런 web.xml을 한 번도 본 적이 없다.\r\n- 그 이유는 뭘까?\r\n- 정답은 스프링 부트와 Servlet 3.0에 있다.\r\n- 우선, 스프링 부트는 servlet이 내장되어 있다. 또한 Servlet 3.0부터 자바 소스 설정으로도 context 설정이 가능하다.\r\n- 스프링 부트에서는 spring-boot-starter 모듈에 이미 모든 내장 컨테이너들의 설정을 지원한다. 부트는 서블릿 컨테이너의 라이프 사이클에 연결하는 대신 스프링 설정을 사용하여 부트 자체와 내장된 서블릿 컨테이너를 구동시킨다. 필터 및 서블릿 선언은 스프링 구성으로 서블릿 컨테이너에 등록한다.\r\n    - 즉, 간단하게 말하면 부트로 프로젝트를 만들때 생기는 application 클래스를 보면 @SpringBootApplication이 존재하는데 이 친구에 의해 빈 자동 등록이 된다고 생각하면 된다.\r\n- 그리고 요즘은 굳이 context를 2개로 나누어서 사용하지 않고 root context 하나를 만들어 모든 빈을 등록하여 사용한다고 한다.\r\n\r\n![Untitled (48)](https://user-images.githubusercontent.com/62014888/145955885-4fbe43ab-2859-4595-8f04-1d9c86af3041.png)\r\n\r\n### Dispatcher Servlet 동작 순서\r\n1. 클라이언트가 was에 접근하면 front controller 역할을 하는 dispatcher servlet이 요청을 가로챔.\r\n2. handler mapping 설정에서 해당 요청을 처리할 controller를 탐색\r\n3. form data 요청이다 그럼 ModelAttributeProcessor가 파라미터를 바인딩함.\r\n   그게 아닌 json 요청이다? RequestResponseBodyMethodProcessor가 MessageConverter을 이용하여 파라미터를 바인딩함. (즉 jackson 라이브러리 사용)\r\n4. 데이터 저장 및 응답 가공\r\n5. 요청을 처리한 뒤, html로 응답할 경우 결과를 출력할 view의 이름, data로 응답할 경우 MessageConverter을 이용하여 json 데이터로 반환,\r\n6. html로 응답한 경우 ViewResolver에서 받은 view 이름(string)으로부터 해당 view를 탐색\r\n7. 탐색한 view 객체를 반환\r\n8. 처리 결과가 포함된 view를 dispatcher servlet에 전달\r\n9. 클라이언트에게 최종 결과 출력\r\n\r\n## 궁금한 점\r\n- dispatcher servlet을 여러 개 둔다는게 무슨 말이지?\r\n- dispatcher servlet이 요청을 받아 적절한 처리를 하는 것 아닌가?\r\n- 요즘은 하나의 서블릿에 하나의 컨텍스트로 처리를 하는게 국룰이다라는 글을 보았고 토비 이일민님께서도 하나의 컨텍스트를 사용한다고 했다. 출력해보니 전부 AnnotationConfigServletWebServerApplicationContext 라는 곳에서 모든 빈이 등록되어 있던데 그럼 더이상 계층이 나누어진 컨텍스트는 공부할 필요없이 그냥 넘어가면 되는걸까? 아니면 레거시를 위해 공부하는 것이 좋을까?\r\n\r\n## 출처\r\n\r\n- [https://velog.io/@gokoy/Spring-동작-순서](https://velog.io/@gokoy/Spring-%EB%8F%99%EC%9E%91-%EC%88%9C%EC%84%9C)\r\n- [https://gompangs.tistory.com/entry/Dispatcher-Servlet](https://gompangs.tistory.com/entry/Dispatcher-Servlet)\r\n- [https://docs.spring.io/spring-framework/docs/3.0.0.RC2/spring-framework-reference/html/ch15s02.html](https://docs.spring.io/spring-framework/docs/3.0.0.RC2/spring-framework-reference/html/ch15s02.html)\r\n- [https://sabarada.tistory.com/16](https://sabarada.tistory.com/16)\r\n- [https://linked2ev.github.io/spring/2019/09/15/Spring-5-서블릿과-스프링에서-Context(컨텍스트)란/](https://linked2ev.github.io/spring/2019/09/15/Spring-5-%EC%84%9C%EB%B8%94%EB%A6%BF%EA%B3%BC-%EC%8A%A4%ED%94%84%EB%A7%81%EC%97%90%EC%84%9C-Context(%EC%BB%A8%ED%85%8D%EC%8A%A4%ED%8A%B8)%EB%9E%80/)\r\n- [https://jeong-pro.tistory.com/222](https://jeong-pro.tistory.com/222)\r\n- [https://github.com/binghe819/TIL/blob/master/Spring/MVC/DispatcherServlet.md](https://github.com/binghe819/TIL/blob/master/Spring/MVC/DispatcherServlet.md)\r\n- [https://docs.spring.io/spring-framework/docs/3.2.x/spring-framework-reference/html/mvc.html](https://docs.spring.io/spring-framework/docs/3.2.x/spring-framework-reference/html/mvc.html)","excerpt":"Servlet 컨테이너는 서블릿을 실행하고 관리한다. 컨테이너가 주는 혜택 통신(커뮤니케이션) 지원 컨테이너는 서블릿과 웹 서버가 서로 통신할 수 있는 손쉬운 방법을 제공. 서버와 대화하기 위해 개발자가 직접 ServcerSocket을 만들고, 특정…","fields":{"slug":"/servlet-dispatcherservlet/"},"frontmatter":{"date":"Jun 10, 2021","title":"Servlet, DispatcherServlet 살펴보기","tags":["java","spring"],"update":"Jan 01, 0001"}}}]}},"pageContext":{}},"staticQueryHashes":["2027115977","694178885"]}